Last login: Tue Oct  2 16:15:06 on ttys002
 siddharthnayak@Siddharths-MacBook-Air  ~   master ●  pip3 install pynput 
Collecting pynput
  Using cached https://files.pythonhosted.org/packages/80/b6/b3558caf276458b123217a1bf8772c75637e500591ece7c3295110dab19e/pynput-1.4-py2.py3-none-any.whl
Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from pynput) (1.11.0)
Requirement already satisfied: pyobjc-framework-Quartz>=3.0; sys_platform == "darwin" in /usr/local/lib/python3.6/site-packages (from pynput) (4.0.1)
Requirement already satisfied: pyobjc-framework-Cocoa>=4.0.1 in /usr/local/lib/python3.6/site-packages (from pyobjc-framework-Quartz>=3.0; sys_platform == "darwin"->pynput) (4.0.1)
Requirement already satisfied: pyobjc-core>=4.0.1 in /usr/local/lib/python3.6/site-packages (from pyobjc-framework-Quartz>=3.0; sys_platform == "darwin"->pynput) (4.0.1)
moviepy 0.2.3.2 has requirement decorator==4.0.11, but you'll have decorator 4.3.0 which is incompatible.
moviepy 0.2.3.2 has requirement tqdm==4.11.2, but you'll have tqdm 4.26.0 which is incompatible.
docker-py 1.10.3 has requirement requests<2.11,>=2.5.2, but you'll have requests 2.19.1 which is incompatible.
Installing collected packages: pynput
Successfully installed pynput-1.4
You are using pip version 10.0.1, however version 18.0 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
 siddharthnayak@Siddharths-MacBook-Air  ~   master ●  ipython
Python 3.6.5 (default, Apr 25 2018, 14:23:58) 
Type 'copyright', 'credits' or 'license' for more information
IPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.

In [1]: for i in range(10):
   ...:     print(i)
   ...:     
0
1
2
3
4
5
6
7
8
9

In [2]: for i in range(10):
   ...:     print('Enter')
   ...:     k=input()
   ...:     print(k)
   ...:     
   ...:     
Enter
s
s
Enter
d
d
Enter
^[


nter
^[


nter
d
d
Enter


Enter


Enter


Enter


Enter



In [3]: 

In [3]: 

In [3]: f=[]
   ...: for i in range(10):
   ...:     print('Enter')
   ...:     k=input()
   ...:     print(k)
   ...:     f.append(k)
   ...:     
Enter
d
d
Enter
f
f
Enter
e
e
Enter
^[


nter
1
1
Enter
2
2
Enter
3
3
Enter
4
4
Enter
5
5
Enter
6
6

In [4]: 

In [4]: f
Out[4]: ['d', 'f', 'e', '\x1b', '1', '2', '3', '4', '5', '6']

In [5]: f=[]
   ...: for i in range(10):
   ...:     print('Enter')
   ...:     k=input()
   ...:     if k=='\x1b':
   ...:         break
   ...:     print(k)
   ...:     f.append(k)
   ...:     
Enter
^[

In [6]: exit
 siddharthnayak@Siddharths-MacBook-Air  ~   master ●  cd Downloads/RL\ Project   
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project   master ●  ls
Code                            Reference Paper for project.pdf lower_brightness
Fredo Durand paper.pdf          higher brightness
Model1.py                       lec16-REINFORCE.pdf
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project   master ●  python3 Model1.py 
Traceback (most recent call last):
  File "Model1.py", line 30, in <module>
    img = Image.open('images_for_training/6.png')
  File "/usr/local/lib/python3.6/site-packages/PIL/Image.py", line 2530, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'images_for_training/6.png'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project   master ●  cd ..                   
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads   master ●  cd RL\ Project 
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project   master ●  cd Code       
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1.py
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-02 16:57:57.855162: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Session Number 0
images_for_training/212
(1, 64, 64, 3)
2018-10-02 16:57:58.179 Python[8879:13150321] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
^[Enter Reward: 0
Traceback (most recent call last):
  File "Model1.py", line 248, in <module>
    rewards = [generate_session() for _ in range(2)] #generate new sessions
  File "Model1.py", line 248, in <listcomp>
    rewards = [generate_session() for _ in range(2)] #generate new sessions
  File "Model1.py", line 220, in generate_session
    r=int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: '\x1b0'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1.py
Done Importing Stuff
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
Model Loaded
2018-10-02 16:59:50.970753: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Session Number 0
images_for_training/256
(1, 64, 64, 3)
2018-10-02 16:59:51.214 Python[8974:13151584] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Enter Reward: 0
images_for_training/89
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/273
(1, 64, 64, 3)
Enter Reward: 0
(3, 64, 64, 3)
images_for_training/276
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/264
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/281
(1, 64, 64, 3)
Enter Reward: 0
(3, 64, 64, 3)
mean reward:0.000
Session Number 1
images_for_training/214
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/252
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/134
(1, 64, 64, 3)
Enter Reward: 1
(3, 64, 64, 3)
images_for_training/136
(1, 64, 64, 3)
Enter Reward: 1
images_for_training/31
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/206
(1, 64, 64, 3)
Enter Reward: 0
(3, 64, 64, 3)
mean reward:1.000
Session Number 2
images_for_training/292
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/136
(1, 64, 64, 3)
Enter Reward: 1
images_for_training/101
(1, 64, 64, 3)
Enter Reward: 1
(3, 64, 64, 3)
images_for_training/26
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/237
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/154
(1, 64, 64, 3)
Enter Reward: 1
(3, 64, 64, 3)
mean reward:1.500
Session Number 3
images_for_training/48
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/3
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/26
(1, 64, 64, 3)
Enter Reward: 0
(3, 64, 64, 3)
images_for_training/267
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/119
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/161
(1, 64, 64, 3)
Enter Reward: 0
(3, 64, 64, 3)
mean reward:0.000
Session Number 4
images_for_training/283
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/280
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/270
(1, 64, 64, 3)
Enter Reward: 0
(3, 64, 64, 3)
images_for_training/81
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/9
(1, 64, 64, 3)
^CTraceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/matplotlib/backend_bases.py", line 1953, in motion_notify_event
    def motion_notify_event(self, x, y, guiEvent=None):
KeyboardInterrupt
Enter Reward: ^C^CTraceback (most recent call last):
  File "Model1.py", line 247, in <module>
    rewards = [generate_session() for _ in range(2)] #generate new sessions
  File "Model1.py", line 247, in <listcomp>
    rewards = [generate_session() for _ in range(2)] #generate new sessions
  File "Model1.py", line 222, in generate_session
    r=int(input("Enter Reward: "))
KeyboardInterrupt
^C





 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1_save.py 
Done Importing Stuff
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
Model Loaded
2018-10-02 17:16:09.827753: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Session Number 0
images_for_training/198
(1, 64, 64, 3)
2018-10-02 17:16:10.433 Python[9434:13161447] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Enter Reward: 0
images_for_training/87
(1, 64, 64, 3)
Enter Reward: 0
images_for_training/7
(1, 64, 64, 3)
Enter Reward: ^C^CTraceback (most recent call last):
  File "Model1_save.py", line 248, in <module>
    rewards = [generate_session() for _ in range(2)] #generate new sessions
  File "Model1_save.py", line 248, in <listcomp>
    rewards = [generate_session() for _ in range(2)] #generate new sessions
  File "Model1_save.py", line 223, in generate_session
    r=int(input("Enter Reward: "))
KeyboardInterrupt
^C
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●                              
                                                                                                                       
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       

 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 New.py        
Done Importing Stuff
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-02 17:21:21.169411: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1_saver.py 
  File "Model1_saver.py", line 152
    print('#'*50)1
                 ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1_saver.py
  File "Model1_saver.py", line 152
    print('#'*50)1
                 ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1_saver.py
  File "Model1_saver.py", line 152
    print('#'*50)1
                 ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  cd ..  
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project   master ●  cd Code
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  cd Code
cd: no such file or directory: Code
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1_saver.py
  File "Model1_saver.py", line 152
    print('#'*50)1
                 ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1_saver.py
Done Importing Stuff
##################################################
Traceback (most recent call last):
  File "Model1_saver.py", line 30, in <module>
    img = Image.open('images_for_training/6.png')
NameError: name 'Image' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model1_saver.py
Done Importing Stuff
##################################################
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
Model Loaded
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Model_v_2.py 
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-03 00:29:59.107200: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Session Number 0
images_for_training/255
(1, 64, 64, 3)
2018-10-03 00:29:59.378 Python[13796:13274596] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 1
images_for_training/11
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 2
images_for_training/89
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 3
images_for_training/176
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 4
images_for_training/54
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 5
images_for_training/217
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 6
images_for_training/224
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 7
images_for_training/272
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 8
images_for_training/243
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 9
images_for_training/50
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 10
images_for_training/3
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 11
images_for_training/130
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 12
images_for_training/91
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 13
images_for_training/148
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 14
images_for_training/196
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 15
images_for_training/151
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 16
images_for_training/115
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 17
images_for_training/201
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 18
images_for_training/174
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 19
images_for_training/240
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 20
images_for_training/133
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 21
images_for_training/177
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 22
images_for_training/158
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 23
images_for_training/76
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 24
images_for_training/291
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 25
images_for_training/39
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 26
images_for_training/163
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 27
images_for_training/266
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 28
images_for_training/227
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 29
images_for_training/98
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 30
images_for_training/235
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 31
images_for_training/175
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 32
images_for_training/15
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 33
images_for_training/85
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 34
images_for_training/161
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 35
images_for_training/235
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 36
images_for_training/27
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 37
images_for_training/278
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 38
images_for_training/195
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 39
images_for_training/88
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 40
images_for_training/35
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 41
images_for_training/281
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 42
images_for_training/230
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 43
images_for_training/47
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 44
images_for_training/15
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 45
images_for_training/153
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 46
images_for_training/282
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 47
images_for_training/210
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 48
images_for_training/294
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 49
images_for_training/13
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 50
images_for_training/45
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 51
images_for_training/197
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 52
images_for_training/96
(1, 64, 64, 3)
Enter Reward: -1
-1
Breaking
Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py   
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-03 00:56:58.432490: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/157
(1, 64, 64, 3)
2018-10-03 00:56:59.682 Python[14379:13286660] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 1
images_for_training/287
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 2
images_for_training/253
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 3
images_for_training/110
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 4
images_for_training/294
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 5
images_for_training/279
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 6
images_for_training/104
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 7
images_for_training/14
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 8
images_for_training/156
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 9
images_for_training/222
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 10
images_for_training/222
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 11
images_for_training/237
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 12
images_for_training/155
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 13
images_for_training/236
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 14
images_for_training/218
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 15
images_for_training/72
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 16
images_for_training/126
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 17
images_for_training/9
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 18
images_for_training/124
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 19
images_for_training/217
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 20
images_for_training/82
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 21
images_for_training/120
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 22
images_for_training/265
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 23
images_for_training/16
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 24
images_for_training/262
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 25
images_for_training/22
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 26
images_for_training/146
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 27
images_for_training/27
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping
Session Number 28
images_for_training/161
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 29
images_for_training/191
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping
Session Number 30
images_for_training/176
(1, 64, 64, 3)
Enter Reward: -1
-1
Breaking
Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-04 00:10:04.423073: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/75
(1, 64, 64, 3)
2018-10-04 00:10:05.699 Python[20053:13452037] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 1
images_for_training/264
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 2
images_for_training/61
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 3
images_for_training/135
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 4
images_for_training/150
(1, 64, 64, 3)
Enter Reward: 1
1
(64, 64, 3)
[[ 1.]]
Backpropping 

Session Number 5
images_for_training/77
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 6
images_for_training/53
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 7
images_for_training/96
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 8
images_for_training/193
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 9
images_for_training/281
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 10
images_for_training/280
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 11
images_for_training/189
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 12
images_for_training/135
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 13
images_for_training/31
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 14
images_for_training/171
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 15
images_for_training/257
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 16
images_for_training/3
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 17
images_for_training/21
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 18
images_for_training/264
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 19
images_for_training/243
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 20
images_for_training/277
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 21
images_for_training/46
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 22
images_for_training/183
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 23
images_for_training/174
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 24
images_for_training/275
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 25
images_for_training/208
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 26
images_for_training/256
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 27
images_for_training/235
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 28
images_for_training/161
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 29
images_for_training/79
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 30
images_for_training/169
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 31
images_for_training/128
(1, 64, 64, 3)
Enter Reward: 
Traceback (most recent call last):
  File "Loader.py", line 177, in <module>
    rewards,flag = generate_session()  #generate new sessions
  File "Loader.py", line 143, in generate_session
    r=int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: ''
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-04 00:12:39.832822: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/62
(1, 64, 64, 3)
2018-10-04 00:12:40.987 Python[20165:13453714] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 1
images_for_training/210
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 2
images_for_training/159
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 3
images_for_training/37
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 4
images_for_training/116
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 5
images_for_training/292
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 6
images_for_training/57
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 7
images_for_training/39
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 8
images_for_training/80
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 9
images_for_training/19
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 10
images_for_training/226
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 11
images_for_training/229
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 12
images_for_training/292
(1, 64, 64, 3)
Enter Reward: 
Traceback (most recent call last):
  File "Loader.py", line 177, in <module>
    rewards,flag = generate_session()  #generate new sessions
  File "Loader.py", line 143, in generate_session
    r=int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: ''
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-04 00:14:29.836451: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/243
(1, 64, 64, 3)
2018-10-04 00:14:31.126 Python[20257:13455125] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/115
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 2
images_for_training/274
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 3
images_for_training/210
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 4
images_for_training/226
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 5
images_for_training/158
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 6
images_for_training/295
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 7
images_for_training/237
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 8
images_for_training/51
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 9
images_for_training/170
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 10
images_for_training/194
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/180
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 12
images_for_training/139
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 13
images_for_training/92
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 14
images_for_training/147
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 15
images_for_training/85
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 16
images_for_training/176
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 17
images_for_training/184
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 18
images_for_training/246
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 19
images_for_training/292
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 20
images_for_training/125
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Saving Weights
##################################################
Session Number 21
images_for_training/233
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 22
images_for_training/12
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 23
images_for_training/231
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 24
images_for_training/176
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 25
images_for_training/124
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 26
images_for_training/64
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 27
images_for_training/92
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 28
images_for_training/148
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 29
images_for_training/286
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 30
images_for_training/61
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Saving Weights
##################################################
Session Number 31
images_for_training/219
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 32
images_for_training/36
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 33
images_for_training/256
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 34
images_for_training/51
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 35
images_for_training/138
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 36
images_for_training/3
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 37
images_for_training/224
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 38
images_for_training/104
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 39
images_for_training/213
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 40
images_for_training/41
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Saving Weights
##################################################
Session Number 41
images_for_training/275
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 42
images_for_training/231
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 43
images_for_training/175
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 44
images_for_training/217
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 45
images_for_training/241
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 46
images_for_training/48
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 47
images_for_training/221
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 48
images_for_training/265
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 49
images_for_training/149
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Session Number 50
images_for_training/48
(1, 64, 64, 3)
Enter Reward: 0
0
(64, 64, 3)
[[ 0.]]
Backpropping 

Saving Weights
##################################################
Session Number 51
images_for_training/123
(1, 64, 64, 3)
Enter Reward: -1
-1
Breaking 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-04 00:35:05.276348: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/109
(1, 64, 64, 3)
2018-10-04 00:35:06.361 Python[20711:13467867] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 26
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/145
(1, 64, 64, 3)
Action: 23
Enter Reward: 0
Backpropping 

Session Number 2
images_for_training/74
(1, 64, 64, 3)
Action: 19
Enter Reward: 0
Backpropping 

Session Number 3
images_for_training/275
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/16
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 5
images_for_training/207
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 6
images_for_training/16
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 7
images_for_training/76
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 8
images_for_training/61
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 9
images_for_training/176
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/220
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/53
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 12
images_for_training/66
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 13
images_for_training/150
(1, 64, 64, 3)
Action: 10
Enter Reward: 1
Backpropping 

Session Number 14
images_for_training/146
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 15
images_for_training/17
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 16
images_for_training/97
(1, 64, 64, 3)
Action: 10
Enter Reward: 0
Backpropping 

Session Number 17
images_for_training/239
(1, 64, 64, 3)
Action: 10
Enter Reward: -1
Breaking 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 18:11:50.384195: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/97
(1, 64, 64, 3)
2018-10-05 18:11:51.570 Python[32324:13815548] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 1.65
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/74
(1, 64, 64, 3)
Action: 1.8
Enter Reward: 0
Backpropping 

Session Number 2
images_for_training/5
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 3
images_for_training/239
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/4
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 5
images_for_training/259
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 6
images_for_training/255
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 7
images_for_training/43
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 8
images_for_training/60
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 9
images_for_training/154
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/230
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/162
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 12
images_for_training/70
(1, 64, 64, 3)
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 13
images_for_training/176
(1, 64, 64, 3)
Action: 0.05
Enter Reward: -1
Breaking 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 18:29:00.652843: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/285
(1, 64, 64, 3)
Policy eval: 
[[  1.65630882e-20   6.70341079e-36   2.59511268e-07   1.90711405e-11
    0.00000000e+00   6.02990917e-21   2.30898336e-17   4.22898106e-14
    4.25116605e-17   1.08254065e-11   5.62570311e-22   5.52558097e-18
    2.39083619e-17   1.79361465e-31   3.48383971e-24   8.47490334e-37
    0.00000000e+00   9.88961756e-01   1.43816106e-32   0.00000000e+00
    1.04416962e-22   2.37853729e-32   8.75106001e-16   1.10485910e-14
    1.06776217e-36   9.14556889e-15   8.98979724e-18   1.94951935e-26
    1.49337884e-28   2.21195791e-07   4.94379121e-11   8.58445316e-23
    1.52027545e-18   1.09456694e-02   9.13148730e-22   1.05112743e-22
    0.00000000e+00   9.18595233e-30   1.43138168e-22   3.54244086e-14
    9.20234306e-05]]
2018-10-05 18:29:01.752 Python[32713:13825079] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 1.65
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/131
(1, 64, 64, 3)
Policy eval: 
[[  3.14565440e-08   1.76978938e-05   5.98733396e-10   6.58404842e-09
    2.29874697e-08   3.07519268e-02   3.07068247e-02   1.00573316e-09
    1.75967205e-08   1.27893865e-01   5.35586514e-06   1.23661960e-06
    2.31149400e-07   7.43370620e-04   2.82240217e-04   3.15742197e-13
    5.76715431e-09   1.40247038e-02   3.50650964e-07   2.92230693e-12
    4.76096407e-09   3.69785425e-06   6.70041008e-13   7.20221578e-05
    1.47331869e-11   6.53453398e-08   5.61948603e-08   5.79804121e-11
    7.33776658e-04   6.36204099e-03   2.17792913e-01   8.42767314e-11
    5.79608383e-15   4.91037071e-01   1.75751103e-09   2.60898941e-11
    2.84598718e-06   1.45392409e-09   1.20292711e-07   3.68406181e-03
    7.58834481e-02]]
Action: 1.5
Enter Reward: 1
Backpropping 

Session Number 2
images_for_training/117
(1, 64, 64, 3)
Policy eval: 
[[  7.22275600e-02   3.03888018e-03   4.55002264e-05   9.23931412e-03
    5.53432292e-05   1.36841065e-03   1.46696647e-03   6.20828405e-06
    7.49293761e-03   2.32081133e-04   7.67453632e-04   6.22547232e-04
    1.40951030e-04   3.29997577e-02   9.54249699e-04   1.09900986e-06
    8.91492411e-04   3.80223355e-04   1.72305088e-02   8.68249510e-04
    1.66847208e-03   1.29815498e-02   4.06040999e-06   2.88495868e-01
    3.61009334e-05   2.20209570e-03   1.32753849e-01   1.99281629e-02
    5.00699095e-02   1.35684371e-04   6.94346651e-02   2.55307623e-05
    5.64999953e-02   1.43026179e-02   7.19219897e-05   3.42588792e-05
    1.92635208e-01   5.86504582e-03   4.95679233e-05   1.42146857e-03
    1.35422603e-03]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 3
images_for_training/77
(1, 64, 64, 3)
Policy eval: 
[[  9.88282044e-15   1.89407282e-10   6.49601979e-21   3.45269875e-08
    5.90041691e-06   3.60548393e-06   1.51024061e-12   4.00317201e-18
    1.17459308e-17   5.06485958e-06   4.52738862e-18   1.69810536e-13
    1.00937167e-20   1.50531273e-14   1.35677721e-12   4.86183910e-15
    2.06895677e-12   2.73702974e-16   2.52595687e-08   3.11418896e-19
    3.07046585e-16   9.97923480e-11   0.00000000e+00   2.25236410e-16
    4.85790785e-08   1.52684924e-22   2.37374875e-09   1.24042253e-26
    4.67744767e-12   9.99828100e-01   4.50239349e-05   5.50553402e-21
    4.47876438e-08   6.83714500e-12   4.99817470e-05   6.36290126e-19
    3.39337728e-20   2.55571363e-11   3.03177473e-18   8.02391790e-13
    6.21843064e-05]]
Action: 0.45
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/20
(1, 64, 64, 3)
Policy eval: 
[[  2.03043860e-14   9.86117661e-01   4.82660443e-16   1.62491307e-03
    1.46679535e-24   4.11922503e-13   3.21532312e-08   2.57671367e-16
    1.81187249e-24   7.71791674e-03   2.04315234e-06   1.60828950e-08
    8.81456999e-19   1.87135585e-10   1.26478472e-09   2.17886925e-30
    1.16924987e-14   1.17578619e-19   4.15468263e-03   7.00236548e-23
    8.62183078e-05   7.44279259e-06   1.47650972e-21   4.06212065e-13
    3.36734738e-05   1.26061881e-08   8.61436856e-05   2.45308709e-16
    1.27291185e-16   1.03303713e-10   6.98510763e-11   6.81558257e-19
    1.93825914e-15   1.51640208e-07   1.69196006e-04   1.53990034e-16
    9.74138881e-15   8.53597304e-13   5.39670678e-14   3.38150892e-19
    3.44410690e-16]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 5
images_for_training/116
(1, 64, 64, 3)
Policy eval: 
[[  2.24442580e-08   2.96230218e-03   1.92051264e-09   8.93311109e-03
    2.04003015e-07   6.14400562e-07   1.59323884e-06   7.48141937e-10
    1.60768217e-08   1.16887009e-02   3.75755772e-05   9.45378244e-01
    8.68713033e-13   8.33621505e-10   1.65638951e-07   1.13088445e-12
    3.90622117e-05   6.36115089e-08   2.13920735e-02   6.36305800e-11
    9.25698783e-03   8.47732554e-06   5.43514261e-11   8.32267574e-07
    1.47265437e-05   1.47499106e-08   3.27177275e-07   1.17932352e-04
    3.49582301e-08   2.13994667e-07   1.35060027e-05   7.06004233e-09
    2.29216512e-09   9.24332653e-06   6.90846103e-10   1.22276163e-06
    3.45371045e-05   1.05294304e-04   6.56619591e-07   2.23126472e-06
    2.15197318e-08]]
Action: 1.85
Enter Reward: 1
Backpropping 

Session Number 6
images_for_training/202
(1, 64, 64, 3)
Policy eval: 
[[  1.78947318e-21   9.99996066e-01   0.00000000e+00   1.58363252e-06
    0.00000000e+00   2.14794526e-36   2.43369050e-06   1.10937195e-30
    8.44898904e-18   7.92034407e-12   9.93728862e-13   1.91300231e-15
    4.52985257e-36   1.01330791e-33   1.26112087e-25   0.00000000e+00
    2.55790246e-12   7.43866848e-28   3.09649169e-19   0.00000000e+00
    8.39578129e-26   1.94237539e-34   0.00000000e+00   1.97018609e-21
    1.60425530e-23   7.99894358e-26   6.27650909e-09   1.05628343e-29
    2.63989967e-23   2.54714073e-21   2.52074734e-25   1.24786887e-34
    4.11922926e-12   3.25912115e-22   3.89612092e-30   8.29997083e-24
    5.80467774e-28   9.05540494e-14   6.63573675e-14   1.42335537e-20
    1.65685269e-17]]
Action: 0.15
Enter Reward: 0
Backpropping 

Session Number 7
images_for_training/144
(1, 64, 64, 3)
Policy eval: 
[[  4.18924362e-09   9.93307829e-01   1.49075660e-07   2.17419118e-03
    1.11907452e-08   1.63773976e-07   1.46274160e-05   1.36985290e-09
    1.03824209e-06   3.76580516e-03   3.02509405e-04   4.32888100e-06
    3.20997309e-08   9.54668593e-08   1.25371997e-08   3.67132670e-12
    8.59627050e-07   3.01056425e-05   5.80806329e-07   3.69173442e-11
    8.92521044e-08   3.43648687e-09   1.48735344e-08   7.78006068e-08
    4.05538202e-07   2.25910318e-10   4.25196004e-06   6.07314348e-07
    1.31438937e-05   3.72596623e-05   4.23989917e-07   5.63274566e-11
    3.09250259e-04   3.41830697e-09   2.20888747e-08   3.60143162e-07
    1.75935565e-05   4.45262185e-06   1.10762551e-06   2.44035037e-09
    8.56637962e-06]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 8
images_for_training/58
(1, 64, 64, 3)
Policy eval: 
[[  3.91999761e-21   9.99921322e-01   3.82398525e-18   7.74000873e-05
    6.59536731e-11   4.05509437e-12   7.49240218e-25   4.06806365e-19
    6.03441787e-22   4.35649503e-11   5.97812476e-14   1.25229724e-06
    6.15275842e-21   4.81284493e-19   1.93957992e-11   6.22512697e-26
    6.38470830e-12   3.60612694e-26   4.93582885e-23   2.39877066e-21
    1.41039820e-14   5.53723114e-25   1.61702444e-24   3.99809841e-17
    1.78876844e-11   3.90780336e-19   2.44170489e-10   1.60213603e-15
    1.39028905e-14   7.85179227e-17   1.99120279e-27   1.56135808e-19
    2.24119967e-09   2.87514229e-19   3.06930452e-13   8.81859452e-22
    3.07190322e-14   1.35062872e-09   8.50889548e-20   2.42825000e-14
    4.07078635e-16]]
Action: 0.15
Enter Reward: 0
Backpropping 

Session Number 9
images_for_training/56
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   1.00000000e+00   0.00000000e+00   3.92325020e-30
    0.00000000e+00   0.00000000e+00   3.04745590e-38   4.80140072e-32
    0.00000000e+00   4.55207322e-38   1.51955891e-35   0.00000000e+00
    0.00000000e+00   0.00000000e+00   5.94753921e-31   0.00000000e+00
    2.71291033e-34   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.01900903e-35   0.00000000e+00   0.00000000e+00   4.06975694e-38
    3.89270243e-16   0.00000000e+00   9.99348919e-14   1.08949133e-33
    0.00000000e+00   7.76015702e-32   0.00000000e+00   0.00000000e+00
    3.24768334e-27   9.74783451e-32   0.00000000e+00   0.00000000e+00
    0.00000000e+00   9.18222836e-30   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/41
(1, 64, 64, 3)
Policy eval: 
[[  1.64795217e-12   2.07948251e-05   3.64977100e-17   4.99396802e-13
    3.52765034e-20   1.10799742e-21   2.49807758e-10   8.11600461e-13
    1.18969432e-10   6.40192609e-19   9.44885969e-01   5.18008433e-13
    5.48672172e-22   1.08838827e-28   7.80632393e-16   5.38963260e-24
    4.57396436e-13   7.03685939e-18   2.22272273e-28   2.56928227e-28
    8.06534837e-04   5.45978991e-29   3.17940404e-26   7.72336761e-21
    1.95833679e-15   1.52162937e-19   5.67107342e-13   1.00694969e-02
    2.04216093e-13   1.96739514e-09   6.38375288e-28   5.10250179e-27
    9.17657429e-17   2.64961848e-08   1.60209334e-18   8.33711988e-10
    3.94753132e-14   4.42171879e-02   3.93498712e-28   2.74115342e-10
    1.24684418e-09]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/284
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   4.19770186e-06   0.00000000e+00   9.99916553e-01
    0.00000000e+00   6.64490010e-36   7.92120773e-05   0.00000000e+00
    0.00000000e+00   3.02479551e-28   0.00000000e+00   9.12511321e-21
    3.37927773e-25   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.27612905e-24   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   7.37568066e-38
    6.17165850e-34   0.00000000e+00   8.79715392e-36   0.00000000e+00
    0.00000000e+00   8.67074786e-29   0.00000000e+00   0.00000000e+00
    4.08014578e-29   1.14009390e-32   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.10043989e-25
    4.52972767e-24]]
Action: 0.15
Enter Reward: 0
Backpropping 

Session Number 12
images_for_training/28
(1, 64, 64, 3)
Policy eval: 
[[  2.79899969e-31   1.00000000e+00   2.02830946e-38   7.77105255e-11
    2.41102990e-31   1.09665352e-28   2.91498116e-28   6.49253325e-27
    1.16998010e-29   2.75079979e-20   3.26264870e-18   6.02456166e-23
    3.64659911e-33   0.00000000e+00   7.68091556e-29   0.00000000e+00
    7.23339413e-26   0.00000000e+00   0.00000000e+00   0.00000000e+00
    9.04903496e-18   2.60043256e-36   0.00000000e+00   2.96235035e-23
    1.03253272e-19   0.00000000e+00   7.05106682e-14   1.32667483e-32
    3.39342465e-23   1.28648496e-25   0.00000000e+00   1.56157982e-22
    4.01269782e-18   7.39226982e-30   8.93020777e-19   4.48072273e-34
    3.81857600e-31   4.06008305e-22   1.29932827e-32   6.85950501e-32
    7.90394687e-33]]
Action: 0.6
Enter Reward: 0
Backpropping 

Session Number 13
images_for_training/231
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   6.16808074e-06   7.08689969e-33   9.99993801e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.19754035e-28   1.50099439e-18   2.47348300e-27
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   7.87708286e-32
    0.00000000e+00   0.00000000e+00   1.39006390e-10   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    2.21971361e-26   1.60963466e-37   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    9.79690995e-09]]
Action: 0.15
Enter Reward: 0
Backpropping 

Session Number 14
images_for_training/154
(1, 64, 64, 3)
Policy eval: 
[[  1.65220729e-06   3.18055786e-03   1.10021944e-07   8.76192212e-01
    2.84191515e-06   2.86205295e-06   1.24588732e-05   8.27663462e-06
    2.14860847e-05   1.48824995e-06   2.19302910e-06   8.99035707e-02
    3.02941498e-06   2.69920601e-08   2.19598332e-05   5.76116532e-09
    1.16128191e-04   1.59369870e-06   9.41633687e-07   5.99795857e-09
    6.37646066e-04   8.45180984e-05   3.98157624e-07   2.64042901e-04
    2.41432426e-05   1.21372932e-06   2.18326004e-05   4.55705740e-05
    1.47036217e-05   1.67814107e-03   3.65398378e-08   1.33182458e-03
    8.05196236e-04   9.70605288e-06   2.41769180e-02   1.08921481e-03
    1.63860415e-04   3.06095208e-05   3.91901409e-07   1.40154312e-04
    6.42920577e-06]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 15
images_for_training/160
(1, 64, 64, 3)
Policy eval: 
[[  6.52920289e-06   3.62547277e-03   3.29388081e-06   3.19196358e-02
    2.42177393e-05   1.19417913e-04   7.27647915e-03   1.40801912e-05
    6.24398468e-04   8.62876623e-05   8.81631568e-04   2.48430651e-02
    2.11327715e-04   6.74080977e-04   3.00944154e-03   4.30993350e-06
    4.57690521e-06   1.96555466e-03   3.06331742e-08   2.37532980e-08
    8.63076746e-01   3.47719379e-06   7.39414006e-08   4.67410253e-08
    2.85824132e-03   5.25946682e-03   1.03489219e-04   2.43355371e-05
    1.22462188e-06   1.48151012e-04   1.72381451e-08   6.73122804e-06
    4.25481312e-02   9.58437857e-04   1.36865932e-03   5.65198809e-03
    9.63521888e-04   1.32269715e-03   4.71110333e-08   2.13338077e-04
    1.97390706e-04]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 16
images_for_training/229
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   1.00000000e+00   0.00000000e+00   8.46977373e-25
    0.00000000e+00   0.00000000e+00   2.27909817e-38   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   8.68064581e-35
    6.07305932e-32   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.65184880e-24   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.84183491e-25   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   8.69513946e-25   0.00000000e+00   6.29042220e-21
    9.67251226e-28   7.46035358e-20   6.31464370e-25   0.00000000e+00
    0.00000000e+00   0.00000000e+00   3.32079507e-35   0.00000000e+00
    3.79795965e-32]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 17
images_for_training/185
(1, 64, 64, 3)
Policy eval: 
[[  1.18865308e-11   9.99702156e-01   2.82373621e-11   7.82221996e-11
    9.18980387e-13   2.10540463e-07   2.36848336e-06   2.43064180e-10
    4.57061082e-12   7.78316167e-09   4.08464189e-07   2.47349186e-09
    1.29670316e-10   1.84383879e-07   6.86851154e-09   5.50425150e-14
    5.98573586e-14   2.64887445e-10   4.88621416e-15   2.32676020e-14
    1.09101202e-05   3.18335522e-15   9.69408942e-19   7.24946535e-12
    1.27280102e-04   3.87627777e-11   1.44639926e-04   2.45137840e-14
    1.40563349e-15   1.59700278e-06   3.24835865e-15   4.88752139e-14
    1.15637846e-07   9.73081387e-06   4.17353618e-08   1.11801739e-07
    4.01872002e-09   1.69976460e-07   4.60910331e-16   7.98759062e-13
    3.00534875e-10]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 18
images_for_training/28
(1, 64, 64, 3)
Policy eval: 
[[  1.26764209e-24   9.99999642e-01   1.97802727e-26   1.35245310e-14
    1.08328867e-30   4.14916408e-33   8.79799922e-33   6.98267261e-22
    8.12671071e-17   2.88992018e-31   3.53743189e-07   1.56028466e-14
    3.05743887e-20   7.81683448e-34   4.04372195e-25   0.00000000e+00
    1.57579769e-29   2.38601901e-27   0.00000000e+00   3.09711220e-37
    2.03205969e-13   1.88769837e-34   0.00000000e+00   2.62492450e-17
    3.49960836e-22   0.00000000e+00   1.53832795e-19   7.10205052e-31
    1.69854418e-26   1.20884688e-14   0.00000000e+00   2.30159419e-16
    4.02759159e-31   1.61541143e-14   1.07031843e-27   3.26256462e-23
    9.44102318e-28   4.72650077e-13   8.44647755e-17   6.09380386e-32
    6.03038156e-29]]
Action: 0.05
0
Enter Reward: Backpropping 

Session Number 19
images_for_training/236
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   9.31546437e-11   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.14367348e-17   0.00000000e+00   0.00000000e+00
    0.00000000e+00   7.51449887e-14   2.26782699e-12   1.23180417e-31
    0.00000000e+00   0.00000000e+00   1.48761999e-24   0.00000000e+00
    0.00000000e+00   1.34969563e-33   0.00000000e+00   0.00000000e+00
    4.17763527e-28   0.00000000e+00   0.00000000e+00   3.83485195e-38
    1.38324614e-13   0.00000000e+00   3.47052373e-05   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.30646252e-28   9.99965310e-01   0.00000000e+00   0.00000000e+00
    0.00000000e+00   6.04044538e-13   8.83235274e-36   0.00000000e+00
    6.35543737e-24]]
Action: 0.55
Enter Reward: 1
Backpropping 

Session Number 20
images_for_training/152
(1, 64, 64, 3)
Policy eval: 
[[  1.73904630e-06   1.89659540e-02   3.79569030e-07   3.90650472e-04
    5.54896451e-06   4.94899868e-05   1.36886420e-05   1.20707580e-06
    4.10357006e-06   1.82384727e-04   8.49265234e-07   4.96955090e-06
    6.57835408e-05   4.02050027e-05   3.80802376e-04   4.53240423e-09
    7.45913712e-05   1.55457155e-06   2.67641603e-10   2.94526115e-09
    3.28550637e-02   1.16240324e-06   1.37555900e-09   5.79866999e-09
    1.46953404e-01   4.81620827e-06   1.77252106e-02   4.93988409e-07
    1.67860778e-03   1.63472709e-04   2.91625751e-11   3.53703797e-07
    1.93402246e-02   1.70042840e-05   7.43521094e-01   6.17164071e-04
    6.15661824e-03   3.51561130e-06   2.15247013e-07   5.92992137e-06
    1.07717682e-02]]
Action: 1.3
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 21
images_for_training/249
(1, 64, 64, 3)
Policy eval: 
[[  5.21663962e-12   5.15896602e-07   5.95235690e-07   2.65047151e-11
    2.31139307e-27   2.72259390e-19   2.53384809e-19   2.99059333e-09
    3.39770442e-28   1.92083266e-17   5.02118525e-24   7.75609296e-05
    4.44443026e-34   7.94134152e-16   2.15115303e-09   0.00000000e+00
    3.88135746e-10   4.44377836e-15   1.71962782e-28   0.00000000e+00
    2.91789010e-10   7.16141277e-17   9.93930090e-13   5.67999119e-16
    5.88267546e-10   8.61929164e-31   4.40334076e-14   5.71232071e-17
    3.78427954e-32   1.20237032e-02   0.00000000e+00   1.61913391e-31
    4.82492466e-16   9.87897575e-01   2.08922516e-16   1.59323891e-19
    2.24841909e-10   1.71548905e-18   9.01244710e-19   1.40830286e-21
    5.47760351e-13]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 22
images_for_training/292
(1, 64, 64, 3)
Policy eval: 
[[  9.12479372e-22   3.07449000e-07   3.25538029e-16   9.62764157e-13
    2.27340743e-19   2.52661177e-17   5.19918275e-10   1.81347976e-19
    2.31392937e-16   1.22944634e-12   3.84358246e-16   2.36235360e-06
    1.64832126e-09   2.99835188e-19   9.99969840e-01   8.86718016e-25
    4.51419957e-10   8.25277401e-13   7.45895433e-37   5.96238571e-20
    5.75530724e-15   4.89756811e-28   1.32577743e-28   5.71455055e-15
    7.84002374e-09   8.27398535e-25   1.40873663e-12   2.40722542e-24
    3.33113240e-15   1.22348132e-08   6.93547102e-24   7.21379404e-14
    2.12509413e-13   2.74741324e-05   5.19489639e-19   1.07025090e-10
    9.99109080e-29   5.62068621e-12   4.73102968e-14   1.09248986e-15
    1.96405586e-10]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 23
images_for_training/80
(1, 64, 64, 3)
Policy eval: 
[[  8.18558362e-07   6.27609086e-04   1.91309693e-14   2.44135645e-09
    9.65315472e-09   1.01517263e-17   2.03498003e-05   5.38534323e-07
    1.80060751e-12   1.92450182e-13   8.67246726e-12   3.21493349e-06
    1.84710382e-06   8.95148885e-18   1.84773530e-09   1.91468489e-18
    2.04418325e-06   1.39726100e-15   1.07628053e-25   2.28410931e-16
    5.00974304e-04   1.39514696e-22   1.14519032e-28   2.74126888e-10
    1.66988229e-05   9.96329455e-22   4.50853105e-11   5.67894778e-04
    2.02015890e-18   1.84010744e-01   1.30481254e-22   4.29026636e-09
    2.16897752e-06   8.08746696e-01   3.70776937e-10   3.26697851e-08
    1.11635774e-17   5.49824722e-03   2.92972401e-23   1.89041796e-08
    7.10099357e-08]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 24
images_for_training/194
(1, 64, 64, 3)
Policy eval: 
[[  7.37437420e-03   1.90938246e-02   1.97026902e-03   4.84363735e-02
    7.70073431e-03   1.58879126e-03   9.13305394e-03   2.04291828e-02
    1.30972068e-03   6.55790791e-03   7.92495627e-03   2.82317679e-02
    5.08508645e-02   1.46861700e-03   1.18888263e-02   2.69615033e-04
    3.67076532e-03   3.32851931e-02   7.93819709e-05   1.91274507e-04
    4.70569264e-03   5.37492917e-04   6.07028836e-04   1.47666717e-02
    1.81773696e-02   8.14105617e-04   2.87494226e-03   1.26762986e-02
    4.99941921e-03   2.98810452e-02   4.44850193e-05   1.85488574e-02
    2.53897220e-01   8.16360563e-02   1.92676008e-01   1.19195161e-02
    1.53823392e-02   1.98998097e-02   1.11361884e-03   3.56329307e-02
    1.77535824e-02]]
Action: 1.85
Enter Reward: 0
Backpropping 

Session Number 25
images_for_training/29
(1, 64, 64, 3)
Policy eval: 
[[  1.73956977e-11   7.53939748e-01   3.11620424e-10   2.73995236e-13
    1.29970190e-09   1.45559356e-10   3.29824019e-04   1.07036518e-04
    3.26777581e-12   1.81760527e-08   4.74441708e-10   9.63537332e-06
    8.71399948e-07   4.71416864e-15   8.98726098e-03   3.68943155e-19
    9.72967570e-14   2.20689023e-09   1.35891283e-20   4.50676908e-18
    7.66388109e-09   5.27018140e-15   1.44436245e-14   4.70117456e-08
    3.83507810e-04   6.21875200e-15   1.29915046e-11   4.77428930e-11
    1.63900694e-07   9.48936020e-07   2.39600038e-20   7.01366116e-06
    9.50973936e-06   2.36097410e-01   1.93008248e-07   2.14926076e-05
    1.54215768e-12   1.05279840e-04   3.23893972e-12   5.00904420e-08
    1.70797456e-11]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 26
images_for_training/245
(1, 64, 64, 3)
Policy eval: 
[[  2.00953579e-13   1.61661137e-06   1.16530841e-09   1.61043695e-22
    3.22543441e-20   5.49459321e-25   1.27818511e-08   2.17446816e-09
    8.25124000e-14   3.00147500e-19   2.58003288e-14   2.96352887e-10
    1.17632508e-08   7.10099642e-16   2.18060570e-10   1.55221482e-21
    5.13379512e-15   1.48937154e-10   1.43726152e-30   1.16535815e-19
    5.26577833e-06   1.50032251e-18   1.61695518e-23   1.90789658e-12
    8.60106375e-04   5.13826381e-22   1.29661694e-14   3.18209208e-16
    2.49896288e-20   2.23804318e-06   5.02651353e-31   3.26086059e-16
    7.79765575e-12   9.99130666e-01   2.55717553e-16   4.95043747e-15
    8.47310933e-16   4.18651121e-11   1.60752200e-14   5.93156135e-10
    4.52550671e-11]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 27
images_for_training/240
(1, 64, 64, 3)
Policy eval: 
[[  6.93630220e-09   5.87204297e-04   2.30289095e-12   1.50774895e-08
    5.11565125e-16   3.17068710e-18   1.94772106e-12   1.08873996e-06
    2.35444404e-07   4.91890582e-08   2.00862038e-09   1.83044621e-10
    3.73732642e-16   2.08619426e-20   6.17345177e-06   2.65908743e-20
    1.38299691e-12   2.03150483e-11   1.92471738e-27   1.66332168e-21
    3.60101163e-02   1.55991785e-16   3.81113047e-21   1.83984598e-12
    9.63368714e-01   2.43712639e-15   2.62145164e-07   2.54396155e-17
    1.04865580e-21   8.79542866e-16   3.65437853e-21   4.68044830e-12
    2.50074627e-05   1.07920383e-11   1.56920399e-09   4.64037953e-07
    3.00005127e-07   4.63993806e-14   4.16863877e-15   3.75093322e-07
    1.08931408e-12]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 28
images_for_training/182
(1, 64, 64, 3)
Policy eval: 
[[  3.82819650e-04   2.38963477e-02   2.06691373e-04   1.32078456e-03
    1.06904504e-03   4.57230164e-03   7.18371123e-02   3.37840244e-02
    8.87154834e-04   1.28424224e-02   2.02280826e-05   1.76221319e-02
    4.31449339e-03   4.57179779e-03   4.12757770e-04   3.14019300e-04
    4.99556027e-03   2.87932297e-03   3.97646181e-06   1.02863880e-03
    1.79900799e-03   1.09110668e-03   2.80346230e-05   4.39115713e-04
    1.02615260e-01   4.52621578e-04   7.12400116e-03   3.25618219e-03
    4.76898858e-04   6.67357817e-03   6.76806783e-04   1.94105264e-02
    9.42549843e-04   5.80275774e-01   3.75768654e-02   2.18860153e-02
    1.03252498e-03   1.20275514e-02   6.37521269e-04   1.19030708e-02
    2.71334266e-03]]
Action: 1.0
Enter Reward: 0
Backpropping 

Session Number 29
images_for_training/243
(1, 64, 64, 3)
Policy eval: 
[[  1.42619033e-11   2.35904459e-04   1.87510396e-10   1.36828769e-11
    5.34628635e-12   1.88402395e-17   4.79304344e-06   7.17708434e-04
    1.44293293e-11   1.41138487e-04   9.77792706e-16   1.68327085e-06
    8.01872624e-10   1.03284060e-13   1.91226057e-08   7.87179903e-20
    6.70873246e-10   1.01899121e-12   8.52895142e-30   1.01157226e-20
    1.90010905e-05   1.58219359e-15   7.44731950e-22   8.23928622e-06
    2.03634351e-01   5.32474093e-20   3.45861686e-08   1.63543099e-08
    8.00130906e-10   4.52308683e-04   2.68023223e-24   5.92096150e-08
    9.91661753e-11   7.94770002e-01   1.87497973e-09   1.79905399e-07
    1.43402867e-05   6.98309464e-08   5.22935688e-12   3.40183576e-11
    1.26512390e-07]]
Action: 1.6
Enter Reward: 0
Backpropping 

Session Number 30
images_for_training/162
(1, 64, 64, 3)
Policy eval: 
[[ 0.01500455  0.01742659  0.01393108  0.00356598  0.00447518  0.00103587
   0.00787069  0.09579533  0.01550477  0.03338631  0.00460712  0.03081284
   0.03656769  0.00759446  0.0107998   0.0023637   0.05203362  0.00930525
   0.00029505  0.00539019  0.14459437  0.00732974  0.00176573  0.03380622
   0.06008805  0.00575343  0.02466534  0.02239854  0.00841702  0.02148904
   0.00064669  0.07444379  0.04304842  0.05741059  0.03194934  0.00928405
   0.01110667  0.03587583  0.00382103  0.01190324  0.02243678]]
Action: 0.45
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 31
images_for_training/43
(1, 64, 64, 3)
Policy eval: 
[[  1.92722018e-06   8.69942824e-07   4.26723909e-06   2.46294819e-13
    1.28165759e-11   7.43212712e-15   1.00920431e-06   1.22655867e-04
    2.98687697e-09   1.36411108e-12   4.12903659e-14   1.32037178e-06
    8.39983085e-13   8.01436144e-08   4.71621231e-09   2.12845173e-18
    3.49074973e-08   2.29278976e-06   9.72003136e-20   4.87873995e-15
    1.71043366e-01   1.35776958e-12   3.01858349e-16   3.12834032e-07
    1.30188704e-01   1.92855323e-17   4.20476262e-13   1.90314813e-11
    1.60687985e-09   7.84374215e-03   4.00373628e-16   3.91474850e-06
    2.96297316e-08   6.79389954e-01   4.07118932e-07   1.13788228e-02
    2.51024375e-08   7.32114103e-09   1.84392002e-10   4.27274891e-08
    1.61738699e-05]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 32
images_for_training/132
(1, 64, 64, 3)
Policy eval: 
[[  2.03633937e-03   3.50660741e-01   2.25935737e-03   2.70865479e-04
    2.40435445e-04   7.56959897e-04   1.64958909e-02   9.14719999e-02
    1.38923181e-02   2.27994714e-02   3.67169239e-04   7.47589441e-03
    7.02677816e-02   7.24558113e-03   9.10992210e-04   1.05873994e-06
    1.21198151e-04   5.35623869e-03   6.01870170e-06   1.56193510e-05
    2.17873300e-03   6.03742228e-05   9.52132468e-05   3.28866276e-03
    7.90384365e-04   1.53960660e-04   3.13536264e-03   4.43328208e-05
    2.20994395e-03   1.37474937e-02   4.35137372e-06   2.39172392e-02
    7.15106865e-03   3.11044842e-01   9.02813487e-03   1.66775391e-03
    7.25646169e-05   3.93012492e-03   4.54191722e-05   2.28763111e-02
    1.90571405e-03]]
Action: 1.45
Enter Reward: 1
Backpropping 

Session Number 33
images_for_training/135
(1, 64, 64, 3)
Policy eval: 
[[ 0.04723057  0.20198005  0.00872591  0.02934338  0.00079897  0.00499934
   0.04789871  0.08423018  0.003053    0.01655394  0.01157142  0.01316333
   0.01546121  0.02151126  0.01329375  0.00054666  0.00266309  0.04051236
   0.00108962  0.00126831  0.02892004  0.00837362  0.00249217  0.03256143
   0.08327203  0.00448102  0.02235443  0.00488296  0.00519325  0.01709835
   0.00066599  0.03043453  0.03154969  0.07028124  0.01395524  0.01078228
   0.01851185  0.01076291  0.01275009  0.00677547  0.01800644]]
Action: 1.55
Enter Reward: 1
Backpropping 

Session Number 34
images_for_training/270
(1, 64, 64, 3)
Policy eval: 
[[  1.03660283e-11   6.34172892e-08   1.08981886e-10   6.68249283e-19
    6.96428795e-14   8.96978139e-16   9.99282062e-01   1.60542001e-12
    3.92745992e-12   3.06226805e-13   1.56296407e-18   3.60870443e-04
    3.33198258e-13   1.13153402e-11   6.19383600e-10   1.37393369e-14
    1.56265289e-12   7.14635436e-13   2.13730918e-29   8.98639950e-22
    9.46305875e-07   5.56584130e-13   7.50543170e-24   1.43924748e-13
    1.91371819e-05   1.23729409e-13   7.89677382e-16   6.60123066e-14
    7.59367367e-16   1.10714846e-05   7.80096762e-15   7.82820694e-13
    6.92890035e-06   5.09700330e-05   3.24815695e-12   2.67958821e-04
    8.60538463e-12   3.73868980e-09   7.71445269e-11   9.07627395e-09
    1.80922465e-11]]
Action: 1.2
Enter Reward: 0
Backpropping 

Session Number 35
images_for_training/287
(1, 64, 64, 3)
Policy eval: 
[[  2.65878679e-08   9.99999285e-01   3.94535010e-17   7.41759881e-16
    9.00273894e-21   4.06162801e-15   8.33483116e-10   4.20730117e-09
    3.40249683e-15   4.48491791e-15   6.60312462e-13   4.39169828e-16
    1.93027357e-13   1.35773994e-19   4.94839697e-14   7.58627373e-21
    2.66235144e-14   3.54532292e-09   1.11869643e-20   4.12184867e-21
    6.36977347e-07   2.39353717e-21   1.90389421e-22   1.21477806e-13
    1.58133145e-10   2.67602799e-20   4.61159677e-17   6.20097405e-15
    1.07585487e-15   1.06411777e-08   1.32289170e-20   1.92854198e-15
    8.86069607e-10   1.39675625e-13   7.84157607e-15   3.25153628e-08
    1.06803129e-17   2.93177375e-13   1.15289167e-13   1.26067559e-13
    3.74985280e-13]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 36
images_for_training/238
(1, 64, 64, 3)
Policy eval: 
[[  1.42199891e-13   5.01399934e-01   5.84280313e-09   2.96704974e-16
    1.10249722e-16   5.61711779e-08   6.11440919e-04   1.09830512e-06
    1.48905112e-21   4.97425914e-01   7.81460191e-23   4.18450545e-05
    5.50308288e-09   5.84500365e-11   1.35686226e-10   1.49775370e-24
    6.87083989e-15   8.59159172e-07   1.53261497e-19   5.85737107e-14
    2.97279598e-07   3.75193854e-13   6.02336069e-22   1.91216956e-13
    1.18053651e-06   2.77826198e-16   3.59588128e-04   6.40295551e-16
    1.66623250e-15   4.24859540e-12   1.73100774e-24   1.57685601e-04
    2.12209788e-08   7.85910146e-08   2.28123943e-11   2.41669965e-11
    4.88891427e-10   3.99884792e-10   2.48022297e-11   3.47104040e-10
    5.94582299e-14]]
Action: 0.85
Enter Reward: 1
Backpropping 

Session Number 37
images_for_training/3
(1, 64, 64, 3)
Policy eval: 
[[  1.84758369e-06   6.65804207e-01   3.10690557e-10   1.63911932e-06
    7.98200173e-09   1.93689249e-11   1.65795223e-04   3.27670753e-01
    3.82807917e-11   2.62046806e-09   3.06178444e-10   3.78547003e-03
    1.82073134e-09   1.74927428e-09   6.47741719e-04   2.84472255e-14
    1.18738823e-08   2.58389832e-06   2.50165895e-14   9.06286435e-11
    2.55878811e-04   1.94025809e-10   4.10109311e-13   3.80925911e-07
    1.01598515e-03   2.63744647e-13   5.95798966e-10   5.10149256e-08
    3.62053214e-07   1.03872866e-08   1.47689706e-12   1.00200326e-04
    2.03026829e-07   5.44061942e-04   3.15359378e-10   1.44938588e-06
    4.34745823e-10   8.84123097e-07   4.49687398e-09   2.44260320e-07
    2.01363491e-07]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 38
images_for_training/76
(1, 64, 64, 3)
Policy eval: 
[[  7.93181389e-05   5.36174863e-04   8.56698716e-06   1.53347102e-09
    1.36415490e-09   7.35192662e-09   2.06914206e-06   9.89989638e-01
    1.09876304e-08   2.51043559e-04   4.05978029e-12   4.67202844e-05
    1.60227998e-09   2.63023267e-05   1.01537706e-04   1.28826214e-12
    1.78872417e-09   1.48227964e-05   7.31423880e-11   9.63426540e-15
    6.39240490e-04   1.78235725e-11   7.21951405e-12   1.74439731e-06
    4.32121707e-03   2.06905479e-10   7.42333100e-07   8.06635035e-06
    1.06242570e-08   4.29715499e-07   4.11564039e-13   1.62820797e-05
    3.62144387e-03   1.84611985e-04   8.05662864e-07   3.31598640e-05
    5.04070174e-10   1.15415016e-04   9.52395385e-10   5.26485131e-08
    5.81246525e-07]]
Action: 0.45
Enter Reward: 1
Backpropping 

Session Number 39
images_for_training/96
(1, 64, 64, 3)
Policy eval: 
[[  2.92776880e-04   1.35463499e-03   1.23149245e-12   8.65666063e-15
    4.75741757e-09   7.86135805e-13   6.11715996e-06   1.83489865e-05
    1.50584988e-03   3.26675072e-04   2.70162412e-14   7.83925589e-06
    2.89857533e-04   5.35272271e-10   2.52318010e-11   2.62543161e-13
    1.40015222e-10   1.82929973e-04   8.76178131e-14   1.99000723e-07
    3.04088940e-06   6.92973956e-10   9.88289485e-12   3.32366512e-09
    4.07622865e-04   9.54133217e-10   2.91372526e-09   1.15021178e-11
    3.28432143e-10   3.53999247e-10   3.47109386e-13   4.26565236e-07
    2.45329996e-08   3.28399328e-04   3.47598686e-11   2.09873377e-07
    1.02932784e-11   2.04487205e-05   6.88985868e-10   9.95254397e-01
    2.09104414e-07]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 40
images_for_training/234
(1, 64, 64, 3)
Policy eval: 
[[  9.00805667e-02   1.58117030e-06   1.48476383e-20   8.82606661e-12
    5.72545047e-22   1.39875904e-14   7.75923695e-07   1.61089065e-05
    1.17372106e-12   6.71302250e-11   6.55969901e-09   9.68313901e-11
    1.43425868e-10   2.05849899e-12   1.28523082e-12   2.72696342e-20
    2.01362144e-14   7.45670346e-04   4.50454975e-21   1.17232576e-18
    1.58275816e-05   1.64830121e-14   2.67743339e-21   2.30578225e-13
    4.60684164e-11   1.14471523e-17   4.14967924e-19   1.83484087e-13
    1.00267652e-14   3.42760217e-12   1.83011146e-21   8.57276027e-05
    2.69379176e-04   3.18178806e-13   5.16239629e-09   7.14508319e-09
    3.02078339e-16   9.08694148e-01   7.33809769e-09   9.01749736e-05
    2.92872526e-09]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 41
images_for_training/209
(1, 64, 64, 3)
Policy eval: 
[[  9.89639997e-01   5.53975615e-11   3.09881969e-08   6.03890355e-21
    1.85384257e-14   4.78959580e-12   5.79450585e-08   3.86322788e-12
    8.62232563e-10   2.97680134e-18   9.14633991e-27   9.48817205e-11
    1.42605493e-15   1.13593560e-04   3.30382250e-07   5.92257764e-20
    2.07882515e-17   1.58403823e-09   4.01537689e-26   8.28848473e-17
    3.55095494e-06   2.09153528e-18   2.97061754e-19   2.12492357e-09
    3.02379462e-03   7.19801348e-14   1.27779742e-12   2.71888421e-22
    5.25255083e-16   5.25946966e-08   1.03086802e-19   9.22190384e-13
    5.26184185e-14   5.43932756e-03   2.27482535e-15   6.25722805e-06
    2.82860909e-12   1.77302596e-03   5.46519982e-11   2.54381671e-09
    1.87671634e-09]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 42
images_for_training/211
(1, 64, 64, 3)
Policy eval: 
[[  9.99453247e-01   3.87316064e-08   7.74268518e-21   4.91667843e-18
    1.34406407e-24   1.18803828e-10   3.42514521e-20   9.89020255e-11
    9.37665540e-14   3.43794228e-23   1.40712307e-23   1.55834839e-12
    6.81050017e-18   5.21115456e-22   1.70537604e-07   4.73048372e-35
    5.08295235e-28   3.60408856e-11   2.76903072e-20   5.61501553e-28
    9.19389367e-06   9.44969032e-22   7.36139886e-20   4.89423048e-15
    1.14666384e-11   1.07441756e-32   2.58140052e-08   1.70730793e-16
    6.65523430e-07   1.13671876e-11   2.45736763e-33   1.92618299e-05
    2.45288148e-18   1.32037574e-04   3.35043194e-16   4.67265376e-12
    3.77958515e-13   4.32786473e-09   1.01068220e-09   9.40591442e-16
    3.85355321e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 43
images_for_training/25
(1, 64, 64, 3)
Policy eval: 
[[  6.10545099e-01   6.89256432e-13   2.31871662e-12   2.92631560e-13
    2.19321797e-10   4.07908299e-14   2.40503432e-05   1.44200976e-13
    8.06671166e-17   1.13530262e-11   3.74356985e-14   2.81823735e-14
    4.60641594e-11   3.14954700e-14   5.46753330e-14   3.72254784e-23
    1.82699823e-14   4.96480079e-10   2.38174922e-19   4.42632271e-15
    8.40823855e-09   1.30140853e-13   7.26134442e-21   2.04568584e-09
    2.69725131e-10   1.49291050e-15   7.50768208e-13   3.34077845e-13
    1.36764100e-14   2.88461521e-09   1.92584827e-22   3.21352145e-15
    1.79497395e-08   1.74024795e-10   3.53256922e-07   1.28199133e-07
    9.06440884e-13   3.89430404e-01   6.17044610e-13   1.27205304e-08
    3.58699751e-13]]
Action: 0.3
Enter Reward: 0
Backpropping 

Session Number 44
images_for_training/281
(1, 64, 64, 3)
Policy eval: 
[[  9.99993086e-01   5.35696508e-25   1.09908530e-17   1.58685131e-13
    1.58460147e-20   4.26241716e-32   4.74611683e-10   8.95497825e-12
    3.13350854e-19   1.59292503e-17   5.65781749e-27   4.53504449e-13
    3.52276857e-08   0.00000000e+00   5.09777021e-09   0.00000000e+00
    1.51674680e-11   1.19553609e-20   0.00000000e+00   9.87148859e-30
    5.34148512e-07   3.23488753e-20   9.54748108e-27   1.15765929e-17
    2.25207256e-10   1.94933643e-37   3.57740828e-25   1.01797396e-17
    1.45475497e-06   1.27298005e-22   0.00000000e+00   4.91270657e-06
    2.38693003e-21   1.87877905e-14   1.03669699e-12   4.06407244e-20
    5.32406317e-25   3.04952256e-19   8.19198277e-26   6.79848953e-20
    1.21240299e-16]]
Action: 1.7
Enter Reward: 0
Backpropping 

Session Number 45
images_for_training/52
(1, 64, 64, 3)
Policy eval: 
[[  3.82227916e-03   1.29208013e-08   1.13010894e-11   3.05082565e-13
    1.84407906e-11   8.43405768e-26   1.68112351e-07   2.15927853e-09
    1.10762295e-15   1.60208465e-18   6.16252208e-31   1.24349242e-07
    1.83905922e-08   3.74799185e-07   1.20342435e-14   1.05382535e-15
    1.75883713e-15   2.99190219e-06   5.64832302e-38   2.53699030e-22
    2.87894032e-11   4.05986919e-12   7.79069437e-23   1.16875558e-13
    9.96117949e-01   5.25969038e-18   3.19842107e-13   5.22211181e-08
    4.31562803e-05   2.03488933e-18   2.40649091e-26   6.72067927e-07
    2.35408859e-10   2.08536835e-06   1.75232943e-13   4.66783036e-12
    2.05541057e-15   9.67514101e-14   2.51610690e-13   8.87260001e-07
    9.15701003e-06]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 46
images_for_training/163
(1, 64, 64, 3)
Policy eval: 
[[ 0.04299331  0.02582874  0.0055432   0.01314664  0.00778057  0.02960161
   0.06202777  0.05346967  0.01063043  0.01058034  0.00854451  0.02132426
   0.04090512  0.04809546  0.02779276  0.00463063  0.0171455   0.09441953
   0.00190853  0.00587642  0.01480516  0.00667525  0.00318534  0.03600443
   0.04847306  0.00447816  0.02769357  0.00821186  0.01370229  0.01222421
   0.00577281  0.03071528  0.06401049  0.02584057  0.05704967  0.01155461
   0.01053313  0.02241037  0.01601091  0.03479381  0.01361013]]
Action: 0.95
Enter Reward: 0
Backpropping 

Session Number 47
images_for_training/243
(1, 64, 64, 3)
Policy eval: 
[[  5.73791154e-02   3.65173316e-18   2.95586297e-27   4.33219113e-26
    9.51657499e-24   1.04338410e-28   2.24130832e-22   4.50743797e-15
    0.00000000e+00   5.90117569e-26   1.52925996e-32   1.39362809e-11
    3.06189697e-27   0.00000000e+00   7.32439453e-22   0.00000000e+00
    1.44291767e-09   2.62101741e-20   0.00000000e+00   0.00000000e+00
    2.20353122e-15   7.70301258e-27   1.64632604e-37   9.34875846e-01
    2.24854193e-17   0.00000000e+00   5.19245127e-35   4.05064219e-30
    0.00000000e+00   1.76712604e-37   0.00000000e+00   7.59112595e-09
    2.09593218e-05   0.00000000e+00   7.72411656e-03   1.30812951e-33
    0.00000000e+00   2.52394219e-16   6.78657416e-31   8.43441232e-37
    1.74367674e-21]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 48
images_for_training/210
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   2.41279749e-15   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   3.71803978e-33   1.36834771e-27   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    3.93999416e-12   7.22937781e-38   0.00000000e+00   3.42470385e-36
    9.84202033e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   2.34204413e-31   0.00000000e+00   0.00000000e+00
    8.63721648e-26   8.22620454e-26   1.19056054e-28   4.76796380e-09
    0.00000000e+00   8.19017491e-16   4.03435958e-38   1.15158816e-26
    0.00000000e+00]]
Action: 0.15
Enter Reward: 0
Backpropping 

Session Number 49
images_for_training/180
(1, 64, 64, 3)
Policy eval: 
[[  8.07698146e-02   1.43716892e-03   1.11139030e-03   5.94876707e-04
    7.32711470e-03   7.06036855e-03   3.13110501e-02   3.65890819e-03
    8.22309994e-06   2.18698103e-03   7.75254521e-05   4.50713411e-02
    1.72620118e-02   2.27830533e-04   1.92953204e-03   4.97106303e-05
    5.53556392e-03   1.40556125e-02   5.93398636e-06   6.68769877e-04
    2.72772135e-03   3.48106783e-04   1.14522800e-05   5.25687775e-03
    5.79587966e-02   1.76226295e-05   6.70320261e-03   3.36467731e-03
    2.98152183e-04   6.30655049e-05   2.93146900e-06   5.87547617e-03
    4.21864539e-02   1.65436659e-02   1.08593024e-01   1.15065207e-03
    3.77163924e-05   4.38514143e-01   2.59072316e-04   8.95768255e-02
    1.60660289e-04]]
Action: 1.7
Enter Reward: 0
Backpropping 

Session Number 50
images_for_training/176
(1, 64, 64, 3)
Policy eval: 
[[  3.07703298e-02   8.91926757e-05   1.16997457e-03   1.60739000e-05
    1.82244534e-04   2.63554875e-06   1.73752084e-02   1.07300968e-03
    1.74071010e-05   1.23924930e-02   1.24093558e-05   8.38504347e-04
    1.00768509e-03   4.50138876e-04   8.48788675e-03   2.53922877e-07
    2.05813034e-04   8.97315424e-03   1.82521603e-07   5.17152401e-08
    2.37445444e-01   3.23450920e-04   6.30503507e-08   1.26132232e-04
    2.05271944e-01   1.22341692e-06   2.62183626e-03   4.66165729e-05
    1.45452186e-05   4.65911944e-05   8.02236968e-07   7.10508844e-04
    3.74349393e-03   7.32282689e-03   8.46255943e-03   1.55718364e-02
    7.65690173e-04   4.33702856e-01   3.24782101e-04   2.59337132e-04
    1.72720916e-04]]
Action: 1.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 51
images_for_training/84
(1, 64, 64, 3)
Policy eval: 
[[  6.60195714e-04   6.73219801e-18   5.70733568e-25   1.09601691e-24
    5.93203275e-28   1.60930800e-30   1.61578996e-17   4.58007320e-21
    5.49386622e-32   1.53666437e-26   3.66407796e-31   5.18244117e-37
    1.82763669e-24   0.00000000e+00   7.00114390e-28   1.57118278e-38
    4.70005924e-13   8.40755319e-26   0.00000000e+00   8.56891040e-38
    1.10120797e-19   0.00000000e+00   0.00000000e+00   1.04733835e-19
    9.96455729e-01   1.67762972e-20   6.28284994e-21   2.10202198e-34
    2.90670914e-37   0.00000000e+00   0.00000000e+00   2.14250712e-27
    2.88374280e-03   8.47163469e-30   1.30817844e-15   3.63261308e-30
    5.43942898e-28   2.96355267e-07   1.21640135e-23   1.03834025e-11
    4.25845445e-31]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 52
images_for_training/128
(1, 64, 64, 3)
Policy eval: 
[[  2.58366074e-02   1.08285610e-06   1.00100842e-04   5.52418875e-04
    1.65961069e-06   9.55166541e-08   2.24376010e-04   1.05248410e-02
    5.63615231e-07   5.35142972e-05   2.01734061e-08   5.82601549e-03
    1.14078997e-02   6.08076989e-05   8.13545630e-05   6.62394797e-08
    3.11868079e-03   2.59225443e-02   3.41417872e-09   2.07255671e-05
    3.66142689e-04   7.62953221e-07   2.27712551e-08   8.34036473e-06
    8.68536253e-03   1.38879319e-09   8.77120983e-05   1.12387608e-03
    5.86733731e-05   1.45510910e-06   5.70858809e-08   1.88453960e-05
    8.98604214e-01   6.20512990e-04   2.26176795e-04   1.34922630e-05
    2.09303744e-05   2.44567660e-03   1.56071590e-04   3.39286402e-03
    4.35489492e-04]]
Action: 1.7
Enter Reward: 0
Backpropping 

Session Number 53
images_for_training/31
(1, 64, 64, 3)
Policy eval: 
[[  6.23002555e-03   4.79921753e-15   2.81892942e-20   3.32833987e-17
    5.29812464e-22   1.59577270e-33   2.21600409e-08   8.23299946e-19
    2.03510159e-24   1.10791835e-13   0.00000000e+00   9.25993888e-17
    1.01805986e-11   3.12302505e-14   1.12263240e-20   5.65070833e-34
    8.79592990e-05   2.06119945e-14   5.40268428e-29   5.78495237e-27
    1.49100757e-04   1.49631830e-26   2.46566970e-31   0.00000000e+00
    2.23485131e-07   1.12624697e-30   9.48379561e-03   2.66706536e-21
    1.23794138e-07   4.07602723e-30   1.38514138e-33   2.70200203e-24
    2.28171032e-02   2.30746030e-11   1.63087476e-04   4.13399103e-18
    3.64988321e-22   9.09914449e-02   3.38618642e-25   8.70077074e-01
    4.44073070e-17]]
Action: 1.7
Enter Reward: 
Traceback (most recent call last):
  File "Loader.py", line 181, in <module>
    rewards,flag = generate_session()  #generate new sessions
  File "Loader.py", line 147, in generate_session
    r=int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: ''
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 18:33:31.732565: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/200
(1, 64, 64, 3)
Policy eval: 
[[  3.82097314e-05   8.82536056e-04   9.10943374e-04   9.28476229e-02
    1.65324236e-04   1.34300342e-06   1.20837125e-03   1.38314892e-04
    1.76944977e-05   2.15990622e-05   5.50196739e-04   9.90073568e-06
    1.99258266e-05   1.88072998e-04   3.02405865e-03   9.94724833e-05
    3.32715754e-05   3.69747318e-02   1.79848925e-04   3.39681219e-06
    4.16414638e-04   1.22632671e-04   4.38998633e-08   2.36014057e-05
    4.07187385e-04   3.89482128e-03   3.08956049e-04   4.36151683e-01
    4.82675731e-02   2.16169901e-05   2.00765669e-01   7.96204586e-06
    3.19681676e-05   2.30483711e-05   4.38731604e-06   1.72052801e-01
    9.05959041e-06   4.60324518e-05   1.12426911e-04   1.69265786e-05
    4.35010890e-07]]
2018-10-05 18:33:32.936 Python[32853:13827316] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 1.75
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/170
(1, 64, 64, 3)
Policy eval: 
[[  2.21877071e-05   1.95653300e-07   1.61373150e-03   9.95578825e-01
    4.27885883e-04   1.29055664e-07   1.17376987e-06   7.43681449e-06
    6.29422604e-04   1.94027734e-06   8.27437634e-06   5.09997289e-09
    9.52043877e-07   3.12444013e-06   4.68542479e-04   1.00169950e-06
    4.52561435e-05   5.19281530e-05   1.78491121e-07   3.90814876e-07
    1.44097488e-04   1.58565138e-06   2.12660780e-05   5.64621381e-08
    9.26130838e-07   2.79339588e-07   3.58848126e-07   6.91138775e-05
    1.82101917e-06   1.32207831e-04   2.56191619e-04   2.30317644e-04
    9.38578069e-07   3.41409359e-05   1.00098096e-05   2.00644790e-04
    2.92169542e-08   3.13051873e-06   5.78175559e-07   2.96935759e-05
    8.85689855e-10]]
Action: 1.2
Enter Reward: 0
Backpropping 

Session Number 2
images_for_training/80
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   3.28878163e-38
    0.00000000e+00   0.00000000e+00   1.46042312e-24   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   2.19663189e-32
    0.00000000e+00   0.00000000e+00   0.00000000e+00   3.08747446e-38
    0.00000000e+00   0.00000000e+00   1.23737048e-25   0.00000000e+00
    1.37409743e-33   2.03507078e-20   0.00000000e+00   1.19054356e-26
    2.96375728e-12   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 3
images_for_training/213
(1, 64, 64, 3)
Policy eval: 
[[  7.93251250e-37   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   4.06683393e-35   0.00000000e+00
    0.00000000e+00   2.81384021e-01   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   5.77240931e-25
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    7.18616009e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   5.14880990e-35   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   3.38929662e-33
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.6
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/99
(1, 64, 64, 3)
Policy eval: 
[[  6.45864475e-17   0.00000000e+00   2.28819893e-24   0.00000000e+00
    0.00000000e+00   0.00000000e+00   9.99953508e-01   0.00000000e+00
    0.00000000e+00   1.13633496e-05   3.87605647e-25   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   2.35545768e-14
    0.00000000e+00   1.18089336e-36   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.31319592e-23   0.00000000e+00   0.00000000e+00   0.00000000e+00
    4.66620692e-24   1.10467328e-26   6.80060127e-29   0.00000000e+00
    3.26975751e-05   0.00000000e+00   0.00000000e+00   2.45984143e-06
    0.00000000e+00   1.56443987e-38   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.6
Enter Reward: 0
Backpropping 

Session Number 5
images_for_training/262
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    7.35095659e-26   0.00000000e+00   2.39770935e-28   0.00000000e+00
    0.00000000e+00   1.27985107e-37   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.42853127e-26
    0.00000000e+00   1.21200114e-01   0.00000000e+00   0.00000000e+00
    0.00000000e+00   7.90818809e-38   9.55621142e-31   0.00000000e+00
    2.23809771e-09   0.00000000e+00   1.10013870e-32   0.00000000e+00
    0.00000000e+00   8.75677049e-01   1.10545581e-25   0.00000000e+00
    3.12281982e-03   0.00000000e+00   0.00000000e+00   3.58176484e-18
    0.00000000e+00   0.00000000e+00   6.89259247e-31   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 6
images_for_training/275
(1, 64, 64, 3)
Policy eval: 
[[  1.00117939e-15   9.58499822e-25   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    3.10900199e-12   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.92948137e-19   9.51118853e-36   0.00000000e+00   0.00000000e+00
    2.30081675e-36   1.97099607e-38   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   6.24013318e-37   0.00000000e+00
    1.66918361e-34   0.00000000e+00   1.10379039e-17   0.00000000e+00
    0.00000000e+00   0.00000000e+00   8.30737727e-33   3.04612720e-33
    0.00000000e+00   0.00000000e+00   3.35849210e-27   0.00000000e+00
    0.00000000e+00]]
Action: 0.4
Enter Reward: 1
Backpropping 

Session Number 7
images_for_training/152
(1, 64, 64, 3)
Policy eval: 
[[  1.20852384e-09   1.42226437e-18   2.42857983e-08   1.84741846e-19
    3.48444723e-14   1.48295617e-16   9.61216331e-01   6.82918611e-09
    1.74479084e-13   2.14028242e-03   6.83598511e-10   1.27719194e-19
    1.70193672e-07   1.62940541e-15   2.80619130e-16   1.91074264e-06
    4.01950011e-08   1.43436220e-04   1.68068426e-17   2.19524232e-10
    1.18902824e-06   1.82157082e-16   6.05542158e-18   1.35609416e-14
    2.90985277e-04   5.95410764e-26   1.06333204e-12   9.63545052e-21
    1.16398587e-06   3.82956068e-06   4.85008179e-11   2.84162169e-08
    1.00761348e-07   6.14541015e-18   1.39356105e-11   3.62005495e-02
    4.89676406e-18   1.32315245e-14   1.67613059e-11   5.98243243e-14
    9.96001479e-16]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 8
images_for_training/254
(1, 64, 64, 3)
Policy eval: 
[[  1.74589925e-08   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   2.96858325e-08   0.00000000e+00
    7.85515760e-04   9.40383671e-18   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   2.71690360e-22
    0.00000000e+00   2.78680474e-28   1.74766016e-36   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   9.99214411e-01   2.36141566e-21   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   5.64856456e-26
    0.00000000e+00   0.00000000e+00   8.29824682e-35   0.00000000e+00
    0.00000000e+00]]
Action: 1.6
Enter Reward: 0
Backpropping 

Session Number 9
images_for_training/128
(1, 64, 64, 3)
Policy eval: 
[[  1.57638565e-01   1.85591906e-12   1.68321932e-07   4.35749187e-10
    1.20271473e-10   2.56450967e-08   2.84870417e-04   5.20632981e-10
    1.45208134e-04   2.64677539e-07   8.80248612e-04   2.69689799e-08
    5.57929480e-10   7.16794166e-04   1.35501954e-09   4.75495435e-05
    1.78621144e-06   1.30174300e-02   1.59908323e-10   9.78785101e-06
    3.27192561e-06   2.45011393e-07   7.72401199e-10   2.10981909e-07
    1.42981708e-02   3.06561362e-15   1.40228295e-07   3.70524054e-12
    1.37185892e-02   7.99142778e-01   3.48922491e-09   8.94121604e-06
    3.08200072e-07   1.72914988e-10   1.66288743e-07   7.27500010e-05
    1.16494948e-05   2.51276049e-11   2.16510561e-08   7.48847928e-11
    2.87779522e-12]]
Action: 0.85
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/25
(1, 64, 64, 3)
Policy eval: 
[[  9.21180348e-15   0.00000000e+00   6.13402193e-37   0.00000000e+00
    0.00000000e+00   0.00000000e+00   7.33116217e-30   0.00000000e+00
    9.91910933e-32   1.00000000e+00   0.00000000e+00   0.00000000e+00
    4.11448499e-28   8.23145326e-32   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.28943059e-21   0.00000000e+00   0.00000000e+00
    1.42256233e-36   6.65695182e-20   0.00000000e+00   1.24190792e-36
    3.56456796e-28   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   2.70571488e-13   0.00000000e+00   3.71610362e-37
    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.55213902e-17
    0.00000000e+00   0.00000000e+00   6.49923025e-25   0.00000000e+00
    0.00000000e+00]]
Action: 0.85
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/43
(1, 64, 64, 3)
Policy eval: 
[[  1.46252048e-22   0.00000000e+00   3.51496380e-32   1.01165705e-36
    1.95891696e-26   1.91054432e-30   1.70799173e-11   1.75667827e-34
    6.46255648e-05   2.92004431e-13   1.75154513e-35   0.00000000e+00
    3.25360400e-38   1.62345839e-36   3.21879098e-38   5.65511073e-21
    2.51323066e-16   1.78046227e-01   1.10110954e-35   4.31275359e-33
    1.59865832e-09   3.38356212e-30   0.00000000e+00   0.00000000e+00
    4.89624037e-20   0.00000000e+00   1.74347897e-05   0.00000000e+00
    1.51532481e-23   8.21871638e-01   8.99297924e-17   4.27563319e-26
    1.24450933e-24   4.46335262e-35   9.39920416e-34   2.93096458e-09
    1.49259396e-24   3.97387395e-30   5.26750728e-35   5.99762463e-28
    0.00000000e+00]]
Action: 0.85
Enter Reward: 1
Backpropping 

Session Number 12
images_for_training/10
(1, 64, 64, 3)
Policy eval: 
[[  3.33883476e-11   3.98505069e-36   6.98828569e-18   3.55827513e-22
    8.94659971e-21   4.17389456e-20   1.14786173e-16   2.04050078e-16
    9.52765324e-18   4.46347226e-09   3.08701581e-15   2.29563378e-15
    2.55847479e-11   2.10424441e-17   1.44155942e-17   9.85349785e-15
    9.18982308e-17   1.35177103e-09   2.92801154e-19   1.35987341e-16
    7.80192815e-15   1.28036355e-20   9.69575380e-27   5.68202957e-15
    2.65929423e-13   5.66247935e-34   1.53753515e-13   1.56155649e-29
    3.10947013e-16   7.33697821e-16   4.76351107e-16   3.59348010e-23
    1.29645831e-22   6.63230239e-16   1.26795408e-21   1.00000000e+00
    1.83467264e-09   1.34420202e-20   2.68587975e-19   3.82292603e-20
    2.58381390e-26]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 13
images_for_training/12
(1, 64, 64, 3)
Policy eval: 
[[  9.99997497e-01   6.69985178e-38   1.25044664e-22   8.76719598e-32
    8.68509529e-20   1.19064596e-32   1.36645339e-12   1.30543984e-26
    1.03101265e-23   3.01780684e-10   9.40380879e-34   4.89834786e-17
    2.07190905e-24   4.23270620e-12   4.34602116e-26   7.59872781e-25
    7.71616855e-21   2.49533559e-06   4.87876477e-33   2.03658941e-26
    1.42375147e-31   1.48066673e-21   7.22425943e-23   4.60639116e-14
    1.84880800e-12   0.00000000e+00   6.73844985e-24   2.21188694e-33
    7.08689704e-11   5.90844706e-09   2.42908148e-23   4.24996323e-11
    3.14096710e-26   9.36365273e-25   1.89934790e-24   1.13596714e-08
    2.01983118e-11   1.53582787e-25   5.97231899e-19   3.36266704e-32
    3.49231771e-38]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 14
images_for_training/179
(1, 64, 64, 3)
Policy eval: 
[[  5.69443226e-01   1.34582824e-05   5.78828622e-04   1.80070333e-06
    1.24354221e-04   4.34092908e-05   4.39180546e-02   2.30302617e-01
    7.96299719e-04   6.08530594e-03   7.59939503e-05   7.58316834e-04
    2.05259930e-04   2.45731557e-04   1.26031198e-04   5.43212611e-03
    8.98813177e-03   5.95458667e-04   5.10558220e-06   5.10869955e-04
    3.39237787e-03   3.34393699e-03   3.12871503e-04   3.88756889e-04
    9.88178793e-03   8.84594726e-07   2.17572134e-03   5.11077778e-05
    5.89907356e-02   7.43456418e-03   9.82713513e-03   8.33685684e-04
    3.31297197e-05   7.77484820e-05   3.53822228e-03   2.32888069e-02
    4.49469342e-04   6.21028812e-05   2.66826735e-03   4.99809906e-03
    2.56189054e-07]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 15
images_for_training/168
(1, 64, 64, 3)
Policy eval: 
[[  3.15326720e-01   8.15065927e-04   1.01864962e-02   1.49739895e-03
    1.69090417e-04   1.72659336e-03   2.45511178e-02   2.66772769e-02
    4.95403865e-03   1.45865390e-02   1.00027246e-03   2.62437668e-03
    4.22491804e-02   1.50911801e-03   1.05336169e-02   8.26827139e-02
    7.69799529e-03   2.59859152e-02   2.13013566e-03   4.25410643e-03
    3.92225869e-02   2.89155077e-03   1.09170692e-03   2.91781710e-03
    2.57640388e-02   6.07456081e-04   4.88878507e-03   8.47900286e-04
    4.23945151e-02   1.92961248e-03   4.43857023e-03   1.61970360e-03
    7.05494033e-03   1.91729038e-03   1.81805193e-02   2.21951216e-01
    3.10259406e-02   2.74130586e-03   1.31373655e-03   4.98774927e-03
    1.05525961e-03]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 16
images_for_training/251
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   0.00000000e+00   1.15583668e-31   8.60353657e-20
    0.00000000e+00   4.68450588e-33   1.06939813e-09   7.21117000e-16
    2.15874689e-29   2.98978774e-17   1.20385828e-30   5.03546150e-29
    0.00000000e+00   1.21205549e-38   1.17611631e-27   1.85140290e-23
    1.18441803e-28   1.06712358e-25   0.00000000e+00   1.44663300e-32
    7.68143528e-16   9.97631841e-20   1.02819389e-33   5.48706148e-37
    7.07556999e-11   0.00000000e+00   1.18687304e-22   0.00000000e+00
    1.14932919e-09   2.69022079e-24   9.64329420e-21   5.19878134e-26
    2.62139865e-28   1.12323421e-35   2.21203925e-30   1.43014466e-17
    2.30981142e-30   1.26131503e-30   1.13765497e-19   1.41508681e-30
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 17
images_for_training/182
(1, 64, 64, 3)
Policy eval: 
[[  1.13945827e-01   1.79173458e-06   3.71489814e-03   3.11139092e-06
    8.51035747e-06   1.02365972e-04   8.18643197e-02   2.83252285e-03
    1.34640578e-02   2.24324912e-01   1.22975485e-04   1.71229025e-04
    1.22458558e-04   3.41368795e-05   4.96318622e-04   7.34739983e-03
    1.29645248e-03   2.15662949e-05   3.96712312e-06   5.29336830e-05
    1.37340337e-01   9.16829426e-03   1.49275984e-05   2.90137323e-05
    3.52009952e-01   4.61260333e-06   1.12249721e-02   3.25088076e-05
    3.04650515e-04   1.01570267e-05   7.13595189e-04   3.92089970e-03
    9.08505444e-06   3.26640846e-04   1.45574717e-03   2.29364149e-02
    7.16878334e-03   7.49302679e-04   7.68156082e-04   1.87526306e-03
    4.84483053e-06]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 18
images_for_training/160
(1, 64, 64, 3)
Policy eval: 
[[  4.30754721e-01   3.33498977e-03   1.06265703e-02   2.91928742e-03
    4.25873674e-04   2.53260345e-03   6.29422292e-02   5.33226877e-02
    2.32669152e-02   1.67668238e-02   3.43671674e-03   3.10302409e-03
    1.41931362e-02   1.44206139e-03   1.93676259e-03   2.33016293e-02
    3.67842093e-02   7.54896784e-03   1.66509219e-03   2.45406083e-03
    3.57869379e-02   7.08881021e-03   1.66080543e-03   2.08672555e-03
    1.91454943e-02   3.29875067e-04   1.06760645e-02   2.12542131e-03
    4.41401675e-02   1.22873895e-02   5.04021998e-03   6.04341505e-03
    4.07488039e-03   2.87338812e-03   8.07779096e-03   4.94158939e-02
    2.46881898e-02   2.35237344e-03   3.63020897e-02   2.23994069e-02
    6.46262954e-04]]
Action: 0.45
Enter Reward: 0
Backpropping 

Session Number 19
images_for_training/54
(1, 64, 64, 3)
Policy eval: 
[[  1.62391678e-09   2.61539727e-22   3.71138636e-17   1.27529315e-24
    3.11687826e-20   4.58664572e-15   3.78942466e-03   2.21154033e-11
    2.08111046e-12   8.99011443e-09   1.00637456e-12   8.47356871e-17
    2.12061098e-12   6.66345658e-15   9.31645900e-07   8.34794134e-14
    8.21783518e-20   5.14016551e-17   7.01177564e-23   1.77233124e-11
    1.28769656e-07   5.03560855e-08   3.33844091e-13   1.58367957e-18
    4.47064449e-05   1.74756545e-18   6.98290776e-08   3.61199836e-15
    9.95502532e-01   7.71913851e-22   6.62090082e-04   1.48022809e-11
    5.96119972e-23   1.23142210e-22   1.17530664e-11   1.42886076e-08
    4.82969201e-19   2.79460760e-16   3.14850912e-21   7.15643744e-13
    8.12853747e-21]]
Action: 1.2
Enter Reward: 0
Backpropping 

Session Number 20
images_for_training/191
(1, 64, 64, 3)
Policy eval: 
[[  5.45456191e-04   1.42475968e-04   7.25316477e-06   2.05954246e-04
    3.71748065e-05   2.13407236e-03   3.00826933e-02   1.81211147e-03
    9.68644817e-05   4.00082350e-01   1.08152465e-03   5.23051526e-03
    1.64921943e-03   6.93875918e-05   5.89673873e-04   8.17126259e-02
    5.13060309e-04   3.36498815e-05   1.71748161e-05   3.86107538e-04
    1.36190569e-02   3.68238823e-03   2.48788492e-05   2.05167080e-03
    1.50085986e-01   3.33916591e-06   3.25628527e-04   3.62809096e-03
    2.24538147e-01   3.50020379e-02   2.58977052e-05   1.14408145e-02
    6.61982995e-05   1.92209438e-04   2.06924565e-02   1.86089810e-03
    9.63039522e-04   1.47437517e-04   1.26317819e-03   3.91688664e-03
    4.04447965e-05]]
Action: 0.25
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 21
images_for_training/56
(1, 64, 64, 3)
Policy eval: 
[[  7.36979011e-09   4.69051737e-15   4.03854838e-10   2.41583144e-18
    1.29454252e-18   1.06264400e-14   1.11789859e-05   5.43616265e-02
    7.83623513e-12   3.66777062e-01   1.39431327e-12   1.74870545e-14
    6.57673221e-12   4.23633099e-16   4.03984832e-11   1.05214126e-09
    7.78926992e-11   1.09128622e-20   1.62226416e-19   1.26244230e-12
    8.83591667e-07   9.15321707e-10   4.76864090e-21   1.15294528e-19
    2.95379877e-13   1.15320093e-18   1.71126675e-16   1.96007446e-11
    5.78805923e-01   6.15702933e-10   1.52559521e-09   5.28236864e-11
    1.39417849e-22   3.48705335e-11   2.49793629e-05   1.61109783e-05
    1.08913317e-14   1.20646268e-06   9.48306308e-07   3.44145074e-10
    3.76487475e-20]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 22
images_for_training/58
(1, 64, 64, 3)
Policy eval: 
[[  8.00534524e-03   1.58742408e-10   1.39718322e-05   5.20026966e-10
    2.31172592e-07   4.18227541e-09   1.58392800e-06   1.86911984e-06
    6.89263544e-08   4.75288369e-02   8.79892013e-07   4.42507329e-08
    1.69208836e-09   3.00878554e-07   5.45378309e-04   2.27202465e-10
    2.81284847e-05   1.42842566e-07   8.23773287e-13   7.47547586e-13
    1.67845329e-03   6.37115518e-05   3.09031711e-09   2.28456912e-07
    9.57208322e-05   7.56222003e-14   1.31971363e-04   1.95752747e-07
    9.41299498e-01   6.34880024e-08   3.01241059e-08   1.78549490e-05
    2.00932831e-07   1.19812875e-11   1.10909309e-06   3.70981326e-07
    3.62993560e-05   5.46861615e-04   3.29123225e-07   2.76154603e-11
    2.88601370e-07]]
Action: 1.4
Enter Reward: 1
Backpropping 

Session Number 23
images_for_training/162
(1, 64, 64, 3)
Policy eval: 
[[ 0.03975191  0.00690776  0.00839948  0.00081682  0.00636675  0.01000246
   0.0463244   0.12841967  0.02533389  0.06706157  0.02096724  0.0089173
   0.02978101  0.00915471  0.01907776  0.02164011  0.0403369   0.01395099
   0.00100799  0.0018454   0.05698986  0.05319277  0.00440879  0.00578113
   0.01224999  0.02232882  0.02256944  0.00467506  0.06165456  0.0088354
   0.03405533  0.01135669  0.00185626  0.02399966  0.03764991  0.05128585
   0.01174699  0.00264033  0.01451439  0.04478913  0.00735549]]
Action: 0.7
Enter Reward: 0
Backpropping 

Session Number 24
images_for_training/112
(1, 64, 64, 3)
Policy eval: 
[[ 0.04180502  0.01220687  0.01054666  0.0118217   0.00746058  0.03995898
   0.01154337  0.02250189  0.01399746  0.05383369  0.02860064  0.01207634
   0.02609237  0.00985727  0.01537705  0.02372168  0.05399315  0.00819787
   0.00549253  0.01887709  0.04462923  0.01587055  0.00773415  0.0058021
   0.06724598  0.00659231  0.06827224  0.01558881  0.11930167  0.00860759
   0.00913232  0.01879384  0.01518377  0.00790144  0.04315604  0.04492861
   0.01680994  0.01462436  0.01389612  0.01882205  0.00914452]]
Action: 1.0
Enter Reward: 0
Backpropping 

Session Number 25
images_for_training/197
(1, 64, 64, 3)
Policy eval: 
[[ 0.03575146  0.01722582  0.01476724  0.00621276  0.0035528   0.01881775
   0.04952658  0.05152286  0.02808546  0.02441681  0.013071    0.00658814
   0.00936622  0.01109691  0.00998003  0.02031912  0.0128054   0.01538786
   0.00756677  0.03062966  0.11587024  0.03811899  0.00908403  0.00464144
   0.05756074  0.00632709  0.05647727  0.02437011  0.05983009  0.01399464
   0.02516575  0.01072801  0.00638398  0.01101835  0.04445611  0.02451398
   0.02347937  0.01927515  0.02283091  0.02828375  0.01089925]]
Action: 1.4
Enter Reward: 0
Backpropping 

Session Number 26
images_for_training/9
(1, 64, 64, 3)
Policy eval: 
[[  1.55260893e-09   6.35381809e-08   1.62008365e-10   2.30440211e-12
    5.40864836e-12   1.96833629e-04   9.74411523e-06   7.18106190e-03
    1.45044954e-08   6.49746787e-03   7.67501831e-07   1.46688495e-10
    3.27370596e-11   4.98548512e-12   1.79377466e-07   3.14044648e-08
    7.11727205e-11   2.27799932e-11   9.69355325e-12   3.44754380e-06
    5.66645940e-06   8.04124434e-10   1.06171410e-06   1.87699227e-12
    9.86076832e-01   5.73924908e-10   1.59810388e-05   8.89431639e-09
    2.12830923e-06   6.19417619e-07   1.16507493e-09   2.25527561e-08
    3.18709729e-12   1.69013588e-11   7.60643297e-06   9.49979071e-12
    2.67347993e-08   2.68762168e-08   2.24544749e-07   5.41426424e-08
    1.42462149e-12]]
Action: 1.0
Enter Reward: 1
Backpropping 

Session Number 27
images_for_training/292
(1, 64, 64, 3)
Policy eval: 
[[  1.54769452e-07   4.77553949e-05   2.73679530e-06   2.18581597e-10
    1.80485113e-10   2.02976844e-05   8.78052901e-07   3.20423496e-05
    1.09487473e-05   5.05858770e-06   9.03131604e-06   1.07686034e-07
    5.45613706e-01   3.49926239e-08   3.81362588e-06   2.59798327e-07
    4.06097541e-07   1.44205203e-10   6.70791792e-07   4.96124471e-07
    6.33866119e-04   3.73323360e-07   8.40874392e-09   1.99937199e-06
    1.24787656e-08   7.31483230e-09   5.75514896e-13   2.03991876e-04
    4.10669118e-01   3.07008270e-02   1.91486919e-07   8.86642592e-05
    1.54593813e-08   1.12875460e-08   9.67370160e-03   4.60398405e-05
    1.71184400e-08   2.04281741e-06   3.56756529e-04   1.87398621e-03
    1.12674554e-08]]
Action: 0.8
Enter Reward: 1
Backpropping 

Session Number 28
images_for_training/24
(1, 64, 64, 3)
Policy eval: 
[[  1.51592001e-01   3.71801592e-02   4.03995765e-03   1.40637637e-03
    3.63603962e-04   4.12673652e-02   1.18814990e-01   6.99155324e-04
    2.15071775e-02   4.01880918e-03   1.60402525e-03   1.69951713e-03
    6.31470990e-04   2.55703431e-04   4.36729810e-04   1.89376362e-02
    3.22234817e-03   2.43357063e-04   7.31690743e-05   1.45163620e-03
    8.51381384e-03   3.38241505e-03   3.61106722e-05   5.61519014e-03
    2.78355684e-02   8.78730407e-06   5.73349709e-04   2.36764606e-02
    1.48053151e-02   1.42345042e-03   5.07046888e-03   7.55086169e-03
    1.77819675e-05   1.99629485e-05   1.16181247e-01   3.22143137e-01
    5.13341697e-03   1.17459020e-03   3.75185199e-02   9.35694575e-03
    5.17429493e-04]]
Action: 0.45
Enter Reward: 0
Backpropping 

Session Number 29
images_for_training/230
(1, 64, 64, 3)
Policy eval: 
[[  3.78274888e-01   2.19068606e-03   3.13581836e-06   1.86619484e-08
    1.30749424e-04   6.11747146e-06   8.95982608e-03   8.46369949e-04
    2.05200240e-06   1.16952416e-03   8.80763423e-07   6.19217122e-09
    3.90247209e-04   1.34930517e-07   5.36737847e-04   1.85107924e-02
    6.65651285e-08   4.52970141e-07   8.01926205e-08   4.70561901e-07
    4.32673469e-03   3.11712247e-05   5.05730888e-08   1.06864149e-10
    3.93802859e-02   1.37113618e-08   2.18454716e-06   1.92341227e-02
    1.13095567e-01   1.24568061e-04   1.43204297e-05   1.27621615e-06
    2.44521914e-08   2.64241482e-08   6.25752611e-03   4.06224281e-01
    1.24440646e-06   1.30361277e-05   1.00172019e-06   2.69269804e-04
    1.45381751e-09]]
Action: 1.8
Enter Reward: 0
Backpropping 

Session Number 30
images_for_training/27
(1, 64, 64, 3)
Policy eval: 
[[  2.93657690e-01   1.52492374e-01   2.31107660e-02   5.43207607e-05
    2.56274105e-03   2.19857246e-02   4.47807135e-03   2.85063609e-02
    1.29306791e-02   8.95864610e-03   2.37233005e-02   5.54506574e-03
    1.83293349e-04   3.41002340e-03   5.12145134e-03   2.31214799e-04
    1.67260622e-03   3.29853938e-04   7.47039521e-05   3.02035682e-04
    1.54934474e-03   1.44761754e-03   1.86301291e-03   3.44373402e-04
    1.20433676e-03   2.24288451e-05   1.06356442e-02   7.18936026e-02
    4.27170098e-02   1.16460836e-02   1.29244057e-03   2.98643894e-02
    1.26573708e-04   4.60943353e-04   2.91038398e-02   1.10488664e-02
    2.90714111e-02   1.44271296e-03   1.31118521e-01   4.89587244e-03
    2.89200414e-02]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 31
images_for_training/121
(1, 64, 64, 3)
Policy eval: 
[[ 0.08181012  0.02227538  0.07972877  0.00681259  0.01117435  0.02839509
   0.02975887  0.02249787  0.01612901  0.02923117  0.05173642  0.01651252
   0.00646039  0.00784508  0.01940282  0.03272812  0.00730211  0.03604374
   0.00459668  0.02206165  0.05746354  0.01735245  0.01489899  0.0182592
   0.02179106  0.00617266  0.01955527  0.01851525  0.0223543   0.01091738
   0.02604568  0.02894677  0.01234363  0.01175301  0.02235302  0.06649115
   0.02199873  0.01630148  0.01080286  0.03263558  0.01054523]]
Action: 0.75
Enter Reward: 0
Backpropping 

Session Number 32
images_for_training/64
(1, 64, 64, 3)
Policy eval: 
[[  9.76522863e-01   7.08536099e-05   2.69535842e-04   2.91000561e-06
    2.43920886e-06   3.99937526e-05   1.20860888e-04   5.89052588e-03
    2.11499446e-05   3.80811944e-05   5.18184388e-04   3.87292268e-04
    4.45346988e-04   4.01131947e-05   2.72308884e-04   3.03430163e-04
    1.96464443e-05   6.16369944e-05   9.08881646e-07   1.44314163e-05
    3.62921186e-04   1.09926923e-05   2.75850311e-06   2.32416664e-06
    1.18622964e-04   4.98314694e-06   2.05201577e-05   1.15404495e-04
    2.54148990e-03   2.15487012e-06   4.01299185e-05   5.00336173e-04
    1.46732382e-05   2.01389666e-05   6.44468179e-04   8.57993029e-03
    1.56601585e-04   3.18896127e-06   1.63945684e-03   1.44416816e-04
    3.18631246e-05]]
Action: 1.45
Enter Reward: 1
Backpropping 

Session Number 33
images_for_training/71
(1, 64, 64, 3)
Policy eval: 
[[  5.19727729e-02   1.20203039e-02   3.84627352e-03   3.08429990e-05
    6.19351747e-04   2.43776920e-03   4.68587605e-05   2.72021979e-01
    6.11122604e-03   8.86950642e-03   2.17831209e-01   2.63979491e-05
    2.78766074e-05   1.86663980e-04   4.07193438e-04   6.49300346e-04
    1.35126436e-04   2.22744842e-04   1.37512223e-04   9.93447538e-05
    5.27853593e-02   3.38948462e-06   1.73290726e-03   2.15211076e-05
    9.43911946e-05   3.59621372e-05   3.41331074e-03   3.35658406e-04
    5.40912850e-04   4.54640031e-05   1.01603800e-04   1.65594334e-03
    2.19365957e-05   6.01772217e-06   4.11333567e-05   1.48556205e-02
    8.10314610e-04   1.04405171e-05   5.30901365e-04   3.45254332e-01
    2.61867626e-06]]
Action: 1.7
Enter Reward: 0
Backpropping 

Session Number 34
images_for_training/196
(1, 64, 64, 3)
Policy eval: 
[[ 0.03761689  0.02620769  0.03103426  0.0135856   0.02654502  0.01338977
   0.03081517  0.06716275  0.01390537  0.01512204  0.01422811  0.01679469
   0.01976183  0.02052074  0.01338045  0.02437768  0.00885086  0.02575611
   0.03343099  0.01878296  0.02183314  0.01243033  0.01417562  0.00830329
   0.03189133  0.01118653  0.01035228  0.05307108  0.0409633   0.0241017
   0.02099443  0.03360505  0.01503026  0.01684458  0.03829236  0.01518409
   0.02824709  0.0125571   0.02521797  0.07292034  0.02152914]]
Action: 0.65
Enter Reward: 0
Backpropping 

Session Number 35
images_for_training/49
(1, 64, 64, 3)
Policy eval: 
[[  4.31916952e-01   8.97686332e-02   1.99801907e-01   3.54278236e-05
    1.01324951e-03   2.67048622e-03   6.66271197e-04   8.97736847e-03
    1.39863305e-02   8.64501819e-02   3.13361995e-02   1.60086360e-02
    1.65018393e-03   2.57665012e-03   5.97344479e-03   7.01404037e-03
    4.96341963e-04   5.92217373e-04   2.45048694e-04   4.20399383e-03
    6.22061500e-03   2.69826996e-04   4.71362291e-05   1.89369428e-04
    2.41564284e-03   1.82471890e-03   2.80556269e-04   2.84052524e-03
    2.00687116e-03   1.78099308e-05   1.75320334e-03   2.50218809e-03
    4.68743019e-05   1.99900824e-03   7.69466441e-03   4.96189808e-03
    5.22747345e-04   1.75728684e-03   3.94977070e-03   5.32363430e-02
    7.94334919e-05]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 36
images_for_training/110
(1, 64, 64, 3)
Policy eval: 
[[ 0.06837111  0.03951067  0.04914516  0.01470546  0.01057458  0.06353264
   0.0380719   0.02569924  0.05132004  0.03342291  0.02992009  0.0104315
   0.02755881  0.00278429  0.01180266  0.06261806  0.02150685  0.01069097
   0.00733763  0.02670305  0.03603318  0.00825361  0.00404992  0.00856996
   0.02475369  0.01008271  0.0197805   0.03954733  0.01141942  0.00313463
   0.01352284  0.0250376   0.00974057  0.01853568  0.02005048  0.02987726
   0.0272685   0.01621747  0.02013691  0.01570487  0.03257519]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 37
images_for_training/69
(1, 64, 64, 3)
Policy eval: 
[[  6.24004662e-01   3.27877402e-02   6.29115328e-02   9.54131701e-06
    4.52363165e-05   2.34065130e-02   1.10959017e-03   1.99066382e-02
    3.39577161e-02   2.14276300e-03   5.08145988e-02   1.56664010e-03
    4.02414193e-03   1.36881819e-04   7.65180332e-04   6.72596879e-03
    1.23850317e-04   1.63842968e-04   4.07577667e-04   9.24333557e-03
    1.25547312e-02   1.96670904e-03   3.54377204e-04   3.44200453e-05
    8.24210234e-04   1.67541031e-04   5.56744984e-04   1.26857974e-03
    2.39235200e-02   1.91826417e-04   6.83768513e-03   3.99024487e-02
    1.93416036e-03   6.71963353e-05   2.15322655e-02   1.86165038e-03
    7.30713771e-04   1.62407072e-04   3.27141699e-03   2.86209630e-03
    4.74143308e-03]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 38
images_for_training/263
(1, 64, 64, 3)
Policy eval: 
[[  4.04540333e-06   9.90333259e-01   6.55596014e-05   6.35848529e-09
    6.79790269e-09   2.17297376e-04   8.67648140e-08   4.96061565e-03
    1.76772577e-04   3.15993966e-04   1.97102060e-03   1.89739531e-08
    3.69247488e-07   1.03808571e-08   4.03661858e-07   1.76631438e-05
    3.53965284e-08   5.60577291e-08   1.70656591e-08   4.22382556e-07
    6.66263877e-05   1.65035114e-08   5.53508471e-07   1.89652329e-08
    6.73046596e-09   2.64886239e-07   1.97989939e-05   1.91866966e-05
    7.96761560e-06   4.41705730e-08   1.94370674e-04   7.81814038e-07
    5.29002548e-08   1.04239980e-05   1.13214246e-05   1.28787030e-06
    5.49735546e-07   2.37437492e-09   1.16270570e-07   1.60199904e-03
    1.00765783e-06]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 39
images_for_training/138
(1, 64, 64, 3)
Policy eval: 
[[ 0.03487006  0.04107162  0.03089433  0.02142549  0.02380996  0.02170246
   0.02392203  0.02867806  0.02501062  0.03243785  0.02377825  0.02082418
   0.0214892   0.01753271  0.02037223  0.02574479  0.02079457  0.02501573
   0.0164758   0.03235579  0.03157419  0.02297509  0.02375878  0.01731017
   0.02411842  0.01590281  0.01941061  0.02022565  0.0294461   0.01956813
   0.02441147  0.01935146  0.02198642  0.02393757  0.02982785  0.03937161
   0.02059709  0.02243814  0.01911145  0.020949    0.02552233]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 40
images_for_training/60
(1, 64, 64, 3)
Policy eval: 
[[  4.56627943e-02   8.48827660e-02   3.06198355e-02   8.16212210e-04
    3.35420656e-04   2.28417781e-03   1.24226511e-01   1.10426359e-01
    9.17840898e-02   1.36158615e-01   5.64188994e-02   2.25494019e-04
    2.16668705e-03   8.22255446e-04   3.02095339e-03   5.24593666e-02
    5.90844639e-03   7.31034158e-03   3.46333440e-03   3.78527977e-02
    2.37017423e-02   1.13891947e-04   6.39315695e-04   4.70871199e-03
    2.42888043e-03   4.36102448e-04   1.05490535e-02   6.98823715e-04
    2.82323677e-02   5.29498374e-03   1.32532185e-02   3.05237737e-03
    3.00155743e-03   3.90617503e-03   7.78525695e-03   4.63014208e-02
    1.44075591e-03   1.46250764e-03   1.67556875e-03   4.25181650e-02
    1.95383350e-03]]
Action: 0.5
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 41
images_for_training/297
(1, 64, 64, 3)
Policy eval: 
[[  3.68808920e-04   6.25784039e-01   2.27200333e-02   2.64543341e-05
    6.05607331e-02   1.61126058e-03   8.58732779e-03   1.94349021e-01
    1.65124761e-03   2.74216309e-02   1.37533969e-03   7.09954693e-05
    1.74140485e-04   3.02580651e-03   5.68159267e-05   8.13299703e-05
    1.89864950e-04   1.79562176e-05   2.11862163e-04   2.97682965e-03
    1.80359895e-03   3.36058525e-04   9.57774580e-04   3.14389908e-04
    5.35683175e-05   9.19792801e-05   1.06845435e-03   1.69295396e-04
    7.20370212e-04   1.29672075e-02   9.64204490e-04   1.33286864e-02
    5.94898484e-05   2.33041961e-03   1.81221799e-03   5.39375935e-03
    4.84156044e-04   1.85624114e-03   1.52671314e-03   2.11385475e-03
    3.86059168e-04]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 42
images_for_training/21
(1, 64, 64, 3)
Policy eval: 
[[  2.88019609e-03   2.00089470e-01   3.02059017e-02   7.55444111e-04
    1.81653583e-03   3.77884204e-03   2.57610977e-02   1.70601793e-02
    4.19548303e-02   8.41930211e-02   1.96412802e-02   2.70772784e-04
    4.48236620e-04   4.24426189e-03   8.87462811e-04   1.94501746e-02
    7.92480481e-04   3.50964518e-04   8.28696322e-03   8.61407071e-03
    1.25990242e-01   3.25785740e-03   1.54120731e-03   8.56555067e-03
    1.31695197e-04   6.32295245e-03   5.17488341e-04   1.10950309e-03
    1.14865825e-02   2.46410444e-02   3.98693467e-03   6.28971830e-02
    4.62399446e-04   2.74156500e-02   1.03685772e-02   4.99289529e-03
    8.27648561e-04   2.43528932e-03   2.55078427e-03   2.28248641e-01
    7.67648744e-04]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 43
images_for_training/95
(1, 64, 64, 3)
Policy eval: 
[[ 0.00966067  0.54045904  0.05310996  0.00371737  0.0142542   0.01127349
   0.0033594   0.02603365  0.04254466  0.02012935  0.06674421  0.00124421
   0.00475141  0.00227312  0.00062612  0.00551697  0.00124084  0.0054041
   0.00773506  0.01813089  0.00604877  0.00437714  0.00160228  0.00511406
   0.00174168  0.00267078  0.00259556  0.00272387  0.00483496  0.00138427
   0.03241057  0.02380529  0.00391065  0.00615469  0.01336388  0.01975503
   0.00189056  0.00252041  0.00230125  0.01109625  0.01148929]]
Action: 1.5
Enter Reward: 0
Backpropping 

Session Number 44
images_for_training/2
(1, 64, 64, 3)
Policy eval: 
[[ 0.002957    0.17472534  0.19404283  0.00033803  0.00097162  0.01735622
   0.02091594  0.12620535  0.00308974  0.02997102  0.03304351  0.03052156
   0.00134856  0.00363022  0.00239227  0.00546283  0.00958507  0.00808545
   0.00277949  0.02410208  0.03062358  0.02169259  0.00170415  0.00130764
   0.00026317  0.00066934  0.0032304   0.00227905  0.0497581   0.00214137
   0.05206137  0.0019638   0.02007451  0.00313706  0.01657207  0.02076884
   0.00304155  0.05298307  0.00788162  0.01325256  0.00307001]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 45
images_for_training/68
(1, 64, 64, 3)
Policy eval: 
[[ 0.00054708  0.22897264  0.05170312  0.01109817  0.01792615  0.01216433
   0.02147556  0.03255647  0.01785195  0.08837889  0.01153413  0.0024956
   0.00286138  0.00468355  0.02135262  0.0174355   0.00616688  0.0003017
   0.00744922  0.00770985  0.05460151  0.00550973  0.01699812  0.00190134
   0.00404247  0.02104345  0.01567735  0.02638914  0.00238712  0.02072071
   0.00182705  0.0307517   0.00372324  0.06316198  0.02327286  0.02206504
   0.00428061  0.07020795  0.00342075  0.03859264  0.00476039]]
Action: 0.25
Enter Reward: 0
Backpropping 

Session Number 46
images_for_training/20
(1, 64, 64, 3)
Policy eval: 
[[ 0.00443124  0.30627641  0.01326663  0.01750156  0.0070071   0.00486333
   0.00322945  0.04831124  0.00623596  0.28281227  0.00420273  0.00236943
   0.00399747  0.00571352  0.02370499  0.00717614  0.00672205  0.00096555
   0.00497534  0.00360597  0.01781093  0.00259868  0.00157315  0.01072714
   0.00091984  0.01417457  0.00356035  0.00419869  0.00180836  0.00587536
   0.00379748  0.02449596  0.00857064  0.05391794  0.01182183  0.00187161
   0.00146001  0.01408755  0.0014888   0.056043    0.00182977]]
Action: 1.1
Enter Reward: 1
Backpropping 

Session Number 47
images_for_training/35
(1, 64, 64, 3)
Policy eval: 
[[ 0.00397141  0.14637242  0.01691938  0.00899055  0.04627959  0.01337387
   0.09068693  0.01633381  0.00609872  0.03764236  0.02251982  0.0107399
   0.02746248  0.02231316  0.01546604  0.01519677  0.0104846   0.00717831
   0.0199101   0.02101438  0.01019156  0.01898665  0.03143177  0.00574832
   0.01230802  0.00671893  0.01784483  0.04426356  0.03140607  0.02274368
   0.0227904   0.03062112  0.01216965  0.01005719  0.03080564  0.02159914
   0.01554845  0.04526505  0.00831826  0.02455408  0.01767316]]
Action: 0.4
Enter Reward: 0
Backpropping 

Session Number 48
images_for_training/230
(1, 64, 64, 3)
Policy eval: 
[[ 0.0026785   0.30978259  0.05987363  0.02102804  0.00829472  0.0021537
   0.00908385  0.04417409  0.06223494  0.137743    0.02597157  0.00215516
   0.00065584  0.00284876  0.00039865  0.01417921  0.01740726  0.00218501
   0.00082746  0.0068076   0.01005774  0.00495853  0.01409746  0.00595799
   0.00236482  0.00043135  0.01840358  0.00147322  0.00180616  0.00377458
   0.02098325  0.06038896  0.00151024  0.00862002  0.00393097  0.0045489
   0.00341531  0.00359464  0.00805824  0.02762939  0.06351112]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 49
images_for_training/70
(1, 64, 64, 3)
Policy eval: 
[[ 0.02053358  0.04840864  0.04119436  0.02063577  0.01259996  0.01773165
   0.02599331  0.02317388  0.03101757  0.05089457  0.01850478  0.00771621
   0.01920765  0.01728554  0.00756479  0.02689392  0.02736795  0.01077182
   0.01702627  0.0205522   0.05477925  0.01254526  0.03674304  0.01794278
   0.01588555  0.0108411   0.02708287  0.01489914  0.01646189  0.03606208
   0.02857264  0.03508365  0.01280804  0.02155357  0.04850978  0.02519086
   0.00747406  0.02229413  0.0141292   0.06181888  0.01424784]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 50
images_for_training/184
(1, 64, 64, 3)
Policy eval: 
[[ 0.02218544  0.03456163  0.02625277  0.02144262  0.02499267  0.02065749
   0.02498163  0.02830504  0.02628798  0.02957739  0.02436675  0.02688298
   0.01993076  0.03033768  0.02563617  0.02538513  0.01703333  0.02134437
   0.02457543  0.02601958  0.02580982  0.02394891  0.02839582  0.02529709
   0.01755202  0.02287927  0.02677859  0.01959082  0.02205886  0.02290561
   0.02232774  0.02598404  0.01879773  0.02135128  0.02861311  0.02112793
   0.02486214  0.02556991  0.02654002  0.02676475  0.02208773]]
Action: 0.2
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 51
images_for_training/149
(1, 64, 64, 3)
Policy eval: 
[[ 0.01957274  0.03623668  0.02861171  0.02279862  0.02314682  0.02607207
   0.02807886  0.0235472   0.02727501  0.02259605  0.02633575  0.02231035
   0.02026771  0.02077568  0.01857954  0.02720825  0.0240971   0.02007881
   0.02727115  0.03243488  0.02907535  0.01914304  0.02443949  0.02606755
   0.01606211  0.0199536   0.02525222  0.01813719  0.01734393  0.0282197
   0.03221922  0.02665969  0.02428808  0.02418422  0.02831747  0.02313889
   0.02196478  0.02315083  0.02595204  0.02965976  0.01947585]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 52
images_for_training/225
(1, 64, 64, 3)
Policy eval: 
[[ 0.00169287  0.16720966  0.01613217  0.0057429   0.0060927   0.03921323
   0.0153459   0.1825262   0.02914595  0.01694129  0.03212177  0.01512901
   0.00585798  0.0191117   0.01266547  0.01906173  0.00630026  0.00481247
   0.02985957  0.01413527  0.01743063  0.01759057  0.03573922  0.01312768
   0.00286789  0.01805961  0.02015441  0.01570937  0.00506447  0.03426097
   0.02028369  0.01556111  0.00741782  0.01676021  0.04021709  0.02105798
   0.01012337  0.01520622  0.00582897  0.02107561  0.00736496]]
Action: 1.2
Enter Reward: 0
Backpropping 

Session Number 53
images_for_training/121
(1, 64, 64, 3)
Policy eval: 
[[ 0.02457345  0.03801473  0.0234644   0.02199367  0.02591676  0.02480923
   0.02494221  0.02458594  0.02870644  0.02462917  0.02166486  0.02701278
   0.0213689   0.02418036  0.02181757  0.02518104  0.02312387  0.02292756
   0.02672882  0.02406179  0.02811662  0.02125837  0.02657281  0.02563033
   0.01883568  0.01993376  0.02324703  0.0247556   0.02559952  0.0251174
   0.02279203  0.02289821  0.0227522   0.02679216  0.0264254   0.02374755
   0.0228395   0.02297408  0.02373966  0.02647859  0.01978991]]
Action: 0.55
Enter Reward: 0
Backpropping 

Session Number 54
images_for_training/46
(1, 64, 64, 3)
Policy eval: 
[[ 0.00805658  0.17104508  0.02515135  0.05699417  0.01964128  0.01399838
   0.01117633  0.02414036  0.01977496  0.02594306  0.03659525  0.02253846
   0.00399134  0.00746488  0.00444246  0.07985338  0.00572196  0.00427749
   0.03343599  0.0814424   0.01009796  0.01030109  0.07053687  0.0050257
   0.01157991  0.00188684  0.01709392  0.01048784  0.00653917  0.03109465
   0.01705637  0.00620721  0.01012629  0.00194268  0.04080499  0.00841496
   0.01433551  0.03205254  0.02319506  0.01358773  0.00194756]]
Action: 1.4
Enter Reward: 1
Backpropping 

Session Number 55
images_for_training/177
(1, 64, 64, 3)
Policy eval: 
[[ 0.02296253  0.0353024   0.02425482  0.02474634  0.02218103  0.02456488
   0.02398949  0.0261812   0.02208903  0.02618489  0.02435665  0.02694636
   0.02366144  0.0242885   0.02362619  0.0253518   0.02372983  0.02068977
   0.0271748   0.02360861  0.0258776   0.02133911  0.0274645   0.02510171
   0.02231218  0.02326448  0.02129198  0.02521902  0.02365196  0.02842387
   0.02328555  0.023705    0.02107217  0.02502081  0.02855176  0.02383554
   0.02244167  0.02162332  0.02263486  0.02616166  0.02183072]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 56
images_for_training/205
(1, 64, 64, 3)
Policy eval: 
[[  2.63010291e-03   4.50600207e-01   3.12987380e-02   3.30786556e-02
    1.06032072e-02   4.23928723e-03   1.44526605e-02   5.30365435e-03
    1.35491583e-02   6.09878786e-02   2.87109967e-02   6.40328135e-03
    2.91073928e-03   1.40289068e-02   1.26681756e-03   2.19012355e-03
    1.51122995e-02   4.55382862e-04   4.33562836e-03   6.64392253e-03
    5.96772619e-02   1.08920950e-02   1.95836872e-02   1.33141913e-02
    3.45901051e-03   3.60708975e-04   1.91434678e-02   2.08521378e-03
    4.52744658e-04   8.47586244e-03   3.90715338e-02   7.72376219e-03
    2.54358660e-04   1.01485075e-02   1.62073914e-02   1.75296254e-02
    1.16144062e-03   1.96454022e-03   2.90825795e-02   1.60421617e-02
    1.45680970e-02]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 57
images_for_training/206
(1, 64, 64, 3)
Policy eval: 
[[  7.13767804e-05   8.72888625e-01   1.61035254e-03   3.54440650e-03
    2.10820232e-02   1.77464099e-03   6.46066910e-04   9.36492812e-03
    1.07144902e-03   5.80329867e-03   5.64593531e-04   2.63090215e-06
    2.11025093e-04   2.56981526e-04   4.04982566e-04   5.72411204e-03
    4.45123645e-04   2.03414329e-05   7.94230436e-04   1.93459433e-04
    1.44489494e-03   4.16034658e-04   3.49532217e-02   1.03285565e-04
    2.25591677e-04   5.76037215e-04   3.97834275e-03   4.68916493e-03
    5.64658367e-05   3.04459478e-04   7.82424991e-04   8.82394519e-03
    1.88386941e-03   1.66307972e-03   2.03197938e-03   3.64679552e-04
    6.93522685e-04   1.15815259e-03   1.06602020e-04   8.94112419e-03
    3.28640686e-04]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 58
images_for_training/160
(1, 64, 64, 3)
Policy eval: 
[[ 0.02039477  0.04002158  0.02747487  0.02028385  0.02388437  0.02524789
   0.0212428   0.02520624  0.02328308  0.02672853  0.02483557  0.02833602
   0.0223741   0.02417916  0.01967378  0.02432144  0.02182727  0.0221152
   0.03051427  0.02303367  0.02625632  0.02083019  0.02843541  0.02199973
   0.0212151   0.02268933  0.02076805  0.02526153  0.02204146  0.02599425
   0.0284586   0.02360334  0.02300259  0.02392097  0.024088    0.02587304
   0.02308623  0.0242247   0.02220143  0.02812357  0.02294774]]
Action: 1.85
Enter Reward: 0
Backpropping 

Session Number 59
images_for_training/271
(1, 64, 64, 3)
Policy eval: 
[[  1.23806440e-05   2.57003337e-01   3.73327942e-03   4.30277921e-02
    2.58857879e-04   3.77739954e-04   8.20433721e-04   7.79390451e-04
    1.30837401e-02   2.01027676e-01   1.29598146e-03   1.34305359e-04
    6.05177833e-04   1.52243206e-06   2.09781192e-05   8.93143192e-03
    1.42947538e-04   8.50074969e-07   1.49029994e-03   7.57346061e-05
    4.54423964e-01   4.04048878e-05   2.39170840e-04   4.65001998e-04
    1.66495265e-05   1.21082376e-05   1.17211828e-04   7.43957426e-05
    4.69284132e-05   3.38380691e-04   1.62146392e-03   6.42104074e-04
    8.66604445e-04   6.56314474e-03   8.32267222e-04   1.46022241e-04
    6.35292372e-06   1.41448792e-04   3.64058142e-05   3.06116504e-04
    2.39990186e-04]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 60
images_for_training/127
(1, 64, 64, 3)
Policy eval: 
[[ 0.01998082  0.05098392  0.02848759  0.02339283  0.02765184  0.02292679
   0.0238365   0.02804783  0.0240626   0.03402456  0.0166693   0.02577912
   0.02475641  0.02208249  0.01955832  0.02153296  0.02026748  0.01489066
   0.02775778  0.01951441  0.02807055  0.02127652  0.028914    0.02551279
   0.01972185  0.01976207  0.02118247  0.02301424  0.01836501  0.02746095
   0.02535309  0.02714139  0.02104232  0.03347453  0.03039166  0.02506348
   0.01972324  0.01998167  0.0207682   0.02311562  0.02446012]]
Action: 0.4
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 61
images_for_training/103
(1, 64, 64, 3)
Policy eval: 
[[ 0.01147218  0.06596609  0.02822664  0.02758761  0.02486056  0.02787117
   0.03293243  0.01901095  0.02851018  0.04491027  0.01929838  0.02045057
   0.01582946  0.02069771  0.0158907   0.03183746  0.02078213  0.01043737
   0.01598535  0.03710841  0.03010626  0.01178869  0.02257474  0.02438939
   0.01838921  0.01692341  0.03048101  0.01436493  0.01032708  0.0241292
   0.03126512  0.03037173  0.0137311   0.03592896  0.02375176  0.02321884
   0.01629706  0.03209123  0.01874239  0.03348558  0.01797671]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 62
images_for_training/280
(1, 64, 64, 3)
Policy eval: 
[[  2.36732513e-03   3.35504800e-01   3.57317913e-04   1.43099697e-02
    6.79778308e-02   9.65827145e-03   8.55783373e-03   2.49833916e-03
    1.23480055e-03   2.34273355e-03   1.02667222e-02   2.42356304e-02
    8.85553964e-05   2.03127391e-03   3.09804501e-03   1.50554942e-03
    7.63934149e-05   3.06376838e-04   4.05155756e-02   1.08435126e-02
    1.02429083e-02   2.90048290e-02   9.84496623e-03   8.53431062e-04
    1.13796117e-03   2.17241788e-04   6.97694952e-04   3.21601182e-02
    2.76936684e-04   1.11852266e-01   3.00895714e-04   8.13300312e-02
    3.16138472e-03   6.01183670e-03   3.41676438e-04   2.53907070e-02
    1.55897783e-02   1.30287677e-01   1.65227416e-03   1.80320372e-03
    6.53074894e-05]]
Action: 0.95
Enter Reward: 0
Backpropping 

Session Number 63
images_for_training/107
(1, 64, 64, 3)
Policy eval: 
[[ 0.01583453  0.05025249  0.02497016  0.02831371  0.02404028  0.03084751
   0.02097631  0.03029055  0.01887078  0.02752263  0.02753888  0.02256518
   0.01757268  0.02601945  0.02599227  0.0185595   0.02635637  0.01997306
   0.024625    0.023136    0.02281638  0.01895924  0.02690476  0.02149306
   0.02243745  0.02319778  0.02369508  0.019203    0.01435831  0.02939926
   0.02045374  0.02617366  0.02951128  0.03734707  0.0293417   0.0215218
   0.02484367  0.01949688  0.01863174  0.02173183  0.02422492]]
Action: 0.35
Enter Reward: 0
Backpropping 

Session Number 64
images_for_training/30
(1, 64, 64, 3)
Policy eval: 
[[  1.58413989e-03   8.10748994e-01   6.92616403e-03   3.95199843e-03
    2.26997188e-03   4.34964051e-04   1.32682745e-03   1.30324066e-02
    3.76567035e-03   1.85503450e-03   3.79154342e-04   4.47281897e-02
    8.83648972e-05   2.15530954e-03   5.21989726e-03   8.01721879e-04
    6.58159261e-05   2.20830855e-03   1.53846620e-02   1.82830234e-04
    3.97166423e-03   1.90576166e-03   1.04362071e-02   4.26165061e-04
    3.99008823e-05   1.36779374e-04   7.01981364e-04   4.32056666e-04
    3.99205601e-04   8.87728762e-03   3.03037092e-02   7.23673962e-03
    1.83354504e-03   3.18835001e-03   1.25092128e-03   4.62203752e-03
    9.89953405e-04   5.31874248e-04   3.02203908e-03   8.30153818e-04
    1.75327132e-03]]
Action: 1.9
Enter Reward: 1
Backpropping 

Session Number 65
images_for_training/79
(1, 64, 64, 3)
Policy eval: 
[[ 0.00330835  0.29342133  0.00894231  0.00259194  0.17784381  0.00518388
   0.01086091  0.00590578  0.00964921  0.01249658  0.02990213  0.00333527
   0.00911387  0.00927168  0.0218833   0.00837969  0.0126592   0.00582182
   0.04557181  0.02533568  0.02140537  0.00502916  0.00492273  0.00372997
   0.00123745  0.00243262  0.03637942  0.00279973  0.00781045  0.01620761
   0.02177382  0.0142173   0.0064723   0.02593098  0.02107241  0.04045554
   0.00126206  0.02051263  0.02588878  0.01469429  0.0042869 ]]
Action: 1.6
Enter Reward: 0
Backpropping 

Session Number 66
images_for_training/133
(1, 64, 64, 3)
Policy eval: 
[[ 0.02291177  0.03587804  0.02573559  0.02689591  0.02770384  0.02234861
   0.02328265  0.02422039  0.02299413  0.03153584  0.01907674  0.02642556
   0.0208143   0.02301059  0.02373484  0.02419219  0.02158174  0.02033381
   0.02830336  0.02738935  0.02871572  0.02478997  0.02530435  0.02419823
   0.02007906  0.02474515  0.02028008  0.02377894  0.02440872  0.02384616
   0.0238576   0.02389054  0.02355734  0.02786464  0.02788603  0.0233423
   0.01872684  0.02478927  0.02211655  0.02309588  0.0223574 ]]
Action: 0.2
Enter Reward: 0
Backpropping 

Session Number 67
images_for_training/6
(1, 64, 64, 3)
Policy eval: 
[[  2.96144435e-06   9.78789747e-01   1.58276487e-06   1.35454477e-03
    1.13288424e-05   5.95708480e-06   2.16102706e-07   7.80738774e-05
    1.15104392e-07   4.59605981e-05   8.79328013e-07   2.93004559e-04
    5.51114965e-07   2.99736639e-05   1.69206050e-05   1.49791795e-05
    1.50121437e-07   4.89919898e-07   8.61095916e-03   1.57964780e-06
    6.92028785e-04   1.33639435e-06   1.48459093e-03   9.04527326e-07
    4.39488133e-07   9.57340376e-07   3.74330615e-04   2.12654177e-05
    1.19550175e-04   7.15959910e-03   5.13961306e-04   5.86978967e-05
    1.75613286e-06   1.67446215e-05   2.00678172e-04   1.71136696e-06
    2.56420481e-06   7.20915887e-06   2.66373736e-05   2.88586725e-05
    2.60875549e-05]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 68
images_for_training/186
(1, 64, 64, 3)
Policy eval: 
[[ 0.02510612  0.03289231  0.02627537  0.02325057  0.02721877  0.02165225
   0.02243258  0.02416931  0.02575117  0.02538785  0.02234666  0.02668503
   0.02157504  0.02230828  0.02415363  0.02459646  0.02468073  0.02356888
   0.02546225  0.02757629  0.02485644  0.02399468  0.02539072  0.0242688
   0.02259363  0.02348702  0.0230916   0.02296558  0.02442237  0.02477369
   0.02523251  0.02192599  0.02372414  0.02299086  0.02392465  0.02571557
   0.02207787  0.0264259   0.02468826  0.02166557  0.0246946 ]]
Action: 0.4
Enter Reward: 0
Backpropping 

Session Number 69
images_for_training/278
(1, 64, 64, 3)
Policy eval: 
[[  1.53478652e-08   9.93343711e-01   2.43904287e-05   2.87413623e-05
    1.24912401e-06   7.76625313e-07   1.97570589e-05   1.95685643e-05
    5.04280820e-07   9.96719427e-06   7.08342995e-05   1.93661210e-04
    2.14919473e-05   5.49791991e-07   3.81006157e-06   9.76328738e-06
    7.70906752e-08   5.88686180e-06   3.47132329e-03   1.82470085e-05
    1.26146173e-04   3.84500891e-04   7.39248753e-06   1.38681810e-06
    1.26485156e-06   1.81192902e-07   3.05006438e-06   1.74954810e-04
    6.71598682e-05   2.39852045e-04   7.24788988e-04   3.92947322e-06
    3.47625086e-04   5.48084108e-06   1.75754922e-05   1.16387137e-05
    1.05478748e-05   6.17611862e-04   8.98658436e-06   2.05833700e-07
    1.43735178e-06]]
Action: 0.15
Enter Reward: 0
Backpropping 

Session Number 70
images_for_training/97
(1, 64, 64, 3)
Policy eval: 
[[  1.73399003e-05   9.62566257e-01   4.69229126e-05   4.78884904e-03
    1.49241343e-04   2.56346575e-05   3.70507682e-04   1.14444993e-04
    2.57401680e-05   1.04223331e-02   1.39823533e-04   1.58999974e-04
    1.72333952e-04   2.06918121e-04   3.40887054e-05   3.36568616e-03
    1.43733505e-05   1.43171155e-06   5.09504462e-03   4.61750053e-04
    4.46637440e-03   5.62926463e-04   1.02923810e-03   6.09240727e-04
    2.64310045e-04   6.21436120e-05   3.42755433e-04   9.43172316e-04
    2.06147801e-04   6.03355118e-04   3.01515509e-04   5.20668109e-04
    4.64068173e-04   1.94116496e-04   4.44183097e-04   2.65978422e-04
    3.14373065e-05   2.94446363e-04   1.65163627e-04   9.40052632e-06
    4.15755203e-05]]
Action: 0.9
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 71
images_for_training/111
(1, 64, 64, 3)
Policy eval: 
[[ 0.01884512  0.06369627  0.02809041  0.02375828  0.02764977  0.03396928
   0.01653076  0.02587007  0.02050486  0.02478605  0.02456489  0.03237767
   0.01825088  0.02267759  0.02548465  0.02059927  0.01986519  0.01736849
   0.03062254  0.02954025  0.01777604  0.02685467  0.04067589  0.01999006
   0.01728871  0.01119512  0.01884107  0.01979091  0.01624109  0.02952396
   0.02659468  0.01886404  0.01781697  0.02334049  0.02549168  0.03016418
   0.02565601  0.02778535  0.02342063  0.01773633  0.01989976]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 72
images_for_training/74
(1, 64, 64, 3)
Policy eval: 
[[ 0.01467714  0.3130402   0.05705559  0.01724186  0.02191973  0.00594388
   0.00560494  0.00658028  0.06429854  0.05301298  0.00548252  0.01383626
   0.00456699  0.00297514  0.00421254  0.01628623  0.03107938  0.00276858
   0.05078988  0.06822053  0.03481833  0.00135006  0.02135691  0.0080164
   0.00174412  0.00475981  0.01033826  0.00389969  0.01118953  0.01006297
   0.03321759  0.009778    0.00563239  0.01243639  0.00493131  0.00879313
   0.00309105  0.00443232  0.01437367  0.02022841  0.01595648]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 73
images_for_training/27
(1, 64, 64, 3)
Policy eval: 
[[ 0.01357338  0.2538088   0.02035688  0.01451418  0.01599455  0.0092879
   0.01604027  0.01816353  0.02156801  0.02195865  0.01926007  0.02908912
   0.01129675  0.02071636  0.00851078  0.00980597  0.01645718  0.00886515
   0.04424518  0.03108437  0.0178024   0.01509304  0.01707651  0.01701051
   0.00915911  0.02878764  0.00927261  0.01081147  0.0155431   0.04620263
   0.02332807  0.01850177  0.01762584  0.02240372  0.02528288  0.02019719
   0.00753604  0.01380793  0.02800716  0.01524344  0.01670995]]
Action: 0.9
Enter Reward: 1
Backpropping 

Session Number 74
images_for_training/115
(1, 64, 64, 3)
Policy eval: 
[[ 0.01895363  0.05454392  0.02412014  0.02214333  0.02420252  0.02071983
   0.02035482  0.03115065  0.02441351  0.03640868  0.01723697  0.01944966
   0.03140818  0.02572815  0.01993559  0.01895398  0.02881882  0.01060418
   0.03072577  0.03368118  0.02082818  0.02101213  0.02797751  0.01288502
   0.0234053   0.015431    0.01970005  0.02477302  0.02668952  0.02374006
   0.03139855  0.01831676  0.02982761  0.02461197  0.03511169  0.02293419
   0.01297434  0.02167593  0.02079821  0.02274408  0.02961134]]
Action: 0.2
Enter Reward: 0
Backpropping 

Session Number 75
images_for_training/272
(1, 64, 64, 3)
Policy eval: 
[[ 0.02786478  0.07606938  0.02870017  0.02035003  0.0324555   0.01620336
   0.02063447  0.02484683  0.0250701   0.02029792  0.02435843  0.02567465
   0.00801701  0.0273573   0.03646393  0.01941707  0.01391195  0.01585651
   0.0335891   0.02800057  0.0223594   0.03200021  0.05067337  0.0149434
   0.02118854  0.01514905  0.01702983  0.01474984  0.02302725  0.01930021
   0.02043433  0.01858066  0.03103692  0.01993422  0.01408799  0.03271097
   0.02622143  0.02054968  0.0162112   0.01126338  0.03340908]]
Action: 0.55
Enter Reward: 1
Backpropping 

Session Number 76
images_for_training/118
(1, 64, 64, 3)
Policy eval: 
[[ 0.02617862  0.02799604  0.0251098   0.02504914  0.02460299  0.02412457
   0.02402599  0.02386056  0.02486679  0.025409    0.02347937  0.02395047
   0.02461504  0.02345769  0.02519356  0.02406273  0.02407768  0.02379528
   0.02434647  0.02321727  0.02369585  0.02321616  0.02450687  0.02366567
   0.02339502  0.0232388   0.02393887  0.02522454  0.02300843  0.02347497
   0.02481079  0.0256367   0.02572435  0.02410193  0.02503993  0.02318217
   0.02444744  0.02500759  0.02465201  0.02298979  0.02562298]]
Action: 1.8
Enter Reward: 0
Backpropping 

Session Number 77
images_for_training/257
(1, 64, 64, 3)
Policy eval: 
[[ 0.07858852  0.11227638  0.02799815  0.04208025  0.00704837  0.01580843
   0.01135664  0.01300356  0.00794705  0.02284708  0.00221365  0.02517766
   0.01060061  0.01541889  0.01585864  0.00790351  0.02439682  0.0279518
   0.03683583  0.04172946  0.03039732  0.00468202  0.01865005  0.00671841
   0.00533143  0.01229157  0.00492272  0.02781488  0.02055156  0.02543564
   0.01698882  0.010915    0.04917142  0.01726587  0.04560035  0.04306117
   0.02009248  0.01033457  0.03156723  0.01409462  0.0370716 ]]
Action: 1.7
Enter Reward: 0
Backpropping 

Session Number 78
images_for_training/266
(1, 64, 64, 3)
Policy eval: 
[[ 0.04822915  0.07892694  0.05698955  0.02033353  0.02744169  0.02328234
   0.01117517  0.02023193  0.01930553  0.08258948  0.01201491  0.02023878
   0.01756734  0.01226992  0.01989497  0.01142204  0.03660706  0.02025121
   0.01464661  0.02890752  0.02676375  0.01449555  0.02031271  0.01162134
   0.01316019  0.01147451  0.01325662  0.01294072  0.0226141   0.0142452
   0.02697745  0.00732678  0.02436686  0.07092338  0.03679289  0.01941657
   0.00923557  0.01394495  0.0208526   0.0124322   0.01452035]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 79
images_for_training/232
(1, 64, 64, 3)
Policy eval: 
[[ 0.04617489  0.163928    0.03287105  0.01316467  0.02895107  0.01474888
   0.02113743  0.02495678  0.04346957  0.04128076  0.0118129   0.02617559
   0.01415814  0.0222776   0.01456247  0.02276522  0.02326882  0.01731099
   0.0215519   0.02397989  0.01931257  0.0155836   0.01785109  0.01299412
   0.01337636  0.00643909  0.01683533  0.0220702   0.031516    0.01480622
   0.02039481  0.01347776  0.0111569   0.02738343  0.0163578   0.02236545
   0.01446116  0.01381868  0.02336283  0.01842054  0.01946952]]
Action: 0.15
Enter Reward: 0
Backpropping 

Session Number 80
images_for_training/206
(1, 64, 64, 3)
Policy eval: 
[[  6.76253319e-01   6.09072745e-02   1.68977119e-02   9.75473132e-03
    3.01452652e-02   1.10237673e-02   1.64498098e-03   1.10763567e-03
    4.58297320e-03   2.97783921e-03   1.37111754e-04   6.44593127e-03
    1.11788744e-03   2.47763703e-03   1.47774222e-03   1.58740114e-03
    8.74839257e-03   5.97298727e-04   1.87955296e-03   1.15754770e-03
    1.37193897e-03   1.31488836e-03   8.26729685e-02   4.59633156e-04
    7.38834089e-04   3.80201178e-04   1.42128789e-03   4.08237014e-04
    1.87127641e-03   3.65666929e-03   6.87885378e-03   1.79261400e-03
    2.51446734e-03   3.01091466e-03   2.51436792e-02   5.66643709e-03
    6.29136851e-03   2.92100455e-03   9.35671676e-04   2.53671408e-03
    7.09033199e-03]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 81
images_for_training/38
(1, 64, 64, 3)
Policy eval: 
[[ 0.08261823  0.04035351  0.03135803  0.03014725  0.02878311  0.01616772
   0.02349804  0.01680134  0.02179452  0.0155555   0.01879572  0.02719752
   0.02819459  0.02627791  0.01665852  0.01624841  0.02777061  0.02444931
   0.02110697  0.02958379  0.01597033  0.01475091  0.02072432  0.01917362
   0.01376603  0.01463969  0.02589701  0.01824599  0.02253854  0.0220477
   0.02859028  0.01878699  0.02165776  0.02276063  0.02681301  0.0360471
   0.01642123  0.01329953  0.03969105  0.02236793  0.02244981]]
Action: 1.05
Enter Reward: 1
Backpropping 

Session Number 82
images_for_training/14
(1, 64, 64, 3)
Policy eval: 
[[ 0.22407193  0.05580774  0.01920799  0.04740047  0.00562885  0.00152795
   0.01317518  0.04047842  0.02801184  0.00448639  0.03745645  0.04142035
   0.01117183  0.00361602  0.00194976  0.01153606  0.00400746  0.0222487
   0.05615162  0.0034118   0.0245619   0.00177093  0.00156888  0.00731861
   0.00278784  0.00153051  0.00547473  0.00153317  0.00624314  0.00345645
   0.03404444  0.0099931   0.03455544  0.00745247  0.04483693  0.07377131
   0.00118837  0.00207431  0.07533372  0.01834952  0.00938734]]
Action: 1.5
Enter Reward: 1
Backpropping 

Session Number 83
images_for_training/165
(1, 64, 64, 3)
Policy eval: 
[[ 0.0271291   0.0289136   0.02464399  0.02612172  0.02452653  0.02388611
   0.02329785  0.02504176  0.02418169  0.02590295  0.0266234   0.02408619
   0.02431558  0.02266138  0.02136739  0.02520924  0.02643961  0.02226115
   0.02469883  0.02272714  0.0242191   0.02314265  0.02331719  0.02460145
   0.02307911  0.02089087  0.02429045  0.02545537  0.02279585  0.02423355
   0.02623544  0.024369    0.02547551  0.02437489  0.02476445  0.02388375
   0.0225982   0.02377608  0.02527828  0.02577254  0.02341099]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 84
images_for_training/44
(1, 64, 64, 3)
Policy eval: 
[[ 0.1512049   0.08314957  0.01730058  0.0202347   0.01528277  0.02253876
   0.0375555   0.01544765  0.01579807  0.01660001  0.01879404  0.02130988
   0.01709163  0.018977    0.01985114  0.0158077   0.03417497  0.01931883
   0.0214048   0.02362092  0.02844898  0.01105676  0.01283261  0.02063554
   0.01242631  0.02005209  0.00968548  0.01375987  0.01756719  0.01872248
   0.02155479  0.01874303  0.01342661  0.02164941  0.02903956  0.03818388
   0.0221642   0.01133844  0.02330691  0.01282506  0.01711736]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 85
images_for_training/137
(1, 64, 64, 3)
Policy eval: 
[[ 0.03328963  0.03112389  0.02664339  0.02650067  0.02541397  0.02316612
   0.02191848  0.02240574  0.02686538  0.02564867  0.02014061  0.02371657
   0.02457976  0.0223649   0.02154531  0.02351042  0.02461411  0.02389436
   0.02565381  0.02272241  0.02556353  0.02308597  0.02480802  0.02458434
   0.02092697  0.02278056  0.02246522  0.02506769  0.02440022  0.0217066
   0.02536112  0.02450978  0.02575576  0.02511054  0.02438607  0.02558406
   0.02416708  0.02437658  0.02265878  0.02166652  0.02531631]]
Action: 1.0
Enter Reward: 0
Backpropping 

Session Number 86
images_for_training/116
(1, 64, 64, 3)
Policy eval: 
[[ 0.0326315   0.04590459  0.02525587  0.02827352  0.02517753  0.02043742
   0.02116708  0.02565292  0.02810908  0.02537847  0.02469252  0.02314764
   0.02127594  0.02155232  0.02147586  0.02441915  0.0271071   0.02148203
   0.02871915  0.02433518  0.03019115  0.02498242  0.02137823  0.02435117
   0.01573973  0.02183811  0.02047629  0.02501329  0.02334511  0.02502648
   0.02139949  0.02309041  0.02294399  0.02896823  0.02170567  0.02307304
   0.02246576  0.01754143  0.0244059   0.02560971  0.02025957]]
Action: 2.0
Enter Reward: 1
Backpropping 

Session Number 87
images_for_training/79
(1, 64, 64, 3)
Policy eval: 
[[ 0.19014432  0.11961912  0.01732033  0.02215161  0.01488642  0.01848812
   0.01825857  0.03682384  0.00768726  0.02782003  0.00187271  0.01279485
   0.01080297  0.01708586  0.02133817  0.00867238  0.01632748  0.01598385
   0.03583385  0.01251273  0.03548373  0.01114649  0.01304212  0.00339619
   0.00433991  0.00645046  0.01106498  0.01135436  0.01537405  0.01981292
   0.022356    0.01762221  0.02254419  0.0219469   0.07170737  0.02708494
   0.00798077  0.00937594  0.01178073  0.0173963   0.01231499]]
Action: 1.15
Enter Reward: 1
Backpropping 

Session Number 88
images_for_training/242
(1, 64, 64, 3)
Policy eval: 
[[ 0.05824279  0.12580481  0.03957852  0.01839872  0.05750722  0.01642555
   0.01755592  0.03411438  0.0212802   0.03936079  0.02036012  0.01653855
   0.01537409  0.01066151  0.0131926   0.02080333  0.01593078  0.01652345
   0.01936096  0.02388224  0.0187791   0.01667579  0.01827212  0.01257973
   0.0104062   0.01628613  0.0167143   0.03060613  0.01573191  0.02007831
   0.02798201  0.01818926  0.03004581  0.02648338  0.01523678  0.0204108
   0.00866272  0.02563726  0.01560873  0.02387998  0.01083708]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 89
images_for_training/72
(1, 64, 64, 3)
Policy eval: 
[[ 0.08071943  0.54392207  0.03464939  0.01207074  0.02968795  0.00544365
   0.00856838  0.01315819  0.01117148  0.00706977  0.00236109  0.01180764
   0.00227586  0.00378882  0.00283685  0.00480897  0.01190292  0.00666888
   0.01241377  0.00888178  0.00547686  0.0032822   0.0056958   0.0040624
   0.0010956   0.00555897  0.00651167  0.01095038  0.01050869  0.01386648
   0.01199169  0.00658739  0.00957967  0.00906915  0.01274607  0.01585178
   0.00564611  0.00826397  0.01108978  0.01349444  0.01446337]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 90
images_for_training/59
(1, 64, 64, 3)
Policy eval: 
[[ 0.04432521  0.05174834  0.02500643  0.01973858  0.02670305  0.02519877
   0.01893308  0.02974721  0.01907416  0.02262147  0.02113496  0.0284612
   0.0214499   0.02513275  0.02058402  0.02044161  0.02199992  0.02307136
   0.02696558  0.02177296  0.02588315  0.03310435  0.02046905  0.01749972
   0.01701933  0.01422161  0.02170008  0.01867506  0.03104777  0.01887181
   0.0288446   0.01810588  0.02581394  0.02302675  0.02948464  0.03062673
   0.0225789   0.02199479  0.01991153  0.0261635   0.02084618]]
Action: 0.6
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 91
images_for_training/38
(1, 64, 64, 3)
Policy eval: 
[[ 0.05409871  0.43642914  0.04204475  0.01645361  0.01540958  0.00631362
   0.01106288  0.0094285   0.00738335  0.02513165  0.00365686  0.01291577
   0.01037246  0.00597453  0.01486576  0.01665891  0.00951667  0.00982147
   0.01137177  0.01155848  0.03351128  0.0088278   0.00955896  0.00644001
   0.00660851  0.01421077  0.00562572  0.01660239  0.0075066   0.00597163
   0.01210795  0.01265359  0.01993251  0.02110438  0.01320032  0.0264758
   0.00976897  0.00827999  0.00819816  0.01003805  0.0129082 ]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 92
images_for_training/179
(1, 64, 64, 3)
Policy eval: 
[[ 0.03151029  0.04674555  0.03152855  0.02214074  0.03073278  0.02458691
   0.02179748  0.02302128  0.02086487  0.02821295  0.01675664  0.02460541
   0.02331456  0.02541403  0.02265823  0.02121166  0.02702761  0.0237998
   0.02389707  0.02271423  0.02002781  0.02377247  0.02394418  0.01925869
   0.02072     0.02174961  0.02308176  0.02771239  0.02579274  0.02186977
   0.02577231  0.02378479  0.02633905  0.02292672  0.02590496  0.02473844
   0.02099043  0.02340781  0.02095255  0.02092081  0.02379204]]
Action: 1.9
1
Enter Reward: Backpropping 

Session Number 93
images_for_training/247
(1, 64, 64, 3)
Policy eval: 
[[  2.33101472e-02   9.76659656e-01   4.91244873e-06   2.92410664e-06
    5.42987152e-07   1.44517953e-09   2.18747147e-07   1.07516387e-08
    1.30728381e-06   4.92634982e-08   1.83086630e-08   1.00754605e-09
    4.41652798e-10   7.18352877e-10   1.97234549e-08   2.02373855e-07
    3.94321347e-07   4.12540153e-08   4.10707145e-07   2.98207787e-08
    3.69136011e-09   8.62526661e-10   4.07494667e-07   1.37911838e-09
    1.02595921e-09   7.83473786e-10   1.06050061e-06   3.55829788e-09
    7.80031328e-09   5.67706820e-07   9.62631202e-06   9.56356629e-08
    3.33748886e-08   3.83744769e-09   1.53110626e-08   8.95585472e-09
    3.84642647e-08   2.33037722e-09   7.22570257e-06   6.78449581e-08
    4.59564564e-09]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 94
images_for_training/243
(1, 64, 64, 3)
Policy eval: 
[[  3.30363438e-02   9.35861111e-01   3.44537618e-03   4.93709289e-04
    3.05016401e-05   1.04542123e-03   8.93226708e-04   1.26373058e-03
    2.98531377e-04   1.77406619e-04   5.73151279e-04   6.78488461e-04
    1.26529150e-04   8.34783132e-05   1.47450104e-04   9.10648610e-04
    2.77750136e-04   3.59296071e-04   1.62882672e-03   1.70036423e-04
    2.35605286e-03   3.43838416e-04   6.38484256e-04   4.35247348e-05
    8.25473107e-05   5.30654332e-04   4.31625318e-04   3.99802695e-04
    2.28761137e-03   1.68195565e-03   1.72026572e-03   8.21131980e-05
    3.55062075e-04   2.01141578e-04   5.90156007e-04   4.00346238e-03
    2.20086076e-04   6.88236178e-05   2.09057331e-03   2.48264434e-04
    1.22891492e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 95
images_for_training/6
(1, 64, 64, 3)
Policy eval: 
[[ 0.0411423   0.70798784  0.02060469  0.0038698   0.00636842  0.00533977
   0.00292463  0.00968699  0.00443221  0.0023662   0.00103314  0.00569937
   0.00400368  0.00446136  0.0077221   0.00547825  0.00241142  0.01213716
   0.00161034  0.0011801   0.01528348  0.00132977  0.00650255  0.00138042
   0.00142291  0.00292955  0.00338056  0.03801986  0.00261307  0.01042412
   0.00479647  0.00829626  0.00514468  0.0083573   0.00572046  0.00932765
   0.00331     0.0023282   0.00228858  0.01326995  0.00341436]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 96
images_for_training/243
(1, 64, 64, 3)
Policy eval: 
[[  8.03577621e-03   9.87112820e-01   7.95513508e-04   1.07981396e-04
    3.54563206e-04   1.11891648e-04   4.20497963e-06   2.95825848e-05
    1.08077566e-05   7.84092626e-05   3.48205387e-04   8.15326566e-05
    7.48581806e-05   4.91682954e-07   3.67201137e-05   1.81801151e-05
    2.93981884e-06   6.58777390e-06   1.89093407e-05   5.25082442e-06
    7.58648210e-04   1.35625510e-06   3.18425441e-06   3.01519390e-06
    2.68309418e-06   1.26355953e-05   4.83293552e-05   5.80193766e-04
    9.43122541e-06   9.41693543e-06   3.58703837e-05   2.29742262e-04
    8.30496487e-04   3.71271381e-05   1.57499580e-05   4.70874584e-05
    1.24538010e-05   5.73547222e-05   1.97263871e-05   2.23855423e-05
    2.78678963e-05]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 97
images_for_training/241
(1, 64, 64, 3)
Policy eval: 
[[  9.36381161e-01   5.10733835e-02   1.19293947e-02   6.84295956e-05
    6.29451688e-06   8.67286599e-06   9.40926668e-07   1.43202360e-05
    1.15498406e-05   1.52172390e-04   2.73924798e-07   3.17248555e-06
    1.38364186e-07   3.53584198e-07   2.88727551e-06   3.20470775e-07
    4.03067105e-07   6.41056204e-07   3.69578970e-07   3.15709894e-06
    5.73930411e-05   3.92845868e-06   4.20121178e-05   7.02088209e-06
    6.44743139e-08   1.78403894e-07   3.73964190e-06   2.36694041e-06
    3.39004578e-06   3.03056197e-07   2.41945463e-06   7.10782979e-06
    6.24947352e-05   3.00929878e-05   2.59050139e-05   5.87069189e-05
    8.79263098e-08   1.10059254e-05   1.52816428e-05   7.10541735e-06
    1.24445614e-06]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 98
images_for_training/243
(1, 64, 64, 3)
Policy eval: 
[[  5.13479754e-04   9.97186244e-01   1.30770914e-05   5.08993326e-05
    1.41095070e-05   4.96811424e-07   2.41546986e-05   2.36648357e-05
    9.42064889e-06   7.36846050e-06   2.77209001e-05   2.40758600e-05
    1.11198960e-06   1.16999308e-06   4.61744293e-07   4.70274317e-05
    5.99157545e-07   3.43618171e-06   7.95874221e-04   5.01983413e-06
    8.73963836e-06   2.76385399e-05   4.88048408e-06   7.54650091e-06
    1.64845824e-05   1.73995769e-08   1.07133301e-05   4.49893669e-05
    5.97021834e-04   1.46391205e-04   6.89976150e-05   7.66317389e-05
    6.36346667e-05   2.39267479e-06   5.84434783e-05   2.09177392e-06
    4.48440260e-05   1.93297674e-05   3.59630867e-05   6.11978794e-06
    7.72187377e-06]]
Action: 1.35
Enter Reward: 0
Backpropping 

Session Number 99
images_for_training/294
(1, 64, 64, 3)
Policy eval: 
[[  6.02874756e-01   3.87219965e-01   2.18985812e-03   9.22513937e-05
    1.07682446e-07   1.73560757e-08   2.07651665e-05   3.12882403e-05
    3.37512558e-03   1.39787429e-04   1.16625633e-05   1.14146722e-07
    3.05440406e-09   1.91795344e-08   6.00686878e-09   1.33613998e-04
    2.24771356e-05   1.35349146e-05   3.14818794e-06   7.99456473e-07
    9.27005931e-06   1.72820819e-06   9.12201131e-07   1.28803949e-03
    3.64569644e-07   6.90737867e-09   7.78325841e-07   8.52012590e-07
    1.89778291e-08   3.91140674e-07   2.06350334e-04   4.24596828e-06
    7.45275912e-08   6.32047977e-06   9.90122226e-06   6.96881500e-04
    3.79400234e-07   8.35388505e-08   1.62428664e-03   1.69034993e-05
    2.88976639e-06]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 18:48:42.842676: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/182
(1, 64, 64, 3)
Policy eval: 
[[  1.59783885e-04   2.68538614e-08   4.08504633e-07   3.52085044e-04
    1.49018941e-02   2.07372897e-04   3.83041624e-04   7.63070107e-01
    5.09422549e-09   9.90277931e-06   1.08532743e-06   3.19629923e-09
    9.66540028e-07   1.90198261e-06   1.02068334e-05   1.91892058e-01
    6.69922400e-03   1.77278207e-03   1.47731691e-06   3.50591290e-06
    1.05319521e-06   2.37515542e-06   9.24958440e-05   1.94896325e-06
    9.35674915e-09   7.80316441e-06   9.00533781e-09   1.67952836e-04
    5.78834397e-06   1.16574418e-04   4.80732888e-05   7.80548761e-03
    9.41338390e-03   3.15167803e-08   2.50825775e-03   3.59820930e-04
    8.82885143e-09   6.62636126e-07   2.67183111e-07   2.30166563e-07
    2.99145384e-08]]
2018-10-05 18:48:43.958 Python[33196:13834703] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 0.9
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/36
(1, 64, 64, 3)
Policy eval: 
[[  5.58625516e-06   1.75738963e-30   9.64229076e-27   7.96158772e-16
    1.60481214e-20   2.87229686e-13   3.96750147e-06   6.86386743e-16
    1.25031370e-15   9.72744125e-21   3.63715395e-21   2.26323401e-20
    2.16860406e-16   2.19705643e-16   3.71863873e-09   3.94593886e-29
    1.58639088e-01   5.22555632e-14   1.00843377e-22   5.48479269e-29
    5.60537735e-30   2.52458807e-13   6.42469308e-20   4.01767541e-22
    1.26026462e-22   1.18906764e-05   3.20065744e-20   1.25648032e-17
    1.53106340e-15   5.94168216e-22   2.65355293e-10   1.45364918e-11
    8.41334760e-01   1.41577674e-28   4.37972039e-06   3.06890598e-07
    1.07155092e-34   1.05085652e-13   5.42636220e-19   3.34153091e-18
    1.05893791e-26]]
Action: 0.3
Enter Reward: 0
Backpropping 

Session Number 2
images_for_training/92
(1, 64, 64, 3)
Policy eval: 
[[  8.46918002e-09   0.00000000e+00   1.37302863e-14   1.96346564e-30
    8.91619469e-20   9.14787219e-16   1.03695728e-08   1.03030657e-21
    4.54031852e-25   5.23592532e-20   8.83856271e-31   2.53886260e-35
    7.30413163e-21   3.01785761e-08   3.58646490e-21   0.00000000e+00
    1.27499238e-01   4.47422654e-10   1.83930963e-26   1.10232131e-14
    0.00000000e+00   7.62321807e-22   2.53255417e-10   5.55263087e-33
    0.00000000e+00   7.68684856e-07   2.14152480e-23   1.57435633e-25
    1.31323194e-19   2.63228500e-21   8.72499943e-01   5.17306679e-21
    1.56520408e-09   0.00000000e+00   1.21197510e-22   5.88347114e-21
    9.47608932e-26   1.03805018e-37   1.86276638e-26   1.45639112e-33
    1.15025600e-14]]
Action: 0.8
Enter Reward: 1
Backpropping 

Session Number 3
images_for_training/240
(1, 64, 64, 3)
Policy eval: 
[[  1.03430841e-06   6.48463204e-34   3.60457849e-33   0.00000000e+00
    2.08650693e-38   0.00000000e+00   5.24911405e-18   1.09613593e-24
    1.10518340e-25   8.33656803e-27   0.00000000e+00   0.00000000e+00
    8.57767782e-26   1.62909657e-13   3.80938928e-32   0.00000000e+00
    9.99998927e-01   3.65471517e-25   0.00000000e+00   0.00000000e+00
    0.00000000e+00   3.96152193e-14   3.21720071e-18   0.00000000e+00
    0.00000000e+00   8.26618324e-32   1.15438512e-32   8.33375335e-16
    2.93946080e-24   6.20187835e-35   2.84597057e-09   5.44351594e-25
    1.66474250e-20   0.00000000e+00   2.57125423e-19   1.62256747e-26
    0.00000000e+00   3.02183873e-28   1.77362491e-34   0.00000000e+00
    5.96392397e-35]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/32
(1, 64, 64, 3)
Policy eval: 
[[  2.48909481e-02   2.83843050e-25   4.40087486e-19   1.87852911e-26
    9.75094140e-01   1.61410284e-17   4.03053018e-18   6.20729579e-11
    1.95710938e-22   2.47943563e-19   8.27951613e-26   1.08026637e-29
    2.85827478e-15   2.93846169e-15   7.22565013e-20   5.45617684e-30
    5.69596637e-09   1.27120243e-26   9.45809893e-19   3.05081658e-19
    2.14812042e-29   2.46858364e-18   8.38043963e-14   1.57165163e-15
    8.21125967e-34   5.49452898e-06   2.25618413e-18   1.95368414e-16
    5.14510622e-11   2.18933218e-17   9.39573420e-06   3.43326917e-18
    3.34918356e-12   4.00565734e-31   4.00894035e-18   1.82263639e-19
    2.58897455e-21   5.55249763e-27   2.37471582e-14   9.56666565e-27
    9.88647325e-27]]
Action: 1.4
Enter Reward: 0
Backpropping 

Session Number 5
images_for_training/34
(1, 64, 64, 3)
Policy eval: 
[[  9.82412577e-01   1.35201160e-12   2.96604119e-09   9.62477450e-17
    1.30230169e-12   3.93938848e-07   1.00950012e-03   1.11111131e-14
    3.54726387e-11   5.10968512e-08   5.20011713e-20   1.28040857e-15
    2.72107831e-15   1.08756048e-07   4.66398170e-11   2.47788622e-19
    5.91999805e-03   2.16855920e-08   1.03715322e-12   1.16429668e-07
    7.77057861e-15   4.09051404e-11   1.27198007e-06   9.14691682e-08
    1.55936828e-15   8.99111630e-09   1.47839301e-14   1.05338881e-06
    1.05845621e-02   1.51574191e-19   3.84863561e-05   1.51263252e-10
    1.07565756e-06   3.60585070e-13   1.27069638e-15   3.06616821e-05
    2.30856436e-12   2.80449383e-12   2.38269907e-13   4.71211958e-09
    1.09303249e-17]]
Action: 0.8
Enter Reward: 1
Backpropping 

Session Number 6
images_for_training/114
(1, 64, 64, 3)
Policy eval: 
[[  1.75532222e-01   6.09833041e-05   3.60137392e-06   1.53461715e-05
    1.25661967e-02   3.27889633e-04   8.59574880e-04   1.45118014e-04
    2.13970733e-03   1.77994196e-03   3.51751405e-05   1.09483441e-03
    2.35084462e-05   4.47818279e-01   1.87951821e-06   1.20914956e-06
    2.67371982e-02   3.52160737e-06   2.30441237e-05   1.08067552e-05
    1.79710514e-05   2.34354613e-03   1.65889054e-04   1.66107748e-05
    2.46042364e-05   9.60287216e-05   4.70185099e-04   2.60368455e-03
    2.15033144e-01   1.19314484e-06   9.89454314e-02   2.10603190e-04
    1.32406072e-03   1.59598985e-05   4.63193841e-03   6.45090418e-04
    2.22612343e-05   3.59457845e-05   3.84492590e-03   3.58460005e-04
    1.25109746e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 7
images_for_training/128
(1, 64, 64, 3)
Policy eval: 
[[  4.53092366e-01   6.77621225e-03   8.63674562e-04   3.42023268e-04
    6.02658242e-02   4.98024374e-03   1.32245710e-02   3.46926972e-03
    1.89408213e-02   1.37359314e-02   1.32426433e-03   4.46117343e-03
    1.21080864e-03   1.32380992e-01   1.61852990e-03   9.82864076e-05
    5.28350100e-02   1.94313249e-03   1.13951461e-03   1.08562375e-03
    1.49867521e-03   4.06576833e-03   3.66951060e-03   5.37306955e-03
    5.03676303e-04   1.17514399e-03   9.44968965e-03   6.79835081e-02
    3.01291402e-02   4.90931794e-04   3.62537056e-02   4.56369948e-03
    6.94184564e-03   4.04451537e-04   1.85900759e-02   5.02306316e-03
    4.06208029e-03   1.66464213e-03   6.04000734e-03   1.78423580e-02
    4.86740726e-04]]
Action: 0.95
Enter Reward: 0
Backpropping 

Session Number 8
images_for_training/263
(1, 64, 64, 3)
Policy eval: 
[[  9.99969840e-01   1.42381949e-25   1.75164159e-18   7.84170212e-23
    7.16474879e-09   2.80925888e-16   9.37572034e-11   1.57545190e-12
    1.36035497e-18   4.31018719e-12   6.06832985e-27   3.48488626e-13
    3.35191130e-14   6.48757040e-16   7.23732319e-09   1.25585056e-32
    1.02603587e-06   7.19232063e-10   4.42007676e-22   1.84237667e-10
    2.04769123e-12   7.23154479e-12   2.88954143e-05   6.81497224e-21
    1.57333454e-31   2.38639529e-07   3.06357412e-10   2.56250472e-11
    3.53470339e-14   2.61550243e-12   3.79345637e-14   5.70033590e-14
    1.26045678e-19   4.84295687e-17   3.54241609e-15   8.82930683e-18
    2.68431696e-24   4.05286914e-24   4.50360748e-16   1.73793434e-21
    8.38542797e-23]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 9
images_for_training/250
(1, 64, 64, 3)
Policy eval: 
[[  6.63392007e-01   8.34133929e-10   1.10800841e-10   5.19839120e-12
    6.40402082e-04   1.28627123e-10   4.28972271e-06   7.42464934e-09
    1.79383064e-09   2.27277155e-07   2.58224775e-10   4.98051413e-08
    5.18855536e-08   9.21519324e-02   3.05735104e-09   2.45142204e-13
    1.51038505e-04   2.55737764e-10   1.25459490e-10   1.48111263e-11
    5.02539832e-09   8.08968325e-05   1.04275227e-01   1.17177157e-09
    1.84456368e-07   2.30430451e-05   2.57450138e-05   1.01536374e-04
    1.67260692e-03   7.86015697e-09   8.28821361e-02   4.53301631e-02
    1.36918572e-06   2.40987953e-04   1.16553326e-06   6.65895059e-05
    5.31873989e-10   6.25460991e-04   9.58050528e-09   8.33289325e-03
    7.72969969e-12]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/97
(1, 64, 64, 3)
Policy eval: 
[[  2.27683276e-01   1.07278977e-11   1.47191148e-11   3.87884558e-10
    1.03560094e-08   5.67250136e-10   1.49829527e-09   1.87675269e-07
    4.84314421e-03   4.11152614e-05   8.73095285e-09   1.44483451e-13
    1.26633331e-11   8.07601737e-08   6.59877086e-09   3.96766002e-20
    2.74665933e-03   4.05479678e-10   4.82417078e-14   2.19470706e-07
    1.66482914e-05   1.68710794e-05   1.56602326e-07   1.38775894e-10
    8.25760467e-12   8.13106360e-10   9.24576125e-06   7.79757414e-09
    1.56151874e-08   2.68949498e-06   7.64639258e-01   2.82814454e-15
    9.12426315e-11   5.17336729e-11   1.70795218e-11   3.40955353e-07
    4.63453165e-10   4.15125172e-15   2.13587326e-09   4.75618724e-14
    9.72319114e-09]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/231
(1, 64, 64, 3)
Policy eval: 
[[  5.33814903e-09   2.81998079e-12   2.98102742e-20   3.00902961e-28
    3.73094455e-17   4.54931496e-16   1.13018570e-11   3.23246235e-17
    5.42589801e-12   7.20865046e-07   1.01385718e-19   3.22594891e-15
    2.31567809e-09   3.60566943e-19   1.53602728e-16   3.21467845e-26
    2.24892665e-02   2.54847870e-14   5.10344713e-18   7.21789707e-14
    5.14840212e-14   2.58037793e-11   7.05005441e-05   1.41771456e-10
    3.15443517e-20   9.77439523e-01   4.51353737e-14   2.35072600e-10
    7.90877974e-10   9.02037912e-15   2.63165406e-10   1.70961822e-09
    4.90385131e-13   1.44383288e-14   5.87828058e-14   5.62650946e-13
    6.82503309e-16   3.20233196e-09   4.99836789e-17   1.03562364e-16
    4.68055424e-21]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 12
images_for_training/292
(1, 64, 64, 3)
Policy eval: 
[[  7.95063853e-01   1.41477121e-13   3.53151268e-06   4.24035012e-19
    6.24168706e-07   1.05092801e-16   6.24319910e-07   1.45928736e-03
    1.09680082e-06   4.79662349e-15   2.12634944e-12   4.09696708e-15
    2.09810138e-11   1.67758382e-14   3.15595861e-09   1.18798472e-17
    2.03325361e-01   1.96717804e-16   1.68611659e-18   1.28415534e-13
    8.18376976e-15   1.59687552e-08   4.84437150e-14   3.43339702e-15
    4.30199181e-24   5.86379225e-14   4.00837195e-07   1.57304400e-13
    3.24563007e-05   2.39905895e-09   1.18303035e-06   2.81253536e-13
    2.89894383e-13   3.91482614e-17   7.21421675e-05   7.43708151e-11
    1.01796030e-14   1.24914974e-18   3.93275914e-05   3.20424491e-17
    3.11987236e-18]]
Action: 0.8
Enter Reward: 1
Backpropping 

Session Number 13
images_for_training/260
(1, 64, 64, 3)
Policy eval: 
[[  4.56997417e-02   2.28360646e-12   2.32191055e-11   5.04194914e-18
    2.01857461e-06   3.69066896e-18   3.68138285e-06   3.82566157e-09
    2.00934312e-03   1.57012912e-13   1.39237775e-15   2.87583997e-12
    1.21105714e-16   4.03293674e-12   1.27770563e-11   7.65248405e-23
    9.45074379e-01   9.09150003e-16   4.66358384e-14   9.67935315e-11
    1.61468823e-14   3.20071400e-08   2.28504216e-10   1.55524427e-09
    1.94851430e-18   7.95375114e-21   3.74037263e-08   4.61033567e-09
    7.21021509e-03   7.90726762e-10   8.63501076e-11   1.37794219e-15
    2.18928409e-09   3.88242415e-17   5.07656182e-07   1.36852140e-14
    3.91079426e-20   1.25097177e-12   1.71705473e-17   5.28094295e-15
    8.35567306e-14]]
Action: 0.65
Enter Reward: 1
Backpropping 

Session Number 14
images_for_training/24
(1, 64, 64, 3)
Policy eval: 
[[  2.14743167e-01   7.77633708e-14   2.16214275e-07   1.96954192e-16
    1.38370806e-05   8.36558253e-13   6.47980656e-08   3.85492961e-14
    2.46702848e-06   1.76014446e-11   1.65719143e-06   1.27871092e-14
    3.14155031e-08   1.40860466e-05   5.15190834e-10   2.26178736e-14
    1.06125960e-07   7.13912129e-08   1.85429336e-13   3.58924110e-12
    2.81337109e-09   2.38695520e-07   3.49186337e-07   6.14443357e-11
    2.45566500e-08   2.99522384e-07   1.12486778e-04   2.59141927e-12
    9.37309489e-03   9.43989678e-13   6.37669132e-07   7.73104548e-01
    9.21134080e-04   5.20745469e-12   2.91053177e-04   1.51289132e-08
    1.41998846e-03   3.65246848e-07   4.77526747e-08   5.17959720e-09
    2.84785615e-11]]
Action: 0.3
Enter Reward: 0
Backpropping 

Session Number 15
images_for_training/33
(1, 64, 64, 3)
Policy eval: 
[[  9.99991655e-01   1.17632657e-19   2.49822508e-14   2.70520655e-21
    2.38528713e-07   2.91072030e-15   2.54628935e-06   2.12690267e-07
    9.06003161e-10   1.32197762e-14   2.90062474e-21   1.72468912e-23
    1.78407094e-13   1.32833453e-10   1.11523513e-15   1.09647090e-24
    1.16584954e-06   1.87976834e-15   1.69145184e-17   3.89488492e-15
    6.84112419e-11   7.65900488e-19   3.79303151e-11   3.96324254e-16
    1.42330216e-25   1.40755615e-12   1.87361801e-12   1.17729811e-16
    2.56988458e-10   1.68953013e-17   4.02689340e-11   1.77760973e-10
    3.27583598e-06   5.78064413e-24   4.27186701e-14   1.64578959e-14
    2.76622445e-20   7.57801335e-18   9.18474598e-07   2.62709889e-16
    1.60108669e-24]]
Action: 1.55
Enter Reward: 0
Backpropping 

Session Number 16
images_for_training/191
(1, 64, 64, 3)
Policy eval: 
[[  4.44293141e-01   3.92655114e-04   1.50403287e-03   1.65513993e-05
    8.34314898e-03   7.03959950e-06   1.11939110e-01   2.08556671e-02
    1.36018723e-01   1.75193403e-04   2.89355830e-05   6.82153986e-05
    9.82971862e-04   6.18003681e-03   1.54636891e-05   3.47273344e-05
    2.21374426e-02   3.76561366e-05   2.85924203e-03   2.94201251e-04
    1.34915358e-03   8.17098990e-05   7.27846462e-04   4.01043100e-04
    5.90274067e-05   1.90800183e-05   4.53980247e-05   2.84535554e-03
    1.70322031e-01   4.47928905e-05   1.51861897e-02   4.09790809e-04
    1.20034898e-02   2.19304208e-03   1.57701131e-03   2.87501365e-02
    1.96146034e-03   8.51348217e-04   2.37728382e-04   4.69547277e-03
    5.47743148e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 17
images_for_training/150
(1, 64, 64, 3)
Policy eval: 
[[  3.21358860e-01   1.20465382e-04   2.74733105e-03   1.96694949e-04
    2.83911359e-02   1.87719322e-03   3.17366002e-03   6.23473199e-03
    9.39761847e-03   2.53788824e-03   2.58284574e-03   2.33860541e-04
    2.21484294e-03   1.60771925e-02   1.74987409e-03   3.38324084e-04
    6.03930838e-03   1.37807231e-03   6.32955402e-04   7.93785881e-03
    1.99167095e-02   2.50709418e-04   1.46205649e-02   1.06712931e-03
    1.19754222e-04   3.30637135e-02   1.43563263e-02   2.53214547e-03
    1.41185531e-02   1.00732443e-03   6.45987466e-02   1.18875884e-01
    2.37644166e-01   2.13405001e-03   7.51450052e-03   1.37178297e-03
    7.71981617e-03   3.74787636e-02   4.78058774e-03   1.22493785e-03
    3.83057864e-04]]
Action: 1.1
Enter Reward: 0
Backpropping 

Session Number 18
images_for_training/63
(1, 64, 64, 3)
Policy eval: 
[[  9.36166704e-01   6.36360041e-25   6.54013649e-12   2.64143507e-24
    7.24507032e-09   5.00203199e-19   7.51280567e-08   6.17398842e-15
    2.56239621e-15   4.26095338e-20   4.66991568e-20   6.96416820e-24
    7.61187399e-18   1.52220071e-14   4.05744240e-15   1.57995422e-22
    1.97294639e-10   1.63361512e-11   2.15398588e-24   3.94025243e-22
    2.30071251e-09   1.18515102e-23   9.61224305e-06   6.05334891e-15
    1.79079649e-27   7.33416439e-09   1.36945929e-17   2.13361360e-25
    7.25786618e-12   3.02677926e-17   1.45781268e-13   2.76102501e-08
    5.85833341e-02   5.71530589e-21   5.24030766e-03   3.12330454e-22
    1.01486103e-11   9.29071273e-19   2.64870612e-12   2.37836820e-16
    3.17113822e-27]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 19
images_for_training/89
(1, 64, 64, 3)
Policy eval: 
[[  9.99989390e-01   2.21714189e-24   4.08545405e-16   2.10191803e-26
    6.20477844e-12   1.33519835e-20   2.46984017e-10   3.59254422e-08
    6.17696977e-16   6.85547129e-20   2.37917602e-21   6.96941604e-18
    1.85407261e-19   9.83526628e-13   4.69499320e-18   3.33587121e-26
    4.63737165e-12   3.47097107e-09   5.02048448e-22   5.36814318e-22
    3.02294478e-17   7.71562179e-17   3.36235861e-09   2.98027245e-16
    7.50999921e-24   9.30687472e-12   5.57413511e-14   1.24824018e-21
    1.57475487e-13   2.17700891e-21   3.44428743e-17   1.06022126e-05
    7.55681975e-11   4.56908556e-18   1.59442331e-14   4.27588585e-17
    4.42705939e-17   1.87162856e-15   1.69693588e-16   2.02414179e-11
    1.39624155e-28]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 20
images_for_training/194
(1, 64, 64, 3)
Policy eval: 
[[  4.14729491e-02   1.53829367e-03   8.37501138e-03   6.55906217e-04
    6.06350414e-02   5.38810808e-03   2.44695723e-01   4.13523614e-02
    1.16426321e-02   8.69912375e-03   7.32254889e-03   7.26570655e-03
    2.76722456e-03   1.41735822e-01   4.41367680e-04   3.20021267e-04
    2.19454104e-03   7.37450505e-03   1.16438640e-03   6.22141815e-04
    6.20815670e-04   4.69669903e-04   1.62579909e-01   9.56168980e-04
    1.20509969e-04   1.75266329e-03   3.83575037e-02   2.47700326e-03
    2.34228931e-03   8.48126423e-04   9.05775577e-02   1.71354674e-02
    2.04370404e-03   3.11327502e-02   1.28392957e-03   2.65440289e-02
    3.02843284e-04   1.38221905e-02   1.46064186e-03   9.29924753e-03
    2.09511709e-04]]
Action: 1.1
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 21
images_for_training/177
(1, 64, 64, 3)
Policy eval: 
[[  1.99274495e-02   9.39420934e-05   6.15405524e-03   4.18357013e-05
    4.71637733e-02   3.47872956e-05   1.96747389e-02   9.33959335e-03
    4.01645191e-02   2.17871070e-02   1.96723195e-04   1.29737484e-03
    2.51739263e-03   1.20626781e-02   1.44184247e-04   5.93889999e-05
    4.03422350e-03   1.83119497e-04   2.74956948e-03   9.34080381e-05
    5.79500571e-04   4.97118162e-04   4.96725082e-01   3.04022944e-03
    3.89002962e-04   4.36174031e-03   1.63676834e-03   4.57363494e-04
    2.11518347e-01   1.47592847e-03   3.44974920e-03   5.51892519e-02
    1.32950554e-02   7.47352373e-04   1.40362941e-02   1.34876568e-03
    2.24726228e-03   2.56514119e-04   2.70529621e-04   6.55870943e-04
    1.02282902e-04]]
Action: 0.4
Enter Reward: 0
Backpropping 

Session Number 22
images_for_training/36
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   9.08666500e-34   2.93682618e-19   0.00000000e+00
    1.36234143e-21   4.91859115e-36   4.54026061e-09   2.45287548e-18
    7.41816495e-25   1.08333969e-28   1.45199733e-30   4.01060523e-31
    1.63911824e-25   2.27535927e-26   2.06530718e-26   4.94647650e-36
    9.07084038e-26   1.78659463e-29   6.69637138e-22   7.89162843e-32
    4.63528289e-26   0.00000000e+00   2.14933411e-18   2.92324971e-24
    6.72473492e-37   9.65313157e-19   3.37564976e-21   4.15468134e-31
    3.62555108e-29   5.57545028e-36   3.86075950e-16   3.24156717e-13
    1.04495572e-25   1.25871267e-18   1.09383585e-16   5.47255665e-21
    3.62137390e-23   5.08332924e-20   1.56030471e-23   8.21182193e-24
    0.00000000e+00]]
Action: 1.1
Enter Reward: 1
Backpropping 

Session Number 23
images_for_training/12
(1, 64, 64, 3)
Policy eval: 
[[  9.89398479e-01   1.17720833e-10   3.92035127e-10   6.89506998e-20
    4.67829757e-08   1.47025581e-09   8.14041954e-08   3.70250086e-06
    7.39222283e-09   5.91022378e-08   9.21573236e-17   9.99658364e-13
    1.83730208e-06   2.97752621e-12   3.90930443e-19   2.06510313e-18
    1.30518494e-14   1.64090981e-15   8.71412666e-08   1.14467706e-11
    9.87868987e-09   4.26195998e-13   5.10941260e-04   2.20423330e-13
    1.04633836e-28   7.66872196e-03   4.19733562e-12   1.84067474e-19
    2.34271955e-12   2.73622457e-14   1.99802313e-03   4.07770684e-04
    1.02216072e-05   3.06173920e-10   2.13179946e-10   8.73784619e-15
    1.14610090e-12   1.98559198e-15   7.44943278e-13   2.34035361e-11
    5.09523353e-19]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 24
images_for_training/204
(1, 64, 64, 3)
Policy eval: 
[[  3.92164558e-01   6.31717123e-10   4.90562488e-05   2.69330011e-24
    4.81566973e-02   3.13784338e-14   6.51846090e-13   4.83289319e-14
    4.89924787e-05   2.16532442e-17   8.25862894e-16   9.05627837e-19
    2.70620831e-10   1.30886619e-03   2.34481753e-21   6.25564540e-30
    1.14341047e-19   8.22529290e-03   2.80169239e-22   2.39961935e-12
    6.30689456e-16   6.45380237e-15   5.20434096e-09   8.50152874e-17
    1.35839040e-23   1.71562192e-11   5.65183907e-11   1.87559884e-24
    2.74169911e-02   2.71043292e-22   2.47087860e-06   1.04761375e-02
    9.10738856e-02   5.54057920e-07   6.30922051e-11   2.44729638e-13
    4.21076387e-01   3.69572213e-08   5.86014527e-12   8.69510774e-09
    4.72525309e-22]]
Action: 1.9
Enter Reward: 0
Backpropping 

Session Number 25
images_for_training/218
(1, 64, 64, 3)
Policy eval: 
[[  2.99035728e-01   1.69523978e-10   1.52211709e-04   1.57757802e-17
    5.11092321e-06   2.73284659e-11   1.55321436e-10   1.20819079e-08
    2.65325866e-07   6.26173701e-13   6.30992975e-18   1.38753494e-12
    1.00932901e-12   3.57439873e-08   2.78644515e-14   7.16748957e-16
    4.95388690e-07   4.69625559e-15   8.05492756e-11   2.10098719e-07
    1.19679376e-16   4.26255614e-10   1.98617386e-07   7.63264596e-02
    6.89039144e-14   3.31797273e-14   1.18800648e-15   7.57716481e-13
    4.08971709e-06   1.78434760e-08   1.53291420e-12   6.18744254e-01
    7.21805282e-10   9.14910183e-13   5.73084271e-03   7.27195488e-15
    2.80041002e-14   2.30168613e-08   3.44191378e-08   1.67573440e-08
    2.49349150e-19]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 26
images_for_training/296
(1, 64, 64, 3)
Policy eval: 
[[  1.52286021e-02   1.26431212e-06   1.04895516e-05   3.85346182e-12
    2.84784228e-01   1.99811473e-10   7.00118989e-02   4.35302228e-01
    2.25896368e-09   1.12117668e-04   3.47767415e-09   6.68321221e-08
    6.42941345e-08   1.93112948e-09   1.20715618e-10   8.59926519e-10
    9.53907669e-02   4.18857053e-06   2.71595042e-07   3.78599424e-07
    6.55161272e-11   9.83292003e-15   5.62821107e-04   1.93748542e-06
    7.69322672e-15   6.24112487e-02   3.49036853e-08   2.22945615e-15
    2.75020546e-04   1.55023243e-02   7.88258985e-05   2.27099772e-05
    2.00437140e-02   5.82940640e-10   5.59924410e-05   2.79017955e-11
    2.63006509e-11   1.81432213e-07   1.98641326e-04   1.22155749e-11
    3.70664350e-12]]
Action: 0.35
Enter Reward: 1
Backpropping 

Session Number 27
images_for_training/245
(1, 64, 64, 3)
Policy eval: 
[[  2.40498539e-02   4.28711633e-19   5.95151519e-08   5.94463191e-18
    9.75930333e-01   4.06085806e-15   5.05077047e-09   2.71690830e-12
    5.43054561e-08   1.83076219e-16   1.23887276e-14   1.04670907e-11
    1.39922365e-10   1.91803665e-05   8.03031385e-19   1.19052226e-17
    4.47555099e-14   3.59400754e-09   3.67727420e-12   1.35500400e-12
    1.04308084e-09   2.97320952e-15   2.00390537e-10   1.03494958e-13
    5.01038707e-12   6.84871387e-12   7.53701379e-10   2.73082347e-18
    3.86019309e-07   1.04846233e-13   6.31514910e-11   5.61788980e-08
    3.85803816e-08   4.21523982e-10   3.95337052e-09   1.92118250e-08
    2.83274554e-12   2.89429678e-12   4.66378916e-14   3.64867497e-10
    3.89442299e-18]]
Action: 0.4
Enter Reward: 1
Backpropping 

Session Number 28
images_for_training/130
(1, 64, 64, 3)
Policy eval: 
[[ 0.05611863  0.08463202  0.03714356  0.00395535  0.0049171   0.01472455
   0.01286744  0.03517837  0.08705507  0.04046205  0.00451118  0.00444637
   0.07215951  0.00725607  0.00731581  0.00665923  0.01498922  0.02866545
   0.02085861  0.01558717  0.01151873  0.00354722  0.05586763  0.02187437
   0.00211296  0.03192283  0.03522327  0.00492807  0.00504379  0.10676461
   0.01292382  0.00829385  0.00917295  0.02359127  0.00376046  0.01129264
   0.01257364  0.00647386  0.01565659  0.04914264  0.00881199]]
Action: 0.35
Enter Reward: 0
Backpropping 

Session Number 29
images_for_training/41
(1, 64, 64, 3)
Policy eval: 
[[  9.14996743e-01   4.58787475e-03   1.27833395e-04   1.52493396e-06
    1.69762224e-03   4.85463715e-05   3.09523719e-04   5.02138864e-03
    2.46784650e-03   3.71895767e-05   3.75218337e-06   8.02638679e-05
    3.42246436e-04   4.52214445e-04   5.50517107e-05   9.36934867e-08
    1.54890688e-04   3.83191255e-05   1.37052452e-03   1.07049826e-03
    1.54487367e-04   4.72994373e-07   5.07073849e-03   3.99582870e-02
    2.27964392e-06   2.14154879e-03   1.05367406e-04   1.63260120e-05
    1.39446638e-04   3.84368876e-04   1.29794739e-02   1.91231175e-05
    1.36309129e-04   2.64631305e-03   4.38613597e-06   1.38096613e-04
    2.12443440e-04   1.19545311e-05   1.87383062e-04   2.82671792e-03
    3.98800637e-07]]
Action: 1.5
Enter Reward: 0
Backpropping 

Session Number 30
images_for_training/228
(1, 64, 64, 3)
Policy eval: 
[[  9.03169453e-01   5.79020925e-05   2.87260744e-04   2.62182454e-08
    3.06883897e-03   3.51343829e-06   6.60682097e-04   1.69083313e-03
    8.32471924e-05   6.94801929e-05   1.99770966e-05   8.39223873e-08
    2.70375330e-02   6.68570690e-04   2.31186959e-07   4.25834315e-07
    2.26860648e-04   2.14120634e-02   1.17294621e-04   3.49698326e-04
    7.63763310e-05   1.10084065e-05   4.07133624e-03   6.51717637e-05
    7.22436198e-07   3.84295636e-05   2.18672067e-05   4.43242134e-05
    9.82172205e-05   2.63353991e-06   4.49656229e-03   3.94610615e-05
    2.28542928e-02   6.85108185e-04   3.93550799e-05   1.02221104e-03
    3.26499459e-04   7.03423936e-03   1.53650535e-06   1.46187551e-04
    4.14248603e-07]]
Action: 1.65
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 31
images_for_training/36
(1, 64, 64, 3)
Policy eval: 
[[  4.87315893e-01   4.29848302e-03   1.36800870e-01   1.08023349e-03
    1.11134741e-02   3.99556663e-03   4.81416890e-03   2.66148876e-02
    3.92018333e-02   2.84316047e-04   1.27446710e-03   1.90186116e-03
    1.57736856e-02   2.11044075e-03   2.22389423e-03   3.00356885e-04
    4.83904593e-03   4.76794131e-02   7.05005229e-03   7.68800313e-03
    1.25159603e-02   3.51818657e-04   3.71438311e-03   2.97289919e-02
    1.33128662e-03   3.03555261e-02   6.03663595e-03   3.74199846e-03
    3.87756410e-03   1.09003261e-02   2.87331361e-03   1.38336793e-02
    1.12427361e-02   2.52863276e-03   3.52339186e-02   5.08014672e-03
    5.59911877e-03   3.13211675e-03   8.12102854e-03   3.19306366e-03
    2.46724609e-04]]
Action: 0.6
Enter Reward: 1
Backpropping 

Session Number 32
images_for_training/87
(1, 64, 64, 3)
Policy eval: 
[[ 0.17505433  0.11105196  0.01412264  0.00073369  0.00668342  0.01141625
   0.00708924  0.03361309  0.13417721  0.01996694  0.00610975  0.00312255
   0.05507611  0.00485496  0.00485501  0.00056904  0.01061187  0.01008411
   0.01884447  0.00755234  0.01793267  0.00301542  0.0110216   0.08995412
   0.00086096  0.01497881  0.05671875  0.01172307  0.00988494  0.06216177
   0.00554014  0.01746996  0.0084469   0.00995259  0.00124027  0.0168372
   0.00284821  0.01239806  0.00587961  0.0021909   0.00335513]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 33
images_for_training/110
(1, 64, 64, 3)
Policy eval: 
[[ 0.26224273  0.04179412  0.0139288   0.003642    0.03253001  0.01393428
   0.02838837  0.03997664  0.01702074  0.01069522  0.019834    0.00896726
   0.01387221  0.0062771   0.01770806  0.00185412  0.03848015  0.01067492
   0.01679666  0.01214396  0.01107691  0.0056609   0.01210312  0.0360901
   0.00911772  0.02617231  0.0170338   0.01320742  0.01958309  0.03810971
   0.01941651  0.02104777  0.00342478  0.0281922   0.03063229  0.02296924
   0.00830664  0.01827215  0.02859242  0.01651031  0.00371925]]
Action: 1.4
Enter Reward: 1
Backpropping 

Session Number 34
images_for_training/217
(1, 64, 64, 3)
Policy eval: 
[[  8.23108912e-01   7.85562769e-03   5.93357440e-03   1.61327498e-05
    7.16541428e-04   1.35321934e-02   1.29123917e-03   1.45647423e-02
    2.62121614e-02   3.72030819e-03   1.15710114e-04   4.44077741e-04
    6.89377717e-04   1.58544816e-02   4.88573802e-04   9.87351959e-05
    8.21940135e-03   1.73678028e-03   3.65075096e-03   9.90044442e-04
    4.81347030e-04   1.28950405e-05   5.07207355e-04   2.81993710e-02
    5.98244742e-06   1.04372809e-03   1.71535816e-02   1.18733291e-03
    3.65602231e-04   5.79507835e-03   1.16233528e-03   1.94097206e-03
    5.37520414e-03   1.77718361e-03   1.09294849e-03   1.63487787e-03
    5.13584702e-04   1.91620889e-03   7.16446812e-05   4.91053332e-04
    3.24996618e-05]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 35
images_for_training/157
(1, 64, 64, 3)
Policy eval: 
[[ 0.06934823  0.03733217  0.02797662  0.01447788  0.03094955  0.0189788
   0.01830944  0.03345999  0.02946014  0.02021915  0.02280432  0.02262703
   0.03291117  0.02047534  0.0195477   0.0124572   0.027424    0.01756874
   0.01858088  0.01716523  0.02244618  0.01688819  0.01899198  0.02687577
   0.01413182  0.0206555   0.03095578  0.02335416  0.02477914  0.02991234
   0.02516005  0.020389    0.02574475  0.02376156  0.02035484  0.02188308
   0.02555119  0.02234408  0.0275546   0.02629502  0.01989739]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 36
images_for_training/53
(1, 64, 64, 3)
Policy eval: 
[[  8.56895685e-01   9.30828881e-03   7.69190537e-03   7.68336031e-05
    1.28990170e-02   1.91361608e-03   7.61675125e-04   1.84783544e-02
    2.33351160e-03   3.76115582e-04   4.49167041e-04   4.80766539e-05
    9.00331594e-04   4.45702812e-04   1.79920491e-04   1.95846660e-04
    2.26992816e-02   2.62762140e-03   2.95640249e-03   9.27282206e-04
    9.90319997e-04   6.67640299e-04   1.19758863e-03   9.53778904e-03
    1.19379933e-04   3.18590226e-03   1.27433892e-03   5.92411915e-03
    1.03235792e-03   1.92944531e-03   6.29337132e-03   4.51159896e-03
    9.38372966e-03   1.91196785e-04   2.08993955e-03   4.54171607e-03
    1.66926638e-03   1.38586131e-03   8.80303734e-04   7.58260081e-04
    2.71206925e-04]]
Action: 0.35
Enter Reward: 0
Backpropping 

Session Number 37
images_for_training/298
(1, 64, 64, 3)
Policy eval: 
[[  8.82511675e-01   4.20694426e-03   3.86896217e-03   4.21048608e-05
    3.96034541e-03   3.99848941e-04   4.12729615e-03   5.70809375e-03
    4.68106475e-03   4.18157829e-03   5.16594155e-04   1.61657837e-04
    5.55480039e-03   2.41464912e-03   2.07146495e-05   9.98173928e-05
    4.74367989e-03   1.63727120e-04   2.93727033e-04   1.81039993e-03
    9.68190667e-04   2.78892490e-04   3.60883074e-04   9.87892505e-04
    1.06191539e-04   1.24447921e-03   3.52785736e-03   3.22582673e-05
    4.53637738e-04   6.77401852e-03   5.23288362e-03   3.46681569e-04
    3.39884721e-02   1.59858449e-04   1.17625005e-03   9.44688078e-03
    1.56604382e-03   9.68280714e-04   7.56687194e-04   8.33165657e-04
    1.32296595e-03]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 38
images_for_training/49
(1, 64, 64, 3)
Policy eval: 
[[  4.79123145e-01   3.22445109e-02   1.05792750e-02   4.23345569e-04
    7.47574568e-02   1.27927156e-03   1.45937339e-03   1.42542914e-01
    1.47168897e-02   5.36645879e-04   1.16824766e-03   8.66584247e-04
    2.64231768e-03   2.98273563e-03   1.50199712e-03   9.28009686e-04
    2.51908693e-02   1.84782203e-02   6.76759169e-04   3.89738940e-03
    1.01017533e-03   1.81595015e-03   1.48193166e-03   4.90545295e-02
    1.60927608e-04   1.16687529e-02   3.48397967e-04   1.01529434e-02
    2.18413980e-03   4.41907384e-02   8.00726004e-03   2.76960316e-03
    4.81598731e-03   2.05333624e-03   2.14900565e-03   1.16397617e-02
    3.93764465e-04   1.19987195e-02   3.55011784e-03   1.41288498e-02
    4.28916683e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 39
images_for_training/173
(1, 64, 64, 3)
Policy eval: 
[[ 0.11608326  0.02577404  0.04703465  0.0122731   0.02380217  0.03906684
   0.01366747  0.02706751  0.01339721  0.01612866  0.01682425  0.0279272
   0.01759367  0.01876702  0.02587921  0.01321487  0.02616638  0.04553406
   0.02054363  0.01853968  0.0121334   0.01490529  0.01768308  0.03622212
   0.01286477  0.0317409   0.02532376  0.02090184  0.00907428  0.03669261
   0.02235277  0.01936175  0.02299102  0.01737579  0.01679804  0.03201632
   0.01765994  0.02969829  0.01660751  0.01420526  0.0081064 ]]
Action: 0.15
Enter Reward: 0
Backpropping 

Session Number 40
images_for_training/202
(1, 64, 64, 3)
Policy eval: 
[[  9.73748565e-01   5.96081559e-03   1.29480357e-03   3.68078759e-06
    7.96654276e-05   3.87575536e-04   2.56464755e-05   5.78009873e-04
    8.68612900e-03   6.87506545e-05   1.25336019e-05   5.66721486e-04
    2.75296916e-05   2.26380842e-04   5.81182030e-06   1.08363668e-06
    1.12462358e-03   6.81902020e-05   1.67336602e-05   1.85381487e-05
    6.69445672e-06   2.02955880e-06   1.54929112e-05   3.96438147e-04
    3.73023431e-05   9.68096501e-05   2.97063473e-03   2.54163228e-04
    3.54558324e-06   1.24785671e-04   7.92332052e-04   1.49100624e-05
    1.65618068e-04   2.38109584e-04   3.16651062e-06   1.30284857e-03
    3.35441546e-05   1.90952022e-04   7.59245449e-05   3.68619745e-04
    4.35302218e-06]]
Action: 1.45
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 41
images_for_training/185
(1, 64, 64, 3)
Policy eval: 
[[ 0.069952    0.02891986  0.02465646  0.01688916  0.03758409  0.02103711
   0.02320788  0.03419262  0.0334137   0.02561693  0.01418683  0.02891132
   0.01992087  0.02942514  0.0198007   0.01326226  0.03116318  0.02855635
   0.02183584  0.02037114  0.02374198  0.01681391  0.01329981  0.01797238
   0.01644986  0.02141014  0.02597149  0.02321025  0.02348452  0.02652413
   0.02192145  0.0204902   0.02094289  0.02715253  0.0195843   0.02596729
   0.02122978  0.02331283  0.03079604  0.02482229  0.01199851]]
Action: 1.1
Enter Reward: 0
Backpropping 

Session Number 42
images_for_training/200
(1, 64, 64, 3)
Policy eval: 
[[ 0.03927695  0.02768899  0.02865259  0.02396524  0.02995932  0.02875897
   0.02314903  0.02636365  0.02743791  0.02546991  0.02236708  0.02402961
   0.02281804  0.02759819  0.02287484  0.01855772  0.02852542  0.02924065
   0.02249684  0.02390076  0.0228903   0.02035271  0.02020585  0.02463562
   0.01811156  0.0246392   0.0268448   0.01906968  0.01904266  0.02663181
   0.02063394  0.01947451  0.01999365  0.02434864  0.02313889  0.0265903
   0.02443726  0.02719339  0.02889864  0.02267578  0.01705907]]
Action: 1.3
Enter Reward: 0
Backpropping 

Session Number 43
images_for_training/189
(1, 64, 64, 3)
Policy eval: 
[[ 0.06373595  0.05690595  0.03844995  0.01868995  0.02184349  0.01919135
   0.01503814  0.02510307  0.04968055  0.0235094   0.03088339  0.01701718
   0.02068334  0.02148455  0.01525042  0.00856974  0.02909893  0.0171312
   0.01822079  0.02053993  0.01859965  0.01917352  0.01629667  0.01922376
   0.01249175  0.01706476  0.02915607  0.01802905  0.01637667  0.02068314
   0.02966229  0.02300065  0.01552639  0.03451042  0.02103231  0.0374407
   0.02354906  0.02350349  0.038532    0.01782722  0.01729313]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 44
images_for_training/91
(1, 64, 64, 3)
Policy eval: 
[[ 0.2178144   0.04070577  0.00516295  0.00031953  0.00873456  0.00793904
   0.00139075  0.0098012   0.05297343  0.00334893  0.00504914  0.0244661
   0.00352894  0.0153493   0.00138547  0.00510145  0.00331624  0.01429504
   0.00575109  0.02848059  0.00850521  0.00266121  0.00792715  0.00270162
   0.00129185  0.00444519  0.24266139  0.00184186  0.00156482  0.01516318
   0.00431514  0.00348574  0.00269793  0.02666906  0.0021116   0.13166587
   0.01858516  0.01126464  0.02415741  0.01479391  0.0165762 ]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 45
images_for_training/95
(1, 64, 64, 3)
Policy eval: 
[[ 0.15817431  0.09337657  0.0587588   0.00686963  0.00714176  0.03384608
   0.00258458  0.01189856  0.02269666  0.02146713  0.00275258  0.03820143
   0.01063524  0.03479219  0.0041304   0.0009495   0.04366061  0.00321095
   0.00944121  0.02385966  0.02800456  0.00725951  0.00920991  0.00578107
   0.00076714  0.00508411  0.18870687  0.00161074  0.00268281  0.05035676
   0.00465332  0.00100076  0.00532549  0.04179789  0.00268796  0.00788564
   0.00285227  0.01624396  0.00498106  0.00570182  0.01895851]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 46
images_for_training/53
(1, 64, 64, 3)
Policy eval: 
[[ 0.16823298  0.03094747  0.00819987  0.00572918  0.01244176  0.05869927
   0.00435528  0.02137614  0.0166874   0.00472057  0.01788232  0.01771346
   0.02252555  0.01165786  0.00415031  0.00385886  0.05535749  0.04902609
   0.02785051  0.0361121   0.02529505  0.00406686  0.01382932  0.01631576
   0.00862614  0.02192129  0.0400656   0.03946889  0.00793228  0.0199957
   0.03480012  0.0212618   0.02147903  0.00804691  0.02138938  0.05425823
   0.01959152  0.00643551  0.02063487  0.01594563  0.00111563]]
Action: 0.55
Enter Reward: 0
Backpropping 

Session Number 47
images_for_training/1
(1, 64, 64, 3)
Policy eval: 
[[ 0.12035846  0.01404861  0.03911256  0.0027855   0.00899024  0.01501985
   0.0009371   0.03858567  0.08160584  0.02071341  0.00888329  0.03146702
   0.03284891  0.0192283   0.00218974  0.00111837  0.02410414  0.00988428
   0.0093649   0.01411997  0.00796319  0.00453475  0.00559568  0.0067364
   0.00600648  0.01233711  0.07478052  0.02879074  0.01795292  0.01931176
   0.00971673  0.00940688  0.00516914  0.01347896  0.01015122  0.17887445
   0.00785271  0.0057411   0.00430558  0.06900603  0.00692145]]
Action: 1.85
Enter Reward: 0
Backpropping 

Session Number 48
images_for_training/4
(1, 64, 64, 3)
Policy eval: 
[[ 0.04208866  0.04688584  0.03688623  0.00556468  0.01844152  0.02088465
   0.01443404  0.00678388  0.05122408  0.02592775  0.0168416   0.0316444
   0.00855536  0.057062    0.0170969   0.00829737  0.07565417  0.01532641
   0.00887967  0.03416747  0.00910178  0.02592595  0.01764296  0.03477992
   0.01690592  0.02040521  0.03690498  0.023066    0.01024784  0.00429981
   0.02171774  0.02739905  0.01659994  0.02270822  0.0183319   0.03829409
   0.01464019  0.02828299  0.05681008  0.00809978  0.00518908]]
Action: 0.85
Enter Reward: 1
Backpropping 

Session Number 49
images_for_training/124
(1, 64, 64, 3)
Policy eval: 
[[ 0.03080605  0.04022836  0.02700458  0.01316232  0.01982687  0.01721134
   0.01251955  0.02363025  0.02680167  0.01349369  0.01727816  0.02705796
   0.02877844  0.01946284  0.02482227  0.01734092  0.05292551  0.03503107
   0.02918413  0.01692776  0.03130101  0.01691832  0.02150282  0.02082349
   0.014898    0.02674469  0.02343525  0.02991244  0.02118729  0.03707924
   0.02845848  0.02253361  0.01390517  0.02402388  0.02418805  0.0301765
   0.01501565  0.02411759  0.02906816  0.02757747  0.0236392 ]]
Action: 1.2
Enter Reward: 0
Backpropping 

Session Number 50
images_for_training/151
(1, 64, 64, 3)
Policy eval: 
[[ 0.03053812  0.02589794  0.02794452  0.0201356   0.02096627  0.02438344
   0.01823764  0.02730568  0.02799457  0.0270342   0.0288398   0.02590659
   0.02790827  0.02604855  0.02225185  0.01891005  0.03377441  0.02818413
   0.02347594  0.02040686  0.02977159  0.01999008  0.0193104   0.02041965
   0.01910553  0.02125327  0.02848828  0.0230485   0.02298032  0.02821996
   0.02222599  0.0204668   0.02233157  0.02409681  0.0209968   0.02734628
   0.02153849  0.02581124  0.0225522   0.02826946  0.02563243]]
Action: 0.7
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 51
images_for_training/231
(1, 64, 64, 3)
Policy eval: 
[[  1.15273327e-01   1.36436969e-01   2.19818428e-02   2.25139767e-04
    9.01844166e-03   1.28448308e-02   9.15004697e-04   9.89155495e-04
    2.21949786e-01   4.16038968e-02   1.39250921e-03   3.27042229e-02
    1.48962475e-02   3.46547514e-02   1.38738449e-03   1.22422178e-04
    2.56778263e-02   2.58484529e-03   1.60119531e-03   2.77808821e-03
    2.17855489e-03   9.73084883e-04   1.60338357e-03   3.95169511e-04
    5.42942398e-05   4.50167048e-04   8.89399946e-02   2.91616307e-03
    1.42100279e-03   4.33804654e-02   8.80877767e-03   5.33901293e-05
    1.70966331e-03   1.92107949e-02   3.43897287e-03   1.13440324e-02
    3.78935365e-03   1.41953230e-02   8.80274624e-02   2.61898078e-02
    1.88223738e-03]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 52
images_for_training/266
(1, 64, 64, 3)
Policy eval: 
[[  3.33274335e-01   1.05937133e-02   1.10348212e-02   8.97458754e-03
    1.89802365e-03   2.54181549e-02   4.33768472e-03   3.50337960e-02
    3.52389477e-02   2.24778103e-03   7.55142944e-04   4.27157059e-02
    1.94369652e-03   1.14477031e-01   6.30264496e-03   3.27166868e-03
    1.33034894e-02   4.53381613e-03   6.76819310e-03   4.11623456e-02
    1.00097647e-02   6.10253424e-04   3.21322074e-03   3.98951117e-03
    4.76006593e-04   3.41447839e-03   6.00869581e-02   5.21949539e-03
    1.17744086e-03   5.25042266e-02   2.22540237e-02   4.84828226e-04
    1.43110636e-03   4.83585410e-02   1.48477126e-02   9.38424654e-03
    1.65543426e-02   9.48454067e-03   2.79053543e-02   5.06003061e-03
    2.48311000e-04]]
Action: 0.8
Enter Reward: 0
Backpropping 

Session Number 53
images_for_training/77
(1, 64, 64, 3)
Policy eval: 
[[ 0.1633891   0.05547394  0.06505539  0.00635253  0.00908541  0.00978264
   0.00289215  0.02521484  0.02583863  0.02075411  0.0117474   0.00182732
   0.02291597  0.00247089  0.02491676  0.00294315  0.03041051  0.09277318
   0.00841042  0.01265187  0.02979414  0.00507054  0.00989932  0.0094213
   0.0023563   0.06547053  0.02701597  0.00938875  0.00395025  0.03166827
   0.04128059  0.00458358  0.03072068  0.00341673  0.00777482  0.04243987
   0.00666645  0.0141984   0.03798278  0.00132575  0.02066885]]
Action: 1.15
Enter Reward: 1
Backpropping 

Session Number 54
images_for_training/189
(1, 64, 64, 3)
Policy eval: 
[[ 0.0389993   0.03959606  0.02786338  0.01415553  0.02083833  0.02354143
   0.02137228  0.0272558   0.03802586  0.02448346  0.01610597  0.02357963
   0.02191384  0.0168968   0.01751463  0.02075008  0.03400082  0.03103803
   0.01966463  0.0155969   0.01859421  0.02018472  0.01142774  0.02096827
   0.02248315  0.02370981  0.02828817  0.02633423  0.02626824  0.02844354
   0.02587427  0.02183033  0.01651204  0.0268179   0.02461611  0.04032275
   0.02389286  0.02316954  0.02752055  0.03011202  0.01943682]]
Action: 0.25
Enter Reward: 0
Backpropping 

Session Number 55
images_for_training/295
(1, 64, 64, 3)
Policy eval: 
[[ 0.01776057  0.05572102  0.03524607  0.00702579  0.00604929  0.01314022
   0.00056054  0.00803446  0.02272952  0.00977969  0.00852904  0.01020514
   0.00338993  0.05805938  0.00319476  0.00482937  0.02565291  0.00778002
   0.00697564  0.17339751  0.0079305   0.00290256  0.00629111  0.00790774
   0.00051671  0.00953031  0.01001631  0.04302273  0.04162348  0.01445948
   0.01386375  0.00230685  0.00900294  0.1657422   0.01030816  0.09485445
   0.00909143  0.00895033  0.00644731  0.01450845  0.04266227]]
Action: 1.5
Enter Reward: 0
Backpropping 

Session Number 56
images_for_training/195
(1, 64, 64, 3)
Policy eval: 
[[ 0.02301565  0.03562608  0.02628671  0.01523843  0.02541641  0.0292623
   0.01642863  0.02397328  0.03137197  0.02637664  0.025428    0.02534722
   0.02750696  0.0223951   0.01655199  0.01916418  0.04086746  0.02915511
   0.01721507  0.02821472  0.03128304  0.01942516  0.0169644   0.02347922
   0.02106944  0.02020331  0.02347077  0.03138928  0.02416385  0.02515523
   0.02755926  0.02124553  0.02087685  0.02127666  0.0275392   0.01954713
   0.02006539  0.02513284  0.02496839  0.02430384  0.0260393 ]]
Action: 1.4
Enter Reward: 0
Backpropping 

Session Number 57
images_for_training/32
(1, 64, 64, 3)
Policy eval: 
[[ 0.02148887  0.0474618   0.06154579  0.00684045  0.02201228  0.01454041
   0.00310144  0.01028416  0.04613696  0.00597204  0.07632172  0.04200799
   0.01308281  0.01577821  0.00687245  0.03772676  0.07249787  0.02454019
   0.02005642  0.02566064  0.05165297  0.00352826  0.01250291  0.0262292
   0.01180831  0.02025928  0.00446372  0.05454728  0.05748523  0.00890187
   0.01299066  0.01951162  0.0070411   0.0111682   0.03694109  0.03114078
   0.01305825  0.01208554  0.0057865   0.01687385  0.00809411]]
Action: 0.8
Enter Reward: 1
Backpropping 

Session Number 58
images_for_training/2
(1, 64, 64, 3)
Policy eval: 
[[ 0.00937894  0.14377561  0.01763862  0.01293417  0.0326707   0.02979783
   0.004337    0.01084911  0.02324625  0.00904376  0.00616765  0.01630671
   0.04155788  0.00959358  0.01937199  0.00667578  0.0493837   0.01335237
   0.04983934  0.02876626  0.00540198  0.02440666  0.00486839  0.01917816
   0.00338444  0.01724828  0.00840003  0.0434501   0.0190852   0.03903996
   0.04677729  0.01477571  0.0066436   0.02238677  0.05502639  0.05891306
   0.00884327  0.004415    0.04169653  0.00352639  0.01784551]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 59
images_for_training/157
(1, 64, 64, 3)
Policy eval: 
[[ 0.02689527  0.02805522  0.02723462  0.02047086  0.02361676  0.02787914
   0.02149928  0.02199671  0.02961249  0.02179235  0.02593548  0.02639491
   0.02096211  0.02242182  0.02378538  0.02122422  0.03052973  0.02322025
   0.02516167  0.02090342  0.02281284  0.02110815  0.02178253  0.02197606
   0.02317251  0.02252004  0.02458756  0.02684448  0.02368936  0.02504457
   0.02458289  0.02712543  0.026804    0.02392924  0.02232489  0.02708295
   0.02186836  0.02519953  0.02716491  0.02581414  0.02497378]]
Action: 1.35
Enter Reward: 0
Backpropping 

Session Number 60
images_for_training/215
(1, 64, 64, 3)
Policy eval: 
[[ 0.0375865   0.03780012  0.07382727  0.07060067  0.02248945  0.00584107
   0.00970114  0.06320903  0.02140974  0.01227869  0.01254282  0.03815326
   0.01635231  0.0158983   0.00417031  0.00660062  0.01086577  0.01073138
   0.04493074  0.02016899  0.01302568  0.0063721   0.01625994  0.00519661
   0.00436149  0.00838121  0.05554473  0.0135146   0.00568279  0.14014468
   0.01598954  0.00156566  0.02730288  0.01725874  0.02772687  0.02136596
   0.01699177  0.00209891  0.01103406  0.00516645  0.04985717]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 61
images_for_training/35
(1, 64, 64, 3)
Policy eval: 
[[ 0.07681363  0.05713047  0.06965373  0.00813933  0.01768622  0.01602022
   0.01355465  0.01398467  0.01568555  0.01810775  0.00825273  0.05306017
   0.03250301  0.02018206  0.00894934  0.00816128  0.06757995  0.02823605
   0.00601998  0.00801545  0.01948135  0.01505838  0.008708    0.01100501
   0.00628315  0.01119898  0.03601033  0.03208575  0.00865809  0.02005736
   0.05455425  0.0115109   0.00307722  0.07362534  0.01270449  0.02798936
   0.02202035  0.02238083  0.03380862  0.01035921  0.01168672]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 62
images_for_training/35
(1, 64, 64, 3)
Policy eval: 
[[ 0.02030099  0.11857411  0.03178171  0.01512578  0.01292707  0.04281633
   0.01420552  0.02754836  0.05383909  0.0246299   0.01519593  0.01664482
   0.01579177  0.00380152  0.0125692   0.01389363  0.0314298   0.015533
   0.08774428  0.02884878  0.02134294  0.00434638  0.0126337   0.01278338
   0.00571777  0.01656437  0.02559801  0.02132988  0.00816081  0.06612544
   0.02697059  0.01343496  0.01319414  0.02585931  0.01747341  0.01441369
   0.00791493  0.01507229  0.02454376  0.0220528   0.02126584]]
Action: 1.45
Enter Reward: 1
Backpropping 

Session Number 63
images_for_training/153
(1, 64, 64, 3)
Policy eval: 
[[ 0.03466053  0.03057235  0.02912707  0.0212794   0.02237445  0.02703153
   0.02155337  0.02055638  0.02168274  0.01952775  0.02281892  0.02392415
   0.0199109   0.02918734  0.02141447  0.02398134  0.03546499  0.02675477
   0.02696139  0.02401113  0.02537713  0.0177271   0.02537013  0.02225979
   0.01941242  0.02010696  0.03039243  0.02881949  0.02034946  0.01829834
   0.02260669  0.02740411  0.02259092  0.02169111  0.03101862  0.02257594
   0.02645457  0.03285363  0.0201533   0.02283498  0.01890798]]
Action: 1.5
Enter Reward: 0
Backpropping 

Session Number 64
images_for_training/69
(1, 64, 64, 3)
Policy eval: 
[[ 0.09447909  0.05486116  0.05750055  0.01539169  0.00787023  0.01618716
   0.01812517  0.00399614  0.03351332  0.02827656  0.0104545   0.0410733
   0.00676782  0.07950193  0.00882314  0.01920704  0.04118511  0.01807057
   0.01269434  0.01902699  0.03125745  0.00480646  0.01341669  0.01242815
   0.00487871  0.01018583  0.02213648  0.02955453  0.02206178  0.01513434
   0.02903272  0.00947786  0.01515004  0.03572229  0.02029058  0.02550473
   0.01975756  0.04255457  0.01082853  0.0241301   0.01468481]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 65
images_for_training/77
(1, 64, 64, 3)
Policy eval: 
[[ 0.03952289  0.08450466  0.10045042  0.00763968  0.02225871  0.01719823
   0.01835794  0.00497768  0.00953305  0.01005383  0.01727782  0.00312999
   0.01273019  0.02923936  0.00564341  0.02917111  0.03851658  0.0528562
   0.01137059  0.0248918   0.03579397  0.03645755  0.02290857  0.0055078
   0.00551005  0.00540985  0.00756267  0.00618866  0.0249239   0.00715278
   0.04197519  0.00667539  0.01676203  0.00433801  0.02158101  0.04446713
   0.09688069  0.04329064  0.01013842  0.00347533  0.01367623]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 66
images_for_training/183
(1, 64, 64, 3)
Policy eval: 
[[ 0.03163942  0.02918849  0.02785151  0.02111849  0.03098353  0.02681781
   0.02959323  0.02203405  0.02897283  0.02165818  0.02273388  0.02388994
   0.02620111  0.02251177  0.02195224  0.02173926  0.02451632  0.02842537
   0.02497035  0.02198309  0.02058546  0.0212085   0.02187785  0.02242508
   0.02435431  0.02574856  0.02153111  0.02385202  0.02477571  0.0257476
   0.02767573  0.02065927  0.02235095  0.02465646  0.02276522  0.02187926
   0.02627587  0.02397912  0.02353685  0.02016953  0.02516477]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 67
images_for_training/284
(1, 64, 64, 3)
Policy eval: 
[[  5.78940213e-01   1.11307517e-01   3.40253417e-03   1.34625016e-02
    2.36213375e-02   2.91417167e-03   1.00300321e-02   2.57650837e-02
    9.42620798e-04   4.64879500e-04   1.17302709e-03   1.07525650e-03
    5.68322081e-04   4.14006040e-03   4.09570610e-04   9.93712107e-04
    5.88105386e-03   5.55001572e-03   3.09094973e-02   1.22133596e-02
    1.29263802e-03   6.97154365e-03   3.71688016e-04   4.06504236e-03
    5.82999131e-03   9.21167061e-03   2.00222875e-03   5.87782683e-03
    1.51677907e-03   4.33735596e-03   7.97976255e-02   4.18338878e-03
    3.41595872e-03   7.33536435e-03   2.27598124e-03   8.45142733e-03
    1.54027306e-02   1.42307393e-03   6.85478270e-04   2.98957486e-04
    1.48853101e-03]]
Action: 0.85
Enter Reward: 1
Backpropping 

Session Number 68
images_for_training/146
(1, 64, 64, 3)
Policy eval: 
[[ 0.03500528  0.02763915  0.02417172  0.02032332  0.0316052   0.03053447
   0.02442424  0.02421016  0.02700224  0.02619193  0.02634267  0.01887493
   0.01523587  0.01895948  0.02423784  0.02913709  0.02541737  0.02941456
   0.02741067  0.02199939  0.02003088  0.02273839  0.01833373  0.02514769
   0.02631672  0.02234766  0.03869493  0.01896902  0.01997257  0.01941785
   0.01907057  0.01140968  0.02697736  0.02149358  0.01850455  0.04652213
   0.02220259  0.02404473  0.01973118  0.01933583  0.03060082]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 69
images_for_training/108
(1, 64, 64, 3)
Policy eval: 
[[ 0.05341499  0.02705643  0.03510903  0.02159725  0.02090836  0.02122744
   0.02300009  0.02726231  0.02833171  0.02138899  0.02537457  0.02113909
   0.02232086  0.02524995  0.02042194  0.01860003  0.02857582  0.03039003
   0.02261331  0.02021166  0.01930666  0.01811086  0.02289176  0.02499514
   0.01943077  0.02036175  0.0221577   0.02540974  0.01867566  0.02457754
   0.03023429  0.01678309  0.02663608  0.02473607  0.01854702  0.0267485
   0.02646847  0.03453014  0.02038385  0.02403845  0.02078265]]
Action: 1.6
Enter Reward: 0
Backpropping 

Session Number 70
images_for_training/75
(1, 64, 64, 3)
Policy eval: 
[[  9.45044041e-01   2.38308366e-02   3.46233859e-03   2.83925256e-05
    6.04040652e-05   8.87140850e-05   1.06794352e-03   1.40375376e-03
    8.26726388e-03   3.76256835e-03   1.01573452e-04   6.46577973e-05
    9.75861971e-04   5.19913505e-04   3.26029585e-05   2.81981170e-06
    4.13124013e-04   2.85904011e-04   4.25361446e-04   4.53793473e-05
    1.68588904e-05   8.22976017e-06   8.83544446e-04   2.11956649e-04
    1.39956035e-06   8.49650605e-05   3.59609294e-05   4.45936545e-04
    6.15941390e-05   5.08919356e-06   4.83925687e-03   2.42590486e-05
    6.47856286e-05   1.31960653e-04   7.92259088e-05   1.56742579e-04
    1.54146750e-04   1.44132227e-03   2.22318544e-04   1.00699568e-03
    2.40028603e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 71
images_for_training/55
(1, 64, 64, 3)
Policy eval: 
[[  1.69900313e-01   3.01090032e-01   1.72910523e-02   2.42632610e-04
    2.43851524e-02   2.24557426e-03   1.53009605e-03   1.61625084e-03
    7.88527133e-04   1.40497927e-03   4.52110980e-04   4.77027847e-03
    6.52128551e-03   9.47475992e-03   3.24296911e-04   8.11091799e-04
    4.97751422e-02   1.82231143e-03   1.20601908e-04   3.76327359e-03
    3.88018205e-04   2.83383706e-04   2.00472516e-03   8.35755607e-04
    3.36415134e-03   3.36133555e-04   3.56785813e-03   5.83301764e-03
    1.59870717e-03   4.92517720e-04   5.48406988e-02   1.27203832e-03
    1.83885521e-03   7.66428933e-02   4.29319497e-03   7.58594414e-03
    2.18986142e-02   1.93447664e-01   1.28235912e-03   1.92597900e-02
    6.03908789e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 72
images_for_training/175
(1, 64, 64, 3)
Policy eval: 
[[ 0.18981659  0.05140135  0.04023358  0.00818988  0.02527051  0.01513218
   0.03636456  0.02109981  0.02475506  0.02633546  0.01083558  0.02614439
   0.01828738  0.02185848  0.01167328  0.0150502   0.01574193  0.03322665
   0.01253838  0.0147919   0.00815915  0.01157602  0.03824381  0.0139972
   0.00836648  0.0161599   0.03794084  0.01612145  0.01772299  0.0206151
   0.03025797  0.00414001  0.01722476  0.02108171  0.00733057  0.02595107
   0.02495351  0.01959772  0.00752629  0.01567156  0.01861471]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 73
images_for_training/282
(1, 64, 64, 3)
Policy eval: 
[[  9.99945164e-01   1.19741208e-06   2.82705884e-07   1.14811199e-12
    6.34712016e-09   7.82124226e-11   5.05263316e-08   4.61679665e-05
    1.31418290e-07   1.91351646e-09   1.50766213e-13   8.21495025e-11
    2.23840493e-06   4.75707518e-09   1.99540895e-09   1.17336485e-09
    1.25310135e-06   1.18881019e-06   4.58892231e-07   6.87327084e-10
    1.53620953e-11   6.17429415e-12   8.98744065e-11   4.63441889e-11
    9.15449938e-11   3.14878019e-11   2.84197732e-09   1.92594762e-09
    5.84608360e-12   3.40467277e-09   8.66794281e-09   8.32237113e-10
    2.44466383e-12   1.12879810e-11   3.32168429e-12   3.79528515e-08
    4.77063679e-07   1.15891601e-06   1.26297750e-10   5.66322367e-09
    4.69648820e-10]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 74
images_for_training/282
(1, 64, 64, 3)
Policy eval: 
[[  4.90030798e-05   2.29315515e-06   1.26136592e-06   4.16051846e-11
    1.61813260e-12   5.52113597e-05   2.97831826e-09   9.31568511e-09
    2.46357587e-07   4.13505816e-08   2.29139641e-05   6.73548470e-08
    3.47128243e-10   5.72843874e-07   1.94424974e-08   3.44279465e-06
    1.84032387e-10   4.35894162e-06   6.29694270e-08   6.25795460e-09
    2.51044234e-08   4.75572056e-12   1.83334060e-11   1.39035157e-08
    6.69062894e-09   2.39564857e-09   8.38682536e-05   7.81474085e-09
    8.46965591e-14   2.81727752e-09   1.21530690e-07   8.99916088e-08
    1.22626045e-06   3.45756623e-09   2.54521718e-13   9.99339759e-01
    2.37679160e-06   6.84401748e-05   1.17714083e-09   3.64410982e-04
    3.08824855e-09]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 75
images_for_training/90
(1, 64, 64, 3)
Policy eval: 
[[  9.96262968e-01   4.84830853e-05   3.64719739e-07   1.69359715e-09
    4.99012231e-07   2.99345229e-05   1.11317444e-04   1.13806351e-07
    2.60082601e-07   7.35628944e-08   6.67309630e-09   1.03822664e-07
    3.66261399e-09   1.07834389e-07   3.33308776e-08   9.92125138e-09
    1.31816778e-05   4.94953467e-10   5.77552690e-08   6.21161234e-10
    2.31551865e-12   6.12311002e-09   8.14576595e-07   6.94994981e-07
    3.65236597e-09   9.26853403e-08   3.51336785e-03   2.50234091e-08
    2.71008882e-10   5.13860421e-08   7.85648808e-07   3.28378458e-09
    1.71943206e-08   3.55544465e-08   4.08290246e-09   4.22756602e-06
    1.12583393e-05   7.22578051e-08   4.26065213e-07   6.46266301e-07
    4.04761684e-12]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 76
images_for_training/97
(1, 64, 64, 3)
Policy eval: 
[[  9.09575105e-01   1.72013789e-03   3.46842367e-04   1.97940281e-07
    9.56805743e-05   1.47624928e-06   5.53849936e-02   1.61573655e-04
    1.07882116e-02   9.00948653e-05   1.76646339e-04   2.46203745e-05
    6.23329310e-04   4.55038913e-04   7.84962253e-07   5.79959647e-07
    6.87461521e-04   3.22931679e-03   3.84422322e-07   1.75432865e-06
    1.29289117e-06   6.51036771e-08   6.27324553e-05   3.23837725e-07
    1.27157473e-05   1.27996586e-07   8.19989111e-07   1.39803538e-04
    8.02475915e-05   6.48035325e-07   1.53366348e-03   2.83340396e-05
    4.80140880e-05   5.80392138e-04   4.35844839e-07   2.92065134e-03
    7.77016801e-04   9.74901393e-03   3.21274274e-04   2.35763055e-05
    3.54634336e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 77
images_for_training/135
(1, 64, 64, 3)
Policy eval: 
[[ 0.13215858  0.07474677  0.02167732  0.01111414  0.02817855  0.02214666
   0.01149834  0.01775167  0.01838962  0.01132902  0.03085205  0.01140151
   0.02021446  0.01261363  0.02097541  0.00916123  0.03028161  0.01193191
   0.0191604   0.0134141   0.01460973  0.00687858  0.02784271  0.01325454
   0.00848332  0.02197375  0.06330355  0.03416554  0.00863024  0.03032801
   0.06258532  0.01389767  0.02225319  0.01813361  0.01647255  0.01103019
   0.02584441  0.03228896  0.01223448  0.01715079  0.00964192]]
Action: 1.5
Enter Reward: 0
Backpropping 

Session Number 78
images_for_training/124
(1, 64, 64, 3)
Policy eval: 
[[  5.66865504e-01   6.94711320e-03   2.09251419e-02   2.28804676e-03
    8.52396130e-04   6.75473874e-03   1.77948978e-02   5.15478244e-03
    2.75773033e-02   3.02972756e-02   6.21072762e-03   1.01922052e-02
    4.11125412e-03   1.49904669e-03   1.13103595e-02   1.66598463e-03
    8.14581569e-03   1.17183719e-02   1.15384366e-02   4.47957776e-03
    3.83308250e-03   5.28672826e-04   4.48483974e-03   9.30468645e-03
    6.87133241e-03   3.09044984e-03   2.85799336e-02   6.68399781e-03
    1.06259156e-02   3.18048848e-03   5.61437085e-02   2.67387554e-03
    5.57181751e-03   3.25536951e-02   3.81142809e-03   1.61575750e-02
    3.20495176e-03   3.41766477e-02   5.17055206e-03   6.03996310e-03
    9.83442413e-04]]
Action: 1.2
Enter Reward: 0
Backpropping 

Session Number 79
images_for_training/127
(1, 64, 64, 3)
Policy eval: 
[[  5.90165734e-01   9.55564603e-02   3.55338082e-02   1.38738623e-03
    1.25206041e-03   3.82032758e-03   2.71949358e-03   4.58932854e-02
    7.17890915e-03   6.60770806e-04   3.37017514e-03   6.45966269e-04
    5.13627008e-03   1.78982760e-03   3.47590121e-03   1.88855000e-03
    1.49194850e-02   1.60099345e-03   7.50458520e-03   7.95367826e-03
    8.54701851e-04   1.78241622e-04   2.49469350e-03   2.04576645e-03
    2.22396897e-03   3.30529088e-04   8.78334790e-03   1.56139424e-02
    9.63052007e-05   3.05588031e-03   4.79305573e-02   6.97846815e-04
    9.38326865e-03   2.97158072e-03   5.74298436e-04   1.71195492e-02
    4.87341778e-03   2.51520760e-02   3.30275320e-03   1.74523871e-02
    2.41121231e-03]]
Action: 1.8
Enter Reward: 1
Backpropping 

Session Number 80
images_for_training/111
(1, 64, 64, 3)
Policy eval: 
[[ 0.43604156  0.01628037  0.04161392  0.00283165  0.00125503  0.02055199
   0.00618779  0.0054987   0.02590317  0.01091578  0.01122593  0.01547302
   0.00687238  0.0037839   0.02493744  0.00645906  0.00942649  0.00806079
   0.01647907  0.01105165  0.02394549  0.0023503   0.00932563  0.00926374
   0.00331615  0.00516347  0.01514543  0.00419921  0.00218003  0.00255178
   0.07591911  0.0059693   0.00768725  0.04291033  0.00688325  0.01042393
   0.00911248  0.04630974  0.00925494  0.02023144  0.00700727]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 81
images_for_training/11
(1, 64, 64, 3)
Policy eval: 
[[  9.42334473e-01   8.40747307e-05   3.94189283e-02   3.56592827e-05
    2.73073441e-03   1.72730244e-04   1.71140011e-03   8.95627076e-04
    5.26871416e-04   2.20841932e-04   8.95245648e-07   6.16125995e-04
    3.11165990e-04   5.93035020e-06   3.24752691e-05   8.78693572e-06
    3.38079612e-04   3.15405377e-05   3.44129745e-04   7.92616356e-06
    5.34275705e-06   3.83333027e-05   4.60363692e-04   3.04039872e-06
    1.54106954e-06   7.71031264e-05   8.53149220e-03   1.54456757e-05
    3.77197139e-05   1.50643348e-06   3.43589309e-05   2.02203446e-04
    1.78787828e-04   7.08329367e-07   4.15092014e-04   2.48305769e-05
    9.97797251e-05   3.77196602e-06   2.83092031e-05   1.03914963e-05
    1.40932741e-06]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 82
images_for_training/167
(1, 64, 64, 3)
Policy eval: 
[[ 0.32550001  0.02839479  0.03063687  0.01417167  0.03219707  0.0149508
   0.03261396  0.04274767  0.0177361   0.00736514  0.00578567  0.00966003
   0.00939067  0.00994103  0.01350677  0.00790754  0.01097135  0.02502243
   0.01270858  0.01179851  0.01275172  0.00886731  0.00900938  0.01230807
   0.01342987  0.0229553   0.05075415  0.00830914  0.00727077  0.01592954
   0.01208146  0.01078117  0.01659834  0.01835405  0.01298072  0.01745681
   0.02933366  0.02037272  0.02048724  0.0105543   0.00640753]]
Action: 1.25
Enter Reward: 0
Backpropping 

Session Number 83
images_for_training/219
(1, 64, 64, 3)
Policy eval: 
[[  9.99749243e-01   1.53717576e-06   9.65100990e-05   1.65489678e-09
    4.55657734e-08   3.79203470e-06   5.62146241e-08   3.35535733e-05
    7.81452254e-05   1.56593831e-06   2.75933104e-07   8.38163539e-10
    3.24862839e-08   4.57431533e-08   1.31655553e-09   6.50174137e-10
    6.36343066e-06   3.68007633e-08   1.07332925e-08   6.56612498e-09
    2.22452751e-11   7.04899383e-09   4.28273736e-08   1.65141567e-09
    2.41654474e-11   5.38791289e-10   1.27631001e-05   1.63267680e-06
    5.17451504e-09   1.18789201e-09   6.43627061e-07   2.92508448e-11
    1.30579323e-07   1.59395395e-08   7.03801772e-09   2.00210820e-07
    9.61655076e-08   2.73295200e-06   4.84932050e-09   1.04381406e-05
    2.62487718e-14]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 84
images_for_training/295
(1, 64, 64, 3)
Policy eval: 
[[  6.88922256e-02   9.05434310e-01   2.43558530e-02   3.79504012e-10
    4.13215702e-07   2.41145788e-08   2.84788664e-04   6.32706474e-07
    8.93710312e-05   1.79607957e-06   3.33875647e-08   1.61234257e-05
    8.91405216e-05   9.17839031e-08   1.41925440e-08   1.28389024e-08
    2.66373645e-05   3.98790889e-10   9.99214649e-08   3.69198694e-09
    1.62994063e-09   3.33463079e-09   1.82645419e-08   7.38272560e-04
    2.79726931e-09   2.33053310e-09   2.52580212e-05   1.76951689e-05
    6.13350366e-08   2.70466148e-06   1.71228237e-06   3.38473660e-06
    5.16208853e-09   4.20146016e-08   4.77610365e-06   5.97026002e-08
    1.28909178e-05   1.12183329e-06   3.94704017e-07   9.64367808e-10
    1.03749347e-08]]
Action: 0.65
Enter Reward: 1
Backpropping 

Session Number 85
images_for_training/187
(1, 64, 64, 3)
Policy eval: 
[[ 0.14734425  0.11722813  0.02554008  0.00743375  0.019613    0.03659342
   0.02726455  0.02043057  0.02837107  0.00951667  0.0185299   0.01035575
   0.01319899  0.00561117  0.01118603  0.00987193  0.01748255  0.04468964
   0.01897841  0.0202259   0.01512264  0.01036198  0.01608638  0.02634134
   0.0142006   0.02052226  0.01405311  0.03968078  0.005444    0.0288546
   0.01827717  0.00917868  0.01333636  0.02712014  0.00962535  0.02738927
   0.02430379  0.02492475  0.01489292  0.01971211  0.01110604]]
Action: 0.65
Enter Reward: 0
Backpropping 

Session Number 86
images_for_training/28
(1, 64, 64, 3)
Policy eval: 
[[  4.18145116e-03   5.98258786e-02   7.61700794e-03   5.73839425e-05
    5.20757574e-04   3.31521709e-03   1.48795650e-03   2.73878151e-03
    2.77180248e-03   1.00142870e-03   4.78606950e-03   2.80720252e-03
    3.20584775e-04   1.07564742e-03   3.21413623e-04   3.12734954e-03
    5.77576458e-03   3.64982313e-03   6.69880945e-04   3.32237477e-03
    6.46770117e-04   6.04437446e-05   1.53184019e-03   1.10685907e-03
    2.21272069e-03   8.22679140e-04   1.61578786e-02   6.86069950e-03
    5.05999742e-05   5.80149004e-04   1.30317081e-02   8.29033437e-04
    5.39633445e-03   9.96322371e-03   1.72082160e-04   1.96324140e-01
    7.52334995e-03   5.64215541e-01   6.91304798e-04   6.23694882e-02
    7.93672079e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 87
images_for_training/4
(1, 64, 64, 3)
Policy eval: 
[[  1.91799134e-01   4.07624841e-01   1.22229122e-02   2.75701750e-04
    6.70486479e-04   2.43569678e-03   2.58045807e-03   2.88435910e-02
    4.13521705e-03   1.88698992e-03   8.83745849e-02   4.88618505e-04
    2.46353401e-03   2.17591933e-05   1.22115656e-03   3.45364725e-03
    1.71255376e-02   1.13578606e-03   3.87561843e-02   4.54852954e-02
    4.06627171e-03   3.34776938e-04   2.18359957e-04   1.29452404e-02
    7.93803338e-05   2.79953051e-02   4.79220325e-04   2.18145065e-02
    1.51365798e-03   1.88610482e-03   1.94229037e-02   8.27873184e-04
    1.00841653e-03   1.06756249e-03   5.12082921e-03   4.46764566e-02
    3.08790593e-04   2.02288432e-03   3.04501317e-03   8.80835723e-05
    7.71929408e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 88
images_for_training/96
(1, 64, 64, 3)
Policy eval: 
[[  1.62354916e-01   2.69967973e-01   1.28669608e-02   1.32835441e-04
    1.66322832e-04   1.92597126e-05   1.61735035e-04   1.43175316e-03
    4.27789148e-03   6.29249378e-04   6.60529651e-04   4.87257028e-03
    1.76377594e-01   5.23746479e-03   2.24857897e-04   7.47758197e-04
    1.02035366e-02   1.59995048e-04   1.19038508e-04   8.90215766e-03
    2.27916194e-03   3.89387242e-05   9.00329323e-04   4.75180801e-04
    2.12158579e-06   1.40019802e-06   4.66449012e-04   3.12229851e-04
    7.27834459e-03   1.56236609e-04   2.87515402e-01   5.00477792e-04
    4.53745539e-04   1.19904440e-03   3.77359018e-02   3.37941281e-04
    1.49877742e-04   2.89521646e-04   1.08231281e-04   6.22125663e-05
    2.22769246e-04]]
Action: 0.95
Enter Reward: 1
Backpropping 

Session Number 89
images_for_training/296
(1, 64, 64, 3)
Policy eval: 
[[  5.23655295e-01   4.66072589e-01   7.91117054e-06   2.81603170e-05
    1.88843273e-06   1.10127257e-04   6.70826389e-03   2.00776904e-05
    5.84458248e-05   7.82524978e-07   5.20466128e-04   2.12138228e-04
    1.74805280e-06   1.22789713e-03   9.44183012e-06   2.80787253e-06
    1.63799172e-07   3.95024726e-05   9.71184054e-05   1.20474124e-05
    1.70106333e-07   1.16811293e-07   1.31609631e-04   6.23176893e-05
    3.26751820e-06   2.24101517e-04   2.53241960e-05   5.10256068e-05
    9.47600165e-06   1.32016476e-05   1.30588538e-04   5.38684446e-07
    1.56195222e-06   2.81496992e-04   5.49600372e-05   3.90136665e-05
    9.91299894e-05   6.53340467e-05   1.39862159e-05   5.86493161e-06
    3.01021608e-08]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 90
images_for_training/223
(1, 64, 64, 3)
Policy eval: 
[[  9.99873638e-01   1.31668685e-05   4.74462468e-07   6.79852263e-08
    2.67764676e-07   2.62098041e-07   1.18292201e-05   1.14153579e-07
    1.84582660e-07   2.27324699e-06   2.51499671e-07   6.39056879e-08
    3.20758708e-08   5.90949057e-05   1.53095914e-09   1.29403350e-08
    7.25782172e-08   4.59349758e-09   6.88325883e-07   4.67908677e-07
    3.69311959e-09   5.22094368e-09   2.03806553e-06   2.60553112e-09
    3.74011844e-09   6.02762174e-10   3.29100794e-06   3.35726789e-08
    1.26270123e-07   1.97863659e-09   1.85736712e-06   1.63529612e-09
    2.97006721e-07   2.48359333e-06   2.48467004e-05   1.29872410e-06
    4.93382686e-07   1.41063879e-07   4.69131134e-09   6.34024460e-08
    3.23504978e-09]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 91
images_for_training/156
(1, 64, 64, 3)
Policy eval: 
[[ 0.03973606  0.04151433  0.0238888   0.01900709  0.02716697  0.03053543
   0.03133827  0.03495641  0.02186956  0.01815007  0.02738056  0.02555103
   0.01700087  0.02275026  0.0156527   0.02356333  0.02464932  0.02773802
   0.02521852  0.02066682  0.02027955  0.01764949  0.01836287  0.01829312
   0.02185828  0.0221412   0.0237437   0.02721391  0.02467415  0.01440803
   0.04072823  0.02083034  0.02384352  0.02366721  0.02585806  0.03078638
   0.02953991  0.03699597  0.01558342  0.01254887  0.01265936]]
Action: 0.4
Enter Reward: 0
Backpropping 

Session Number 92
images_for_training/293
(1, 64, 64, 3)
Policy eval: 
[[  3.58364254e-01   5.24864316e-01   6.91445952e-04   3.92430366e-06
    1.22565631e-04   3.23801999e-07   1.05615058e-04   1.72186911e-03
    5.46165102e-04   1.73117917e-06   3.42430323e-02   6.44548854e-05
    2.16058316e-03   4.72221087e-04   9.50585309e-06   4.90246111e-06
    4.47065430e-03   1.50526859e-04   4.98688081e-03   4.82381656e-05
    3.97827360e-04   8.19466823e-06   5.44147892e-03   1.77931452e-05
    7.59746617e-05   2.22366798e-05   2.02184019e-05   9.13405238e-05
    1.49828302e-05   1.48356257e-05   5.30174235e-04   2.69805514e-06
    6.86538266e-03   7.09615924e-05   6.66073465e-05   2.15844437e-02
    5.06852008e-03   2.60871723e-02   5.25212963e-04   4.69866936e-05
    1.37386751e-05]]
Action: 1.5
Enter Reward: 0
Backpropping 

Session Number 93
images_for_training/132
(1, 64, 64, 3)
Policy eval: 
[[ 0.13003919  0.07275692  0.02798419  0.01416892  0.01988575  0.01455304
   0.00722896  0.02367889  0.00706609  0.00543636  0.03217314  0.00950625
   0.04067196  0.01583868  0.01692421  0.00816616  0.02367902  0.0387096
   0.01341358  0.03115307  0.02639068  0.00970908  0.03071921  0.01774032
   0.00791837  0.02791715  0.01465094  0.02198045  0.01967149  0.01041041
   0.05055676  0.01434983  0.01401092  0.01964483  0.0184424   0.04318861
   0.02700184  0.03142323  0.02162046  0.00438204  0.01523696]]
Action: 1.85
Enter Reward: 1
Backpropping 

Session Number 94
images_for_training/131
(1, 64, 64, 3)
Policy eval: 
[[ 0.09773678  0.05222329  0.03061615  0.01000956  0.01536431  0.02216177
   0.01611057  0.05185785  0.03039553  0.0137359   0.0214916   0.02934925
   0.01166005  0.01784434  0.00916723  0.00837484  0.04709087  0.0336665
   0.0119202   0.01145054  0.01204573  0.00732553  0.01826621  0.01560163
   0.02534468  0.00548369  0.02659572  0.02106171  0.00931992  0.01474581
   0.03344457  0.0089464   0.04416065  0.03742448  0.01442312  0.03693341
   0.02712103  0.04210922  0.01350701  0.03505541  0.00885695]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 95
images_for_training/10
(1, 64, 64, 3)
Policy eval: 
[[ 0.34816146  0.21386245  0.00580964  0.00231233  0.01005388  0.00388258
   0.01200002  0.02070965  0.0040063   0.01215255  0.01029822  0.01659199
   0.02407854  0.01627402  0.00210389  0.00999527  0.02722202  0.0038169
   0.0179091   0.00427739  0.00765983  0.00166745  0.01148048  0.02701238
   0.00209857  0.0023203   0.00707279  0.01225269  0.00172297  0.01010314
   0.0225632   0.00362235  0.00995008  0.00772946  0.00642127  0.00780271
   0.04806046  0.01057823  0.01140234  0.01949476  0.00346635]]
Action: 1.85
Enter Reward: 1
Backpropping 

Session Number 96
images_for_training/167
(1, 64, 64, 3)
Policy eval: 
[[ 0.09498096  0.07321164  0.02918704  0.01619474  0.03732867  0.01303989
   0.02192965  0.02287284  0.0132212   0.01608997  0.02083119  0.02057332
   0.01453006  0.02462724  0.02365933  0.02383926  0.04331528  0.0257128
   0.01568014  0.01986354  0.01989893  0.00949323  0.01470972  0.02458293
   0.01318525  0.00692781  0.01893599  0.03223547  0.01697562  0.01056065
   0.03058327  0.02312887  0.01703633  0.01820514  0.02182827  0.02440878
   0.04821678  0.02433523  0.02650682  0.01577643  0.01177971]]
Action: 1.75
Enter Reward: 1
Backpropping 

Session Number 97
images_for_training/289
(1, 64, 64, 3)
Policy eval: 
[[  6.35789335e-03   9.87156689e-01   1.51954538e-07   4.50093967e-06
    1.31128167e-04   2.19772460e-06   3.51838850e-07   6.11887008e-05
    4.27955592e-06   2.38570976e-08   6.20531093e-04   7.55340324e-09
    1.41159708e-05   1.20603117e-05   8.68705172e-07   2.48733603e-08
    3.58537977e-06   2.77669551e-06   1.87601131e-06   1.83404342e-03
    4.04518069e-04   7.10957409e-08   1.64970493e-06   6.85691484e-05
    5.48361179e-09   5.85736075e-07   5.81688226e-08   6.07280454e-05
    1.81770902e-05   2.84051066e-06   2.98383180e-03   3.31742065e-08
    5.49871220e-06   4.66034135e-06   5.14725889e-06   1.72242158e-04
    6.36960249e-06   2.83863010e-05   8.65080347e-06   1.51912801e-07
    1.94313325e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 98
images_for_training/181
(1, 64, 64, 3)
Policy eval: 
[[ 0.06940173  0.05993848  0.01706152  0.02478279  0.03757928  0.01628557
   0.02807772  0.03672202  0.0289981   0.02277584  0.02758113  0.01104044
   0.01485217  0.02060863  0.02490286  0.010078    0.03170051  0.01597689
   0.02345255  0.01831097  0.01669725  0.01264041  0.01816346  0.02812136
   0.01640682  0.01333871  0.01571948  0.02253335  0.02016392  0.02946218
   0.03811629  0.01115822  0.02069767  0.02521274  0.03503456  0.01738597
   0.02754872  0.02753946  0.02287911  0.01504639  0.02600672]]
Action: 0.85
Enter Reward: 0
Backpropping 

Session Number 99
images_for_training/178
(1, 64, 64, 3)
Policy eval: 
[[ 0.04680261  0.06828574  0.03081974  0.01328695  0.02000217  0.01974175
   0.0268934   0.02082262  0.0181131   0.01881861  0.04111922  0.01824585
   0.03183635  0.02092888  0.02104716  0.01503651  0.028556    0.0364711
   0.02111497  0.02039975  0.01944165  0.01592911  0.02841698  0.02956948
   0.02306732  0.0130156   0.01556897  0.02606695  0.01912852  0.01423083
   0.02804662  0.01707293  0.02301766  0.02175598  0.01330584  0.03733445
   0.03549778  0.02832028  0.0163261   0.0163344   0.02021009]]
Action: 1.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 19:08:57.605960: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/284
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.04460216e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   8.06883509e-06
    9.71920997e-38   0.00000000e+00   0.00000000e+00   2.10791353e-26
    0.00000000e+00   1.85425690e-16   0.00000000e+00   0.00000000e+00
    0.00000000e+00   2.10051745e-29   0.00000000e+00   9.99991894e-01
    1.65834978e-33   1.27371884e-34   0.00000000e+00   5.02603518e-37
    0.00000000e+00]]
2018-10-05 19:08:59.193 Python[33642:13846339] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 0.7
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/18
(1, 64, 64, 3)
Policy eval: 
[[  5.34855049e-09   3.35278356e-34   3.71135367e-09   5.27925203e-29
    1.15479322e-14   0.00000000e+00   9.25364861e-29   0.00000000e+00
    0.00000000e+00   6.56291244e-09   1.38333128e-35   2.55576024e-24
    0.00000000e+00   0.00000000e+00   9.17226370e-27   1.42738921e-21
    0.00000000e+00   8.42823695e-08   9.99999881e-01   7.01355977e-30
    4.14122721e-18   1.47027596e-34   7.89256915e-15   4.40293201e-12
    0.00000000e+00   1.13528683e-28   0.00000000e+00   5.41529385e-24
    1.07490678e-32   2.68014934e-33   4.98952730e-31   1.68535602e-14
    6.49690897e-22   7.15087501e-24   0.00000000e+00   6.30939861e-16
    0.00000000e+00   7.91111499e-28   1.26754515e-25   1.67203075e-28
    0.00000000e+00]]
Action: 1.35
Enter Reward: 1
Backpropping 

Session Number 2
images_for_training/234
(1, 64, 64, 3)
Policy eval: 
[[  3.38936569e-21   0.00000000e+00   0.00000000e+00   1.41451972e-38
    0.00000000e+00   0.00000000e+00   4.73294247e-36   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   6.38276156e-35   7.87385119e-26
    0.00000000e+00   2.16072986e-24   4.78790385e-09   0.00000000e+00
    7.65778734e-33   0.00000000e+00   0.00000000e+00   2.12673529e-17
    0.00000000e+00   0.00000000e+00   9.10032370e-36   7.81408808e-28
    1.00000000e+00   1.26351322e-19   0.00000000e+00   1.89074466e-37
    1.71314057e-11   0.00000000e+00   2.57318032e-34   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   5.36971294e-38
    0.00000000e+00]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 3
images_for_training/250
(1, 64, 64, 3)
Policy eval: 
[[  4.67962712e-01   2.66057292e-21   3.25012141e-26   5.18134384e-21
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   2.06772785e-30   0.00000000e+00   8.54457635e-37
    4.21025434e-34   0.00000000e+00   4.32871289e-21   2.69999990e-27
    0.00000000e+00   3.68805594e-12   3.89608814e-21   7.65230467e-28
    1.36342936e-16   5.41935319e-18   4.33303565e-01   9.44506377e-02
    1.54151841e-38   3.73340059e-24   3.96604225e-21   6.41355134e-28
    8.46930436e-26   0.00000000e+00   1.30591453e-33   1.25515300e-18
    8.30694030e-21   4.74615625e-34   4.91397636e-26   4.28303983e-03
    0.00000000e+00   2.29026356e-19   0.00000000e+00   7.10364575e-22
    0.00000000e+00]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/105
(1, 64, 64, 3)
Policy eval: 
[[  2.99502820e-01   5.84124148e-01   1.58825377e-03   8.70897239e-08
    3.98363454e-07   1.54789419e-07   4.96917812e-04   3.46841778e-10
    4.88457408e-06   2.51171491e-06   7.07209793e-08   8.54044119e-05
    2.80161184e-04   1.08224253e-06   1.48924795e-04   1.68566636e-08
    1.83017757e-09   4.04996012e-04   3.10917414e-04   2.72834200e-08
    4.76147048e-04   2.13210296e-05   8.95548030e-04   6.80546016e-02
    7.15839299e-09   2.00076727e-04   6.91788300e-05   2.29070578e-02
    4.17903997e-03   6.11968790e-05   3.93450973e-05   1.07305941e-05
    3.76759242e-04   1.53649819e-06   8.61982536e-03   7.12663867e-03
    5.57426574e-07   5.85523139e-06   2.96537426e-08   2.88120077e-06
    1.36311545e-10]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 5
images_for_training/177
(1, 64, 64, 3)
Policy eval: 
[[  3.87510180e-01   1.07836269e-01   5.54099155e-04   8.92792923e-11
    1.75927009e-04   1.95934877e-06   4.92077634e-05   5.27870088e-06
    5.50615820e-09   3.56399505e-05   5.73495618e-06   2.63481983e-04
    1.27323673e-07   2.08027586e-07   3.01766158e-05   1.53371639e-05
    2.58093058e-09   1.16501555e-01   2.58299056e-04   1.71714518e-07
    2.15831042e-05   5.75270178e-03   7.92020801e-05   1.22662168e-04
    6.57221619e-07   2.02437658e-02   6.55027252e-05   9.10001690e-05
    7.55409928e-05   5.44354907e-06   8.89243747e-05   1.00349556e-04
    2.02744150e-06   3.20624700e-03   1.60802085e-06   3.56893063e-01
    2.31418562e-06   6.44365969e-07   1.02694116e-06   2.01290754e-06
    3.02524654e-08]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 6
images_for_training/108
(1, 64, 64, 3)
Policy eval: 
[[  7.09189614e-03   1.17281243e-01   7.91380735e-05   4.14357964e-05
    5.51684097e-05   5.54744028e-09   9.01611838e-06   2.83139173e-07
    1.34044413e-07   6.87158717e-06   1.15830261e-08   1.07228625e-04
    9.43827771e-09   3.77968092e-08   7.91823913e-05   2.71990039e-08
    1.20742956e-12   3.06809694e-01   3.67157049e-02   2.94851452e-05
    8.14189017e-03   5.38350374e-04   9.49225341e-06   3.69141926e-05
    4.09672310e-07   1.20189525e-05   9.39181675e-08   5.04458285e-06
    4.98675168e-01   1.31960451e-05   1.75079967e-05   1.72052343e-04
    6.48535490e-07   2.71965167e-04   8.43436432e-09   2.37037446e-02
    1.39429384e-08   4.15025133e-05   1.13088859e-07   5.33208840e-05
    1.66221509e-10]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 7
images_for_training/283
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   1.50362114e-35   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   6.50252677e-18   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    9.44872538e-23   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.17203840e-32
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 8
images_for_training/129
(1, 64, 64, 3)
Policy eval: 
[[  1.44873311e-05   9.99985456e-01   1.00616463e-16   1.37102243e-29
    1.88871553e-12   7.02839935e-16   6.96309059e-18   4.42146334e-21
    1.18293629e-23   9.00993458e-28   1.14561980e-21   6.48199897e-11
    1.55558436e-19   5.70650154e-27   3.47891977e-19   8.80123983e-16
    1.48413111e-30   2.78182721e-08   2.00669967e-16   2.38934432e-21
    2.26023054e-11   1.98573087e-21   1.16811801e-12   9.52361079e-10
    5.98255379e-19   3.73650937e-12   1.15267544e-17   6.67254159e-20
    5.35209065e-11   8.27401619e-11   1.58758396e-13   7.62809886e-14
    9.30915811e-17   1.81511050e-15   3.93909731e-11   9.67452229e-11
    4.65830057e-16   1.83186155e-14   2.29590614e-23   1.25427526e-18
    1.28567909e-21]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 9
images_for_training/17
(1, 64, 64, 3)
Policy eval: 
[[  1.73170265e-33   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   8.73600964e-38   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/259
(1, 64, 64, 3)
Policy eval: 
[[  6.17313776e-20   6.57336533e-01   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   4.63334416e-24   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   5.60964438e-38   1.03332848e-20   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.60380496e-21   0.00000000e+00   0.00000000e+00   2.16170168e-03
    0.00000000e+00   5.01550102e-31   0.00000000e+00   3.40501726e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/73
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.83105204e-19   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.54950039e-27
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.9
Enter Reward: 1
Backpropping 

Session Number 12
images_for_training/77
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   7.85557804e-34   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   3.63932449e-29   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 13
images_for_training/137
(1, 64, 64, 3)
Policy eval: 
[[  7.49416929e-03   2.87532359e-01   2.58386019e-04   7.30734310e-12
    1.05357039e-08   6.85859789e-07   1.19400318e-06   2.40083264e-09
    5.96055827e-07   2.89796236e-13   8.17156898e-10   7.28703861e-04
    7.18315107e-07   1.68236483e-08   7.63063397e-12   1.17958086e-02
    1.25268112e-12   2.82643350e-06   9.92023014e-03   3.19382416e-05
    2.49640692e-07   2.93393700e-08   1.24468249e-06   2.24520704e-06
    4.89394040e-07   5.28192061e-07   7.18884030e-03   2.61044409e-02
    5.73151647e-06   9.77579548e-05   4.48824053e-08   2.23293726e-04
    9.82025987e-04   2.46082545e-05   1.09830957e-07   6.47594750e-01
    1.09812731e-07   1.07831147e-06   9.07663011e-09   4.20292781e-06
    7.02971420e-07]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 14
images_for_training/32
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   5.85143082e-21   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.00252189e-28   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 15
images_for_training/14
(1, 64, 64, 3)
Policy eval: 
[[  1.41444349e-27   9.99997735e-01   5.88163068e-28   0.00000000e+00
    5.45659757e-36   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   2.22929157e-06   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    4.39055595e-22   0.00000000e+00   1.97110543e-37   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   7.34576036e-37
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 16
images_for_training/132
(1, 64, 64, 3)
Policy eval: 
[[  5.04135068e-18   9.99995947e-01   4.06662927e-19   0.00000000e+00
    2.47048650e-37   3.07781523e-33   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   5.57707734e-17
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.23217373e-34   1.29058739e-20   3.65245552e-35
    4.52127229e-21   2.27905714e-28   2.48846320e-25   2.38995616e-33
    0.00000000e+00   5.46435339e-30   2.74652170e-27   0.00000000e+00
    4.06965137e-06   6.69409539e-30   1.30447145e-27   0.00000000e+00
    0.00000000e+00   0.00000000e+00   2.61120601e-37   7.27826493e-17
    7.43985004e-38   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 17
images_for_training/42
(1, 64, 64, 3)
Policy eval: 
[[  1.10945489e-33   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   8.55261536e-36   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   2.71619776e-08
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 18
images_for_training/281
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.40066390e-19
    0.00000000e+00   0.00000000e+00   8.00705711e-28   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.99501524e-21
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 19
images_for_training/154
(1, 64, 64, 3)
Policy eval: 
[[  1.30573389e-05   5.46685310e-13   2.15412241e-27   1.69872701e-22
    7.18312088e-25   8.37359071e-29   1.49223425e-15   1.39956417e-30
    1.32516429e-26   6.82166836e-36   1.40433599e-28   4.82644147e-09
    1.47750304e-28   3.36078507e-32   5.16346697e-21   7.85767687e-23
    7.35840421e-32   7.65557442e-28   2.30994787e-23   5.59609259e-27
    6.31676293e-22   2.02755721e-29   5.34086797e-27   4.70560048e-16
    2.75501278e-23   7.10706732e-20   2.57217581e-11   4.11570872e-25
    3.13100483e-11   9.12821996e-15   4.75610480e-12   1.56328147e-30
    9.93443651e-23   1.59144450e-33   4.20686896e-18   9.99986887e-01
    1.74309751e-20   2.03473878e-30   5.86769332e-21   8.78306786e-25
    0.00000000e+00]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 20
images_for_training/53
(1, 64, 64, 3)
Policy eval: 
[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
   0.  0.  0.  0.  0.]]
Action: 1.75
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 21
images_for_training/155
(1, 64, 64, 3)
Policy eval: 
[[  4.73271751e-17   2.43479317e-08   1.01849989e-20   0.00000000e+00
    5.46481599e-29   3.62383765e-36   0.00000000e+00   1.79039748e-26
    0.00000000e+00   0.00000000e+00   1.15384022e-25   1.67547036e-38
    1.33405247e-34   0.00000000e+00   6.14105835e-18   1.30817198e-23
    0.00000000e+00   7.66566691e-21   6.61943344e-17   1.09824573e-33
    7.35048621e-37   2.13734621e-27   1.37135933e-32   9.00662041e-30
    2.23893874e-33   2.64284288e-30   7.45502989e-21   0.00000000e+00
    1.46430081e-23   4.00622801e-33   7.14571966e-32   0.00000000e+00
    5.26865935e-33   3.16552455e-34   1.62097184e-35   1.00000000e+00
    2.75465910e-31   1.50114532e-35   1.31356893e-36   4.84853510e-33
    3.24526822e-27]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 22
images_for_training/155
(1, 64, 64, 3)
Policy eval: 
[[  5.13359846e-05   9.50775319e-16   4.21744904e-15   1.14633367e-37
    2.43760317e-10   1.15001633e-31   5.77276597e-34   6.63086771e-26
    9.10299336e-34   0.00000000e+00   7.28614730e-24   1.24713121e-24
    2.83334335e-36   0.00000000e+00   1.30711087e-33   6.80658524e-16
    0.00000000e+00   0.00000000e+00   9.99941349e-01   1.04206267e-28
    1.16367601e-21   9.45625482e-14   2.66185947e-31   1.24111124e-35
    0.00000000e+00   5.66283652e-12   1.88513791e-23   0.00000000e+00
    4.38208841e-24   2.30725988e-25   3.63722372e-29   3.65717122e-31
    1.15906645e-32   5.85682688e-21   2.26463337e-28   7.25755899e-06
    7.61271601e-11   2.60014648e-32   6.74420977e-26   1.56681783e-13
    1.73322313e-37]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 23
images_for_training/21
(1, 64, 64, 3)
Policy eval: 
[[  9.80056846e-37   3.50129137e-15   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   2.71157358e-28   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 24
images_for_training/175
(1, 64, 64, 3)
Policy eval: 
[[  4.25077737e-22   4.16742990e-30   1.33686140e-31   0.00000000e+00
    0.00000000e+00   0.00000000e+00   3.42322175e-32   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.38893602e-28   0.00000000e+00
    0.00000000e+00   4.40018108e-26   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.30830208e-30   2.41862229e-22   0.00000000e+00
    1.71156455e-28   1.02770216e-36   0.00000000e+00   0.00000000e+00
    1.49677177e-34   0.00000000e+00   0.00000000e+00   1.00000000e+00
    1.92935827e-32   0.00000000e+00   8.93546006e-33   2.80564952e-38
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 25
images_for_training/248
(1, 64, 64, 3)
Policy eval: 
[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
   0.  0.  0.  0.  0.]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 26
images_for_training/68
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   4.66299215e-23   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 27
images_for_training/276
(1, 64, 64, 3)
Policy eval: 
[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
   0.  0.  0.  0.  0.]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 28
images_for_training/214
(1, 64, 64, 3)
Policy eval: 
[[ 0.          0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.99420184  0.          0.
   0.          0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.          0.
   0.0057981   0.          0.          0.          0.          0.        ]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 29
images_for_training/215
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   2.58684499e-34   0.00000000e+00
    0.00000000e+00   5.18488232e-05   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    4.11960703e-30   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   9.99948144e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 30
images_for_training/129
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.08017775e-30
    0.00000000e+00   0.00000000e+00   1.99388513e-25   0.00000000e+00
    0.00000000e+00   4.35776226e-29   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00   0.00000000e+00   3.04487182e-26   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 31
images_for_training/21
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00   0.00000000e+00   5.63869368e-30   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 32
images_for_training/76
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   5.56315367e-12   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 1
Backpropping 

Session Number 33
images_for_training/218
(1, 64, 64, 3)
Policy eval: 
[[  2.00771259e-20   6.27313790e-38   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   6.73423954e-35
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.17717280e-09
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 34
images_for_training/6
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   5.62357443e-24   0.00000000e+00   0.00000000e+00
    8.53481779e-32   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   5.33719420e-36   0.00000000e+00
    1.15005856e-32   6.37896180e-01   0.00000000e+00   0.00000000e+00
    0.00000000e+00   2.44140073e-15   1.57467400e-10   0.00000000e+00
    3.62100512e-01   0.00000000e+00   1.19749746e-16   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   3.29480463e-06
    0.00000000e+00   0.00000000e+00   1.29273129e-30   0.00000000e+00
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 35
images_for_training/27
(1, 64, 64, 3)
Policy eval: 
[[  7.74579307e-30   9.14769844e-05   1.95944677e-35   1.98007860e-14
    2.27137253e-24   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.48565669e-34   0.00000000e+00   0.00000000e+00   4.93742175e-16
    2.82027308e-32   2.70288172e-18   8.18927970e-36   2.16655985e-14
    0.00000000e+00   1.92578921e-35   2.05421803e-21   0.00000000e+00
    9.31718921e-38   3.98350589e-11   1.78264381e-24   2.60451771e-10
    0.00000000e+00   0.00000000e+00   3.46797769e-24   0.00000000e+00
    6.93835127e-17   2.42536999e-27   9.99908566e-01   0.00000000e+00
    5.53583582e-23   6.83155715e-34   1.90549085e-33   1.49240778e-15
    0.00000000e+00   0.00000000e+00   4.60864952e-38   7.96750107e-15
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 36
images_for_training/1
(1, 64, 64, 3)
Policy eval: 
[[  6.25236478e-27   1.00000000e+00   0.00000000e+00   0.00000000e+00
    2.65823583e-12   0.00000000e+00   9.88218457e-37   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.40328993e-25
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   3.12175147e-36   0.00000000e+00   0.00000000e+00
    3.01907034e-32   5.80008908e-23   0.00000000e+00   1.81061874e-10
    0.00000000e+00   0.00000000e+00   4.55216112e-30   0.00000000e+00
    1.58770552e-26   0.00000000e+00   1.19473005e-17   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.07788196e-28
    0.00000000e+00   6.56393812e-32   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 37
images_for_training/4
(1, 64, 64, 3)
Policy eval: 
[[  4.33574755e-34   1.00000000e+00   3.74210935e-21   0.00000000e+00
    9.83935792e-26   0.00000000e+00   6.40329721e-27   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.59941726e-29
    1.09256423e-23   0.00000000e+00   1.36687376e-31   6.81319610e-30
    0.00000000e+00   0.00000000e+00   9.66159945e-20   0.00000000e+00
    9.69514262e-31   1.13964600e-31   0.00000000e+00   4.74489177e-21
    0.00000000e+00   2.74908421e-24   1.32455705e-38   0.00000000e+00
    2.63985171e-29   2.19775728e-30   0.00000000e+00   0.00000000e+00
    4.06667891e-33   8.08256030e-33   1.34505179e-30   1.62436271e-14
    0.00000000e+00   0.00000000e+00   3.69630875e-23   1.47748972e-19
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 38
images_for_training/156
(1, 64, 64, 3)
Policy eval: 
[[  1.70190447e-06   9.91422713e-01   1.35985674e-05   9.51097187e-12
    5.40193214e-05   1.65949629e-07   5.97146718e-05   3.13851061e-08
    1.03661023e-05   3.20728943e-10   1.12708653e-11   6.36954269e-07
    5.37086453e-05   1.65721248e-09   1.19350545e-07   1.93323267e-05
    6.93019392e-11   1.91989125e-06   7.16528948e-03   2.54861675e-06
    8.20196692e-06   1.61688004e-04   1.13913916e-06   7.98171342e-08
    5.30564925e-09   1.99062575e-04   1.70462852e-04   1.83388352e-06
    1.76441335e-05   2.39455563e-04   5.31232274e-07   5.20538421e-08
    2.93237548e-07   2.54467500e-06   7.31068095e-09   2.48255819e-04
    4.66577355e-08   6.07637674e-07   1.41990618e-04   2.35713571e-07
    6.75389911e-10]]
Action: 1.4
Enter Reward: 0
Backpropping 

Session Number 39
images_for_training/74
(1, 64, 64, 3)
Policy eval: 
[[  1.13764194e-34   1.00000000e+00   0.00000000e+00   0.00000000e+00
    1.88604796e-37   0.00000000e+00   0.00000000e+00   8.74551472e-30
    0.00000000e+00   0.00000000e+00   0.00000000e+00   9.00301137e-38
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   3.01864331e-25   0.00000000e+00
    0.00000000e+00   1.61853891e-33   0.00000000e+00   2.05370859e-36
    0.00000000e+00   5.37894515e-28   4.57647125e-21   0.00000000e+00
    5.21344574e-38   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 40
images_for_training/140
(1, 64, 64, 3)
Policy eval: 
[[  8.36669060e-05   9.99380350e-01   1.94885850e-08   2.26591367e-11
    8.78642581e-08   1.99605239e-08   8.99842334e-09   7.03815803e-13
    2.08019209e-11   8.90443318e-13   3.58447820e-12   2.92445037e-08
    6.89009871e-09   1.65121181e-10   3.77710814e-11   1.66271008e-07
    4.49039101e-15   1.36276424e-11   1.17878517e-05   2.11423536e-08
    1.63659664e-07   1.37434828e-08   3.85116095e-07   3.17543308e-04
    1.77917888e-13   1.32815126e-09   2.77368108e-05   1.04185910e-10
    3.65812127e-07   1.61235014e-09   1.13575183e-07   1.36644340e-09
    2.74620326e-08   1.75809662e-04   1.72350245e-09   5.93515148e-09
    3.13156239e-13   1.37742268e-06   1.64190880e-07   8.99633505e-08
    6.29207741e-10]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 41
images_for_training/145
(1, 64, 64, 3)
Policy eval: 
[[  3.37813458e-11   9.99998331e-01   1.13075465e-07   4.82392508e-22
    1.97951389e-09   2.40703312e-12   1.38394299e-14   4.34422697e-22
    1.34459901e-06   8.51030836e-25   9.98158025e-15   1.56031490e-07
    9.24329718e-14   3.70012248e-17   6.42047963e-20   7.24549103e-15
    5.59921733e-17   3.18082619e-15   2.75927975e-10   2.28536656e-12
    4.04041623e-18   1.07449857e-07   1.38596647e-14   8.27512798e-12
    2.42063394e-19   1.48637620e-16   3.99643968e-13   4.97509884e-14
    5.89763960e-10   2.43689671e-13   7.02515685e-11   1.85487446e-19
    1.41598227e-13   2.78099517e-14   3.73532150e-10   9.43649655e-16
    1.90188551e-18   2.70479196e-13   1.66309966e-10   5.66111770e-16
    7.99483698e-20]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 42
images_for_training/95
(1, 64, 64, 3)
Policy eval: 
[[  3.53396899e-06   9.99996424e-01   7.98993779e-14   0.00000000e+00
    7.66367325e-23   0.00000000e+00   1.35465852e-33   0.00000000e+00
    8.64663213e-37   0.00000000e+00   0.00000000e+00   3.31983407e-27
    1.03896419e-21   7.53029983e-33   0.00000000e+00   2.94383734e-34
    0.00000000e+00   2.33317495e-36   2.51983089e-28   3.20163372e-32
    4.26537569e-17   3.73563517e-36   0.00000000e+00   1.71923385e-36
    0.00000000e+00   0.00000000e+00   5.32408250e-17   1.11512056e-24
    1.40870472e-30   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.07439369e-34   7.68882097e-32
    1.38639963e-37   0.00000000e+00   0.00000000e+00   1.22372682e-37
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 43
images_for_training/38
(1, 64, 64, 3)
Policy eval: 
[[  6.06307673e-19   1.00000000e+00   2.24237153e-21   0.00000000e+00
    2.48913613e-19   8.77936176e-33   5.35504210e-32   1.16967542e-31
    6.31257856e-23   0.00000000e+00   0.00000000e+00   3.62515471e-19
    2.91199740e-24   1.88935600e-34   2.23673864e-31   2.93843174e-17
    0.00000000e+00   3.86429148e-33   2.01000799e-16   1.97709976e-34
    2.37434205e-28   3.63947450e-08   1.52912767e-16   1.46202293e-24
    0.00000000e+00   1.02520381e-29   1.14939203e-14   0.00000000e+00
    2.66120522e-22   1.40406096e-34   1.97340255e-09   0.00000000e+00
    1.90215947e-23   2.26433271e-22   1.45646674e-25   2.17970329e-25
    4.93502739e-32   3.92695667e-26   1.28404958e-38   1.89493839e-31
    1.33852807e-34]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 44
images_for_training/199
(1, 64, 64, 3)
Policy eval: 
[[  6.34868593e-06   9.97279584e-01   1.35571345e-05   1.31407762e-09
    5.53175632e-05   1.82226961e-06   1.12836398e-08   1.47076628e-06
    2.29259001e-07   3.19893279e-10   1.78712405e-08   5.77469291e-06
    4.88682765e-08   5.38423819e-06   7.94918492e-07   3.61857602e-08
    2.39842157e-11   8.22979160e-08   2.37957254e-04   9.37458822e-07
    6.40503288e-07   8.50798278e-06   1.28441471e-07   7.59063923e-08
    3.81144227e-09   5.58072543e-06   1.27227358e-05   3.28481664e-09
    2.35066935e-03   1.35405676e-09   1.44856273e-07   5.68092062e-08
    1.59736828e-06   1.43393515e-06   5.09866593e-10   1.13629838e-07
    1.56018505e-08   8.77204639e-06   1.96093453e-08   8.36052365e-08
    1.27615536e-08]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 45
images_for_training/80
(1, 64, 64, 3)
Policy eval: 
[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 46
images_for_training/151
(1, 64, 64, 3)
Policy eval: 
[[  4.81317784e-07   9.98863459e-01   5.46070456e-04   1.36667663e-10
    3.48123067e-05   7.41764623e-08   1.71757577e-08   1.12044380e-12
    1.83903040e-07   7.53269842e-13   3.68373509e-09   7.21677225e-07
    6.43260376e-11   3.35278241e-06   3.81501735e-07   3.00054595e-08
    1.35583610e-11   1.03885889e-09   3.64362859e-05   1.43607604e-09
    2.34519632e-07   4.81011739e-07   3.70650852e-08   4.08908127e-05
    5.38693428e-08   4.21951445e-05   4.45531441e-05   1.11945323e-11
    3.60245176e-04   1.58257228e-06   1.94596305e-05   1.33783358e-11
    1.29961435e-07   6.19368307e-11   3.67259645e-06   4.54335606e-07
    5.50260393e-10   6.79035539e-09   4.40297132e-09   4.85536908e-08
    7.38117195e-13]]
Action: 0.75
Enter Reward: 0
Backpropping 

Session Number 47
images_for_training/275
(1, 64, 64, 3)
Policy eval: 
[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 48
images_for_training/165
(1, 64, 64, 3)
Policy eval: 
[[  3.07588605e-04   9.92594421e-01   5.68515190e-07   3.25371730e-07
    7.85164084e-05   4.55600775e-06   1.25123279e-06   1.50085793e-06
    3.56767487e-06   8.88622287e-10   2.61602526e-08   1.56256065e-04
    2.36808702e-07   1.52740427e-07   1.04396713e-05   4.72045758e-05
    1.43859324e-07   2.08184383e-06   3.13248529e-05   1.14148554e-06
    7.08791868e-06   1.23571535e-05   3.58839279e-05   9.75204330e-06
    5.09543543e-06   3.19763017e-03   8.08979905e-07   2.16296735e-06
    2.09392947e-05   2.23916459e-07   2.80282111e-03   4.00964410e-07
    4.32257628e-04   4.60830762e-07   1.40945776e-04   4.46880023e-07
    3.78712564e-08   7.90944177e-05   7.84736949e-06   2.31828244e-06
    3.65588626e-08]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 49
images_for_training/189
(1, 64, 64, 3)
Policy eval: 
[[  1.69505666e-16   9.99999046e-01   6.32677452e-11   1.91785444e-13
    2.04171194e-10   9.51216710e-12   2.76088430e-16   3.19672064e-19
    3.65857761e-11   7.01726103e-26   8.00704774e-21   1.06460629e-09
    1.91333625e-15   3.87562602e-14   7.36008097e-13   1.11205212e-09
    3.85868847e-19   6.46772293e-15   2.04084198e-08   1.52049768e-19
    6.59692370e-11   2.75581294e-12   1.95065450e-10   4.98273526e-15
    1.70041815e-17   1.31994355e-11   1.91846610e-16   2.47815032e-21
    6.02083555e-15   2.36622950e-13   6.74031810e-07   5.70610125e-19
    1.64522354e-11   4.16915678e-16   2.62366728e-09   1.91186162e-16
    1.67898308e-21   3.56291663e-11   2.89499042e-07   8.84399082e-11
    1.05642603e-17]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 50
images_for_training/246
(1, 64, 64, 3)
Policy eval: 
[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 51
images_for_training/22
(1, 64, 64, 3)
Policy eval: 
[[  3.18713453e-38   1.00000000e+00   0.00000000e+00   0.00000000e+00
    6.59816803e-36   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    4.54560326e-37   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   2.02254500e-31   0.00000000e+00   0.00000000e+00
    6.44708831e-22   0.00000000e+00   4.18170349e-35   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 52
images_for_training/274
(1, 64, 64, 3)
Policy eval: 
[[  6.54653783e-36   7.65518725e-01   0.00000000e+00   0.00000000e+00
    8.63497994e-38   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   6.33314935e-37
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   8.26074029e-07   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   2.61120377e-37   0.00000000e+00   0.00000000e+00
    2.34480381e-01   0.00000000e+00   2.67959333e-34   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Action: 1.7
Enter Reward: 0
Backpropping 

Session Number 53
images_for_training/218
(1, 64, 64, 3)
Policy eval: 
[[  4.62490405e-23   8.60906635e-09   0.00000000e+00   0.00000000e+00
    1.42717607e-37   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   2.99532465e-09
    0.00000000e+00   1.76114183e-25   9.99999881e-01   0.00000000e+00
    0.00000000e+00   7.81472114e-26   0.00000000e+00   1.88480013e-33
    0.00000000e+00   1.91927531e-21   0.00000000e+00   0.00000000e+00
    1.41412676e-14   0.00000000e+00   4.18118128e-18   0.00000000e+00
    1.02102341e-07   1.70505219e-38   2.54729038e-33   0.00000000e+00
    0.00000000e+00   8.45532373e-37   0.00000000e+00   3.58816854e-21
    0.00000000e+00]]
Action: 0.9
Enter Reward: 1
Backpropping 

Session Number 54
images_for_training/281
(1, 64, 64, 3)
Policy eval: 
[[  1.16978732e-23   1.39640447e-22   7.13368142e-32   1.54958050e-38
    4.94510054e-28   9.88638503e-34   0.00000000e+00   8.01148475e-36
    2.09493989e-30   0.00000000e+00   0.00000000e+00   2.97801649e-33
    0.00000000e+00   3.26438261e-31   0.00000000e+00   3.72831213e-16
    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   2.41723919e-29   1.66372593e-38   3.15012971e-34
    6.24125404e-29   1.80336756e-17   2.93848189e-36   0.00000000e+00
    8.68388747e-21   0.00000000e+00   4.02560941e-32   0.00000000e+00
    5.52627290e-17   9.99893492e-38   1.53823016e-32   7.61611028e-30
    0.00000000e+00   1.21336099e-29   0.00000000e+00   9.31193124e-15
    0.00000000e+00]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 55
images_for_training/36
(1, 64, 64, 3)
Policy eval: 
[[  1.16129240e-09   6.85996339e-02   3.38928330e-09   7.24527896e-16
    4.88921553e-01   1.88235066e-10   1.09817225e-11   2.00402993e-11
    4.85266071e-07   1.76434499e-30   8.24168383e-20   1.37720902e-11
    5.44163072e-07   1.04432403e-14   4.68031066e-17   1.83432212e-06
    1.94058560e-24   1.30960748e-12   3.46024698e-09   5.23659900e-11
    2.96656638e-02   1.07143062e-11   1.19824186e-14   6.63986699e-10
    5.86917684e-15   2.71902066e-02   2.30555063e-15   8.85863685e-22
    6.72295863e-09   7.38302388e-12   3.85606438e-01   1.67050236e-19
    4.20951608e-07   1.23887720e-10   1.31188463e-05   7.80016585e-09
    1.68548579e-13   3.03502956e-09   1.04596615e-15   4.31740615e-10
    2.19291816e-14]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 56
images_for_training/190
(1, 64, 64, 3)
Policy eval: 
[[ 0.10392404  0.23363373  0.01268595  0.00316132  0.04127524  0.01231741
   0.01091147  0.00348026  0.01959367  0.00302452  0.01322966  0.02101475
   0.00417471  0.01112316  0.0034494   0.00341065  0.00093805  0.00570529
   0.0171966   0.01948277  0.00567229  0.0069401   0.00768664  0.08345173
   0.00694635  0.01712001  0.0229442   0.00708053  0.02755187  0.02189646
   0.01711124  0.00252551  0.02177226  0.09798538  0.05050028  0.00302971
   0.0026503   0.01191629  0.01114754  0.01970536  0.01063324]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 57
images_for_training/57
(1, 64, 64, 3)
Policy eval: 
[[  7.80227967e-03   4.89220656e-02   5.70203969e-03   5.77404705e-07
    1.39732305e-02   1.42197609e-06   7.02529868e-10   9.25762966e-14
    4.99439814e-08   5.69971099e-13   3.06479842e-09   7.79507900e-07
    2.95102343e-08   7.81756228e-07   1.56673650e-07   3.46055045e-03
    8.72018725e-15   2.07007730e-07   2.08093524e-02   6.59145516e-10
    8.25282812e-01   1.84516819e-06   1.34656008e-03   2.37997592e-05
    2.20171060e-12   3.45925509e-04   6.45737543e-07   3.59334923e-10
    1.54904847e-04   2.48784800e-05   3.39300401e-04   1.20963449e-07
    3.10887757e-04   3.12706948e-06   2.44118477e-04   2.52017959e-12
    1.38409891e-11   8.10325048e-07   2.99549492e-06   7.12435916e-02
    6.43868114e-09]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 58
images_for_training/4
(1, 64, 64, 3)
Policy eval: 
[[  4.26167576e-03   5.29340029e-01   2.84194231e-01   3.09839379e-05
    1.00199739e-02   9.76089814e-06   6.22077714e-05   4.10754816e-04
    6.47285581e-03   1.35724554e-06   3.75130094e-06   4.72514454e-04
    4.72982880e-04   1.66340708e-03   7.35616923e-05   2.18875110e-04
    1.14338561e-09   1.42677607e-06   1.99571270e-02   2.83834629e-06
    2.91935238e-03   5.87768108e-02   1.41735809e-05   5.85217262e-04
    9.35908338e-06   2.88607017e-03   5.73017925e-04   7.97100881e-07
    2.69083655e-03   1.04641967e-05   1.26059016e-03   2.41628527e-07
    2.55762599e-04   4.94760200e-02   2.24671239e-05   2.97258637e-04
    1.43553858e-04   2.31330905e-05   6.91552168e-06   2.23764721e-02
    1.12715929e-06]]
Action: 1.25
Enter Reward: 1
Backpropping 

Session Number 59
images_for_training/150
(1, 64, 64, 3)
Policy eval: 
[[ 0.04776811  0.03742011  0.02473836  0.0211726   0.0303426   0.02377664
   0.01140111  0.01548164  0.01376498  0.00877917  0.0180758   0.02843454
   0.01995372  0.02036071  0.0177013   0.03613924  0.00712838  0.03324553
   0.0239963   0.01383275  0.0254409   0.01876109  0.02178542  0.02760061
   0.02222932  0.02698469  0.02443949  0.00815792  0.03937797  0.03634541
   0.06827249  0.00857498  0.02176747  0.03073865  0.03389059  0.03866536
   0.00990995  0.01744496  0.01717744  0.02564945  0.02327233]]
Action: 1.1
Enter Reward: 0
Backpropping 

Session Number 60
images_for_training/228
(1, 64, 64, 3)
Policy eval: 
[[  4.30311717e-04   9.99544919e-01   9.62091917e-07   3.38796977e-11
    2.76573337e-06   2.31591191e-09   4.65840566e-09   5.29951771e-09
    2.65389630e-08   1.79813553e-12   3.16765530e-10   4.99150268e-08
    6.23080698e-09   2.24101093e-08   8.20151932e-11   2.83429502e-10
    1.03764653e-12   3.36039989e-07   1.95609723e-10   2.14741136e-09
    1.32758415e-10   6.77821221e-09   1.30125468e-12   1.50486312e-05
    1.79378595e-11   5.29306987e-10   8.09292686e-08   3.45094064e-10
    2.20893597e-07   3.74215592e-09   4.31972830e-06   3.55814960e-14
    3.44265239e-09   2.31659044e-07   1.65304769e-07   4.72524186e-10
    2.32077639e-07   3.40993935e-08   1.25055790e-11   7.51416795e-09
    1.12318027e-07]]
Action: 0.1
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 61
images_for_training/285
(1, 64, 64, 3)
Policy eval: 
[[  1.35301212e-02   2.66811028e-02   1.92910448e-01   8.62656179e-07
    3.62632709e-05   1.48310501e-04   6.19689536e-06   4.28203947e-07
    3.35919962e-04   4.16017429e-07   1.53027565e-06   9.64250503e-05
    5.23956269e-02   1.70632702e-04   3.97910411e-03   6.25165738e-03
    6.86803253e-11   3.27559828e-04   9.07532573e-02   9.83602058e-06
    5.47713398e-06   5.17175114e-03   5.51048517e-01   7.72787607e-05
    1.04054454e-09   1.50453718e-03   2.49611214e-02   1.74543184e-05
    1.27478343e-04   2.41118614e-02   1.00084479e-04   1.43174811e-05
    5.77229250e-04   1.87804744e-05   2.91726692e-03   1.45611912e-03
    7.30128795e-06   5.07894656e-05   7.96283894e-06   1.88566424e-04
    3.67644930e-07]]
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 62
images_for_training/261
(1, 64, 64, 3)
Policy eval: 
[[  5.10941148e-01   4.50578779e-02   7.79793877e-03   2.59089079e-02
    3.32353031e-03   1.61532369e-02   6.59138948e-08   6.16680609e-07
    1.88721533e-04   4.18449470e-10   4.91769460e-05   2.10387680e-05
    1.18518867e-04   1.64473196e-03   1.11529296e-07   1.45468162e-03
    4.69895123e-10   6.27465488e-04   4.86223085e-04   5.08858058e-08
    2.90642492e-03   2.21402137e-04   8.43250251e-04   2.78850098e-06
    1.20171910e-06   5.39526285e-04   1.04343308e-05   3.29662353e-10
    1.31410445e-04   3.55937660e-01   8.17830907e-04   6.80148785e-11
    3.87042792e-06   2.67172232e-04   2.17628025e-04   4.56286671e-06
    4.01122513e-09   9.10272138e-06   3.89014967e-05   2.42694709e-02
    3.31032834e-06]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 63
images_for_training/181
(1, 64, 64, 3)
Policy eval: 
[[ 0.05715344  0.03357349  0.04803906  0.01162433  0.01975141  0.0238946
   0.01700918  0.01408182  0.02465657  0.00440211  0.01766769  0.01184363
   0.03885086  0.03988611  0.01155241  0.03375861  0.00526119  0.02013218
   0.03902981  0.02082963  0.02409735  0.01492167  0.02374611  0.05822567
   0.00898662  0.03069231  0.01103184  0.01446561  0.06958369  0.05021309
   0.01399435  0.01171476  0.00702665  0.02547862  0.02045645  0.01658338
   0.00892896  0.01358902  0.02039537  0.04533347  0.01753688]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 64
images_for_training/198
(1, 64, 64, 3)
Policy eval: 
[[ 0.07061086  0.01932549  0.01886456  0.01720305  0.01456736  0.0176041
   0.01696024  0.01674137  0.05708839  0.00623509  0.02342698  0.01373022
   0.0341682   0.01588323  0.01531332  0.03054484  0.01041274  0.01611682
   0.03068749  0.01791729  0.02057476  0.02415707  0.0341811   0.02665916
   0.02017127  0.03210983  0.01612509  0.01595277  0.03993361  0.03619114
   0.0253231   0.00948334  0.03454468  0.04087162  0.03646842  0.0140938
   0.01095946  0.01179621  0.01854897  0.04324744  0.02520547]]
Action: 0.4
Enter Reward: 0
Backpropping 

Session Number 65
images_for_training/172
(1, 64, 64, 3)
Policy eval: 
[[ 0.08917356  0.03124023  0.01755244  0.0348789   0.01381316  0.01670624
   0.0126646   0.015937    0.01875465  0.01296743  0.01522553  0.00930142
   0.00925764  0.02946761  0.03499728  0.0373358   0.00666173  0.02187309
   0.02922864  0.0231432   0.02690708  0.02340713  0.04775406  0.04181552
   0.01376886  0.01421972  0.032032    0.01191076  0.05722971  0.03194199
   0.01431061  0.02713753  0.03766822  0.0273333   0.03262406  0.00911995
   0.01650647  0.01328363  0.00708402  0.01840312  0.01536212]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 66
images_for_training/37
(1, 64, 64, 3)
Policy eval: 
[[  4.28634614e-01   1.96476821e-02   3.18274558e-01   6.89201115e-04
    9.29502712e-04   3.64213600e-04   3.52955103e-04   1.13005575e-04
    2.85163056e-02   8.85216741e-06   3.27572401e-04   8.65567563e-05
    1.91314801e-04   2.12440570e-03   3.12432152e-04   9.53663792e-03
    9.52801884e-07   4.71868727e-04   5.98322861e-02   6.21814164e-04
    1.85502879e-02   6.20877894e-04   1.92544460e-02   1.93566196e-02
    1.79330964e-04   4.36601025e-04   1.29469936e-05   4.73528526e-05
    4.95919678e-03   3.16173509e-02   1.55466059e-05   1.86621997e-04
    1.96474561e-04   8.57725448e-04   1.33340042e-02   4.21104982e-04
    2.81533321e-05   7.67520920e-04   3.81889549e-04   1.77000221e-02
    3.91812282e-05]]
Action: 0.75
Enter Reward: 1
Backpropping 

Session Number 67
images_for_training/239
(1, 64, 64, 3)
Policy eval: 
[[  8.87141451e-02   1.57184131e-03   1.72095795e-04   1.70912013e-08
    5.19397669e-04   3.02017391e-01   9.73196013e-09   6.04229990e-06
    9.16849094e-05   2.55507302e-07   1.40392527e-04   1.17876007e-05
    1.13955594e-03   2.88430631e-01   2.37643981e-04   5.44390269e-03
    7.72076003e-09   2.65902430e-02   2.48672478e-02   9.43804298e-06
    1.22655422e-06   8.18132605e-07   7.74013533e-05   6.81899197e-04
    4.25076820e-07   1.52368331e-04   9.39859365e-06   5.95913252e-06
    2.56086707e-01   1.68569153e-03   7.25687187e-07   1.42332601e-06
    3.22521169e-04   7.85328302e-06   9.04992921e-04   2.51716301e-06
    4.88010343e-08   1.06805364e-05   2.27568125e-06   2.03281052e-05
    6.08849732e-05]]
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 68
images_for_training/259
(1, 64, 64, 3)
Policy eval: 
[[  4.31153774e-02   9.32204306e-01   1.78281497e-03   7.50098593e-07
    3.05606402e-04   2.58370623e-04   1.60853676e-06   1.11737623e-04
    8.74402485e-06   5.03881097e-07   1.61068150e-04   2.09780646e-05
    1.37922543e-04   7.87999379e-05   4.33526566e-06   2.35170056e-03
    4.80254494e-05   5.33231068e-04   3.74516618e-04   3.61952370e-05
    4.17332351e-03   1.69188042e-05   4.75228035e-06   6.15722893e-05
    4.52917050e-07   2.01859461e-06   7.16237673e-06   5.76745842e-05
    2.32829789e-05   6.60744088e-04   4.07895859e-05   5.24710231e-06
    4.62737553e-05   1.09608605e-04   1.99567949e-05   1.87135015e-07
    1.11399058e-04   1.98003562e-07   2.90682436e-07   1.31074795e-02
    1.40865995e-05]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 69
images_for_training/109
(1, 64, 64, 3)
Policy eval: 
[[ 0.07765613  0.03549983  0.01089621  0.03133696  0.01613794  0.01870666
   0.00858103  0.00726864  0.07619184  0.00278833  0.03023942  0.02130307
   0.00789125  0.02342886  0.00989944  0.05828813  0.0022846   0.00902934
   0.13379517  0.01113142  0.06337062  0.05109276  0.00963256  0.01323558
   0.00458374  0.02782826  0.00534925  0.0061708   0.04776731  0.01873525
   0.02518664  0.00231015  0.06385146  0.01000485  0.01490687  0.0031727
   0.00411175  0.00688065  0.01221244  0.01386372  0.00337841]]
Action: 1.3
Enter Reward: 0
Backpropping 

Session Number 70
images_for_training/222
(1, 64, 64, 3)
Policy eval: 
[[  8.63521159e-01   3.81177268e-03   1.45480847e-02   2.74462654e-05
    2.12296845e-06   5.95902493e-05   8.09189729e-08   7.69375220e-07
    3.52917016e-02   1.93121821e-11   3.14407060e-08   6.63563424e-06
    3.58150949e-08   1.49542234e-06   3.73621916e-08   1.01280340e-04
    6.64088368e-11   6.00531236e-10   7.36183938e-05   1.58738294e-06
    7.72521123e-02   1.15438161e-05   3.16545265e-06   4.33117151e-03
    3.95060255e-04   1.10036044e-05   5.78836193e-07   9.90470880e-07
    6.03047852e-08   2.65425217e-04   5.61000297e-06   1.69998668e-10
    6.19900311e-06   3.48179242e-06   2.05638236e-04   1.29466518e-08
    1.81682978e-07   3.48822505e-05   2.35049207e-08   2.53912985e-05
    3.33646111e-09]]
Action: 1.15
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 71
images_for_training/249
(1, 64, 64, 3)
Policy eval: 
[[  9.61232543e-01   6.79312798e-05   1.29847831e-05   7.76258730e-06
    1.01550427e-07   3.60900003e-07   2.28737022e-07   7.65809176e-08
    4.78046061e-03   3.52254059e-11   6.36223433e-07   1.60020633e-07
    2.56470435e-06   2.52236964e-06   5.18590415e-09   4.23064921e-04
    3.53294505e-10   1.09653957e-08   2.21038032e-02   4.32026015e-09
    2.02139840e-03   1.72499887e-04   6.51862592e-06   9.19527447e-05
    4.10988514e-06   2.35268861e-04   1.41688713e-06   1.74189196e-08
    8.15075915e-03   2.56230742e-05   2.56317144e-04   1.23992612e-08
    2.72848440e-04   2.54793558e-05   8.57249979e-05   1.51004244e-07
    2.87395864e-07   8.75706689e-08   1.07456697e-06   1.29912369e-05
    1.76379103e-07]]
Action: 1.85
Enter Reward: 0
Backpropping 

Session Number 72
images_for_training/139
(1, 64, 64, 3)
Policy eval: 
[[ 0.11144242  0.06539968  0.04018861  0.00753085  0.01801951  0.02396961
   0.01019065  0.01509553  0.04012076  0.01316223  0.02563195  0.02779174
   0.02972719  0.06272291  0.01092623  0.01617779  0.00423903  0.02084816
   0.04122218  0.01935074  0.01007157  0.02681786  0.0054778   0.00672288
   0.00334496  0.01339709  0.0389069   0.00726575  0.09332819  0.02593053
   0.0197823   0.00868436  0.01862036  0.02487733  0.01551705  0.0121129
   0.01287592  0.00457401  0.00501366  0.03264543  0.01027532]]
Action: 0.65
Enter Reward: 0
Backpropping 

Session Number 73
images_for_training/49
(1, 64, 64, 3)
Policy eval: 
[[  5.18171906e-01   2.84416109e-01   9.09216586e-04   8.83781293e-04
    4.98950612e-05   2.76295841e-03   2.08917874e-04   9.67266351e-06
    5.77113125e-04   2.64805509e-04   9.54973698e-02   1.87736284e-03
    3.00449483e-06   3.41727887e-03   2.18682480e-03   1.32775132e-03
    4.58893783e-06   5.16973887e-05   8.69484711e-03   6.84370534e-05
    4.55134897e-04   5.89414849e-04   9.90062300e-03   2.26782844e-03
    5.68429753e-03   5.31409576e-04   1.60930038e-03   2.80979904e-04
    6.19436987e-03   1.36649851e-02   2.95489375e-03   2.64943182e-03
    2.52917613e-04   2.02793572e-02   9.27732605e-03   5.01371796e-05
    3.09721130e-04   7.32397093e-05   3.55187280e-04   5.46499272e-04
    6.89491164e-04]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 74
images_for_training/81
(1, 64, 64, 3)
Policy eval: 
[[  1.34612635e-01   6.57972276e-01   5.72457584e-03   1.66910875e-04
    1.08165063e-04   2.28821696e-03   1.78784865e-03   3.55599914e-05
    3.18419392e-04   7.24669644e-06   6.56489516e-04   2.09290185e-03
    7.74685806e-03   1.79336603e-05   6.02221553e-05   2.96603557e-05
    1.00463194e-06   5.54627506e-03   4.00819030e-04   7.78860431e-06
    6.92682341e-04   3.85081548e-05   9.39616759e-04   3.54116783e-03
    3.09227034e-05   1.84172713e-05   1.90215616e-03   6.49758585e-05
    1.66733593e-01   3.26165301e-03   7.49651299e-05   1.01855330e-05
    1.26509505e-04   3.15099489e-04   1.51888456e-03   1.75120382e-04
    1.23676422e-04   6.28907264e-06   2.77585234e-04   3.53030016e-04
    2.13184016e-04]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 75
images_for_training/40
(1, 64, 64, 3)
Policy eval: 
[[  3.70338149e-02   1.92099124e-01   2.90788077e-02   3.96343909e-04
    1.00528786e-03   1.18345227e-02   1.92418796e-04   3.40897636e-03
    9.27037653e-03   8.24300660e-05   2.84160618e-02   2.53476668e-03
    5.50162280e-03   1.59903092e-03   3.11497337e-04   3.55230942e-02
    7.38718954e-05   7.63692847e-03   2.30991766e-01   1.00676925e-03
    2.34195427e-03   9.62604806e-02   9.08592250e-03   3.26470385e-04
    1.54070808e-02   3.95698851e-04   2.39969399e-02   3.14052450e-03
    3.34655903e-02   3.74921784e-02   5.98676386e-04   2.47326167e-03
    2.86305603e-03   1.61832254e-02   2.96720807e-02   2.68511503e-04
    1.40057958e-03   2.85053463e-03   5.81266941e-04   1.19891196e-01
    3.30722518e-03]]
Action: 1.6
Enter Reward: 0
Backpropping 

Session Number 76
images_for_training/146
(1, 64, 64, 3)
Policy eval: 
[[ 0.04250466  0.05902032  0.08616433  0.01145667  0.00860491  0.02896875
   0.00643263  0.0160575   0.0288765   0.00586796  0.01547391  0.0116059
   0.01868173  0.06329141  0.0281304   0.01547221  0.00739559  0.02205923
   0.0577064   0.01541982  0.0151452   0.06296399  0.02269504  0.01774191
   0.03781563  0.00684232  0.01435252  0.01329099  0.03286361  0.00630281
   0.01590097  0.00406228  0.01113736  0.03205888  0.01462825  0.01577343
   0.01540879  0.04789272  0.02217229  0.03093829  0.01082184]]
Action: 1.45
Enter Reward: 1
Backpropping 

Session Number 77
images_for_training/133
(1, 64, 64, 3)
Policy eval: 
[[ 0.04603307  0.04178046  0.0381033   0.02047909  0.01805492  0.02533003
   0.01376276  0.02235031  0.03316896  0.01262525  0.04016778  0.02870506
   0.01906849  0.02747085  0.02390471  0.02723936  0.01093691  0.02360616
   0.02587022  0.02904984  0.02461968  0.03384083  0.02562877  0.02816148
   0.04171166  0.01973831  0.02593688  0.01858769  0.02120024  0.02661931
   0.01383279  0.01625759  0.0195318   0.01482582  0.03228745  0.01095355
   0.01762406  0.02717472  0.02183046  0.01577096  0.01615834]]
Action: 1.85
Enter Reward: 1
Backpropping 

Session Number 78
images_for_training/12
(1, 64, 64, 3)
Policy eval: 
[[  4.77203517e-04   6.69911457e-03   4.87794802e-02   4.92428285e-07
    9.12512885e-04   2.16046907e-03   1.29130145e-04   3.22708865e-06
    8.77392722e-06   7.90323469e-08   1.08866999e-03   8.76890772e-06
    1.59911096e-01   1.56620182e-02   2.37368222e-05   2.50468869e-02
    3.05197361e-08   3.37399179e-05   4.39312635e-03   5.84563240e-04
    8.99683000e-05   2.59615394e-04   2.05116453e-06   3.28511223e-02
    1.16888059e-05   9.13468921e-06   3.48973600e-03   7.19001328e-05
    6.64986670e-01   1.15944538e-02   6.45030697e-04   1.06259016e-07
    1.72752570e-02   3.94440431e-04   5.81190125e-06   1.25627627e-03
    1.27645457e-04   5.24118514e-06   8.09550344e-04   1.14328919e-04
    7.68467507e-05]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 79
images_for_training/227
(1, 64, 64, 3)
Policy eval: 
[[  8.16216528e-01   1.83619559e-01   4.26495035e-06   9.89410665e-10
    1.03966879e-11   1.74634948e-07   2.23043570e-10   6.21154612e-08
    2.41227190e-06   1.13758276e-12   5.15117681e-05   5.44151007e-05
    1.50486397e-08   2.86537603e-08   1.78805792e-09   3.57310554e-08
    5.58700395e-12   4.54336623e-05   1.78564576e-08   5.69193901e-07
    3.11901255e-10   3.13842508e-10   3.67777915e-07   1.98637011e-07
    2.48222295e-06   3.48435142e-10   3.54306877e-08   3.01973291e-09
    5.01287730e-07   8.11733400e-07   2.26102720e-10   8.50461301e-09
    4.91594072e-08   2.22546703e-11   6.73240175e-09   1.03551681e-11
    9.21769442e-14   7.89726062e-09   3.85109757e-07   9.30642646e-11
    3.02563063e-09]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 80
images_for_training/241
(1, 64, 64, 3)
Policy eval: 
[[  1.36803789e-03   2.53219604e-01   2.04887148e-03   1.71135252e-05
    1.08747668e-06   1.33676276e-05   2.10209052e-07   1.50219621e-05
    1.96559427e-07   1.19658594e-08   9.20502993e-04   3.65847991e-05
    6.75365754e-08   5.54787403e-04   1.36610169e-07   6.98873964e-06
    2.89872357e-08   5.09132587e-06   4.35670285e-04   2.29276202e-06
    1.03080720e-05   6.67213500e-01   3.38450423e-04   5.12477527e-07
    1.65572203e-07   8.40424946e-07   1.59885840e-05   7.97564951e-07
    1.46224438e-05   4.37924750e-02   7.41109659e-07   1.85651843e-05
    3.14067222e-07   1.20943660e-04   1.55622096e-04   1.03258808e-05
    2.94295754e-02   1.10470311e-04   1.51180501e-07   1.11406203e-04
    8.51340610e-06]]
Action: 0.1
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 81
images_for_training/183
(1, 64, 64, 3)
Policy eval: 
[[ 0.055788    0.03624235  0.02167548  0.03212782  0.01254257  0.02659953
   0.0111724   0.02318412  0.0095656   0.01084112  0.03297893  0.03679133
   0.01984144  0.04567499  0.01918444  0.03026893  0.00828022  0.01905275
   0.02519117  0.02204756  0.02062838  0.02779259  0.01777803  0.03251882
   0.02110645  0.01069395  0.04406462  0.01181197  0.03775196  0.05487687
   0.01624633  0.00999551  0.02760745  0.02040214  0.02723759  0.02459718
   0.01552762  0.01640267  0.01532382  0.027592    0.02099336]]
Action: 1.85
Enter Reward: 0
Backpropping 

Session Number 82
images_for_training/226
(1, 64, 64, 3)
Policy eval: 
[[  1.09898648e-03   5.91474950e-01   3.79984704e-06   3.12466426e-08
    1.30667274e-07   9.50762915e-05   1.64226894e-05   3.04460377e-06
    1.02860011e-01   2.46045184e-09   3.31476112e-05   1.60371512e-01
    2.76533200e-07   9.43156294e-07   9.23802781e-06   1.99712766e-03
    2.01568935e-11   3.51617793e-08   6.98714256e-02   2.52220525e-06
    5.09931846e-03   4.34708374e-04   9.53385170e-05   1.75233593e-03
    2.06485376e-04   1.85425335e-04   1.69339954e-04   5.65494075e-02
    7.76239613e-05   1.71828875e-03   8.17925780e-08   1.10248727e-07
    3.56620830e-03   6.67812943e-04   6.42456114e-04   2.78572898e-09
    6.89379988e-07   9.77069372e-04   1.51205359e-05   2.45366380e-07
    3.37652887e-06]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 83
images_for_training/165
(1, 64, 64, 3)
Policy eval: 
[[ 0.04007329  0.05163494  0.06953829  0.01115667  0.02418779  0.02635554
   0.01021739  0.01878055  0.01744263  0.00971457  0.01928086  0.02022302
   0.00658212  0.02689553  0.02041123  0.03611739  0.0072794   0.01356208
   0.03621055  0.03139376  0.02347537  0.04041037  0.0132152   0.04132207
   0.03363982  0.03847301  0.0151213   0.00849672  0.03341835  0.02237299
   0.01709977  0.01617226  0.02107719  0.0351529   0.02654354  0.01234928
   0.01829485  0.03099367  0.0201434   0.02293289  0.01223746]]
Action: 0.3
Enter Reward: 0
Backpropping 

Session Number 84
images_for_training/286
(1, 64, 64, 3)
Policy eval: 
[[  6.57150224e-02   2.44245911e-03   5.48051205e-03   1.82356459e-08
    3.72227191e-08   2.92575662e-03   2.37197045e-16   2.37152165e-09
    1.25506222e-05   2.84033685e-10   7.53423152e-03   5.62925270e-05
    4.10672207e-09   3.19034047e-03   2.21740244e-08   1.62542656e-01
    3.51447734e-15   3.08033687e-09   3.20281797e-05   7.11595050e-08
    4.76930654e-06   1.62270895e-04   2.58545497e-05   2.04802607e-04
    3.83959879e-04   1.50276549e-06   6.18020480e-04   7.53103656e-12
    4.03207014e-06   3.12847224e-05   1.25193139e-07   1.53565881e-13
    2.84815324e-05   3.16115290e-09   8.47072840e-07   1.83902327e-09
    3.47278623e-10   4.06329334e-01   2.01361079e-08   3.42272609e-01
    9.73650387e-08]]
Action: 0.5
Enter Reward: 1
Backpropping 

Session Number 85
images_for_training/164
(1, 64, 64, 3)
Policy eval: 
[[ 0.03583841  0.06473576  0.07452324  0.02146447  0.00754337  0.01600459
   0.01048854  0.01235874  0.02709804  0.01376345  0.02699878  0.02507946
   0.02780189  0.03038138  0.01970308  0.02918846  0.01098145  0.01953423
   0.03211766  0.02229232  0.02904873  0.03239438  0.03541194  0.01447404
   0.01846255  0.01748065  0.0375542   0.01610065  0.04429397  0.02924268
   0.01555247  0.0194376   0.02320857  0.01903711  0.02699119  0.0122739
   0.01386881  0.01822062  0.01049847  0.02486647  0.01368361]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 86
images_for_training/248
(1, 64, 64, 3)
Policy eval: 
[[  9.62737024e-01   1.51402736e-02   1.49390735e-02   2.91956344e-08
    3.07788568e-08   1.53106866e-05   9.78085700e-06   3.44572413e-06
    1.76954127e-05   1.00502184e-07   9.46698128e-05   1.55705237e-03
    8.31958168e-05   1.64692698e-04   1.92048155e-09   6.31621588e-05
    2.86384648e-07   1.66374491e-07   1.97808477e-04   4.01665375e-07
    2.89163636e-05   5.96604559e-06   4.36026312e-06   6.61144122e-06
    2.34253283e-04   7.62655930e-07   5.07633740e-06   2.80968728e-03
    7.14276830e-05   5.08929486e-04   3.03077150e-06   2.58863313e-08
    4.67740875e-07   7.24022742e-04   2.55882987e-05   1.31142531e-06
    2.60443755e-07   4.38762662e-08   2.78372386e-06   5.42025489e-04
    2.88779205e-07]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 87
images_for_training/25
(1, 64, 64, 3)
Policy eval: 
[[  6.91428781e-02   2.06816308e-02   2.14013040e-01   9.58474632e-03
    6.60715450e-04   3.64582433e-04   1.58380899e-05   2.78277730e-05
    3.64369154e-03   2.72614416e-05   4.41444386e-03   5.47893671e-03
    8.28005941e-05   1.24522662e-02   6.71819842e-04   1.75891444e-03
    5.10894900e-08   3.80475190e-04   1.82142726e-03   2.80559668e-03
    1.03352787e-02   2.97360532e-02   1.06073532e-03   1.55914659e-02
    8.66733771e-03   1.09299493e-04   7.31706386e-03   6.62629609e-05
    1.85415708e-03   4.38268572e-01   4.52066213e-03   4.44768775e-05
    6.94271037e-03   2.29204949e-02   9.79610998e-03   6.31331815e-04
    5.46928146e-04   2.02996544e-05   3.87873952e-05   8.90324488e-02
    4.47055651e-03]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 88
images_for_training/52
(1, 64, 64, 3)
Policy eval: 
[[  8.07069659e-01   5.51162055e-03   1.08813995e-03   1.36097311e-03
    2.86511613e-06   1.30906096e-03   3.40435713e-06   6.28056223e-05
    1.88451634e-06   1.37245388e-06   6.06137428e-06   1.73545741e-02
    1.18914155e-04   7.72290696e-06   2.49670138e-05   6.23920350e-05
    4.00707868e-05   5.19972062e-04   8.20225221e-04   2.74743506e-05
    8.70628282e-04   8.82095537e-06   6.79464210e-06   7.17252900e-04
    7.18117633e-04   1.24951484e-07   1.21844467e-04   5.72814815e-06
    4.51066269e-04   9.17145982e-02   7.47173000e-03   2.44160763e-08
    1.67859364e-02   1.66024256e-05   1.45499202e-04   1.29147804e-08
    6.60494652e-06   8.90886167e-06   1.67719406e-07   4.55553383e-02
    9.21604268e-08]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 89
images_for_training/229
(1, 64, 64, 3)
Policy eval: 
[[  5.09970367e-01   1.11751761e-02   4.53155041e-01   4.97294046e-12
    5.66650269e-14   4.80572415e-10   2.24905472e-09   3.62635610e-09
    6.91155437e-05   2.15356864e-11   5.56326370e-07   4.27215709e-04
    1.47609142e-04   2.46251346e-07   1.74450399e-09   1.74743047e-06
    3.44539089e-12   1.44347347e-11   1.31547939e-10   2.67689271e-09
    8.08029108e-06   1.36332426e-06   4.44569241e-06   2.50953581e-05
    8.86724683e-06   2.92688762e-09   2.71696539e-04   3.92814883e-07
    1.47121609e-04   2.44078506e-02   1.89906937e-10   4.27492388e-08
    3.78816534e-09   2.38270926e-12   1.23073260e-05   5.66103182e-08
    4.85295502e-08   5.73143977e-10   1.66019871e-11   1.65437872e-04
    2.02101003e-09]]
Action: 0.75
Enter Reward: 1
Backpropping 

Session Number 90
images_for_training/83
(1, 64, 64, 3)
Policy eval: 
[[  9.60015059e-01   1.92773674e-04   1.60619456e-04   2.28643712e-05
    3.45996796e-07   5.53953250e-05   4.32587171e-07   1.01757514e-05
    2.23816387e-04   9.29263848e-08   1.10246947e-04   3.94319370e-03
    1.19730954e-04   7.66592711e-06   7.65650111e-06   7.60875482e-05
    2.31523494e-08   5.74787964e-06   1.73992903e-05   9.66341142e-03
    1.75659557e-06   3.21366685e-03   4.30677801e-06   1.03521557e-03
    1.27445513e-04   5.94416952e-06   2.37644031e-06   5.68296628e-07
    2.73127545e-04   2.01865621e-02   3.50583650e-06   1.87100829e-06
    5.11807812e-05   8.93145000e-07   2.32856546e-04   1.25979295e-05
    1.57748119e-07   4.34225200e-07   2.26489101e-05   1.83483047e-04
    6.55338863e-06]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 91
images_for_training/41
(1, 64, 64, 3)
Policy eval: 
[[  4.69436884e-01   1.87049364e-03   7.30865495e-03   8.25853553e-04
    1.19778269e-05   4.72991451e-05   3.63866047e-06   7.44451836e-06
    3.57102347e-03   1.29092485e-04   1.81267213e-04   5.34404884e-04
    1.29951395e-05   2.65236507e-04   2.84413283e-04   1.37025455e-03
    9.26795352e-08   7.90534705e-06   3.32009345e-01   1.43518264e-03
    2.87921648e-06   1.01923406e-01   1.07332155e-04   1.75539497e-02
    1.12413749e-04   2.18035711e-06   1.29788838e-04   3.68136061e-05
    5.93964160e-06   4.29822728e-02   1.01210542e-04   2.74305933e-07
    8.64638598e-04   1.32500238e-04   1.14011660e-03   7.13455393e-06
    8.78108494e-06   3.56492383e-05   4.56472335e-05   2.47296225e-03
    1.30206393e-02]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 92
images_for_training/16
(1, 64, 64, 3)
Policy eval: 
[[  6.17078304e-01   2.16393191e-02   2.15920419e-01   5.59927503e-06
    9.00673149e-06   9.96123254e-03   5.09123318e-04   7.18935439e-07
    2.50409823e-04   1.02186141e-05   2.80297827e-03   2.88906973e-03
    1.48153165e-03   2.78813910e-04   1.49426603e-04   8.32575187e-02
    8.33879810e-08   1.55217800e-04   1.80443691e-03   4.79421957e-04
    7.38229777e-04   1.17046060e-03   6.72117458e-04   3.42075982e-05
    4.60540978e-05   2.32295413e-03   3.05623194e-04   1.73291119e-04
    6.95630966e-04   3.27987149e-02   8.64873800e-06   9.74456780e-05
    2.32852573e-04   5.13781852e-05   9.41057078e-06   9.80969708e-05
    3.08733666e-04   5.90075706e-06   5.71774552e-04   9.05397697e-04
    7.03141122e-05]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 93
images_for_training/98
(1, 64, 64, 3)
Policy eval: 
[[  2.84510881e-01   1.53726377e-02   5.85950073e-03   4.83580539e-03
    1.56853825e-03   6.04000054e-02   3.41689702e-06   2.56589148e-03
    9.23788175e-05   2.51083766e-05   3.70316819e-04   2.03597927e-04
    5.08185040e-05   5.91830350e-04   3.43979191e-04   1.04535669e-01
    4.88858268e-06   1.46038225e-02   1.08024140e-03   5.21443598e-03
    1.72276318e-03   6.95067551e-03   1.72345829e-03   2.17954163e-02
    8.81697685e-02   6.50389993e-04   2.39628763e-03   2.21090639e-04
    3.28615936e-03   2.72941142e-01   3.11767426e-03   3.21358704e-04
    3.33354436e-03   5.06429824e-05   1.20522976e-02   3.05574900e-03
    5.83723560e-02   2.88157782e-04   1.14979483e-02   5.71809942e-03
    1.01286598e-04]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 94
images_for_training/282
(1, 64, 64, 3)
Policy eval: 
[[  1.85691133e-01   4.66416008e-04   1.44055593e-05   1.51537724e-05
    9.93159097e-11   1.15235359e-03   3.49534823e-09   7.01197278e-09
    2.69775148e-02   2.35860789e-08   3.73156936e-08   2.50858379e-09
    1.74972459e-09   7.67173395e-02   2.84224461e-06   1.85102166e-03
    2.68186047e-15   1.70036674e-06   3.14964622e-01   2.22225790e-03
    3.64042378e-08   3.47659916e-01   3.92631482e-05   1.27485273e-02
    2.53455937e-02   1.41630285e-09   2.63912102e-06   1.72585203e-07
    4.43242461e-05   4.47119692e-06   1.31383682e-09   2.12158611e-08
    1.09252619e-06   2.76401897e-06   3.73932696e-03   1.50541746e-06
    8.37917680e-10   5.23240578e-06   2.57206967e-08   4.04764933e-06
    3.24292836e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 95
images_for_training/215
(1, 64, 64, 3)
Policy eval: 
[[  2.54679061e-02   5.30892401e-04   2.59243989e-05   1.47355161e-06
    5.61776681e-10   3.99437547e-02   4.94092722e-09   1.07228479e-05
    5.59337204e-05   2.06779282e-06   8.12616345e-05   5.80980889e-02
    1.99356887e-08   1.38615485e-06   1.04005303e-04   4.12127265e-04
    5.55458118e-15   2.95826999e-06   2.94238562e-03   3.34679586e-04
    7.42418464e-08   5.64808734e-02   1.86770776e-05   3.27794805e-05
    1.09823688e-03   1.00330544e-08   6.27048433e-01   2.53887265e-06
    1.79061142e-04   4.40504262e-03   2.07610960e-08   9.69741976e-09
    1.29762921e-05   5.77564560e-06   5.39090261e-02   2.15350548e-04
    4.96520486e-04   4.28815525e-08   1.90227041e-07   1.27280414e-01
    7.98441237e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 96
images_for_training/286
(1, 64, 64, 3)
Policy eval: 
[[  3.37261669e-02   1.05540457e-05   3.01885583e-09   2.22239809e-08
    1.34533196e-09   5.20670710e-07   4.36367088e-11   1.04015169e-12
    1.30291937e-08   1.52624066e-10   9.55107105e-09   1.36443690e-09
    2.37194270e-12   6.41477427e-11   1.54519955e-06   5.98106184e-04
    2.45852411e-13   4.15110524e-09   4.39028147e-09   1.43592560e-08
    9.65569854e-01   7.79327536e-09   1.94526839e-09   6.87399443e-05
    8.76435934e-06   2.80939190e-07   9.30313812e-11   1.79071376e-11
    1.49550345e-08   1.58071917e-10   2.42789213e-07   5.04618125e-09
    2.47419422e-07   1.84781257e-09   2.48885392e-08   7.97994991e-15
    1.08193488e-09   9.02165596e-08   1.63157345e-08   1.48249419e-05
    1.49174877e-08]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 97
images_for_training/118
(1, 64, 64, 3)
Policy eval: 
[[ 0.06903997  0.0565949   0.04696838  0.02061629  0.01935175  0.05472019
   0.00856943  0.01133554  0.01342299  0.01231968  0.02174739  0.04579752
   0.01292206  0.01379154  0.02339337  0.03060908  0.0126965   0.02027581
   0.01795954  0.03849944  0.01514902  0.03033412  0.01904953  0.02897413
   0.02560161  0.02334987  0.01827086  0.01692193  0.0256841   0.02459827
   0.02847269  0.01334527  0.02453096  0.02779154  0.03230463  0.00784482
   0.01450237  0.01345915  0.0269555   0.01873137  0.01349679]]
Action: 2.0
Enter Reward: 1
Backpropping 

Session Number 98
images_for_training/289
(1, 64, 64, 3)
Policy eval: 
[[  9.81965840e-01   2.40136114e-06   1.78219028e-09   9.22323551e-09
    8.41160475e-13   7.08752568e-09   2.48447218e-11   2.78322830e-07
    6.85846802e-09   2.05504572e-11   2.33479173e-11   1.11562781e-09
    9.06923336e-09   4.33456693e-09   4.57073838e-07   9.07649883e-06
    4.69837086e-11   3.63462082e-13   1.44714527e-02   7.02881620e-09
    1.74523954e-11   1.23837144e-05   1.92845295e-08   2.74625100e-10
    1.50084476e-11   2.02033945e-11   1.02467190e-09   3.93790112e-09
    1.90487750e-08   3.97654745e-08   4.21187956e-08   6.00290623e-14
    2.97571717e-07   1.04632271e-07   2.28137864e-09   1.64805604e-12
    1.19607755e-08   2.92007356e-11   1.76709528e-15   3.53755220e-03
    2.55405808e-09]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 99
images_for_training/42
(1, 64, 64, 3)
Policy eval: 
[[  1.95809524e-03   6.23421147e-05   2.71055556e-04   1.20913751e-06
    2.10873367e-11   1.80442623e-06   4.37388614e-08   2.56963006e-10
    2.23207159e-08   6.71970465e-11   2.68671502e-05   9.13029563e-09
    1.00783548e-10   8.45778345e-08   3.25465408e-05   7.05447933e-03
    2.36003030e-15   1.98315164e-09   1.42949971e-03   2.59576700e-05
    1.17263654e-09   9.91206325e-05   9.32701141e-07   4.35306749e-04
    6.69285904e-10   1.82684829e-07   3.72968900e-09   6.65921346e-11
    3.42099884e-05   1.64489034e-09   1.06783367e-10   3.74239477e-07
    3.74498010e-01   2.07730366e-08   9.38507512e-08   7.62952375e-12
    2.73612812e-07   1.81013440e-10   8.90040575e-09   6.14067495e-01
    2.21034815e-10]]
Action: 1.05
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 19:23:14.839579: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/118
(1, 64, 64, 3)
Policy eval: 
[[  4.20926845e-05   3.17215425e-04   3.23982764e-04   6.04084320e-03
    2.91200310e-01   8.91392352e-04   1.57241698e-03   8.06387290e-02
    3.97080153e-01   4.29102639e-03   2.19878443e-02   3.43237333e-02
    8.56955594e-04   2.47742212e-03   1.57999981e-04   1.90853636e-04
    6.82346465e-04   2.87732258e-02   1.57238971e-02   4.03755575e-06
    5.54844039e-03   1.10958908e-02   1.95573477e-04   4.64581128e-04
    1.64404028e-05   3.71331000e-03   1.53630935e-02   9.34374766e-05
    3.37784900e-03   1.90851334e-02   5.51152136e-03   1.69412941e-02
    2.94545642e-03   1.32939368e-02   7.30734027e-04   2.14509061e-03
    7.77776586e-03   2.16229213e-03   3.47253750e-04   1.08930247e-03
    5.25186304e-04]]
2018-10-05 19:23:15.928 Python[33965:13854357] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 1.6
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/250
(1, 64, 64, 3)
Policy eval: 
[[  5.24103090e-21   1.07751225e-06   1.35685782e-24   9.63568249e-37
    8.68168032e-19   4.64961078e-04   2.36742607e-19   1.37428060e-08
    1.75844937e-19   9.05427644e-09   9.98978615e-01   1.02643870e-18
    2.90184651e-13   3.36889025e-14   1.29843900e-14   2.00502700e-20
    7.41400170e-12   6.46473785e-18   1.03143119e-11   7.26421835e-29
    4.72573578e-18   6.72825308e-07   9.33968173e-38   7.42727954e-19
    0.00000000e+00   1.22890600e-10   7.63693260e-18   8.27305416e-29
    1.53627102e-26   7.83895120e-23   3.70405840e-16   5.71996686e-20
    5.54667145e-04   2.02488904e-27   9.89165753e-14   7.98532795e-09
    2.26082255e-13   0.00000000e+00   1.74616244e-20   3.66355286e-27
    2.27946244e-17]]
Action: 1.05
Enter Reward: 1
Backpropping 

Session Number 2
images_for_training/13
(1, 64, 64, 3)
Policy eval: 
[[  5.63813850e-37   1.04164636e-30   0.00000000e+00   0.00000000e+00
    3.35526008e-31   5.15266032e-27   1.62251554e-02   1.37688821e-05
    3.79969105e-22   0.00000000e+00   1.23370425e-25   1.56020309e-32
    5.49135525e-15   8.49161985e-24   9.83761132e-01   4.19347976e-12
    1.22335618e-18   1.32950720e-10   3.01553526e-19   1.83018377e-30
    5.56114518e-18   2.07461805e-26   5.80744252e-23   1.95147896e-37
    3.75160749e-33   2.03598126e-19   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   9.58143587e-37   1.08121815e-28
    1.01316830e-20   2.07835574e-27   4.17633536e-34   2.67625579e-20
    3.87429708e-35   0.00000000e+00   2.53836735e-26   0.00000000e+00
    2.84540921e-25]]
Action: 0.45
Enter Reward: 0
Backpropping 

Session Number 3
images_for_training/152
(1, 64, 64, 3)
Policy eval: 
[[  2.49160003e-05   1.06293820e-02   1.91510563e-09   5.21829861e-07
    4.40817871e-09   1.37192046e-06   2.32624484e-06   3.51787021e-05
    6.34004182e-10   9.05629406e-07   1.91743334e-06   1.38311516e-05
    1.15071671e-05   1.42563922e-05   7.19963253e-01   7.55229092e-04
    9.11033130e-05   4.03831336e-06   1.22987491e-03   1.67434139e-03
    6.43164685e-06   7.32224944e-05   1.46974198e-04   1.22409993e-09
    1.51104562e-09   2.72815145e-04   3.70425078e-05   9.41611290e-07
    4.18229392e-05   1.14404175e-09   4.52301748e-07   1.38226466e-03
    5.44615286e-05   1.46344928e-06   6.25193053e-08   2.96251895e-03
    1.65709134e-04   2.44996538e-14   2.60396540e-01   3.47418421e-07
    3.09583061e-06]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/104
(1, 64, 64, 3)
Policy eval: 
[[  5.09719864e-15   9.61230755e-01   2.11852411e-11   1.51149370e-14
    5.43512613e-08   6.10949378e-03   9.02809916e-09   9.95699270e-12
    8.61142187e-16   1.02879063e-07   1.95722032e-06   5.82514801e-08
    7.34998539e-05   2.23576130e-10   3.24988253e-02   6.32059391e-06
    1.92940636e-10   6.64182444e-05   7.25701712e-14   3.70906306e-09
    1.80797590e-14   2.03699266e-10   3.42764393e-11   1.83582516e-09
    9.41848121e-16   7.49822815e-10   5.92431009e-12   7.82065645e-12
    1.04934453e-17   5.16050800e-16   1.92990224e-11   2.02817472e-12
    3.40403595e-13   1.72236249e-13   1.60432726e-11   1.23686332e-05
    4.88997135e-13   5.07837682e-21   1.08684790e-10   2.35464859e-13
    1.00844211e-14]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 5
images_for_training/112
(1, 64, 64, 3)
Policy eval: 
[[  2.27466808e-04   2.66716301e-01   2.72989739e-04   1.37444364e-03
    2.91210581e-02   1.96373396e-04   2.30663503e-03   5.78414137e-03
    3.70309484e-04   1.02937734e-03   1.32246222e-03   1.76978093e-02
    6.60438600e-05   1.35527744e-05   8.52598548e-02   9.77923907e-03
    6.79327233e-04   8.65511447e-02   1.06293587e-02   4.62955981e-02
    7.48672697e-04   1.51902037e-02   1.16307836e-03   2.48950091e-05
    2.66121219e-06   9.19482391e-03   2.17023335e-04   1.03146269e-03
    1.29550768e-04   8.60961227e-05   9.40227910e-05   2.14027520e-03
    2.43926897e-05   8.66785467e-06   1.32404163e-03   4.02146816e-01
    4.71000021e-05   8.43790673e-08   4.92464053e-04   4.98810587e-05
    1.90341700e-04]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 6
images_for_training/8
(1, 64, 64, 3)
Policy eval: 
[[  1.50350094e-26   4.83860402e-13   0.00000000e+00   5.30748699e-26
    7.45630166e-22   1.30583050e-34   0.00000000e+00   2.29922195e-33
    1.20789446e-33   2.44225191e-38   3.76054554e-25   1.33514046e-35
    0.00000000e+00   0.00000000e+00   3.13652215e-09   4.05818618e-32
    1.66290226e-13   4.18622643e-01   0.00000000e+00   8.05148037e-09
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   5.81377387e-01   7.26861054e-31   0.00000000e+00
    1.79512186e-26   0.00000000e+00   0.00000000e+00   3.60625375e-28
    0.00000000e+00   0.00000000e+00   3.32696461e-37   1.65310264e-31
    5.70757909e-28   0.00000000e+00   8.03394776e-20   0.00000000e+00
    5.51650355e-37]]
Action: 1.55
Enter Reward: 0
Backpropping 

Session Number 7
images_for_training/231
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   7.82089532e-11   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.89786645e-18   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.86337343e-27   0.00000000e+00   3.39664172e-35
    0.00000000e+00   0.00000000e+00   4.29749788e-33   2.21874648e-25
    0.00000000e+00   1.95103766e-38   8.35405652e-34   0.00000000e+00
    0.00000000e+00   7.45623634e-33   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   2.21508573e-24
    0.00000000e+00   0.00000000e+00   3.64633297e-34   1.97560483e-36
    0.00000000e+00   0.00000000e+00   1.71268060e-29   0.00000000e+00
    0.00000000e+00]]
Action: 0.7
Enter Reward: 1
Backpropping 

Session Number 8
images_for_training/229
(1, 64, 64, 3)
Policy eval: 
[[  1.26046930e-35   3.40117347e-30   9.06033512e-38   0.00000000e+00
    2.91460662e-17   2.03590717e-21   0.00000000e+00   0.00000000e+00
    9.27281842e-32   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   9.99999404e-01   7.31919268e-24
    1.91618416e-24   2.07041229e-16   3.36700298e-15   1.03045134e-25
    0.00000000e+00   9.30937359e-29   0.00000000e+00   0.00000000e+00
    0.00000000e+00   6.01762508e-07   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.48369154e-28
    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.61465000e-21
    2.37690895e-10   0.00000000e+00   1.41838917e-21   0.00000000e+00
    0.00000000e+00]]
Action: 0.75
Enter Reward: 1
Backpropping 

Session Number 9
images_for_training/226
(1, 64, 64, 3)
Policy eval: 
[[  6.34190626e-04   1.24973420e-04   1.82282372e-28   0.00000000e+00
    5.11351128e-10   2.76243418e-06   8.35206383e-12   2.88626194e-36
    8.09448257e-34   6.98925770e-26   4.24159822e-16   9.76599052e-30
    0.00000000e+00   0.00000000e+00   9.98793483e-01   2.55588409e-23
    9.17179793e-26   4.44608275e-04   7.18559936e-14   1.15281593e-20
    0.00000000e+00   3.36301357e-26   3.38495191e-22   3.81550921e-17
    0.00000000e+00   2.21226186e-16   0.00000000e+00   2.04060042e-29
    0.00000000e+00   0.00000000e+00   7.76054026e-14   4.53866168e-23
    1.30446538e-18   9.60970354e-38   1.07512074e-35   5.15335864e-11
    4.82036191e-27   0.00000000e+00   2.01883796e-27   3.87238704e-25
    0.00000000e+00]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/64
(1, 64, 64, 3)
Policy eval: 
[[  6.47009656e-05   9.87971127e-01   1.11429263e-18   2.28280806e-17
    2.63610016e-13   1.75664039e-10   2.34111565e-20   2.21263142e-18
    1.68707014e-15   2.53520871e-10   5.79790827e-13   1.96211630e-10
    2.45974005e-18   9.09380329e-17   1.96741275e-05   1.17745902e-08
    1.72788207e-11   1.84625049e-09   1.71607940e-13   8.90523921e-08
    2.65300172e-14   1.22459665e-09   3.87800859e-12   1.35344600e-20
    1.06678055e-24   3.54953720e-08   2.71288309e-13   9.99819162e-16
    7.66143524e-16   7.43025518e-15   1.40533153e-15   1.01395082e-13
    1.16155073e-22   3.17073311e-16   2.01143822e-17   3.22379878e-09
    1.19443201e-02   2.37995391e-26   4.51083448e-10   4.37215580e-15
    2.16300581e-21]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/183
(1, 64, 64, 3)
Policy eval: 
[[  6.20214045e-01   3.44535559e-02   8.79273110e-04   5.53875638e-04
    1.63072941e-03   3.25809087e-04   8.70271644e-04   2.79627944e-04
    1.65690426e-02   6.54519463e-05   7.75881065e-03   5.30799245e-03
    1.55808590e-03   3.63414438e-04   5.44971228e-02   2.64816061e-02
    4.37427964e-03   7.42930360e-03   9.57673695e-03   1.13118561e-02
    1.24074088e-03   4.38485900e-03   9.51354450e-04   5.30601898e-03
    2.12036015e-04   3.18514928e-02   7.48993596e-04   8.91329814e-03
    2.67395983e-03   8.52862198e-04   7.64516965e-02   5.85994031e-03
    2.73670559e-03   1.41274056e-03   3.46615096e-04   2.85828039e-02
    1.11073330e-02   6.17125261e-05   1.03361364e-02   1.14721816e-03
    3.20561230e-04]]
Action: 1.25
Enter Reward: 0
Backpropping 

Session Number 12
images_for_training/161
(1, 64, 64, 3)
Policy eval: 
[[  1.08416021e-01   2.58843154e-01   9.81612946e-04   4.45203914e-04
    4.71703298e-02   6.83138985e-03   5.81170106e-03   7.69558887e-04
    1.44526297e-02   2.43301201e-03   1.51080787e-02   1.19647617e-03
    5.98973420e-04   2.28659832e-03   9.25042555e-02   3.45663377e-03
    2.53828801e-02   2.36843359e-02   4.88696992e-03   2.65838485e-02
    1.09299403e-02   5.31796645e-03   2.23115762e-03   4.88785328e-03
    4.55191545e-03   1.06897922e-02   1.28170196e-03   3.13827060e-02
    7.93836731e-03   2.21291237e-04   2.16836948e-02   4.34034970e-03
    1.59990098e-02   1.16116991e-02   3.53690179e-04   3.17793414e-02
    1.20340422e-01   4.97281260e-04   6.47044778e-02   3.93461948e-03
    3.47908656e-03]]
Action: 0.4
Enter Reward: 0
Backpropping 

Session Number 13
images_for_training/112
(1, 64, 64, 3)
Policy eval: 
[[ 0.0903622   0.0842301   0.00784454  0.00298236  0.00814777  0.0174359
   0.00187634  0.0038754   0.00817153  0.00785205  0.04981363  0.0139542
   0.00814985  0.00536863  0.03214521  0.01987648  0.03939869  0.08125214
   0.02769952  0.02245306  0.00840617  0.01577657  0.00963393  0.01379247
   0.00294419  0.25555065  0.00772885  0.01669658  0.00943387  0.00261016
   0.00620372  0.00370141  0.00338409  0.01526118  0.00489155  0.00875284
   0.0263126   0.00074204  0.04688828  0.00347191  0.00492726]]
Action: 0.95
Enter Reward: 0
Backpropping 

Session Number 14
images_for_training/190
(1, 64, 64, 3)
Policy eval: 
[[  2.63114244e-01   9.05559584e-03   3.75531777e-03   1.75482593e-03
    8.83536041e-03   1.67654478e-03   1.44852838e-03   2.99277017e-03
    1.01182833e-02   5.67630865e-03   7.82050565e-02   8.21480341e-03
    2.62202439e-03   2.00497173e-03   1.71307772e-02   8.77976138e-03
    4.29087915e-02   3.23435403e-02   8.67265277e-03   1.27435535e-01
    8.87737086e-04   5.21491561e-03   1.09906355e-02   4.41172067e-03
    6.49047608e-04   1.79345354e-01   1.97279989e-03   5.48010785e-03
    7.93570245e-04   1.03467256e-02   5.71347587e-03   7.48486398e-03
    1.10450452e-02   3.18406615e-04   1.22240640e-03   1.46574052e-02
    2.03406680e-02   1.57942472e-04   7.57954717e-02   2.79399613e-03
    3.63196852e-03]]
Action: 1.05
Enter Reward: 0
Backpropping 

Session Number 15
images_for_training/185
(1, 64, 64, 3)
Policy eval: 
[[  2.47959852e-01   3.97589505e-02   6.04140572e-04   9.40607861e-04
    1.92958713e-02   1.42865321e-02   2.94789905e-03   2.65901978e-03
    2.84136795e-02   7.96489650e-04   9.98492092e-02   1.28660351e-03
    7.74789485e-04   1.70029452e-04   1.52596042e-01   1.32773472e-02
    5.39073348e-02   1.39297964e-02   4.92877979e-03   4.62132366e-03
    2.20503984e-03   7.79461935e-02   4.77099419e-03   1.82257239e-02
    5.54963917e-05   2.62396988e-02   5.88111288e-04   7.92425964e-03
    3.37440753e-03   5.34184568e-04   9.33559518e-03   2.95005436e-03
    2.58441549e-03   6.89894240e-03   9.37218254e-04   3.40419672e-02
    4.91446406e-02   4.39797077e-05   3.47057134e-02   7.78446486e-03
    6.70457957e-03]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 16
images_for_training/127
(1, 64, 64, 3)
Policy eval: 
[[  3.63300025e-01   8.08612385e-04   2.20945789e-04   5.20025878e-06
    9.52105224e-03   1.42542543e-04   2.33133134e-04   3.30758739e-05
    1.46378565e-03   6.41652849e-04   4.69831377e-03   2.26142540e-04
    7.09200249e-05   6.10721705e-04   3.38664814e-03   1.55991552e-06
    4.49505113e-02   8.13581501e-05   1.98327252e-04   4.94606560e-03
    5.20131016e-06   3.22516751e-03   3.66705528e-04   3.78814503e-03
    4.45592286e-06   2.83162534e-01   1.58319686e-04   8.65603797e-04
    2.22523915e-04   1.05995978e-05   1.10731581e-02   2.38057855e-03
    8.49950220e-03   2.61180758e-05   5.39915636e-05   3.78739554e-03
    2.09705025e-01   2.92912910e-06   7.74652045e-03   2.86482461e-02
    7.26647791e-04]]
Action: 1.25
Enter Reward: 0
Backpropping 

Session Number 17
images_for_training/132
(1, 64, 64, 3)
Policy eval: 
[[  2.82214165e-01   1.82597054e-04   3.08937742e-04   1.43490274e-06
    3.01290639e-02   3.35513987e-03   5.70664008e-04   2.09079899e-05
    3.64397099e-04   1.08971889e-03   2.05019815e-03   9.00338113e-04
    1.09646865e-03   2.32105594e-05   8.13834742e-02   5.87447896e-04
    9.65357572e-03   2.01575909e-04   4.10529301e-02   1.14536076e-03
    2.44616880e-04   1.84063858e-04   4.34348267e-03   9.43922997e-03
    8.53521499e-07   1.31823987e-01   1.21681172e-04   8.49700999e-03
    7.19225427e-05   4.38356847e-06   5.50879538e-03   1.07576932e-04
    7.27099599e-04   8.28478078e-05   6.11426367e-05   2.65502513e-05
    3.30197848e-02   2.47646123e-04   3.47790420e-01   7.88659439e-04
    5.76657825e-04]]
Action: 1.9
Enter Reward: 1
Backpropping 

Session Number 18
images_for_training/77
(1, 64, 64, 3)
Policy eval: 
[[  3.60385398e-04   6.03549508e-03   1.68771619e-09   8.00164934e-11
    1.44271850e-09   1.02575996e-06   6.79036006e-17   1.84633175e-09
    6.92870830e-11   1.41582890e-09   2.14267821e-08   1.78223181e-05
    1.48380985e-09   7.89965966e-13   8.49107146e-01   2.16653842e-08
    1.10315446e-11   2.47653446e-07   4.62968455e-05   1.96504004e-08
    1.57566355e-05   2.84982660e-09   5.68590499e-03   6.54413856e-10
    4.96622144e-12   1.54735302e-04   6.67832900e-10   3.14710515e-11
    8.10743226e-12   7.20704217e-14   7.72985150e-05   2.61327154e-10
    9.57944593e-14   2.39331038e-11   8.07006405e-16   3.47155399e-12
    6.31436531e-04   1.40887710e-15   1.37866214e-01   5.90962446e-13
    2.29591350e-07]]
Action: 1.25
Enter Reward: 1
Backpropping 

Session Number 19
images_for_training/280
(1, 64, 64, 3)
Policy eval: 
[[  1.24546459e-05   9.94988739e-01   5.88227456e-20   1.27320599e-17
    6.40663873e-14   1.28528698e-12   4.76971557e-22   2.78657772e-16
    9.86858842e-14   1.32186417e-12   9.55525081e-09   1.43034822e-15
    1.73067439e-16   1.51563904e-21   4.99824807e-03   5.07608116e-13
    6.42094919e-11   3.74214400e-18   2.38386242e-13   2.99751252e-10
    7.03967185e-14   1.21734957e-12   1.54159644e-13   2.67992988e-22
    1.65873080e-25   4.18006428e-11   2.24240538e-14   2.34393261e-14
    3.56064014e-21   1.57902418e-21   5.68098221e-14   3.21086414e-19
    3.91561331e-21   4.76745665e-16   1.20833663e-20   1.47873365e-07
    4.04772500e-08   8.94682060e-25   3.26015424e-07   1.27582233e-16
    7.71596474e-18]]
Action: 1.25
Enter Reward: 0
Backpropping 

Session Number 20
images_for_training/36
(1, 64, 64, 3)
Policy eval: 
[[  2.22202814e-07   9.99747455e-01   2.24344876e-05   2.36553745e-07
    6.75426345e-05   1.85473880e-07   7.74110429e-11   1.04156932e-08
    1.60206799e-08   1.81970805e-07   9.14657335e-07   6.83785693e-05
    3.86517574e-09   2.78746609e-10   7.41768929e-07   2.43722589e-08
    8.38359992e-05   2.18056158e-07   5.86913984e-07   1.03810782e-09
    4.60325961e-12   5.62602736e-06   1.55909881e-08   4.94990715e-10
    6.90976096e-11   2.60931499e-09   5.21423438e-09   5.80544111e-08
    5.01513098e-09   3.23035314e-11   1.54318698e-07   4.34418855e-11
    4.02206135e-09   1.05487516e-07   4.81656892e-09   9.07412534e-10
    7.92211097e-07   2.28961503e-11   6.82173251e-08   1.14512266e-09
    2.04944936e-10]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 21
images_for_training/75
(1, 64, 64, 3)
Policy eval: 
[[  1.19416227e-05   5.49078465e-01   1.04308265e-05   8.38220842e-07
    5.55954614e-07   2.19990609e-10   2.69313571e-10   4.70555648e-08
    5.87543347e-09   2.15221656e-12   3.91653032e-07   5.22212884e-10
    2.57902705e-12   3.16284135e-14   8.58801059e-07   9.54848645e-10
    6.87531781e-07   1.40651002e-09   8.90746378e-06   4.23690021e-01
    9.46879172e-11   4.75841137e-11   6.76552414e-09   3.71840925e-14
    4.98552623e-11   3.36387211e-06   2.05030437e-09   4.08175474e-05
    2.64032286e-12   1.23667092e-12   1.39844414e-10   6.76068312e-10
    7.99471166e-13   5.21610540e-18   2.52864008e-10   7.74348849e-11
    1.52392640e-10   5.63589253e-17   2.71279421e-02   6.55307009e-09
    2.48139168e-05]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 22
images_for_training/211
(1, 64, 64, 3)
Policy eval: 
[[  3.47344695e-08   1.00000000e+00   2.15028272e-13   1.38308941e-19
    3.35826473e-14   1.60369634e-11   3.05308526e-17   7.20366423e-16
    4.22402625e-14   1.77350509e-19   7.88851796e-12   1.37370787e-13
    3.28489055e-18   4.51136713e-21   3.25499600e-15   4.06806393e-16
    2.41718050e-13   2.66233170e-15   7.66344432e-10   2.68813694e-10
    5.93550066e-17   4.47802973e-16   1.28954111e-10   2.12040961e-16
    1.28709596e-14   2.27286289e-13   1.03406999e-19   8.65910872e-14
    1.03888737e-16   1.02669435e-15   8.04811002e-16   4.34845857e-16
    2.53230393e-17   3.42645393e-14   6.82757049e-19   6.32014989e-14
    2.46347248e-10   6.25171738e-28   2.50010776e-12   1.05126973e-16
    1.22212331e-12]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 23
images_for_training/111
(1, 64, 64, 3)
Policy eval: 
[[ 0.01209767  0.35318673  0.01528065  0.00282556  0.16479151  0.00474362
   0.01304331  0.00558666  0.08527528  0.00268486  0.00856377  0.05187913
   0.00535354  0.03561779  0.00377318  0.00171492  0.01121886  0.00391088
   0.00873285  0.01317153  0.00091184  0.00331051  0.04429506  0.00131852
   0.00042354  0.01119953  0.00206393  0.00607328  0.00250142  0.00363769
   0.00364262  0.00128885  0.00227912  0.00086786  0.0072139   0.00322583
   0.02681728  0.00058106  0.03149486  0.0419086   0.00149237]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 24
images_for_training/10
(1, 64, 64, 3)
Policy eval: 
[[  7.26796401e-09   9.99832511e-01   3.60795207e-06   2.48391132e-07
    9.83486803e-09   3.20804730e-07   4.82331615e-08   1.20069501e-06
    2.77732653e-07   3.35179084e-06   1.14055024e-06   5.88475268e-06
    1.53205679e-06   2.08084757e-07   1.82660847e-06   6.56308730e-10
    2.67404594e-05   3.10036635e-10   6.58914303e-07   2.25631466e-05
    3.88487024e-07   1.54632517e-07   1.57365703e-05   1.69892633e-09
    1.96398293e-08   1.30099750e-06   4.81051984e-07   1.40855619e-07
    1.50526375e-06   2.43186538e-08   3.78927911e-09   1.64060225e-07
    1.69489376e-05   1.36077194e-08   5.65614400e-08   1.19431618e-07
    1.32609003e-07   7.90813942e-11   3.90294081e-05   1.96127767e-05
    2.07197718e-06]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 25
images_for_training/161
(1, 64, 64, 3)
Policy eval: 
[[ 0.00847315  0.32698521  0.04227973  0.0450222   0.02080738  0.02172601
   0.01011265  0.0153134   0.01524131  0.0130993   0.01871581  0.01160062
   0.00742746  0.01207829  0.04223821  0.00538737  0.02818759  0.00600173
   0.03154491  0.02011422  0.00274828  0.01491318  0.00962165  0.00206538
   0.00238362  0.0052038   0.00797736  0.01847331  0.0169213   0.03714614
   0.00820188  0.006323    0.01716942  0.00265141  0.03269592  0.01947065
   0.03345941  0.00328508  0.02184098  0.02758446  0.00750714]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 26
images_for_training/89
(1, 64, 64, 3)
Policy eval: 
[[  2.57309922e-03   8.18297982e-01   5.00990544e-04   2.42812075e-06
    1.84116667e-04   1.23800623e-04   2.62910248e-06   1.09634413e-04
    2.46728850e-05   2.19501794e-06   2.39013205e-03   3.66344830e-06
    6.27624956e-07   6.54585165e-07   3.59794013e-02   9.51237598e-05
    9.00440682e-06   1.09771527e-05   1.16525687e-01   2.87699459e-05
    1.08183565e-04   9.97075313e-06   1.94029901e-02   1.46368437e-08
    1.70927215e-05   3.89081606e-06   1.68160698e-03   3.09413444e-04
    8.47651390e-05   6.09377537e-07   1.17111949e-06   1.36178405e-05
    2.19180052e-08   1.20516162e-07   2.37485210e-06   2.47066018e-05
    1.63440665e-04   1.45997596e-08   7.94356514e-04   1.44842932e-06
    5.14595245e-04]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 27
images_for_training/75
(1, 64, 64, 3)
Policy eval: 
[[  1.51436558e-04   6.95959151e-01   3.65094547e-06   1.65748258e-06
    7.71032297e-04   6.10047573e-05   1.02035992e-04   2.98590817e-06
    3.14326787e-10   3.94972552e-08   1.33854137e-08   2.53672333e-10
    4.92497021e-09   1.38014056e-09   5.43594865e-07   8.74420104e-04
    4.63607278e-11   1.53401025e-08   1.00984425e-05   6.77988399e-04
    5.33296873e-09   6.41306862e-04   3.57128120e-05   1.45425305e-09
    7.57317277e-13   4.69971506e-10   3.32183063e-08   9.96616855e-03
    1.43487194e-10   1.37189671e-13   1.91093186e-08   2.53823231e-07
    1.16195997e-09   4.08127391e-07   3.50288225e-08   3.01164096e-06
    2.47295088e-06   1.12735552e-13   2.90732145e-01   1.95201139e-07
    2.12894020e-06]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 28
images_for_training/284
(1, 64, 64, 3)
Policy eval: 
[[  1.58589396e-13   1.00000000e+00   9.14316271e-20   2.12645140e-17
    9.93718386e-15   2.84600556e-17   2.52625047e-20   1.79383350e-14
    1.64582366e-16   2.53539831e-16   1.27542996e-13   1.28671964e-19
    4.86941327e-15   5.17105541e-17   2.21273344e-13   1.96478427e-19
    3.94822577e-11   1.94233147e-26   1.45534109e-15   2.66012600e-17
    2.15904953e-16   1.20769043e-14   1.04975837e-17   5.72141487e-24
    1.04541055e-17   1.28329808e-19   1.40762178e-19   9.82686928e-18
    1.28044629e-13   2.38469191e-19   2.00190240e-18   3.31950640e-18
    3.17818988e-21   9.44635655e-21   5.80292055e-16   1.38904377e-18
    9.38670580e-18   2.31942255e-26   2.28353687e-15   1.19347712e-10
    5.94119616e-14]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 29
images_for_training/161
(1, 64, 64, 3)
Policy eval: 
[[ 0.0130704   0.42751914  0.01032542  0.04097176  0.00861836  0.02322847
   0.01476778  0.01164593  0.02628547  0.00871705  0.00873036  0.0208993
   0.03755643  0.01171012  0.04257049  0.00596209  0.00579329  0.00350412
   0.03494874  0.01006463  0.00616613  0.01952037  0.02600055  0.00298998
   0.00744327  0.00439601  0.02171201  0.00469664  0.02732167  0.00831742
   0.00245589  0.01040698  0.00728038  0.00185124  0.0039973   0.00409233
   0.01017014  0.00157996  0.02981519  0.0160571   0.01684021]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 30
images_for_training/45
(1, 64, 64, 3)
Policy eval: 
[[  1.10796271e-02   4.66304889e-04   5.32378920e-07   6.67074840e-09
    4.36301855e-03   5.95509354e-03   3.79162520e-01   1.25534898e-05
    1.52517416e-04   2.04373055e-06   7.17467259e-08   1.61597040e-04
    4.22362473e-06   2.10724244e-10   4.53678444e-02   5.66868493e-07
    1.54459087e-06   9.32024569e-10   1.06348834e-05   1.93023065e-04
    1.59914419e-03   2.06769351e-02   2.13787314e-02   5.80296502e-04
    1.70795431e-06   8.94963364e-07   3.96715507e-07   5.01584947e-01
    4.35885508e-04   1.76203080e-10   2.62500322e-03   1.46011288e-07
    6.72697738e-08   6.32801616e-08   1.04316532e-05   1.57193983e-06
    7.68256314e-07   6.20824636e-09   3.21134203e-03   8.59860040e-04
    9.81868288e-05]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 31
images_for_training/214
(1, 64, 64, 3)
Policy eval: 
[[  2.76923484e-10   9.10147965e-01   8.35571904e-04   3.23427700e-12
    1.06487608e-09   3.47050011e-09   1.41587209e-09   1.90051006e-16
    1.02472859e-06   3.65453502e-07   1.76311765e-08   1.15622133e-04
    2.25404938e-06   1.11002527e-10   3.13199272e-10   6.66623527e-15
    5.77843166e-14   4.54054791e-17   3.76095155e-10   2.03928776e-05
    2.89633768e-14   1.38198720e-05   4.63099582e-07   5.10598034e-21
    7.02396195e-16   3.07448728e-13   3.02151641e-12   1.01301032e-06
    7.52564517e-08   7.35577066e-09   9.85610371e-10   4.52433113e-09
    1.70041856e-12   2.46935854e-14   3.53058965e-07   2.15774520e-07
    2.70322009e-09   2.31950956e-17   1.94462109e-02   6.94146529e-02
    1.06975109e-10]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 32
images_for_training/178
(1, 64, 64, 3)
Policy eval: 
[[ 0.00746258  0.04311164  0.02441326  0.01276767  0.01073099  0.01222784
   0.01378943  0.00897353  0.02059665  0.01441637  0.04382044  0.02383813
   0.02915419  0.0195767   0.04664081  0.00663007  0.00844613  0.0123254
   0.01314691  0.03984192  0.01084814  0.06776859  0.01570672  0.00415872
   0.00670781  0.00185499  0.01817608  0.04382917  0.03295256  0.02009942
   0.00548213  0.0356731   0.02085468  0.00484483  0.00171291  0.02474666
   0.02516851  0.00477487  0.14169775  0.0944104   0.00662137]]
Action: 1.25
Enter Reward: 0
Backpropping 

Session Number 33
images_for_training/133
(1, 64, 64, 3)
Policy eval: 
[[ 0.03153199  0.05713773  0.01599178  0.01175494  0.04728195  0.05178343
   0.03778384  0.0343615   0.03959224  0.01018134  0.01767771  0.01869013
   0.03614082  0.02212538  0.04977298  0.00962471  0.00758191  0.00156174
   0.01959406  0.03338924  0.01566392  0.02115025  0.04696617  0.01042726
   0.00703763  0.00411429  0.01741324  0.0063994   0.12821989  0.00977761
   0.00713369  0.01954852  0.01386017  0.00792283  0.00897764  0.02258104
   0.02007564  0.01247492  0.01298142  0.03588279  0.01783227]]
Action: 0.65
Enter Reward: 0
Backpropping 

Session Number 34
images_for_training/185
(1, 64, 64, 3)
Policy eval: 
[[ 0.00966827  0.06163594  0.065318    0.00182123  0.01482211  0.11053305
   0.00680054  0.01096304  0.01477672  0.01363592  0.01345332  0.04069315
   0.01522596  0.00682578  0.02266138  0.01777074  0.01341879  0.00344261
   0.05784983  0.02579516  0.0054187   0.09502135  0.0260641   0.00171886
   0.0085877   0.00150254  0.05267557  0.06450402  0.01598642  0.01289616
   0.02152979  0.01424545  0.01142558  0.00207198  0.01707132  0.06288693
   0.00814496  0.00780264  0.00959907  0.01812512  0.0156102 ]]
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 35
images_for_training/217
(1, 64, 64, 3)
Policy eval: 
[[  2.65528488e-09   1.23776281e-05   1.77164765e-07   6.56063366e-13
    1.05352020e-15   6.19414059e-05   1.13439605e-11   1.56637650e-18
    1.73550251e-17   7.04050080e-07   2.44424598e-13   1.96760941e-10
    1.73564126e-06   1.87555615e-09   1.81568469e-10   1.32506965e-08
    4.18447776e-17   9.79820066e-13   7.75824827e-09   1.45655605e-07
    8.93080832e-10   9.99780476e-01   3.34612427e-09   1.59815788e-21
    3.44967067e-12   1.27252266e-18   6.36243713e-05   5.73635189e-05
    5.20137711e-08   1.26354631e-16   1.05729321e-14   6.52407195e-09
    2.38616050e-12   4.48244211e-18   5.57692889e-13   3.87494623e-08
    8.06256006e-10   1.87934608e-19   2.05920842e-05   6.83859753e-07
    2.22207865e-18]]
Action: 0.25
Enter Reward: 0
Backpropping 

Session Number 36
images_for_training/65
(1, 64, 64, 3)
Policy eval: 
[[  7.26678329e-10   3.54767438e-09   1.50254607e-06   1.53857531e-08
    4.96524481e-05   1.38306103e-04   5.71727578e-04   1.24728047e-10
    1.24756145e-04   3.26118948e-06   1.18490455e-07   1.26320356e-05
    8.57732147e-02   3.51787328e-08   4.16645780e-04   8.05021050e-10
    7.73788533e-10   2.89349032e-07   2.69224443e-09   1.18479271e-07
    3.91257610e-10   8.34572362e-04   1.83139332e-06   1.26018451e-09
    2.02627380e-05   1.62956866e-07   6.75745105e-06   1.09358170e-05
    8.68222415e-01   6.97993469e-11   1.42839551e-09   6.36316910e-09
    8.06223088e-09   4.95893389e-08   4.52055920e-10   1.44981004e-06
    8.20877403e-03   4.19190654e-11   2.90931930e-04   3.53095196e-02
    9.18292959e-12]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 37
images_for_training/150
(1, 64, 64, 3)
Policy eval: 
[[ 0.01060178  0.03264025  0.02116663  0.01845028  0.02935833  0.0578892
   0.03730287  0.01957397  0.01602835  0.04491625  0.02215716  0.02286864
   0.02344283  0.02021641  0.02966473  0.0120991   0.0116617   0.00789725
   0.03221913  0.03288384  0.03528095  0.02973011  0.05567888  0.0120248
   0.0209843   0.01321658  0.03165571  0.02099851  0.02680583  0.01251478
   0.01625843  0.0084432   0.01322661  0.04874963  0.02523716  0.01937546
   0.03107283  0.01021269  0.01388456  0.04113321  0.01047707]]
Action: 0.95
Enter Reward: 0
Backpropping 

Session Number 38
images_for_training/245
(1, 64, 64, 3)
Policy eval: 
[[  2.40547138e-06   1.42761598e-06   2.27807355e-08   2.74416623e-09
    1.72553332e-08   4.98753600e-03   2.88273753e-07   3.92373556e-09
    4.18827417e-09   2.11139544e-04   1.65004916e-08   1.47996424e-11
    3.00595573e-12   3.90926425e-06   8.40730208e-05   6.88743591e-01
    4.09092538e-09   1.60833635e-09   3.05752903e-01   3.66858082e-08
    1.73036835e-06   3.13402634e-05   1.09511529e-06   1.01708941e-12
    5.81337986e-07   2.27490552e-14   5.23743620e-05   1.36754750e-08
    6.38411777e-08   9.33562852e-14   3.03858241e-12   1.05141496e-08
    2.80185368e-08   1.73237629e-06   3.88295757e-10   6.97635727e-10
    2.08670912e-08   2.62013911e-10   1.48315876e-13   1.23510647e-04
    3.57526810e-16]]
Action: 0.7
Enter Reward: 1
Backpropping 

Session Number 39
images_for_training/211
(1, 64, 64, 3)
Policy eval: 
[[  4.49252188e-01   1.12423304e-05   1.50583879e-10   4.22442876e-18
    4.51688997e-08   9.58531600e-05   4.83290989e-08   7.23353955e-09
    2.19515075e-12   1.32241420e-15   6.20042692e-06   1.97704537e-13
    1.44673540e-09   3.05155753e-15   3.40247294e-04   7.65101415e-14
    3.60505891e-17   8.13476215e-17   8.41051433e-03   1.51190189e-11
    1.51932381e-13   1.55046771e-04   4.42951259e-10   1.89564161e-14
    2.56091859e-09   2.25116772e-15   5.20918697e-10   2.39138598e-09
    5.41681468e-01   6.38956976e-09   3.30258632e-19   9.10900307e-18
    2.63200017e-09   6.27883552e-12   2.99558073e-10   6.19314642e-06
    4.05227329e-05   6.11723844e-20   8.97767863e-13   3.69103361e-07
    5.38326154e-11]]
Action: 0.7
Enter Reward: 1
Backpropping 

Session Number 40
images_for_training/224
(1, 64, 64, 3)
Policy eval: 
[[  2.03103573e-05   8.62391153e-06   1.23076687e-08   5.62439162e-09
    1.28654530e-04   4.41491429e-05   1.42514364e-06   5.82581094e-08
    1.29244407e-10   1.53226720e-05   1.79225879e-06   5.99341521e-10
    4.27638411e-11   6.29360229e-02   2.43119178e-08   6.16023293e-16
    2.06842180e-03   4.09807126e-06   1.65892744e-09   9.13111309e-10
    1.15121677e-15   9.33771491e-01   9.21176138e-07   6.97326696e-10
    9.96204210e-04   3.53718416e-10   1.45431954e-06   3.27335624e-11
    3.69597529e-07   1.34804973e-10   3.54944858e-11   5.75641410e-11
    1.56439228e-09   4.26075673e-07   2.36680151e-08   8.40697123e-10
    1.79531645e-09   2.04091830e-11   5.62590197e-10   1.32860592e-07
    3.26769826e-11]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 41
images_for_training/105
(1, 64, 64, 3)
Policy eval: 
[[ 0.28338555  0.00831924  0.01668959  0.01300188  0.057029    0.02016982
   0.03334129  0.01076043  0.04565496  0.00830633  0.00900503  0.00680774
   0.00534162  0.00287226  0.05602142  0.00842736  0.00813801  0.01103797
   0.02735824  0.01024923  0.00408881  0.0249112   0.02494376  0.01716281
   0.00600495  0.01876713  0.01409988  0.02865699  0.02723881  0.01355578
   0.01329957  0.01252387  0.0187528   0.01412347  0.00838475  0.01719752
   0.03811412  0.01141795  0.02211446  0.01828629  0.00443801]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 42
images_for_training/120
(1, 64, 64, 3)
Policy eval: 
[[  7.15857446e-01   1.69937906e-04   2.26928131e-03   1.94192841e-03
    1.91247067e-03   1.69655576e-03   6.71131362e-04   9.65821499e-04
    1.86938283e-04   5.04835916e-04   2.98666861e-03   4.90679929e-04
    3.21973930e-05   8.97647406e-05   1.00209555e-02   1.32892700e-03
    3.81543813e-03   8.80080508e-04   3.52189713e-03   5.11924969e-04
    1.61459466e-04   9.35253687e-03   3.39886360e-02   4.25241393e-04
    4.70961593e-02   1.68343652e-02   8.19809083e-03   4.81712539e-03
    1.32813700e-03   1.51856308e-04   1.60892750e-03   5.86997376e-05
    7.67248101e-04   2.04736600e-03   4.08281945e-03   5.90009056e-03
    9.30110291e-02   3.82926111e-04   1.59946494e-02   3.20529728e-03
    7.32454064e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 43
images_for_training/91
(1, 64, 64, 3)
Policy eval: 
[[  9.99991655e-01   4.35314666e-11   3.50145938e-13   2.90305046e-20
    4.06657416e-11   8.26828561e-09   5.03864765e-14   3.34433214e-15
    8.42801740e-13   8.62203688e-18   1.91718708e-15   3.87044675e-15
    1.39255711e-15   4.33677904e-15   1.56022695e-11   7.73839441e-17
    2.92028373e-16   4.28454031e-21   2.83931809e-06   5.36130645e-12
    4.93019296e-15   7.05405482e-12   3.86764150e-08   9.71389219e-11
    1.10830982e-07   3.47000082e-08   6.10081484e-13   5.19581021e-16
    2.95342830e-12   3.65397140e-21   5.35185154e-06   7.51322393e-17
    8.38641697e-14   8.28699250e-17   1.93150565e-11   4.27432232e-13
    3.96866880e-11   5.60966746e-13   1.04683710e-12   9.93820692e-10
    5.04770333e-16]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 44
images_for_training/265
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   9.22331548e-27   8.44214539e-29   7.02630870e-37
    2.70142309e-29   1.53909844e-25   1.38105331e-28   1.85074241e-27
    8.90604915e-35   4.73304478e-31   1.41847298e-26   1.97143818e-32
    5.85057233e-32   2.50035299e-29   6.52787093e-20   2.49747801e-26
    1.67216968e-30   1.66468833e-26   6.00627810e-14   6.63420000e-31
    9.05475482e-28   3.95875777e-16   4.74050023e-19   1.31541954e-28
    8.77273990e-24   5.32214145e-21   1.76612271e-30   1.41770661e-31
    3.04105805e-30   1.40642418e-35   1.24039762e-21   2.98914535e-27
    2.50557448e-30   6.53236434e-32   8.68437265e-31   3.85847646e-24
    5.18576167e-21   1.94023283e-29   1.20484146e-30   1.64697954e-23
    2.33512448e-36]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 45
images_for_training/67
(1, 64, 64, 3)
Policy eval: 
[[  9.99999285e-01   5.37977161e-17   1.73940955e-16   4.45024923e-17
    2.39184920e-13   6.43022744e-13   6.68463169e-13   2.08837743e-17
    2.54963341e-13   9.90892915e-13   5.49557455e-10   3.24220766e-13
    8.40712890e-17   6.61892721e-16   6.98538770e-07   2.80351507e-14
    6.95424274e-10   7.28938665e-14   1.83984447e-12   1.73362911e-13
    5.24386341e-14   1.54963824e-12   7.45408513e-10   1.51088898e-11
    1.72974072e-14   1.09033538e-09   3.16777908e-13   5.53065875e-16
    1.74722129e-11   1.46827862e-13   1.62298035e-14   1.07466594e-14
    9.46392270e-12   1.71692088e-11   8.99067637e-17   2.91793603e-11
    9.28435714e-13   1.76974310e-15   2.47793305e-14   6.78546490e-15
    7.37821783e-12]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 46
images_for_training/17
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   1.75189031e-23   1.40999937e-16   1.32490408e-18
    4.41074836e-20   2.21294337e-14   7.63925646e-19   1.08640246e-20
    5.18729046e-19   1.21779277e-16   1.94289605e-17   3.16282499e-24
    2.78894957e-23   2.87663018e-19   1.07238461e-16   6.63439228e-19
    1.06457350e-19   5.60089197e-10   5.53122977e-13   9.86773428e-19
    4.56054947e-18   4.93368454e-12   1.03287867e-09   1.01823286e-18
    3.99139068e-08   5.97369376e-14   2.07685174e-13   2.06139007e-16
    4.35838826e-24   4.20874534e-22   2.39892233e-14   1.57570330e-20
    5.71845346e-22   6.84590443e-19   5.57218174e-19   2.98260270e-15
    1.90796781e-10   6.71253836e-21   4.51045923e-19   6.77950941e-14
    1.75132233e-23]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 47
images_for_training/60
(1, 64, 64, 3)
Policy eval: 
[[  9.99997735e-01   4.97731314e-08   4.22020613e-11   1.60205644e-08
    3.21417858e-11   7.88586085e-10   8.76956147e-12   1.37862172e-12
    6.99947655e-10   1.27005684e-10   8.22515775e-13   9.09678996e-15
    1.51406481e-12   2.37775966e-12   2.03696782e-10   4.06436973e-09
    6.15226895e-07   3.40372197e-09   2.93139490e-09   9.96729609e-17
    2.42151416e-12   4.40317893e-10   1.30903572e-07   4.75073214e-13
    4.09496785e-12   2.26562866e-10   1.39336362e-06   6.04673700e-10
    1.62216472e-13   9.52127832e-17   1.16676641e-10   1.17452255e-11
    1.34275473e-11   2.85731985e-12   1.02082830e-11   8.48023658e-16
    1.56332702e-09   1.76636219e-14   1.33475601e-13   7.27668370e-09
    1.35016163e-18]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 48
images_for_training/196
(1, 64, 64, 3)
Policy eval: 
[[  9.73423898e-01   3.16533296e-05   1.13054900e-03   4.61839285e-04
    1.86101708e-03   6.55293872e-04   7.82634364e-04   3.18098719e-05
    5.11168083e-03   9.94750299e-05   6.95685230e-05   4.50239258e-06
    1.04333130e-05   8.45193426e-08   5.36687905e-04   3.28562637e-05
    8.59151551e-05   7.25962163e-05   5.64502552e-04   6.00426893e-06
    9.22363768e-07   3.26636899e-03   2.58658803e-03   3.78512486e-04
    4.31020919e-04   3.65908607e-03   1.89928120e-04   3.51446324e-05
    3.25821282e-04   5.46804149e-05   6.91050198e-04   2.32060447e-05
    4.37677409e-05   1.33851454e-05   1.75237260e-03   4.10834145e-05
    5.64450829e-06   6.15470053e-05   6.69121364e-05   1.37598370e-03
    2.40312347e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 49
images_for_training/181
(1, 64, 64, 3)
Policy eval: 
[[  9.91639674e-01   1.29630294e-04   3.07850460e-05   5.04619384e-05
    3.49438487e-04   1.69446197e-04   7.56826921e-06   2.81051343e-05
    2.48557015e-04   3.48405942e-04   5.57252279e-05   4.43758945e-05
    5.81383065e-05   1.17470947e-04   5.57131425e-04   3.49397806e-06
    1.09241239e-03   2.98477680e-05   8.93258140e-04   1.82939693e-04
    1.48597974e-05   3.42613726e-04   2.02324751e-04   1.76097557e-04
    3.80284764e-04   1.44743986e-04   7.18815543e-04   1.26600899e-05
    3.64709886e-05   2.01635430e-05   5.74822130e-04   6.87325664e-05
    1.28913030e-04   3.27793932e-05   2.07748963e-05   8.90946103e-05
    2.60313391e-04   2.83971603e-05   3.84346604e-05   6.61016733e-04
    1.07091246e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 50
images_for_training/240
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   1.68517621e-29   1.59058915e-21   4.89342110e-28
    0.00000000e+00   2.92296510e-28   5.57351841e-20   5.52093472e-27
    2.72728143e-19   6.13329845e-29   1.38625911e-26   2.67561204e-27
    1.68571342e-25   7.59979197e-32   1.93115333e-11   3.24574686e-22
    4.16182061e-23   2.31442475e-22   6.21032593e-16   1.01300059e-22
    2.19135361e-22   2.46852142e-27   5.79115116e-25   1.31000830e-25
    2.24540579e-25   4.64169888e-14   1.40239370e-15   4.94606651e-34
    4.35297957e-13   1.77749533e-18   3.73754165e-30   4.70485721e-15
    5.27509611e-25   1.23727891e-28   1.40417263e-35   5.53083686e-29
    1.07994997e-17   3.44211900e-31   1.63743455e-28   3.81143814e-12
    6.60072710e-31]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 51
images_for_training/100
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   3.45400978e-16   8.50048930e-18   5.19928146e-17
    5.08776269e-16   8.20448851e-18   2.45116644e-16   8.69812773e-17
    2.28620307e-16   4.78192027e-15   9.52750352e-19   1.99627336e-19
    3.31879402e-20   1.92353501e-20   2.21701493e-15   3.53980239e-18
    1.35994018e-17   6.45341886e-20   2.76346220e-13   8.13352841e-19
    4.23965405e-21   3.93860378e-12   6.63574490e-12   1.94846826e-19
    4.80772713e-12   1.13525994e-11   8.76679185e-15   3.61188770e-20
    1.84805682e-17   2.86232492e-18   7.07699853e-19   1.05439839e-16
    1.71428981e-20   1.17433111e-21   1.49058066e-12   2.45099432e-19
    1.30668041e-16   7.38006435e-24   5.05818295e-20   7.47589664e-12
    3.93706513e-19]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 52
images_for_training/175
(1, 64, 64, 3)
Policy eval: 
[[  9.91107821e-01   5.16668342e-06   3.19857486e-06   2.65764629e-06
    3.79387871e-04   3.45568871e-04   2.95281061e-05   8.80012667e-05
    1.11399444e-04   5.11618509e-06   7.34624846e-05   1.94661116e-04
    1.82840165e-06   1.26648411e-05   1.94411972e-04   3.71026545e-05
    2.53216767e-05   3.55315206e-05   2.75947241e-04   2.75006041e-05
    1.88431144e-07   9.31955874e-04   1.39119758e-04   3.61602614e-03
    2.63829370e-05   2.80495995e-04   5.11310762e-04   1.79087619e-05
    3.83012093e-06   3.86782375e-07   8.93198070e-04   6.83737369e-07
    2.20004822e-05   3.18788152e-05   2.92859855e-04   7.24524762e-06
    7.16571833e-07   2.77768122e-05   5.94067124e-08   2.37599786e-04
    2.15470823e-06]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 53
images_for_training/119
(1, 64, 64, 3)
Policy eval: 
[[  6.14728451e-01   4.10598796e-03   1.73642562e-04   5.79730549e-04
    8.22370348e-04   4.35328780e-04   6.92862726e-04   1.49604259e-03
    6.63764833e-04   7.17232237e-03   1.16355615e-04   3.49267176e-03
    1.32405388e-04   1.34422062e-05   8.83388566e-04   2.91884444e-05
    6.61531521e-06   5.65252139e-06   2.92636603e-02   8.28325283e-04
    3.89768538e-05   4.53229040e-05   2.76761323e-01   1.54991096e-04
    5.00890352e-02   2.96175363e-03   1.72475047e-04   2.30555670e-05
    1.16058392e-04   1.72959000e-04   3.18000297e-04   8.82094537e-06
    1.47331211e-05   1.21760968e-05   2.29007821e-03   2.75747107e-06
    5.69983851e-04   5.82338471e-05   5.46971307e-07   5.22463524e-04
    2.39343844e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 54
images_for_training/294
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   2.70673402e-15   1.61935825e-28   7.24094592e-22
    3.83153324e-31   7.61840400e-23   5.66224587e-25   2.65608820e-26
    4.89684569e-25   1.02374973e-22   1.33640358e-22   2.43285960e-25
    6.91810405e-25   1.52243221e-26   2.90981805e-11   2.67432629e-27
    2.59849635e-08   5.55774647e-34   1.84049803e-20   3.28743453e-26
    8.58918676e-32   6.29409936e-12   2.09228468e-11   3.01906048e-16
    1.16621660e-26   2.16668523e-20   5.06008430e-16   8.11914626e-26
    7.13863406e-25   1.86960570e-17   5.33562300e-12   4.53911432e-18
    1.51040477e-35   4.48343115e-16   6.43442689e-17   2.79853045e-23
    8.35586109e-22   3.43268242e-36   0.00000000e+00   1.62238637e-15
    6.14098978e-25]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 55
images_for_training/109
(1, 64, 64, 3)
Policy eval: 
[[  4.02314998e-02   4.29018913e-03   5.71055058e-03   2.78347798e-05
    2.37243057e-05   1.27952590e-04   1.38133194e-03   7.43138371e-05
    2.38936559e-06   3.67627808e-06   1.30623637e-03   9.61157605e-02
    3.50823348e-06   3.09108987e-06   4.02636640e-02   1.42399955e-03
    1.45018714e-06   4.74519824e-04   6.12164676e-01   1.57267938e-03
    4.10912025e-06   2.39007804e-03   1.44893760e-02   1.96717530e-02
    1.40812099e-01   1.99128734e-03   9.71640475e-05   4.71875363e-04
    7.07301206e-06   8.50043671e-06   1.03144103e-03   6.58246572e-05
    2.36207736e-04   4.16498864e-03   5.06136660e-03   3.03419506e-06
    4.16154228e-03   8.64022659e-05   1.08445555e-07   4.21847872e-05
    6.71632051e-07]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 56
images_for_training/204
(1, 64, 64, 3)
Policy eval: 
[[  9.99771893e-01   1.06997668e-12   8.75218696e-17   3.17173979e-19
    7.59901115e-33   2.64612671e-20   4.83253419e-16   7.75731979e-10
    4.20571382e-15   8.88122839e-11   8.52734613e-20   2.09492103e-34
    1.49637862e-27   5.63922690e-18   1.79801881e-16   1.13309688e-16
    1.70219455e-15   3.08573639e-29   2.99305907e-06   4.84737352e-18
    4.91207084e-28   1.55552626e-10   2.27847336e-16   2.56770242e-18
    1.41864714e-11   8.07615808e-10   2.25172742e-04   3.23252830e-37
    9.27349703e-18   3.12689512e-18   8.56751673e-20   5.95260063e-10
    6.37057735e-13   3.17035538e-15   1.88048971e-21   5.34772018e-31
    1.78938192e-18   2.80304466e-28   3.92124225e-18   4.06150669e-09
    1.30720947e-24]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 57
images_for_training/292
(1, 64, 64, 3)
Policy eval: 
[[  9.99983191e-01   3.75984974e-27   7.16371512e-34   8.81091075e-20
    2.06965156e-09   7.31825506e-19   1.09564463e-12   5.63119729e-25
    2.60227290e-22   4.36909613e-19   2.22658579e-25   2.16737401e-22
    1.96534952e-28   1.05157374e-22   3.22569491e-08   1.28400484e-21
    3.56558244e-28   9.98907743e-24   1.67213093e-05   0.00000000e+00
    2.96249191e-16   7.57783302e-18   8.49373802e-17   9.85943859e-27
    1.40009406e-21   4.36784657e-19   2.53823895e-09   1.63410780e-26
    5.68510370e-21   1.50143586e-34   8.65003436e-25   2.78087480e-28
    3.05231590e-22   1.19365736e-25   4.00937566e-31   7.24673780e-22
    3.11146975e-24   2.06866880e-28   8.61389619e-36   1.54742867e-22
    8.03934810e-32]]
Action: 0.7
Enter Reward: 1
Backpropping 

Session Number 58
images_for_training/204
(1, 64, 64, 3)
Policy eval: 
[[  9.99905944e-01   1.60251045e-28   2.26098590e-30   5.13749547e-26
    4.55077000e-26   0.00000000e+00   9.82125048e-20   1.70948191e-32
    1.12180918e-21   3.72800320e-24   0.00000000e+00   0.00000000e+00
    0.00000000e+00   4.59242627e-36   1.76896280e-16   6.33552429e-32
    3.00693003e-14   1.94779071e-38   9.40376849e-05   3.59027857e-38
    0.00000000e+00   6.79059987e-24   1.61418510e-14   5.07951460e-21
    3.34392390e-19   3.63456432e-10   4.65543240e-13   0.00000000e+00
    2.06470012e-29   5.93960690e-25   7.63377941e-14   2.21257597e-28
    1.01971631e-31   8.33913337e-27   9.51548833e-20   1.25216920e-38
    3.75850746e-22   8.27194904e-31   0.00000000e+00   4.56203188e-19
    0.00000000e+00]]
Action: 0.9
Enter Reward: 1
Backpropping 

Session Number 59
images_for_training/253
(1, 64, 64, 3)
Policy eval: 
[[  2.15803417e-11   8.61056864e-19   6.90399888e-18   1.80193194e-08
    5.44684413e-18   2.11581461e-14   5.13283487e-23   6.19528029e-15
    1.92535234e-16   6.20921907e-14   7.10176107e-22   9.13031221e-33
    1.40463537e-25   4.23706984e-20   4.26349561e-06   5.47070127e-28
    9.98456359e-01   6.69363763e-15   1.53892220e-03   2.20879255e-23
    9.08943311e-28   4.17443961e-11   1.44381998e-19   2.89484835e-27
    3.76213309e-14   1.46410369e-18   4.71405713e-07   3.69954027e-30
    1.20967229e-23   5.44768792e-21   2.92990213e-25   6.66429208e-21
    5.44346683e-30   2.88756830e-35   7.93399504e-28   1.47121357e-26
    6.39134015e-12   3.51096087e-38   2.48518361e-31   2.04340501e-25
    5.91680615e-32]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 60
images_for_training/143
(1, 64, 64, 3)
Policy eval: 
[[  7.87108660e-01   2.91020591e-02   1.56116294e-04   4.53622342e-04
    1.83712319e-03   2.76967221e-05   4.03176382e-05   8.85707050e-05
    4.34897235e-03   4.41202568e-03   5.04857802e-04   2.31054574e-02
    1.26447876e-05   1.67751368e-05   6.87972526e-04   7.07942876e-04
    1.16637698e-03   6.41965773e-04   1.37043307e-02   2.49521196e-04
    2.44763651e-04   1.23541337e-03   1.71763741e-03   8.58781787e-05
    2.58764420e-02   1.48821319e-03   4.99235243e-02   1.53017265e-03
    9.71675559e-04   2.28572302e-04   1.12863639e-02   6.70015346e-04
    4.36750939e-04   2.23899540e-03   6.34260708e-03   9.78672779e-06
    2.11043237e-03   3.24537723e-05   1.64624944e-05   2.51748543e-02
    5.94541689e-06]]
Action: 0.9
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 61
images_for_training/190
(1, 64, 64, 3)
Policy eval: 
[[  3.45080793e-02   6.38756081e-02   4.32742527e-03   1.12434663e-02
    9.65389889e-04   4.12210310e-03   4.29609604e-03   6.87126955e-03
    7.21053965e-03   3.42147388e-02   8.32385570e-03   1.14560891e-02
    1.08396430e-02   8.91885720e-04   9.41849500e-02   6.41333917e-03
    3.14662278e-01   1.26969656e-02   3.80968563e-02   2.08060769e-03
    2.38750200e-03   5.78686818e-02   3.60168889e-02   6.88549317e-03
    1.21892961e-02   4.82580811e-03   1.57372057e-02   1.66046601e-02
    3.17967217e-03   4.87418193e-03   1.68466419e-02   3.72417318e-03
    1.18562048e-02   1.78308003e-02   1.31129660e-02   2.97268998e-04
    9.42219272e-02   3.86446645e-03   2.61431123e-04   5.83325047e-03
    3.00279295e-04]]
Action: 1.45
Enter Reward: 0
Backpropping 

Session Number 62
images_for_training/88
(1, 64, 64, 3)
Policy eval: 
[[  2.36972155e-05   5.55925314e-13   6.84252785e-20   1.86501302e-06
    6.45760631e-18   1.73915716e-16   4.80717333e-08   2.11835744e-13
    3.44779370e-12   1.10460842e-10   1.06204155e-19   1.71781379e-16
    5.33770729e-15   1.39049276e-14   1.68643322e-09   1.55683563e-10
    4.11328172e-09   2.29064443e-16   1.00184996e-02   1.65561223e-18
    6.97302470e-17   1.16273803e-10   9.89861846e-01   1.52305089e-13
    7.06977055e-09   2.52114085e-09   6.15091153e-07   5.74800735e-18
    5.20929328e-13   2.69006115e-19   6.53542932e-12   3.55217557e-11
    2.44397513e-16   7.84101110e-14   3.37046476e-19   4.80835437e-20
    9.34417403e-05   2.75263514e-12   1.53262955e-13   1.25352555e-13
    8.45900847e-19]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 63
images_for_training/22
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   4.82761134e-16   8.10648684e-19   3.05451992e-16
    6.46502019e-10   7.08673885e-15   3.38378683e-20   3.16957744e-16
    9.36878145e-11   4.44382378e-13   3.62066880e-16   1.24759869e-10
    1.78362275e-17   2.05580505e-25   2.30806650e-12   3.83154771e-16
    5.97261672e-16   1.49607387e-21   1.51994411e-13   6.72708314e-18
    9.19984783e-11   1.88339449e-15   4.80103479e-13   1.91486430e-15
    1.16899307e-12   6.10197400e-16   8.68887295e-10   1.22119217e-18
    3.17740693e-14   1.99733115e-20   1.61600529e-12   2.41938500e-17
    6.14306409e-21   7.84297584e-18   5.69854544e-16   4.47167273e-19
    2.31449305e-24   9.10908455e-19   1.95913225e-28   5.80419908e-14
    1.45838841e-20]]
Action: 1.1
Enter Reward: 1
Backpropping 

Session Number 64
images_for_training/116
(1, 64, 64, 3)
Policy eval: 
[[  3.67608041e-01   1.53048662e-04   2.28092745e-02   3.55055742e-03
    1.58916417e-04   1.63201790e-03   1.02773095e-02   2.40983125e-02
    2.77102436e-03   9.71334230e-04   9.22943000e-05   2.70335091e-04
    1.03441474e-03   4.15428913e-05   2.67895926e-02   7.64881074e-02
    1.01193204e-03   2.93448189e-04   3.98791246e-02   3.05559952e-04
    5.42777474e-04   7.10864644e-03   3.32043648e-01   3.54741327e-03
    6.28694193e-03   3.94848958e-02   1.99689064e-03   5.17759181e-05
    5.03463030e-04   3.31907620e-04   1.87509751e-03   2.26313918e-04
    9.41543747e-03   1.99289454e-04   1.36989623e-03   1.84469201e-04
    4.15248331e-03   2.33613746e-03   1.95427565e-03   5.96658280e-03
    1.85607307e-04]]
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 65
images_for_training/238
(1, 64, 64, 3)
Policy eval: 
[[  3.16866130e-01   1.14754613e-07   3.39682060e-08   3.28311359e-07
    5.29173981e-13   3.03119162e-12   1.61805443e-12   4.19987742e-08
    1.08504577e-11   1.20737944e-08   8.24985844e-11   6.40246728e-17
    6.54862824e-16   2.73536704e-09   5.19021562e-11   8.75673069e-13
    1.44089790e-06   3.17089074e-13   1.33040501e-07   3.56125324e-10
    9.19957317e-15   3.80045909e-04   3.01226457e-08   2.75163430e-14
    1.56856021e-11   1.01956188e-09   1.15534457e-11   1.97761441e-15
    4.77155153e-13   8.52899626e-11   4.89953322e-09   7.26845125e-13
    1.77902029e-06   5.19271278e-14   1.28924954e-10   4.34426556e-13
    3.42112713e-07   1.68178671e-18   1.43682353e-12   6.82749510e-01
    5.37975854e-21]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 66
images_for_training/189
(1, 64, 64, 3)
Policy eval: 
[[ 0.20788562  0.02697633  0.0046251   0.01629678  0.00949448  0.0186559
   0.00731039  0.00414779  0.01882747  0.01345877  0.02625627  0.0143676
   0.01539891  0.00482829  0.03231188  0.01486518  0.0220583   0.01118969
   0.08007368  0.00666449  0.00652944  0.09464737  0.06323118  0.00687459
   0.00651701  0.01029009  0.05671077  0.00505464  0.00476798  0.01048926
   0.03080901  0.00367819  0.07553954  0.00572555  0.02228396  0.00469088
   0.0081415   0.0056006   0.00237754  0.0172538   0.00309413]]
Action: 1.8
Enter Reward: 1
Backpropping 

Session Number 67
images_for_training/32
(1, 64, 64, 3)
Policy eval: 
[[  7.02246487e-01   1.09748403e-02   2.35499727e-04   3.86215840e-03
    4.48010505e-05   1.42582081e-04   5.03117405e-03   6.07521133e-03
    1.68164249e-03   5.84081886e-03   1.85802986e-03   4.58208960e-05
    8.54034151e-04   2.78977444e-04   2.95604207e-02   5.89986425e-03
    1.91577373e-03   1.17253956e-04   7.13363364e-02   2.53607373e-04
    6.32326526e-04   4.73818835e-03   3.16830948e-02   1.73351855e-03
    5.62267229e-02   3.28596984e-03   1.55964820e-03   1.78945644e-04
    6.09641243e-03   4.53059009e-04   2.85444688e-03   3.02301138e-04
    1.41169131e-02   2.65745330e-03   8.73984769e-03   1.40500109e-04
    1.81126327e-03   1.49917684e-03   1.96023728e-03   9.77899320e-03
    1.29568472e-03]]
Action: 0.3
Enter Reward: 0
Backpropping 

Session Number 68
images_for_training/112
(1, 64, 64, 3)
Policy eval: 
[[ 0.02968806  0.02946213  0.03251707  0.02758026  0.02269075  0.02362877
   0.02315587  0.02291618  0.02275407  0.02221237  0.02253312  0.02695245
   0.02027006  0.02073929  0.0220011   0.02445149  0.02248852  0.02380691
   0.02858984  0.02226357  0.01948268  0.02914473  0.03155038  0.02705401
   0.0273594   0.03071271  0.02777666  0.01989212  0.02251604  0.02169668
   0.02326262  0.01976411  0.02332598  0.0206365   0.03088742  0.01947753
   0.02377425  0.02114327  0.02314997  0.02669859  0.01999245]]
Action: 0.6
Enter Reward: 0
Backpropping 

Session Number 69
images_for_training/251
(1, 64, 64, 3)
Policy eval: 
[[  4.09461528e-01   8.93932208e-02   3.59046622e-03   1.48909539e-02
    4.29905165e-04   7.68523291e-03   1.24927424e-02   9.95464157e-04
    2.08400954e-02   6.89371228e-02   6.02534786e-03   1.70438420e-02
    1.22650748e-03   2.22432218e-03   2.73904260e-02   9.05180583e-04
    2.49272157e-02   8.72462580e-04   6.07283413e-02   4.67149913e-03
    2.83557514e-04   9.03662294e-03   3.52952145e-02   1.74145475e-02
    1.34617847e-03   9.81785823e-04   1.41632687e-02   1.03373535e-03
    8.26763734e-03   6.40847348e-03   1.07355677e-02   5.59052965e-03
    8.78312290e-02   2.44787475e-03   7.05103576e-03   1.59104064e-04
    8.02855764e-04   5.74641163e-03   1.15537981e-03   8.68362561e-03
    8.33454076e-04]]
Action: 1.05
Enter Reward: 1
Backpropping 

Session Number 70
images_for_training/274
(1, 64, 64, 3)
Policy eval: 
[[  5.71208715e-01   3.02550137e-01   1.08370045e-03   1.14652887e-03
    3.47130917e-05   1.64746496e-04   2.96636601e-04   1.28318334e-03
    5.89228701e-04   9.22162784e-04   9.25384986e-04   5.48359531e-04
    8.49440228e-03   5.88170136e-04   2.73405714e-03   3.85013758e-04
    9.81990620e-03   2.92981812e-03   5.61563240e-04   8.01959482e-04
    7.25217469e-05   2.78891511e-02   1.73220178e-03   1.77487513e-04
    4.33967030e-03   8.67604685e-04   9.72388720e-04   3.19144427e-04
    1.91122585e-03   1.62294149e-04   5.92300610e-04   5.31793758e-03
    7.19988078e-04   5.21828304e-04   5.71361219e-04   3.23282147e-05
    6.74475334e-04   3.71047972e-05   1.13927526e-03   4.45270985e-02
    3.54244927e-04]]
Action: 1.1
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 71
images_for_training/124
(1, 64, 64, 3)
Policy eval: 
[[ 0.06677622  0.06166388  0.03014241  0.0283631   0.01896437  0.01946187
   0.02200206  0.0191617   0.01855182  0.01789102  0.0236154   0.01990112
   0.02935989  0.01668389  0.02303126  0.03293796  0.01551288  0.01639764
   0.03631516  0.02447328  0.02251692  0.04024112  0.02779192  0.02187837
   0.02921883  0.01800204  0.02790733  0.01815443  0.01795702  0.02193655
   0.0235846   0.02066268  0.01631994  0.01345471  0.02703837  0.01273588
   0.02502881  0.0181385   0.01695793  0.02235128  0.01691583]]
Action: 1.25
Enter Reward: 1
Backpropping 

Session Number 72
images_for_training/188
(1, 64, 64, 3)
Policy eval: 
[[ 0.03564693  0.04577017  0.02600826  0.02618146  0.02095363  0.02531175
   0.02639771  0.02317264  0.02610904  0.02324836  0.02444358  0.0268311
   0.02199036  0.02245387  0.02298659  0.02233613  0.0242908   0.01569133
   0.02321134  0.02347901  0.02731916  0.02443411  0.03633697  0.02188585
   0.02854723  0.01904618  0.01831885  0.01683351  0.01868665  0.03024204
   0.02442327  0.01635446  0.02518249  0.02477232  0.02815018  0.01830156
   0.0281931   0.021535    0.0167314   0.02853767  0.01965383]]
Action: 0.4
Enter Reward: 0
Backpropping 

Session Number 73
images_for_training/11
(1, 64, 64, 3)
Policy eval: 
[[ 0.05690375  0.06133797  0.02013322  0.04125942  0.01784658  0.02537507
   0.0363662   0.0366668   0.03338039  0.03490303  0.03770728  0.02597881
   0.0107805   0.01497347  0.0321011   0.01998171  0.0299355   0.01167678
   0.02546109  0.01989286  0.02925762  0.01719123  0.04662823  0.02665809
   0.02612365  0.01619618  0.00967327  0.01035728  0.01601255  0.01803118
   0.01501624  0.01146641  0.01614803  0.0185587   0.02555806  0.0109185
   0.01808271  0.01602403  0.00729472  0.03183504  0.0203067 ]]
Action: 0.8
Enter Reward: 1
Backpropping 

Session Number 74
images_for_training/198
(1, 64, 64, 3)
Policy eval: 
[[ 0.0372626   0.05500735  0.0173591   0.0236141   0.02971948  0.02915067
   0.01826787  0.02116304  0.02468811  0.02728584  0.03062514  0.02761927
   0.02483886  0.02142374  0.0329471   0.01702604  0.01871712  0.01736143
   0.02375106  0.0256421   0.03993412  0.02849705  0.03496697  0.02268246
   0.02303883  0.01932313  0.02811515  0.01848098  0.02380847  0.01298728
   0.03037067  0.02348422  0.02122095  0.02003801  0.01920493  0.01452508
   0.01774736  0.01776501  0.0188839   0.02249613  0.01895921]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 75
images_for_training/144
(1, 64, 64, 3)
Policy eval: 
[[ 0.0500785   0.1160064   0.02848582  0.03633051  0.01287     0.01605674
   0.0181513   0.0172978   0.03032873  0.0242053   0.02735521  0.01817917
   0.02706681  0.02539502  0.02927812  0.02626096  0.02629656  0.01627905
   0.02949305  0.01660622  0.01106633  0.03361055  0.0262637   0.01298545
   0.02279927  0.01197037  0.02059061  0.01205884  0.01449703  0.04261896
   0.01520719  0.01145156  0.01613321  0.0219069   0.0275682   0.00930453
   0.02729931  0.01516867  0.01084362  0.02923145  0.01540284]]
Action: 2.0
Enter Reward: 1
Backpropping 

Session Number 76
images_for_training/222
(1, 64, 64, 3)
Policy eval: 
[[  3.71702403e-01   3.97133797e-01   4.70353029e-04   3.88032794e-02
    3.86730884e-04   1.08494412e-03   6.58418430e-05   1.44996913e-03
    1.50129991e-03   1.79637014e-03   1.53987901e-03   5.58859378e-04
    3.77935321e-05   6.55619521e-03   5.05946353e-02   1.36253759e-04
    6.83941459e-03   2.83982517e-04   8.21825862e-02   2.35000672e-03
    1.61816156e-03   2.81734113e-03   9.42242332e-03   4.71793144e-04
    6.55173266e-04   4.72144457e-04   2.50817393e-05   3.22677843e-05
    1.17035423e-04   1.37848116e-03   1.22334494e-03   4.39782780e-05
    4.88100282e-04   3.57724912e-03   1.55659753e-03   1.55920188e-05
    5.91974519e-03   2.67007340e-06   1.17321888e-05   4.66754194e-03
    8.86517410e-06]]
Action: 0.75
Enter Reward: 1
Backpropping 

Session Number 77
images_for_training/102
(1, 64, 64, 3)
Policy eval: 
[[ 0.04500904  0.06982794  0.03677327  0.02327505  0.02963091  0.02932603
   0.02807399  0.0310437   0.02380866  0.02571896  0.02907768  0.01625515
   0.01864162  0.01650401  0.01934312  0.03930925  0.01600345  0.01223621
   0.03209925  0.02203033  0.02707242  0.02694107  0.0528924   0.02317424
   0.02798502  0.01751091  0.01441372  0.01137829  0.01181987  0.01472802
   0.02287989  0.01055302  0.02102811  0.01879185  0.02506346  0.01489098
   0.01644254  0.02294686  0.01628791  0.02334952  0.01586231]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 78
images_for_training/266
(1, 64, 64, 3)
Policy eval: 
[[  4.69214797e-01   1.79401830e-01   7.43151233e-02   1.54975825e-03
    2.07674282e-04   1.67158525e-02   1.38417963e-04   3.03060049e-04
    1.90402325e-02   1.44994317e-03   4.99455584e-03   1.58423733e-03
    1.25260281e-04   3.83194245e-04   1.92023590e-02   8.13369360e-03
    1.76550145e-03   3.33712832e-03   3.40602198e-03   7.21828127e-03
    2.83474233e-02   1.21990847e-03   1.52186966e-02   5.51307399e-04
    6.24130759e-03   2.30674609e-03   1.88724126e-03   4.14136244e-04
    1.75289693e-04   9.81428102e-03   5.29832067e-03   1.22786919e-03
    3.66572116e-04   2.75757955e-03   2.05347897e-03   2.98607250e-04
    1.04827754e-01   1.57255345e-04   1.96093041e-03   1.81543990e-03
    5.72851975e-04]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 79
images_for_training/274
(1, 64, 64, 3)
Policy eval: 
[[  9.04438257e-01   7.62671605e-02   1.12361595e-04   8.34327802e-05
    3.24779762e-06   4.55692607e-05   4.99798625e-06   1.21270052e-04
    1.24917249e-04   3.90996465e-05   7.75931869e-04   2.79026339e-04
    9.93853519e-06   1.90905412e-04   6.97724579e-04   1.85934908e-03
    2.73412326e-03   1.22356296e-05   2.65295297e-04   1.72408496e-03
    3.11719312e-04   2.12363061e-03   1.47681322e-03   4.56098496e-06
    1.21905783e-03   1.93175836e-03   5.52283309e-04   5.14676867e-06
    4.17943011e-05   2.37978864e-04   3.51808740e-05   3.17861486e-05
    3.96530086e-04   1.28241618e-05   3.43612075e-04   4.00942008e-06
    1.12168709e-05   2.39477704e-05   2.68580097e-05   1.28652295e-03
    1.33825204e-04]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 80
images_for_training/137
(1, 64, 64, 3)
Policy eval: 
[[ 0.03600369  0.03912214  0.02369851  0.02689601  0.02295491  0.02607479
   0.01993894  0.02265134  0.02540351  0.02261806  0.02234988  0.02861523
   0.02217504  0.02151331  0.02601242  0.02040253  0.02270392  0.02123242
   0.02400761  0.02703057  0.02847375  0.02571995  0.03229225  0.02485789
   0.02271103  0.02594469  0.02032844  0.02208998  0.0226327   0.02013914
   0.02340024  0.02239582  0.02274106  0.02400058  0.03198262  0.01856404
   0.02405299  0.01562881  0.02310919  0.02752129  0.02000864]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 81
images_for_training/257
(1, 64, 64, 3)
Policy eval: 
[[  9.43228364e-01   4.98517305e-02   5.14825515e-05   3.61948420e-04
    1.34670729e-04   1.55416346e-05   1.84470155e-05   2.37330587e-05
    9.50360089e-04   2.02674437e-05   5.95521196e-05   1.83377033e-05
    5.30473597e-04   2.79044107e-05   6.20716892e-04   1.48735680e-05
    2.91958248e-04   1.39368258e-05   9.54406787e-05   1.36555118e-05
    5.80872766e-05   8.62187808e-05   7.98088004e-05   8.47144838e-06
    1.52455890e-04   4.00660647e-05   2.21133247e-04   4.38570942e-06
    1.37584982e-04   2.00366703e-05   4.68230792e-05   1.24294647e-05
    2.36826281e-06   2.23559641e-06   6.79066361e-05   2.66435418e-05
    2.61031208e-03   1.14661145e-06   6.66455844e-06   6.09618000e-05
    1.06758544e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 82
images_for_training/78
(1, 64, 64, 3)
Policy eval: 
[[ 0.27076182  0.09525865  0.01848625  0.0169551   0.00363643  0.00251973
   0.01160415  0.00613377  0.03878479  0.05254344  0.00180387  0.01831973
   0.0056461   0.00697337  0.03315162  0.00319825  0.0125389   0.00431333
   0.0258955   0.00717416  0.00441904  0.01224772  0.07006048  0.00984942
   0.00321322  0.0150263   0.0270564   0.00132174  0.01275487  0.00327811
   0.00953824  0.00322522  0.03127847  0.01835768  0.00907637  0.00998379
   0.02504573  0.00214904  0.00170887  0.09127825  0.00343205]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 83
images_for_training/126
(1, 64, 64, 3)
Policy eval: 
[[ 0.07133227  0.08532199  0.03712322  0.03131811  0.02925812  0.02985884
   0.01408883  0.02094103  0.04264443  0.028915    0.04545664  0.03248302
   0.01595367  0.01257278  0.02089578  0.02208626  0.02511264  0.01345425
   0.01835737  0.01787098  0.02271998  0.01608679  0.02893073  0.02039479
   0.01791475  0.01577279  0.01564571  0.01249971  0.01238406  0.01917673
   0.02618432  0.01339874  0.02324301  0.01118397  0.03063794  0.01142716
   0.01729783  0.01719556  0.01714017  0.0206335   0.01508655]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 84
images_for_training/215
(1, 64, 64, 3)
Policy eval: 
[[  8.95037651e-01   4.50763665e-02   1.71388942e-03   1.68160059e-05
    2.14572836e-04   1.59804930e-03   3.54958174e-04   7.10586610e-04
    7.03235215e-04   6.47225708e-04   3.65045434e-03   3.17905826e-04
    1.46790131e-04   3.54561489e-04   1.18295080e-03   7.41022814e-05
    2.63438607e-03   7.97781977e-05   1.41897320e-03   6.43004023e-04
    4.40006005e-03   3.56907956e-04   8.13689921e-03   4.48222680e-04
    6.53544150e-04   5.11271879e-04   5.54517959e-04   3.49090493e-04
    1.70369120e-03   3.41232051e-03   2.30139936e-03   5.61808352e-04
    3.80168459e-03   5.20459190e-03   1.51902868e-03   1.09273987e-03
    4.01210244e-04   3.80460231e-04   7.93850631e-05   7.04482151e-03
    5.10030484e-04]]
Action: 1.2
Enter Reward: 0
Backpropping 

Session Number 85
images_for_training/160
(1, 64, 64, 3)
Policy eval: 
[[ 0.03577618  0.02840606  0.02815868  0.02354631  0.0234175   0.02703641
   0.02529881  0.02031684  0.03039019  0.02207548  0.02351771  0.02602298
   0.02606467  0.01878164  0.02723561  0.02490071  0.02161521  0.02336244
   0.02394022  0.02248237  0.02140571  0.0245387   0.02806592  0.02485522
   0.03146911  0.0259989   0.02913227  0.0203092   0.02245108  0.02008536
   0.02136459  0.02245161  0.02229103  0.02102952  0.02799883  0.01811254
   0.02512502  0.02120522  0.02423718  0.02212647  0.02340052]]
Action: 0.3
Enter Reward: 0
Backpropping 

Session Number 86
images_for_training/240
(1, 64, 64, 3)
Policy eval: 
[[  9.14920807e-01   3.76215577e-02   9.88300052e-03   6.81038888e-04
    2.20229311e-04   4.69464896e-04   3.26181471e-05   2.09647333e-05
    3.37625528e-03   1.80779037e-03   1.59333635e-03   1.26320476e-04
    2.75551400e-04   9.88757256e-06   1.11552514e-02   3.81845352e-03
    4.44899808e-04   4.93169318e-05   1.54446549e-04   4.85986052e-03
    1.74514961e-03   4.22233599e-04   5.24368836e-04   3.53465075e-05
    3.62521168e-05   4.11746514e-05   3.03594861e-04   1.19076016e-04
    1.81263258e-05   1.54453772e-03   1.92949607e-04   3.70009875e-05
    1.12051188e-04   1.94699328e-06   1.19545998e-03   4.29747306e-05
    2.74036167e-04   6.51444352e-05   7.61956733e-04   9.30120877e-04
    7.54662469e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 87
images_for_training/205
(1, 64, 64, 3)
Policy eval: 
[[  7.28834033e-01   1.97782815e-01   1.59460155e-03   6.59000711e-04
    2.28205783e-04   5.54188213e-04   2.66799849e-04   2.90978351e-04
    2.77898111e-03   4.71072766e-04   3.12380114e-04   1.02481637e-02
    5.57220425e-04   4.49941057e-04   1.55480206e-03   2.64706177e-04
    1.87815551e-03   7.80266491e-05   1.03237340e-03   6.96007954e-03
    2.36221022e-04   4.70474549e-03   3.81126930e-03   1.61251053e-04
    4.93494328e-04   5.12255728e-03   5.51531743e-03   2.05031174e-05
    3.28183174e-04   7.80655755e-05   5.36507985e-04   3.55483353e-04
    2.02261191e-03   9.23705229e-05   1.72962341e-02   4.78141883e-05
    2.22176983e-04   3.06603506e-05   1.04763487e-04   1.58100284e-03
    4.42206656e-04]]
Action: 0.6
Enter Reward: 1
Backpropping 

Session Number 88
images_for_training/34
(1, 64, 64, 3)
Policy eval: 
[[ 0.22091076  0.25797692  0.01360004  0.00854745  0.02383015  0.01673198
   0.00088588  0.00323757  0.01613611  0.00286521  0.0177082   0.06235532
   0.00271239  0.00209211  0.1205662   0.01032009  0.01673822  0.001744
   0.02227118  0.0068828   0.03085447  0.02759152  0.00401493  0.02952094
   0.00404383  0.00617767  0.00256625  0.0091253   0.01390261  0.00408086
   0.00551378  0.00262487  0.00404597  0.00849112  0.0086666   0.00163339
   0.00164989  0.00052097  0.0003232   0.00395283  0.00258641]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 89
images_for_training/1
(1, 64, 64, 3)
Policy eval: 
[[ 0.38716471  0.22286411  0.00621068  0.00392373  0.00305512  0.01531319
   0.0087621   0.00124497  0.00597658  0.01645933  0.0436018   0.00579006
   0.0024421   0.00187624  0.01515031  0.01966909  0.00793591  0.00622706
   0.01992648  0.00889942  0.00948742  0.02671318  0.03895045  0.00414343
   0.01853753  0.00200505  0.02271719  0.00924443  0.00088501  0.00449672
   0.00459483  0.00143805  0.00498663  0.01244887  0.00924473  0.00174536
   0.01551999  0.00121621  0.00196112  0.00289297  0.00427793]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 90
images_for_training/43
(1, 64, 64, 3)
Policy eval: 
[[ 0.38077891  0.14752011  0.03099329  0.00676805  0.00966129  0.00878212
   0.00837613  0.01397696  0.03174229  0.02038741  0.04648148  0.01486324
   0.01198861  0.00284485  0.01057592  0.01275387  0.02074493  0.01073801
   0.00301186  0.0088702   0.00550234  0.02394999  0.00724159  0.0059145
   0.01330245  0.0205614   0.00613383  0.00241734  0.00568737  0.00236149
   0.01001378  0.00761954  0.00571229  0.00169548  0.01964835  0.00130138
   0.01094919  0.00139889  0.00371139  0.03164398  0.01137386]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 91
images_for_training/232
(1, 64, 64, 3)
Policy eval: 
[[  9.29499447e-01   6.05230592e-02   1.20766839e-04   2.20151214e-05
    2.38686160e-04   2.71531375e-04   1.05692940e-04   7.54717548e-05
    7.03961414e-04   1.02014877e-04   6.99379947e-04   1.70005907e-04
    3.26127367e-04   5.69384902e-05   9.29010159e-04   1.47695362e-04
    8.76368140e-05   2.33688006e-05   2.16799290e-05   3.84736020e-04
    1.22226367e-03   9.39083839e-05   4.94262029e-04   1.61675111e-04
    7.31356849e-04   1.82877920e-04   4.10418346e-04   2.21360679e-05
    9.03020264e-05   2.91168428e-04   2.89812364e-04   7.92751889e-05
    8.08450714e-05   1.05491636e-04   3.19172046e-04   9.81202174e-05
    9.39409874e-05   6.27199042e-05   9.26510165e-06   5.97632024e-04
    5.40791807e-05]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 92
images_for_training/180
(1, 64, 64, 3)
Policy eval: 
[[ 0.04501171  0.03761881  0.02736357  0.02808328  0.02365021  0.02406462
   0.02166743  0.02420156  0.02983107  0.02071532  0.02373748  0.02179795
   0.02265207  0.01841775  0.03216984  0.02585134  0.02495953  0.02226606
   0.02499042  0.02110582  0.02496041  0.02559193  0.02355971  0.02271895
   0.02341268  0.02456598  0.02649943  0.01999082  0.02544574  0.02232901
   0.02129985  0.02382069  0.01904875  0.01896885  0.02451927  0.01932697
   0.02422038  0.01939426  0.0242119   0.0228824   0.02307609]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 93
images_for_training/268
(1, 64, 64, 3)
Policy eval: 
[[  5.39679587e-01   3.41043264e-01   2.18951702e-03   4.36822092e-03
    1.54183141e-03   1.52046168e-02   7.21794378e-04   6.76454802e-04
    2.06758711e-03   8.22644273e-04   6.83207251e-03   1.23576652e-02
    4.91649611e-03   3.33136122e-04   5.46846259e-03   1.06960833e-02
    3.09653999e-03   1.31736975e-03   3.62872845e-03   6.00719417e-04
    2.61466973e-03   3.09132482e-03   7.63497129e-03   8.28485354e-04
    4.04733408e-04   2.15437263e-03   2.07813852e-03   4.21576813e-04
    3.90492263e-04   1.08815299e-03   1.56643672e-03   6.16481237e-04
    2.15437030e-03   2.29981472e-03   7.16668600e-03   8.29271507e-04
    2.20353296e-03   1.92199223e-04   2.71083508e-03   6.86832878e-04
    1.30380446e-03]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 94
images_for_training/186
(1, 64, 64, 3)
Policy eval: 
[[ 0.04673646  0.03317607  0.02928609  0.02265426  0.0275084   0.02243377
   0.02273935  0.02266044  0.02790905  0.01954099  0.02221864  0.02686819
   0.02297356  0.02048845  0.02676172  0.0223827   0.02542331  0.02232216
   0.02388456  0.02018958  0.02546421  0.02291051  0.02620582  0.02717726
   0.02255065  0.02516276  0.02071371  0.0204921   0.02570044  0.0207599
   0.02802329  0.01999939  0.02073213  0.02263266  0.02746449  0.02460417
   0.02714214  0.01902114  0.01863579  0.02667409  0.01977562]]
Action: 1.25
Enter Reward: 0
Backpropping 

Session Number 95
images_for_training/120
(1, 64, 64, 3)
Policy eval: 
[[ 0.05016929  0.07562263  0.02887736  0.02482174  0.0209951   0.02820047
   0.02370258  0.0254475   0.02390833  0.02439532  0.0237005   0.02348818
   0.02511885  0.01595424  0.02882634  0.01809564  0.02065939  0.01284801
   0.02079949  0.02849123  0.02327268  0.02292013  0.03561242  0.02665984
   0.03591147  0.01697552  0.02203648  0.02026819  0.0198924   0.01769971
   0.0248122   0.01955583  0.02128202  0.01760987  0.01992938  0.01235314
   0.02005744  0.02196809  0.01450121  0.01992067  0.02263911]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 96
images_for_training/239
(1, 64, 64, 3)
Policy eval: 
[[  1.16166897e-01   4.90686864e-01   6.55275024e-03   8.61892104e-03
    7.74492789e-03   1.02827605e-02   8.13799561e-04   4.42015287e-03
    4.31098789e-02   3.03985458e-02   5.32015786e-02   1.11356545e-02
    7.28995632e-03   4.53594985e-04   4.59577143e-02   4.49955277e-03
    5.55841578e-03   9.77164134e-04   2.63114041e-03   2.71248026e-03
    7.28297159e-02   4.36973339e-03   9.61312931e-03   3.48413107e-03
    4.92141768e-03   3.94113275e-04   2.91170995e-03   2.18683039e-03
    1.51403225e-03   3.17761372e-03   4.19831416e-03   2.33046780e-03
    1.28862087e-03   1.02935117e-02   6.57984940e-03   7.65061751e-03
    1.31791783e-03   9.58351302e-04   4.50764404e-04   5.53279463e-03
    7.83569238e-04]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 97
images_for_training/226
(1, 64, 64, 3)
Policy eval: 
[[  4.42804068e-01   2.37469226e-01   2.11719815e-02   3.86029598e-03
    1.27011118e-03   1.90944399e-03   9.25720786e-04   2.57547293e-03
    8.13165773e-03   2.14627222e-03   1.58211999e-02   7.27716554e-03
    4.03273199e-03   4.63317754e-03   1.73380710e-02   7.04091415e-03
    5.38477907e-03   2.51084045e-02   1.62812807e-02   7.52573041e-03
    2.20417064e-02   1.28643345e-02   1.66078322e-02   1.53719587e-03
    7.77631206e-03   1.07759070e-02   4.79202392e-03   5.56990097e-04
    3.45674518e-04   3.35954316e-03   3.25243943e-03   1.88538316e-03
    8.69890093e-04   1.28479232e-03   1.06075117e-02   3.11072357e-03
    4.62957881e-02   2.32617109e-04   6.80370815e-03   1.17951417e-02
    4.96870605e-04]]
Action: 0.95
Enter Reward: 1
Backpropping 

Session Number 98
images_for_training/1
(1, 64, 64, 3)
Policy eval: 
[[ 0.16539823  0.08675912  0.06709468  0.01685475  0.00672396  0.01151188
   0.00654651  0.00818065  0.0364319   0.01849346  0.0298959   0.04062544
   0.00829439  0.01171968  0.0241421   0.02742049  0.02767862  0.01628716
   0.0182994   0.01328912  0.018901    0.02154908  0.02176984  0.00800487
   0.02920255  0.02302608  0.01627818  0.01593606  0.00788641  0.01752439
   0.02663062  0.01167528  0.01774988  0.01731419  0.04150603  0.00559654
   0.01202384  0.00643419  0.00833871  0.00913712  0.02186777]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 99
images_for_training/203
(1, 64, 64, 3)
Policy eval: 
[[  7.29150534e-01   9.78412032e-02   8.35793465e-03   8.75217607e-04
    3.79491830e-04   1.04726208e-02   3.15644941e-03   2.22199410e-03
    4.03502770e-03   1.25036947e-03   5.34733292e-03   6.39652135e-03
    4.68819671e-05   3.42564483e-04   1.38478652e-02   8.26492719e-03
    7.74818799e-03   4.39689786e-04   7.03431107e-03   2.97992281e-03
    3.71651677e-03   1.37937476e-03   2.94851772e-02   4.97125555e-03
    3.54989851e-03   5.63471764e-03   1.01920739e-02   1.50426594e-03
    5.49263507e-03   2.66427058e-03   3.10181815e-04   3.94507451e-03
    7.23931706e-04   2.61220196e-03   3.69973155e-03   2.74370861e-04
    1.80147064e-03   7.52813998e-04   1.70458268e-04   2.00195564e-03
    4.92851064e-03]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 20:29:59.552533: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/32
(1, 64, 64, 3)
Policy eval: 
[[  0.00000000e+00   9.74300086e-01   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   7.42532084e-33
    5.54831192e-13   0.00000000e+00   0.00000000e+00   2.87599203e-34
    1.17320328e-34   2.56999321e-02   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.38780883e-33   0.00000000e+00
    0.00000000e+00   2.30171193e-35   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   6.12597074e-38   1.71039323e-23
    0.00000000e+00   0.00000000e+00   5.33743266e-34   0.00000000e+00
    0.00000000e+00   6.47765785e-28   0.00000000e+00   7.33696961e-17
    0.00000000e+00   6.04096186e-32   0.00000000e+00   0.00000000e+00
    0.00000000e+00]]
Log Policy eval: 
[[ -1.48562378e+02  -6.24404907e+01  -2.07986725e+02  -8.16195221e+01
   -2.10175095e+02  -1.59026886e+02  -9.68020020e+01  -5.26706390e+01
   -4.43448735e-05  -1.78295364e+02  -2.02573227e+02  -1.95741959e+02
   -5.08624268e+01  -1.18799866e+02  -9.99660339e+01  -1.03085152e+02
   -2.32457714e+01  -2.24797287e+02  -6.24184685e+01  -1.25611946e+02
   -2.35971268e+02  -1.95568115e+02  -7.28947678e+01  -2.50203384e+02
   -1.76790543e+02  -1.01533447e+02  -9.19006424e+01  -1.17358276e+02
   -1.28342728e+02  -1.47282196e+02  -5.14074631e+01  -8.71575165e+01
   -1.74412811e+02  -1.23608604e+02  -2.07536301e+02  -3.03177624e+01
   -2.07427750e+02  -1.00242062e+01  -3.41924438e+01  -1.07974136e+02
   -9.51103897e+01]]
2018-10-05 20:30:00.795 Python[34519:13869262] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 0.65
Enter Reward: -1
Breaking 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 21:40:21.507795: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/160
(1, 64, 64, 3)
Policy eval: 
[[  5.32344729e-03   4.15361515e-04   3.65162082e-03   1.65514951e-03
    2.70366240e-02   1.18746411e-03   1.16554310e-03   1.16709676e-02
    6.03043893e-03   1.31032092e-03   3.70228523e-03   8.15918762e-03
    2.53262371e-02   1.49951910e-03   7.81129580e-04   4.75313235e-03
    2.98721669e-03   2.02177628e-03   4.96184570e-04   1.81354880e-01
    2.31050700e-03   2.87423491e-01   2.48594978e-03   3.14568765e-02
    2.64829211e-03   6.45674590e-04   1.36688473e-02   7.10552704e-05
    1.30542414e-03   7.61387928e-04   7.94964749e-03   9.70452428e-02
    2.35526683e-03   3.16463993e-04   5.00752963e-03   1.63197785e-03
    3.72429774e-03   1.03415479e-03   3.87898646e-04   1.76880769e-02
    2.29553506e-01]]
Log Policy eval: 
[[-7.14961052 -3.01488709 -5.57714367 -4.75738907 -7.53077602 -4.23932028
  -6.31556702 -7.99777031 -5.54242039 -1.07226205 -8.10152721 -4.80538654
  -8.53562927 -3.44633603 -9.68667984 -7.21651173 -9.41042042 -5.91919994
  -7.7651701  -6.3372345  -8.09774685 -8.27638817 -4.72500801 -6.80650616
  -9.66526794 -5.06170368 -4.20247221 -6.72951984 -8.07754612 -9.90289497
  -3.39526153 -1.08974957 -5.51250839 -7.27365685 -5.36638832 -4.79012775
  -6.55809116 -2.27246213 -7.93437004 -6.44990826 -7.09486198]]
2018-10-05 21:40:22.640 Python[35915:13909339] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 0.15
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/281
(1, 64, 64, 3)
Policy eval: 
[[  1.22475988e-20   2.69608844e-38   2.88930519e-15   0.00000000e+00
    2.34093063e-21   9.96043581e-10   6.37511893e-28   2.88681099e-33
    2.93273093e-25   1.39069649e-35   3.22778994e-32   2.35497472e-21
    2.04176628e-12   1.37476572e-37   9.18547469e-25   2.09783909e-11
    4.20116099e-28   2.68192315e-15   0.00000000e+00   5.44662618e-29
    0.00000000e+00   3.67810018e-27   5.86937959e-22   1.83744316e-16
    2.41699278e-27   1.18146977e-08   2.94776368e-23   0.00000000e+00
    0.00000000e+00   0.00000000e+00   1.62256141e-13   1.75858023e-22
    1.65891847e-20   4.85430425e-20   5.25987589e-36   1.07317577e-21
    1.45202166e-12   0.00000000e+00   6.79642772e-30   4.08331799e-15
    1.00000000e+00]]
Log Policy eval: 
[[ -6.98701782e+01  -1.22039589e+02  -3.26284409e+01  -6.30294647e+01
   -5.19365158e+01  -3.28334122e+01  -4.35758934e+01  -9.11965103e+01
   -3.64869652e+01  -8.30813904e+01  -6.71046829e+01  -2.68830929e+01
   -4.89205627e+01  -6.27888565e+01  -1.02022758e+02  -2.91056995e+01
   -1.04675941e+02  -2.55178967e+01  -7.72650757e+01  -5.13629036e+01
   -9.84921036e+01  -2.61106701e+01  -4.13283539e+01  -2.28433704e+01
   -9.48678360e+01  -7.54924316e+01  -7.23658524e+01  -7.73885880e+01
   -9.48433914e+01  -6.65436554e+01  -1.16504412e+01  -4.77002449e+01
   -6.14821701e+01  -2.06215038e+01  -8.88875809e+01  -5.88038177e+01
   -8.50825272e+01  -1.68913956e+02  -1.03835258e+02  -7.99922943e+01
   -8.70223994e-06]]
Action: 1.5
Enter Reward: 0
Backpropping 

Session Number 2
images_for_training/102
(1, 64, 64, 3)
Policy eval: 
[[  2.46578056e-05   2.60486627e-06   1.27846775e-07   2.92987153e-02
    1.54921692e-02   9.60253354e-04   3.08130458e-02   1.57883695e-09
    6.37051289e-06   9.37806908e-06   8.51749610e-06   1.30533678e-02
    6.32331823e-04   7.04601640e-04   6.50954206e-08   2.68217409e-04
    1.69685227e-05   2.46223090e-06   1.09791567e-04   4.84669209e-02
    1.35415978e-09   2.98158906e-04   4.98143082e-09   1.86043826e-03
    5.27782358e-05   4.90238272e-05   4.34188296e-05   6.19320373e-09
    7.52323537e-09   5.81422171e-07   3.26966122e-02   6.00240827e-02
    3.53458631e-06   3.28716069e-01   6.28234912e-03   1.26704726e-05
    1.11250019e-05   1.09481835e-12   5.51143148e-06   1.85674019e-02
    4.11505669e-01]]
Log Policy eval: 
[[ -4.70533562  -6.43487358  -1.41116524 -10.91967773  -2.68032837
  -11.6811142  -10.91906738 -18.76976776  -9.31897831  -5.42814827
  -12.27859116  -4.82628775  -0.81376559 -11.15594101 -14.88895893
   -6.73837376 -17.63421059 -14.03277111 -15.23443985 -11.93746185
  -10.23237896 -19.46764374 -19.55381775  -4.48492765 -21.58679962
  -12.79399014 -16.19275093 -17.30898285 -19.91489983 -21.01832962
   -1.77464294 -10.74873447  -4.63192272  -8.57056427 -16.57549095
   -9.79140186  -5.09111643 -20.76605988 -15.67595768  -3.77264833
  -12.5238142 ]]
Action: 1.15
Enter Reward: 0
Backpropping 

Session Number 3
images_for_training/43
(1, 64, 64, 3)
Policy eval: 
[[  1.88666634e-20   6.94770403e-21   5.11778672e-18   3.69124731e-11
    1.64425862e-09   5.12943734e-06   1.16826849e-25   4.70450081e-19
    2.49380025e-26   2.84107265e-13   6.06750707e-13   1.06778053e-09
    1.48185575e-09   2.50224777e-15   4.60534994e-26   2.29287440e-11
    8.93522859e-14   2.61998912e-18   1.20706555e-24   3.16404245e-15
    2.02235219e-21   7.08804780e-17   1.05121717e-22   1.58776258e-13
    7.91328330e-27   1.37319938e-11   2.24507360e-21   4.19155256e-35
    7.55868570e-28   1.62501441e-18   7.49828814e-06   8.91989899e-15
    2.67703800e-27   1.28805554e-24   1.09072863e-19   5.40656383e-29
    9.99987364e-01   5.16560248e-34   5.02692647e-17   2.75487945e-14
    6.64696637e-14]]
Log Policy eval: 
[[-37.16887665 -47.38707352 -24.31871796 -56.18368912  -0.49621448
  -14.44407749 -24.87630081 -36.92813873 -40.27783966 -45.22921753
  -33.46107101 -29.7917881  -21.48668289 -47.72142029 -36.25207138
  -32.804039   -61.69174194 -19.43639946 -57.2127533  -40.96427917
  -41.62601471 -59.78899384 -44.94402695 -11.47868633 -61.41731262
  -29.54444504 -42.19171906 -80.71128082 -74.48322296 -40.31150818
   -0.95852911 -26.10850525 -62.1750946  -46.02854538 -59.50050354
  -18.21054268 -62.11846924 -94.86560059 -55.89826202  -4.86633158
  -27.3172226 ]]
Action: 2.0
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/74
(1, 64, 64, 3)
Policy eval: 
[[  2.57967674e-19   4.03153200e-29   1.51358471e-25   2.61172001e-18
    1.00000000e+00   6.45014568e-20   2.28792277e-30   0.00000000e+00
    4.02775677e-26   0.00000000e+00   2.88766791e-27   5.17726378e-13
    4.48511303e-21   7.64735413e-36   0.00000000e+00   2.47142542e-18
    0.00000000e+00   2.16214138e-15   0.00000000e+00   8.30266119e-32
    5.21142298e-36   2.60884367e-32   0.00000000e+00   2.93017473e-22
    0.00000000e+00   1.48224373e-33   0.00000000e+00   0.00000000e+00
    4.31455703e-29   1.32862258e-35   6.62949617e-23   4.31411053e-30
    0.00000000e+00   0.00000000e+00   3.66360224e-37   6.19983485e-25
    7.68491728e-25   0.00000000e+00   0.00000000e+00   8.25098011e-31
    1.82969187e-25]]
Log Policy eval: 
[[ -29.76917648  -31.59392738  -61.74702454  -39.64264679   -0.10684251
   -60.12349701  -28.28323555  -55.91560364  -48.12927628  -75.92008209
   -37.1409874   -38.33803558  -45.94821167  -52.57811737  -40.87825012
   -35.27794647  -42.84536743   -2.28934526  -53.7233429   -17.61448669
   -68.61680603  -23.57645798  -55.54543686  -47.10810471  -51.1519165
   -53.75382996  -45.26480103  -65.53223419  -40.39437485  -55.95246124
   -38.98885727  -35.55474854  -70.38009644  -83.7101593   -60.36618042
   -47.76707458  -57.12641525 -100.97039032  -68.84938049  -34.59978485
   -41.1642952 ]]
Action: 1.15
Enter Reward: 1
Backpropping 

Session Number 5
images_for_training/60
(1, 64, 64, 3)
Policy eval: 
[[  2.02679041e-21   9.14340138e-01   7.76250907e-31   3.16302331e-23
    8.56596529e-02   1.09767195e-09   5.18488898e-13   6.02813725e-29
    6.05334383e-15   3.00274660e-21   1.01868716e-21   3.34476394e-20
    7.52979173e-25   1.31401951e-24   1.74615983e-32   1.25738045e-10
    3.45813941e-24   4.59397809e-09   8.01016228e-18   8.57620330e-16
    8.68179973e-31   1.09538462e-19   1.79243121e-24   2.32323953e-13
    2.01039582e-29   5.52503140e-26   1.97042852e-14   0.00000000e+00
    7.55814575e-23   3.74925216e-13   5.69828906e-13   2.55383668e-07
    2.66780357e-23   1.47206103e-36   5.52917814e-21   6.20419528e-25
    1.62615263e-26   9.30928765e-28   1.31298102e-26   5.52143290e-17
    3.32000518e-25]]
Log Policy eval: 
[[ -1.73570404e+01  -2.11921539e+01  -3.12897568e+01  -3.36569252e+01
   -3.89416957e+00  -4.43909950e+01  -5.05859718e+01  -3.54912910e+01
   -2.59121189e+01  -4.60414467e+01  -1.84913692e+01  -3.92993546e+01
   -5.96330605e+01  -6.04556656e+01  -1.97624283e+01  -4.07684374e+00
   -5.24002495e+01  -5.14113270e-02  -3.15220680e+01  -1.84153919e+01
   -5.09357033e+01  -4.35902071e+00  -2.49049454e+01  -3.08483849e+01
   -7.71741562e+01  -1.92944889e+01  -3.86830559e+01  -4.40060349e+01
   -4.29462700e+01  -4.47574387e+01  -1.98827248e+01  -2.25658531e+01
   -6.20881233e+01  -7.67372360e+01  -2.83019600e+01  -3.85716133e+01
   -6.42105637e+01  -7.78370056e+01  -5.34652672e+01  -4.05273743e+01
   -3.02051201e+01]]
Action: 1.5
Enter Reward: 0
Backpropping 

Session Number 6
images_for_training/167
(1, 64, 64, 3)
Policy eval: 
[[  4.37832095e-05   2.36643988e-04   4.03340027e-06   4.47205646e-04
    5.27238590e-05   2.11617703e-06   1.30496164e-06   6.71880189e-05
    1.11042016e-06   1.15011935e-05   1.19737797e-06   2.26259817e-05
    5.20260401e-05   5.74556395e-07   4.55356940e-06   1.00144331e-04
    4.69516126e-05   9.72684801e-01   7.50546178e-06   4.77958517e-03
    1.30506805e-05   3.05348280e-04   1.90950864e-08   2.20578769e-03
    1.53942167e-07   4.42990167e-05   1.85465547e-06   6.47680790e-05
    2.80859155e-07   3.76439608e-08   3.08403432e-05   3.56574878e-06
    2.93661742e-06   7.60093588e-09   7.35977679e-09   1.34927081e-02
    2.71466881e-04   4.94415815e-08   7.18277704e-07   4.92716162e-03
    6.73660033e-05]]
Log Policy eval: 
[[-11.82748127  -3.34200978 -12.8813715  -11.85577297  -0.85510564
   -6.64509392 -14.13269424 -12.51693439  -4.75207424  -9.93514252
   -5.25214005  -6.83404636 -12.72267342 -12.24390125 -13.13606071
   -9.68527031 -11.99496555  -2.14315915  -7.63011074  -8.65904045
   -8.98925114  -6.61981106 -14.28398323  -1.14063478 -11.22704792
  -11.33110046 -11.65997696 -12.24323082  -9.58448792 -10.85407925
   -8.12872887 -11.23602295  -9.67241287 -14.83799362  -2.51005197
  -10.96115971 -12.26629162 -20.18669891 -13.18359375  -6.12179756
  -13.02107906]]
Action: 0.2
Enter Reward: 0
Backpropping 

Session Number 7
images_for_training/277
(1, 64, 64, 3)
Policy eval: 
[[  3.51265653e-34   7.85064670e-24   0.00000000e+00   1.12334164e-05
    9.99988794e-01   3.38726490e-18   0.00000000e+00   0.00000000e+00
    1.67868701e-25   0.00000000e+00   0.00000000e+00   3.11468709e-28
    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.10955511e-23
    0.00000000e+00   2.43384769e-22   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   2.19060124e-30
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   4.43765131e-35   0.00000000e+00   1.82749178e-21
    0.00000000e+00   0.00000000e+00   0.00000000e+00   8.26794969e-12
    0.00000000e+00   0.00000000e+00   0.00000000e+00   6.55899709e-28
    0.00000000e+00]]
Log Policy eval: 
[[ -65.15566254   -0.63209391  -70.16280365   -6.36666346   -0.76186991
   -73.94747162  -62.91213608  -98.81840515  -39.11211014 -110.18498993
   -68.73897552  -73.42852783  -75.15010834 -117.14430237 -115.5723877
   -46.17753983  -54.79090881  -29.29626656  -77.1839447   -82.56720734
  -120.345047    -59.2553215   -96.84947968  -23.12814903  -88.67337036
   -41.8738327   -70.68640137  -75.74913025  -71.08139801  -74.18126678
   -35.07726669  -69.73799896 -107.97496033 -121.69857788  -70.91860962
   -18.66435814 -134.40602112 -143.82878113  -93.32139587  -53.38428116
   -11.35917473]]
Action: 0.2
Enter Reward: 0
Backpropping 

Session Number 8
images_for_training/199
(1, 64, 64, 3)
Policy eval: 
[[  9.50964727e-03   7.38772377e-02   2.47351732e-02   1.04391687e-01
    5.92990033e-03   7.11885840e-02   2.75884609e-04   1.52689739e-04
    3.33561515e-03   4.83969139e-04   2.08125636e-03   4.79098745e-02
    3.16825276e-03   1.44024729e-04   1.98213221e-03   2.02204939e-03
    3.80991101e-02   3.84022564e-01   4.25136834e-03   7.15378392e-03
    8.55824817e-03   5.87071385e-03   1.12494489e-03   5.86395431e-03
    4.04095714e-04   4.05225297e-03   4.98455018e-02   1.35926099e-03
    1.10179866e-02   3.21987667e-04   5.60990199e-02   1.32346142e-03
    1.33944894e-04   7.65823817e-04   6.89586950e-03   1.21642854e-02
    2.00258773e-02   1.14184972e-04   5.60822431e-04   1.94604341e-02
    9.32240859e-03]]
Log Policy eval: 
[[-3.45431566 -1.0832063  -4.14503145 -5.44042206 -6.17172241 -2.46716881
  -3.52163219 -6.8896513  -2.28216982 -5.32199383 -5.50171471 -3.73717117
  -7.25560522 -7.64219761 -8.69800758 -5.69234562 -9.88305473 -5.31824064
  -4.15032434 -7.86582994 -6.78083611 -6.99514675 -6.67751265 -3.91194439
  -6.78111887 -7.14251661 -3.57043171 -5.69878387 -6.34414482 -6.72992039
  -2.34159088 -2.12312555 -7.43097496 -8.88911629 -7.32391691 -4.60375023
  -6.36005497 -8.27180862 -7.14071703 -5.60353279 -3.26563215]]
Action: 0.25
Enter Reward: 0
Backpropping 

Session Number 9
images_for_training/164
(1, 64, 64, 3)
Policy eval: 
[[  5.49487285e-02   1.82481725e-02   6.39994349e-03   2.82161385e-01
    6.26639090e-03   3.59510677e-03   4.09474503e-03   1.64100784e-03
    2.25932628e-01   1.29077537e-03   3.09454626e-04   3.48277437e-03
    1.83590222e-04   1.30707078e-04   9.16445279e-05   5.28121293e-02
    5.68275433e-03   1.73143327e-01   3.12018860e-03   3.58472299e-03
    3.51581397e-03   1.16050979e-02   1.77092326e-03   4.87494137e-04
    2.88201874e-04   2.90445657e-03   7.13686878e-03   5.34441097e-05
    7.07533793e-04   2.12975196e-03   3.74388346e-03   2.44410941e-03
    1.95612595e-03   9.64465507e-05   1.17472373e-03   1.69762243e-02
    1.31035270e-03   2.31591712e-05   9.13390133e-04   9.74564627e-03
    8.38962495e-02]]
Log Policy eval: 
[[ -6.82083082  -2.3455472   -8.97170258  -7.8179183   -7.40274763
   -5.09636068  -8.96823025  -7.07672787  -0.23012784  -5.33869982
   -9.97880077  -3.84388447  -9.66113186  -9.52601147  -6.61715794
   -6.11990976  -8.41995621  -4.00322104  -6.58578777  -8.22912025
   -7.16080093  -9.46980762  -5.84455824  -7.93255377  -9.21448612
   -5.36874533  -7.79135275  -5.45597219  -9.07840919  -8.8021431
   -7.25289965  -3.42590046 -11.64621449 -12.01249123  -8.6762886
   -7.65320826  -7.61262655 -10.14646626  -9.78381157  -7.31368971
   -6.54510546]]
Action: 0.4
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/71
(1, 64, 64, 3)
Policy eval: 
[[  9.99490804e-17   6.41413465e-07   1.07196986e-31   5.31547289e-12
    4.96083579e-04   1.69887506e-16   1.70084116e-22   2.40276417e-15
    9.99502778e-01   1.43671568e-24   1.05561017e-20   2.08694455e-15
    1.83039385e-33   1.35854438e-23   3.12019376e-17   1.15694609e-17
    1.21016484e-07   3.64438514e-13   4.07249894e-16   1.84727407e-22
    9.32616353e-32   9.66244107e-26   2.65477559e-20   1.21077464e-14
    5.76106352e-26   3.00522242e-23   5.33951655e-15   6.93936227e-20
    4.07505046e-22   4.22746416e-09   6.29103861e-28   3.77950573e-13
    1.27329469e-27   1.96364304e-26   8.41779575e-20   1.55000202e-14
    5.07469235e-23   0.00000000e+00   5.28676745e-27   3.49135092e-07
    6.98809540e-16]]
Log Policy eval: 
[[ -2.12302952e+01  -4.39491043e+01  -3.96921349e+01  -4.81007767e+01
   -4.77735596e+01  -2.18477764e+01  -6.19875870e+01  -6.58696365e+01
   -4.05310766e-06  -5.34248085e+01  -5.18444862e+01  -2.66478577e+01
   -4.45535622e+01  -6.64693451e+01  -4.91380348e+01  -3.47389679e+01
   -3.87640228e+01  -1.25870590e+01  -4.16089783e+01  -4.21245422e+01
   -4.11103401e+01  -6.59826584e+01  -5.07279968e+01  -6.22466240e+01
   -5.27505112e+01  -4.35656433e+01  -3.29912682e+01  -5.90140953e+01
   -5.17912407e+01  -5.50138130e+01  -3.62213478e+01  -3.32645454e+01
   -6.88540573e+01  -9.21638718e+01  -4.69465981e+01  -3.85772324e+01
   -6.29676933e+01  -8.01847763e+01  -4.73202477e+01  -1.42796783e+01
   -5.55144005e+01]]
Action: 0.4
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/107
(1, 64, 64, 3)
Policy eval: 
[[  1.34851446e-03   3.47606391e-02   2.09984009e-05   7.04750892e-06
    1.58215351e-02   1.65806375e-02   2.47359857e-01   5.37261076e-04
    2.57898588e-02   5.55644765e-05   4.27941677e-06   1.29964063e-02
    8.10410165e-06   1.48041570e-03   2.51204383e-05   3.86598222e-02
    1.57864179e-05   6.47749752e-03   1.02179115e-06   2.00267451e-07
    1.82703400e-06   7.33865658e-04   1.57764775e-03   3.57458775e-04
    2.69692191e-05   5.66160961e-05   2.59414673e-01   1.69862290e-06
    8.41161673e-05   1.69688810e-05   3.00521260e-05   2.50702538e-02
    8.24721056e-08   3.26498899e-08   2.01724924e-06   3.09260279e-01
    9.04541864e-08   4.06182510e-12   5.14286455e-07   4.15183931e-05
    1.37271441e-03]]
Log Policy eval: 
[[ -4.34080601  -5.88693666  -3.8844347  -10.44987106  -2.75929213
   -6.49395037 -10.13855553 -10.7199955   -3.86237955  -6.83023977
  -13.40225792  -2.99423838 -11.02817154 -12.9465847   -9.20371819
   -0.73514032 -11.92481041  -7.85814714  -8.05712891 -10.00549698
   -6.33791113 -11.00856781 -10.57208252 -10.18502808  -8.9095993
   -5.48210144  -5.54069042  -7.74759388  -6.68856382  -7.47977066
   -5.86995506  -1.73430109 -16.94039536 -18.72395706  -6.8966651
   -8.38060188  -5.54335737 -18.37735558 -15.52664375  -1.91535425
   -6.15961027]]
Action: 0.75
Enter Reward: 0
Backpropping 

Session Number 12
images_for_training/194
(1, 64, 64, 3)
Policy eval: 
[[  7.52029737e-05   3.29397433e-02   2.37706859e-04   2.51783145e-04
    7.41566590e-04   2.92477012e-03   8.35565079e-05   5.64737071e-04
    7.44161367e-01   4.41526470e-04   1.84629613e-03   3.56870209e-04
    4.10244218e-04   1.62066826e-05   1.55211785e-06   1.58331502e-04
    1.49125222e-03   6.80332596e-05   2.69938982e-03   1.15143688e-04
    1.15345807e-04   1.05767494e-05   1.15452785e-04   1.03672864e-04
    1.95700686e-05   2.78331060e-03   1.88792139e-04   5.83861605e-04
    6.36153200e-05   1.31570240e-02   2.27302935e-05   1.90942109e-01
    1.23973484e-06   3.67862185e-08   8.65118363e-06   1.14809105e-03
    4.17275032e-07   2.88954993e-07   7.45046691e-07   4.13817994e-04
    7.35376845e-04]]
Log Policy eval: 
[[ -3.12940574  -3.52840972  -8.03621197  -9.54722214  -5.04109812
   -5.96429014  -9.31703949  -8.99461174  -0.30163321  -9.03386593
  -12.29952621  -2.3849442   -7.78384256  -9.99763203 -12.44400501
   -4.78872728  -6.96021748  -7.84279299  -4.84828901  -7.84363413
   -8.65089035  -7.36913252  -8.51544476 -10.77213764  -9.51205158
   -6.50362778  -7.43710375  -5.37004566  -9.63400841  -9.90849781
   -9.21202755  -6.90971518 -15.18403625 -14.4394083   -6.07108927
   -6.39119196  -8.14129734 -15.9933424  -13.7015276  -10.1168108
   -2.92443061]]
Action: 0.55
Enter Reward: 0
Backpropping 

Session Number 13
images_for_training/229
(1, 64, 64, 3)
Policy eval: 
[[  1.57490111e-04   3.36939618e-02   4.10229430e-37   3.39595434e-38
    3.24091817e-12   1.26766339e-17   8.17031926e-36   1.11007800e-27
    5.27166784e-16   6.33306672e-15   3.26720360e-38   6.03168028e-14
    0.00000000e+00   2.53737776e-37   0.00000000e+00   7.41613770e-10
    1.35512078e-17   1.23639423e-12   7.74811530e-13   5.13773525e-17
    1.64445615e-18   4.50839485e-22   8.80421234e-36   2.55543032e-26
    6.79810147e-21   2.09713855e-14   8.38594028e-10   1.14401470e-19
    3.89457560e-18   9.79731776e-17   7.62119549e-18   9.66148555e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.91446194e-25
    5.00499867e-37   0.00000000e+00   6.52766425e-25   1.28331980e-11
    2.51849418e-16]]
Log Policy eval: 
[[ -6.42732162e+01  -2.90513687e+01  -7.06421814e+01  -1.34929161e+01
   -4.42653084e+01  -5.59044800e+01  -4.89663124e+01  -5.76213531e+01
   -2.06633148e+01  -6.41589355e+01  -5.10445747e+01  -3.38771133e+01
   -6.12958908e+01  -6.34631424e+01  -7.49470367e+01  -2.26349449e+01
   -2.64403038e+01  -6.47795563e+01  -3.18531113e+01  -4.18314552e+01
   -4.75863457e+01  -2.37938576e+01  -5.03236580e+01  -6.90141068e+01
   -5.99161148e+01  -2.65819759e+01  -6.85451202e+01  -4.29547119e+01
   -4.17202377e+01  -7.99182129e+00  -7.43366318e+01  -4.23222606e-04
   -9.83845291e+01  -1.34300034e+02  -9.38994217e+00  -5.65148315e+01
   -3.52262077e+01  -7.21174850e+01  -1.02485832e+02  -2.91561584e+01
   -5.62003937e+01]]
Action: 1.3
Enter Reward: 0
Backpropping 

Session Number 14
images_for_training/73
(1, 64, 64, 3)
Policy eval: 
[[  1.77641224e-14   3.81886363e-12   1.49103404e-23   3.64970294e-12
    6.18775951e-12   2.17280025e-08   2.59083862e-07   7.80564849e-13
    4.79009181e-01   7.56168288e-21   2.64880140e-25   3.22793261e-03
    3.62472364e-18   4.66042949e-14   1.80297888e-26   5.71940837e-14
    1.40166261e-18   7.06011406e-07   4.02786302e-17   2.80595908e-10
    2.25226887e-15   1.48293354e-16   4.68337910e-16   9.24126904e-19
    1.85050691e-20   9.02033673e-21   5.16687214e-01   4.33231144e-23
    1.41847811e-09   1.78338367e-16   9.53668677e-20   3.04155279e-08
    1.54405798e-20   1.71831489e-27   5.29115017e-26   3.16374899e-10
    5.51980301e-23   5.29175995e-32   3.03491946e-18   2.11034789e-13
    1.07469608e-03]]
Log Policy eval: 
[[ -3.84062920e+01  -3.84742584e+01  -5.98513908e+01  -3.56538631e-02
   -4.14403114e+01  -3.38622818e+01  -4.11641121e+01  -4.96061020e+01
   -2.92263889e+01  -3.11813450e+01  -4.26682587e+01  -2.98261681e+01
   -4.77332687e+01  -3.49842949e+01  -3.41459999e+01  -1.06752033e+01
   -3.32485962e+01  -4.46996155e+01  -2.18141079e+01  -2.37966309e+01
   -5.48365517e+01  -5.67821121e+01  -5.08398972e+01  -4.56025581e+01
   -5.26888657e+01  -1.15061398e+01  -2.96598396e+01  -4.87388420e+01
   -3.53123398e+01  -3.42294655e+01  -2.94637661e+01  -3.42126632e+00
   -4.34486504e+01  -7.50664139e+01  -2.60127563e+01  -3.70931587e+01
   -8.16978264e+00  -8.27468796e+01  -5.81049728e+01  -6.19561195e+00
   -2.59176197e+01]]
Action: 0.55
Enter Reward: 0
Backpropping 

Session Number 15
images_for_training/280
(1, 64, 64, 3)
Policy eval: 
[[  5.01487169e-15   2.55981558e-20   2.72512921e-19   9.54172852e-11
    8.78454695e-20   0.00000000e+00   0.00000000e+00   1.33214533e-27
    1.95323773e-05   1.33193791e-18   0.00000000e+00   1.01263758e-07
    0.00000000e+00   0.00000000e+00   2.67484773e-34   3.62163521e-09
    2.21769928e-16   0.00000000e+00   4.64466240e-27   3.12781375e-17
    3.80914123e-35   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   4.56540425e-34   5.31763557e-14   3.05237243e-34
    1.70300920e-33   0.00000000e+00   8.94408707e-26   6.07293517e-20
    0.00000000e+00   0.00000000e+00   0.00000000e+00   9.99824703e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.55681220e-04
    1.27815998e-17]]
Log Policy eval: 
[[ -4.10581665e+01  -9.62695465e+01  -9.89503403e+01  -1.02962143e+02
   -4.52702103e+01  -5.97083282e+01  -1.05963089e+02  -1.02393181e+02
   -8.77981720e+01  -7.43824768e+01  -1.76238373e+02  -1.14923859e+02
   -1.33039124e+02  -1.04781441e+02  -1.01897202e+02  -1.35259256e+01
   -1.47745056e+02  -1.86869526e+01  -1.27116745e+02  -1.15126060e+02
   -1.18357231e+02  -9.68100052e+01  -1.12723518e+02  -1.11797363e+02
   -1.31311859e+02  -4.01606750e+01  -9.59478912e+01  -1.22742043e+02
   -1.03826309e+02  -1.07903641e+02  -1.39274155e+02  -1.31130128e-06
   -1.75090240e+02  -2.34930969e+02  -1.52939102e+02  -5.89049683e+01
   -7.93201447e+01  -1.88088516e+02  -1.41644302e+02  -6.10920639e+01
   -2.45867329e+01]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 16
images_for_training/43
(1, 64, 64, 3)
Policy eval: 
[[  1.36687412e-23   0.00000000e+00   4.08765688e-27   1.97932471e-35
    3.53623656e-27   4.79608556e-27   2.21834639e-27   1.28317377e-22
    4.84052909e-27   9.04098587e-20   0.00000000e+00   9.32178347e-21
    0.00000000e+00   1.33307574e-19   3.70414635e-36   1.00000000e+00
    0.00000000e+00   2.33710693e-25   0.00000000e+00   0.00000000e+00
    4.89131063e-36   1.63628152e-33   1.60045238e-17   0.00000000e+00
    0.00000000e+00   1.04249625e-23   2.18100357e-30   1.36416546e-38
    6.10840821e-29   2.64277429e-36   0.00000000e+00   5.62250442e-13
    0.00000000e+00   0.00000000e+00   1.67473076e-36   8.90102238e-20
    8.42532591e-35   0.00000000e+00   0.00000000e+00   6.20754485e-19
    4.81522566e-19]]
Log Policy eval: 
[[ -4.02634506e+01  -1.57663097e+01  -4.94860573e+01  -1.01143742e+01
   -5.39495125e+01  -4.06620064e+01  -5.64546318e+01  -6.72531700e+00
   -2.29932652e+01  -5.93548927e+01  -4.08906822e+01  -4.02429848e+01
   -3.65114899e+01  -7.96340866e+01  -6.32649651e+01  -2.34699345e+01
   -1.24150899e-03  -7.79126587e+01  -1.89276981e+01  -2.73545647e+01
   -5.46201210e+01  -3.20961800e+01  -6.64198608e+01  -4.31630669e+01
   -3.84637527e+01  -4.61857491e+01  -3.79571419e+01  -4.59760399e+01
   -4.37942009e+01  -4.03670883e+01  -2.28638363e+01  -2.34756527e+01
   -7.10913315e+01  -8.59957504e+01  -6.38785515e+01  -4.15529518e+01
   -6.46779404e+01  -8.77010574e+01  -4.69766960e+01  -1.79187107e+01
   -2.80206699e+01]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 17
images_for_training/163
(1, 64, 64, 3)
Policy eval: 
[[  6.67162612e-02   1.80224612e-04   3.24599780e-02   9.94595140e-03
    6.71276217e-03   1.68669841e-03   1.37381081e-03   6.49806857e-03
    1.05629554e-02   3.60502861e-03   6.66445587e-04   1.02694193e-02
    1.88332039e-03   2.18733004e-03   3.45401699e-03   4.24300909e-01
    1.26727754e-02   9.96406376e-03   1.23468004e-02   2.53674537e-02
    1.48353120e-02   4.69515957e-02   1.85704436e-02   7.73324107e-04
    1.22669782e-03   2.39496641e-02   9.56761744e-03   1.79588015e-03
    2.28306279e-03   7.71651464e-03   2.15696357e-02   1.17292643e-01
    2.53931154e-04   1.42718573e-05   7.26042432e-04   1.73965432e-02
    5.83146466e-03   3.52627540e-04   3.52495379e-04   4.95745614e-02
    1.61114726e-02]]
Log Policy eval: 
[[-1.0629375  -4.45294046 -3.86837339 -3.95223689 -3.71394181 -7.06475544
  -6.55873394 -5.62201118 -3.50184703 -5.14587116 -7.3549881  -4.05412722
  -7.58489227 -8.38336182 -5.4581852  -3.59075856 -3.86978364 -5.87223434
  -6.95137024 -5.74683857 -5.83318424 -6.22163105 -7.46377373 -6.93492317
  -6.85264301 -5.71990395 -4.91576004 -5.59469604 -6.50518417 -4.08782864
  -4.06434536 -1.39236903 -7.03830051 -9.92652416 -7.14337635 -2.32338881
  -7.62464237 -8.88858318 -6.55005646 -3.44655418 -3.97205472]]
Action: 0.75
Enter Reward: 0
Backpropping 

Session Number 18
images_for_training/102
(1, 64, 64, 3)
Policy eval: 
[[  7.39697157e-08   2.14742182e-11   2.03910444e-10   2.86421535e-08
    9.17397585e-07   6.26947170e-08   9.02133782e-13   6.56316321e-11
    8.44487261e-07   1.84212912e-09   7.84413756e-10   1.57455837e-11
    1.67701270e-12   1.48407009e-10   2.20392628e-11   2.80307024e-03
    1.41129582e-11   3.09622266e-08   1.05665893e-11   5.90685865e-08
    2.57011287e-11   7.18882092e-08   3.83204312e-15   5.00216119e-11
    1.24257653e-11   8.52754667e-08   4.09347422e-06   1.04935343e-05
    8.69065886e-09   3.57686455e-13   2.16381268e-09   9.96628702e-01
    1.59893476e-09   2.99069864e-16   7.84162655e-17   4.00561294e-05
    1.27992994e-09   3.05950404e-11   4.11687698e-12   1.13755227e-07
    5.11358958e-04]]
Log Policy eval: 
[[-14.05404091 -19.8509655  -13.12709618 -10.9999733  -16.27555656
   -6.60219622 -26.04598045 -17.82873344  -4.55584192 -16.46702385
  -33.24271774 -20.72463989 -25.47173119 -20.35434914 -13.83439255
   -0.29889739 -19.82932472 -16.53015327 -18.11876488 -25.46017075
  -20.82542038 -19.81608391 -17.51898003 -30.34156036 -20.15196609
  -12.27937222 -15.0872736  -19.15794945 -18.91577911 -13.36119938
  -22.3158493   -3.60744715 -21.71053886 -41.17642975 -16.58165741
  -21.55607033 -18.52522469 -26.62228775 -26.66054535  -1.54234755
   -5.20760584]]
Action: 0.75
Enter Reward: 0
Backpropping 

Session Number 19
images_for_training/293
(1, 64, 64, 3)
Policy eval: 
[[  3.50444680e-29   0.00000000e+00   0.00000000e+00   8.87840352e-20
    4.46672884e-34   0.00000000e+00   0.00000000e+00   0.00000000e+00
    4.16273932e-24   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.14556944e-16
    0.00000000e+00   1.35099037e-31   1.60599037e-28   2.64485189e-36
    6.00120264e-26   0.00000000e+00   6.83451931e-29   0.00000000e+00
    0.00000000e+00   1.67836475e-27   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.24269840e-30   0.00000000e+00   1.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.72089352e-36
    3.58908270e-38]]
Log Policy eval: 
[[ -90.30664825 -118.94171906  -94.9130249   -71.73735046  -69.63674927
   -95.67028809 -126.33600616  -87.65149689  -70.17586517  -84.13465881
  -107.52384949 -105.58116913 -124.81684875 -125.96485901 -108.91439819
   -25.72476196  -31.39797211 -108.98551178  -74.82530212  -68.11999512
  -118.69374847  -86.7230072   -78.92927551 -144.69985962  -67.41950989
   -65.06604004  -74.74299622  -77.67093658  -69.25074768  -92.87057495
   -95.23970032  -22.43254089  -95.51383972 -134.58444214  -78.08773041
   -78.43367767 -102.23192596 -141.81576538 -107.31895447  -86.17299652
     0.        ]]
Action: 1.55
Enter Reward: 0
Backpropping 

Session Number 20
images_for_training/274
(1, 64, 64, 3)
Policy eval: 
[[  8.69106948e-02   0.00000000e+00   3.92061123e-12   0.00000000e+00
    0.00000000e+00   0.00000000e+00   3.50711150e-36   1.71558897e-17
    5.14641307e-20   2.67046042e-30   0.00000000e+00   5.39526184e-07
    0.00000000e+00   1.15766524e-37   8.88557238e-32   1.67472217e-10
    0.00000000e+00   2.86632030e-07   1.37778546e-37   0.00000000e+00
    3.10410893e-35   1.37058948e-20   3.44347411e-31   1.51316670e-37
    0.00000000e+00   5.87052718e-14   3.70085046e-10   1.52060303e-21
    2.95853775e-29   0.00000000e+00   7.86879163e-31   9.13088381e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   3.47612143e-26
    6.49793895e-27   0.00000000e+00   1.64138117e-29   1.57148565e-11
    2.63129571e-08]]
Log Policy eval: 
[[ -4.95567436e+01  -1.28532349e+02  -1.06476776e+02  -1.10049339e+02
   -9.84377899e+01  -8.97517853e+01  -1.46588486e+02  -7.50253906e+01
   -9.54357452e+01  -8.57751236e+01  -1.30748398e+02  -1.19941475e+02
   -1.44959534e+02  -1.04265396e+02  -1.09087593e+02  -1.31939471e-01
   -1.09365028e+02  -1.04890671e+02  -4.63589211e+01  -5.16020164e+01
   -7.90545502e+01  -1.00247620e+02  -7.18619919e+01  -7.03694992e+01
   -6.52047653e+01  -1.55831192e+02  -5.88756714e+01  -1.03052933e+02
   -1.07529732e+02  -4.36433754e+01  -1.12338516e+02  -2.09065676e+00
   -1.71251587e+02  -2.14961502e+02  -5.35932198e+01  -6.74326172e+01
   -1.22776497e+02  -1.87868973e+02  -1.33595535e+02  -5.02998848e+01
   -7.17944946e+01]]
Action: 0.8
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 21
images_for_training/66
(1, 64, 64, 3)
Policy eval: 
[[  1.58899784e-04   5.82515512e-37   1.08047112e-16   3.77008164e-37
    0.00000000e+00   5.13889361e-31   0.00000000e+00   1.85784807e-18
    1.25298921e-11   7.74903065e-28   1.81310522e-37   3.31107799e-24
    0.00000000e+00   0.00000000e+00   8.07106443e-29   1.51959727e-33
    2.12719203e-25   0.00000000e+00   1.53330023e-16   3.74212762e-29
    2.15041340e-31   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.30035733e-38   5.12162200e-35   2.76054395e-23   0.00000000e+00
    8.20855655e-36   2.86043741e-20   4.46133828e-33   9.99841094e-01
    0.00000000e+00   0.00000000e+00   2.91627607e-35   6.93559883e-27
    0.00000000e+00   0.00000000e+00   3.69432582e-38   1.25596807e-15
    6.89750468e-18]]
Log Policy eval: 
[[ -53.73350143 -109.21112061  -81.58966064  -81.15061951  -78.50665283
   -51.80534363 -116.22962952 -133.88381958  -51.74802017  -50.33408356
  -126.67050171 -121.97780609 -134.36872864  -95.18634033  -56.94539261
   -45.3458519  -106.2877655   -69.41459656  -90.7000885   -99.71790314
   -85.467659   -135.82385254  -76.08583832 -149.00064087  -81.52058411
   -82.01251221  -67.09283447  -94.02561951 -107.76031494  -82.44975281
  -100.6990509     0.         -138.5058136  -158.38652039  -56.55794525
   -67.03147888  -84.18447876 -146.9176178  -103.92996979  -76.82437134
   -65.51670837]]
Action: 2.0
Enter Reward: 0
Backpropping 

Session Number 22
images_for_training/275
(1, 64, 64, 3)
Policy eval: 
[[  1.06197305e-03   0.00000000e+00   3.29343413e-24   2.76901418e-10
    6.04966457e-21   4.29108528e-12   1.22343798e-26   1.53517834e-12
    6.50257961e-15   4.04048734e-07   2.56375346e-18   3.34850439e-23
    0.00000000e+00   1.46094576e-31   3.43409492e-20   1.19871208e-13
    9.83158406e-03   4.75513521e-24   4.44502579e-38   2.45641679e-37
    1.03080831e-03   6.50507936e-17   9.81676224e-29   4.00960477e-32
    1.78350675e-23   1.13169762e-27   8.57788563e-01   8.66618062e-12
    1.61918836e-30   6.48767713e-26   1.02729036e-27   3.49258397e-26
    0.00000000e+00   1.08236517e-33   5.43579797e-32   3.86314712e-21
    2.29260732e-19   0.00000000e+00   2.21203868e-21   1.30286649e-01
    2.91508923e-13]]
Log Policy eval: 
[[ -3.99343153e-05  -1.11038071e+02  -6.80556564e+01  -7.54875412e+01
   -4.60949478e+01  -6.47145767e+01  -1.35017944e+02  -1.11646912e+02
   -6.39215546e+01  -1.05214104e+02  -1.50950638e+02  -1.06837090e+02
   -6.97227783e+01  -1.15818886e+02  -1.01448067e+02  -2.09809437e+01
   -3.02737598e+01  -1.33539078e+02  -3.23166428e+01  -1.24611458e+02
   -5.02138023e+01  -6.32764130e+01  -9.87881088e+01  -1.00222107e+02
   -1.18181358e+02  -5.58910751e+01  -1.49859257e+01  -8.11500168e+01
   -1.04193214e+02  -1.08029297e+02  -8.52381439e+01  -1.02270374e+01
   -1.59523788e+02  -1.29049149e+02  -1.20312653e+02  -2.73699970e+01
   -1.11601448e+02  -1.33858414e+02  -9.04139938e+01  -4.63484077e+01
   -1.26122379e+01]]
Action: 1.3
Enter Reward: 0
Backpropping 

Session Number 23
images_for_training/180
(1, 64, 64, 3)
Policy eval: 
[[  7.57814705e-01   4.52630251e-04   4.02767037e-04   1.53099035e-03
    5.77974315e-05   4.20552492e-03   3.34033916e-06   8.58710380e-04
    2.20200922e-02   1.93706393e-04   6.66550623e-05   1.13455804e-04
    1.98685229e-04   1.89970456e-06   1.47293380e-04   9.92194284e-04
    8.19643959e-02   1.11429574e-04   2.96953577e-03   2.72511243e-04
    5.88545692e-04   6.54590433e-04   2.64553346e-05   1.36828632e-04
    1.61259577e-05   1.19742565e-03   1.00105498e-02   2.36582418e-04
    8.18816887e-04   5.33494349e-05   4.17696901e-06   9.46211964e-02
    4.89756360e-08   7.28921464e-07   1.57746363e-05   9.85297258e-04
    1.02342738e-05   9.36397441e-07   2.10992264e-04   1.25375073e-02
    3.49524477e-03]]
Log Policy eval: 
[[ -5.70031881 -13.60959435  -9.95792103 -10.60793781  -9.80256557
   -4.97687721 -10.09151363  -7.07190514 -10.00154686 -10.07276726
  -10.67038536  -9.86054039 -14.57719326  -9.68058205  -8.32490635
   -5.81292582  -6.04586697  -8.8210535   -6.88563061  -8.50224209
   -6.2907033   -6.62187576  -9.08893585  -9.86171532  -9.90600872
   -5.84052324  -4.435287    -8.96852207  -7.60040951 -11.6179266
   -9.25775528  -0.0705614  -12.07548332 -13.30307674  -6.57039309
   -5.7980566  -10.0749445  -14.33986378 -13.62110996  -3.85213566
   -5.28593826]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 24
images_for_training/231
(1, 64, 64, 3)
Policy eval: 
[[  4.48216903e-14   4.17416621e-34   0.00000000e+00   6.87488573e-38
    6.22446494e-22   4.33701116e-23   0.00000000e+00   0.00000000e+00
    2.30499888e-20   3.78511927e-30   0.00000000e+00   6.00716877e-37
    0.00000000e+00   4.52179755e-25   1.49574654e-23   2.83086782e-17
    0.00000000e+00   0.00000000e+00   6.04567947e-28   0.00000000e+00
    1.78159830e-22   8.23300877e-20   2.04431915e-30   0.00000000e+00
    0.00000000e+00   2.30713557e-21   5.56425474e-35   9.56484381e-23
    0.00000000e+00   2.82202243e-35   3.02494576e-34   9.99969244e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   6.61323975e-27
    3.07310765e-05]]
Log Policy eval: 
[[ -29.99159241 -191.84037781 -113.03251648  -84.86446381 -163.94346619
   -32.14505005 -135.22631836  -70.66067505  -53.21439362 -130.16711426
  -157.92773438  -46.37885284 -159.22001648 -104.54699707 -127.37306976
   -90.62527466 -111.7130127  -148.33215332 -102.07858276 -121.11698914
   -85.93288422  -83.19858551 -120.14710999 -147.86419678 -128.91723633
  -117.49940491  -56.84291077 -107.00554657 -118.76087189  -82.43891907
  -138.39907837  -71.22298431 -167.58294678 -214.4559021  -113.60377502
  -100.18728638  -81.42948914 -268.58435059 -137.75526428    0.
   -70.18563843]]
Action: 1.3
Enter Reward: 0
Backpropping 

Session Number 25
images_for_training/186
(1, 64, 64, 3)
Policy eval: 
[[  9.94273961e-01   1.00170774e-10   4.03409649e-06   4.99974647e-07
    2.62120037e-09   9.13354597e-05   3.05417691e-09   1.14176294e-06
    2.25368035e-09   2.61962612e-07   2.29667108e-09   6.87621622e-08
    1.52660065e-10   6.58812604e-09   4.99795156e-08   1.25057813e-05
    2.56045463e-10   2.29842834e-09   1.06008486e-06   7.56616373e-07
    2.96169816e-07   1.07505244e-07   3.93789122e-07   5.00201169e-09
    2.30366777e-06   2.41711200e-06   6.89624634e-04   1.31820098e-05
    2.65075446e-08   3.52331249e-08   9.29903052e-08   3.84483300e-03
    3.91479869e-11   2.51053085e-12   1.75813331e-09   2.33489641e-06
    8.91890409e-07   4.39343050e-12   6.16060467e-11   2.45217270e-05
    1.03333464e-03]]
Log Policy eval: 
[[ -6.15158224 -26.03109932 -10.59785175 -15.94950294 -15.04555511
  -13.20322609 -17.0611248  -14.97287941 -19.53068352 -14.15831184
  -22.99279594 -20.59088898 -24.27891159 -11.77672577  -7.71646261
  -10.42224884 -21.29876709 -13.57185936 -14.36602116 -19.03822899
  -11.6595211  -14.45991135 -11.87379265 -21.47578239 -17.30071831
   -8.59706879 -10.0639925  -14.85028458 -17.96311378 -20.75191116
  -22.03130341  -0.02937728 -21.72719002 -24.48033142 -15.80868912
  -11.9212513  -11.68233013 -25.42866898 -19.01368523  -3.65150285
   -9.25433636]]
Action: 0.95
Enter Reward: 0
Backpropping 

Session Number 26
images_for_training/45
(1, 64, 64, 3)
Policy eval: 
[[  9.87456143e-01   0.00000000e+00   1.00252362e-09   0.00000000e+00
    3.96549837e-38   2.63244746e-23   0.00000000e+00   0.00000000e+00
    8.36851337e-24   1.65535341e-34   0.00000000e+00   0.00000000e+00
    3.86942559e-32   0.00000000e+00   6.34137991e-35   0.00000000e+00
    6.26469472e-08   3.67312039e-20   1.88785352e-30   1.84905849e-31
    1.98652679e-26   5.13080693e-34   0.00000000e+00   1.60041726e-37
    2.48399973e-37   1.99123823e-26   1.96126559e-10   0.00000000e+00
    2.39768515e-15   0.00000000e+00   6.77405797e-31   1.25437016e-02
    0.00000000e+00   0.00000000e+00   1.64418721e-36   0.00000000e+00
    8.96874182e-28   0.00000000e+00   1.18758784e-30   3.30895276e-08
    1.01969324e-27]]
Log Policy eval: 
[[   0.         -143.96586609  -79.12068176 -138.33169556 -133.99778748
   -94.2180481  -139.20854187 -144.56332397 -117.39762878 -109.9614563
  -168.98712158  -90.49062347 -154.53106689 -138.39094543 -138.00842285
   -98.56427002  -79.88179016 -110.4414978  -132.81744385  -92.72814941
  -138.05638123 -109.41620636 -130.23034668 -129.54510498 -112.64594269
  -153.99716187  -45.76421356 -166.58088684 -109.70570374  -99.93460083
  -114.88375092  -47.9211731  -148.31742859 -186.48049927 -106.2370224
   -65.32807159 -115.10850525 -185.75309753 -119.08139038  -78.62310791
  -102.33381653]]
Action: 1.3
Enter Reward: 1
Backpropping 

Session Number 27
images_for_training/155
(1, 64, 64, 3)
Policy eval: 
[[  7.25514770e-01   1.49827954e-07   1.76041591e-04   1.92025944e-03
    8.56930285e-07   3.16359475e-02   2.18994956e-06   3.86216911e-04
    1.33523415e-03   1.75966736e-04   1.24030412e-05   9.41646704e-07
    1.12707075e-05   1.97299028e-06   2.09302510e-04   1.26592226e-06
    1.23854179e-03   3.07582610e-04   6.29766073e-05   2.17152148e-04
    3.94264469e-03   2.43072236e-06   1.80810480e-03   2.13306630e-05
    2.48733468e-05   2.29590678e-05   1.85654104e-01   1.01099840e-05
    4.55592340e-03   1.50203596e-06   1.99185361e-05   1.59310084e-03
    2.83172244e-06   1.26367513e-06   6.57343335e-05   5.24458359e-04
    1.27630320e-03   5.15207103e-06   1.39962439e-03   3.52990814e-02
    5.57468738e-04]]
Log Policy eval: 
[[ -1.39387643  -9.54607391  -5.40324688  -7.18241072 -11.12798023
   -0.91859281 -12.00979519  -8.33651733  -6.69767618  -7.86465931
  -11.54478168  -3.37832069  -6.61929655  -7.72738409 -10.52754307
   -7.95648384  -4.84671497  -8.18245316  -8.94379807  -8.88308048
   -9.31110287 -11.10553741  -8.04315662  -9.27718449  -8.13029385
   -8.91054249  -1.61529577  -9.75587082  -6.08647299  -9.0777359
  -10.1630125   -3.75452566 -12.86222649 -12.45944977  -9.72760201
   -7.2928586   -4.96734142 -14.63242149  -6.81008434  -2.73702145
   -6.39142084]]
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 28
images_for_training/271
(1, 64, 64, 3)
Policy eval: 
[[  1.11038230e-01   2.02466086e-21   9.82891102e-09   4.15900338e-25
    2.06857683e-19   3.62639253e-06   9.63886648e-22   3.40967987e-12
    2.26675449e-11   1.64201297e-19   2.40541326e-17   2.84662804e-09
    3.72144816e-22   2.94034990e-22   1.21413529e-18   8.18349333e-10
    7.36121345e-18   2.21349453e-10   1.26106461e-21   4.15778743e-15
    8.88925731e-01   7.67125252e-12   7.77653820e-13   1.84423200e-16
    2.08238373e-20   3.83173221e-17   3.23292043e-05   3.37272235e-15
    1.34073606e-24   1.76973677e-14   7.83723481e-16   2.71705723e-14
    7.87039820e-24   4.85311084e-29   2.09181918e-19   2.23062942e-14
    1.54855027e-16   1.17601281e-18   1.80247867e-17   1.30969681e-07
    1.13520382e-09]]
Log Policy eval: 
[[ -2.95592823e+01  -1.00548820e+02  -4.40654755e+01  -5.87084427e+01
   -5.83860168e+01  -3.07493801e+01  -6.29989471e+01  -4.32431335e+01
   -4.84767761e+01  -5.51827545e+01  -7.21638565e+01  -5.66034927e+01
   -8.45181274e+01  -6.88897247e+01  -4.96727943e+01  -5.68217010e+01
   -4.64762726e+01  -6.10310745e+01  -5.80297394e+01  -5.89218483e+01
   -5.19891930e+01  -5.05147362e+01  -6.38432121e+01  -7.38519669e+01
   -6.10263824e+01  -4.44837799e+01  -5.96044674e-06  -6.06347351e+01
   -3.38883247e+01  -5.08643074e+01  -5.54673042e+01  -1.83260517e+01
   -3.70370560e+01  -6.88390198e+01  -9.10087051e+01  -4.91823349e+01
   -5.13960724e+01  -7.68682480e+01  -6.09155922e+01  -1.20225658e+01
   -1.93879566e+01]]
Action: 1.25
Enter Reward: 0
Backpropping 

Session Number 29
images_for_training/146
(1, 64, 64, 3)
Policy eval: 
[[  1.48161173e-01   1.85666548e-04   4.84534204e-02   3.96263925e-03
    1.36203389e-03   2.96286736e-02   5.25286945e-04   1.66798185e-03
    4.84470883e-03   2.01393031e-02   1.45764980e-05   6.33601891e-03
    4.67361417e-04   3.26498994e-04   8.70024506e-03   2.26828095e-04
    9.69921798e-02   1.59916412e-02   2.03104317e-03   1.28379290e-03
    8.46913143e-04   7.44177014e-05   2.30336632e-03   3.28886264e-04
    3.10294447e-03   1.21804681e-02   4.37950850e-01   1.30270456e-03
    3.62328067e-03   1.81375537e-03   9.88178654e-05   1.72920693e-02
    3.12099903e-04   7.17598668e-05   3.20306543e-04   1.78101903e-03
    8.04844499e-03   2.34173172e-06   5.06002456e-04   5.53709902e-02
    6.13674819e-02]]
Log Policy eval: 
[[-0.18840834 -7.00782108 -4.81360292 -4.94245911 -7.53804731 -4.04683685
  -6.67492294 -7.4636817  -3.77327967 -5.91663599 -8.23430538 -5.75851011
  -6.36383486 -5.66434383 -6.31154108 -5.43048191 -6.75910473 -6.0317421
  -6.65816259 -7.77598667 -5.40837288 -7.01459122 -4.73498011 -7.64160919
  -6.49202394 -6.23562717 -4.03937387 -6.43028402 -6.15394592 -7.04032278
  -9.74997425 -4.04399157 -9.189785   -8.2047224  -6.60156918 -6.01668453
  -4.36490679 -8.46982193 -5.67127657 -6.04140234 -4.69570017]]
Action: 0.8
Enter Reward: 0
Backpropping 

Session Number 30
images_for_training/244
(1, 64, 64, 3)
Policy eval: 
[[  9.48569402e-02   4.42521159e-10   1.49437916e-02   1.47901778e-03
    1.19385501e-09   7.14395791e-02   1.22076514e-07   3.28546932e-08
    8.55482998e-04   3.27000862e-08   1.58341269e-08   5.00540657e-04
    2.75152095e-04   4.08850356e-05   2.09536974e-08   3.18931853e-10
    4.33202542e-04   5.68220457e-06   4.13441603e-06   9.82457641e-05
    1.88330667e-08   9.09237130e-08   1.70635121e-06   1.84978959e-11
    5.61454499e-07   1.39583187e-06   7.11175442e-01   2.30942198e-04
    1.43988570e-03   2.78193397e-07   6.32717615e-07   8.71533528e-04
    6.11992164e-08   1.59177706e-11   2.04933202e-03   6.31590297e-07
    1.95634039e-03   1.24604992e-06   1.67806546e-09   9.56410319e-02
    1.69598532e-03]]
Log Policy eval: 
[[ -1.74709875e-02  -9.74704647e+00  -7.36331224e+00  -6.74024153e+00
   -1.44444771e+01  -1.12164202e+01  -2.31617355e+01  -1.31068449e+01
   -1.17611570e+01  -1.30481367e+01  -2.41619987e+01  -1.59041138e+01
   -2.19609966e+01  -9.09038639e+00  -1.55724564e+01  -2.12035732e+01
   -1.31692152e+01  -1.26035929e+01  -1.97511864e+01  -1.25767136e+01
   -2.10443497e+01  -2.37002010e+01  -1.37429771e+01  -1.70131416e+01
   -2.00633545e+01  -1.04935226e+01  -5.99231768e+00  -9.60230446e+00
   -1.05601501e+01  -2.12440090e+01  -2.08476162e+01  -8.17192936e+00
   -3.35898285e+01  -2.95717773e+01  -1.79840698e+01  -1.74499550e+01
   -1.44532366e+01  -2.86374493e+01  -2.47950573e+01  -4.92598486e+00
   -5.27113295e+00]]
Action: 1.55
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 31
images_for_training/28
(1, 64, 64, 3)
Policy eval: 
[[  1.51385918e-01   7.18557509e-03   3.20747815e-04   4.12578171e-04
    3.81471637e-06   7.99147936e-04   7.46155820e-07   1.41658311e-04
    1.09599176e-04   2.36532811e-04   7.88323450e-06   1.84871635e-06
    5.33664606e-05   4.06433583e-06   1.15171890e-04   1.90461342e-05
    2.12015346e-01   6.73800008e-03   7.77994690e-04   8.96067009e-04
    4.12979687e-04   1.11502923e-05   1.26822351e-05   3.76555727e-05
    1.88467035e-04   1.21810380e-02   1.96974631e-02   6.65717525e-05
    6.49044669e-05   8.14596278e-05   1.56575570e-05   5.78936815e-01
    1.49086915e-07   4.30119508e-06   7.18296797e-04   1.33357139e-03
    1.43404555e-04   3.64048265e-06   2.61774147e-03   1.12760870e-03
    1.11934112e-03]]
Log Policy eval: 
[[ -0.58483386  -9.24951935  -8.58290005  -8.24846935 -11.96882343
   -4.32796383 -11.91764832  -7.39816475 -10.61832905  -8.96043777
  -11.05243301  -7.32634258 -10.76029491  -5.05655098  -9.36750031
   -7.8059721   -7.13611698 -10.39665127  -6.97550678  -3.91432357
   -9.2015934   -8.26922989  -7.20362854  -8.79848576 -12.25866413
   -6.71561623  -3.25114274  -5.77917385  -7.18148041 -10.16651249
  -11.78416729  -1.10066485 -10.36194134 -14.26436234  -4.82905293
   -8.29539108  -5.23168087 -14.51322079 -11.24679756  -4.8790369
  -10.44579315]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 32
images_for_training/63
(1, 64, 64, 3)
Policy eval: 
[[  1.26385435e-01   4.28812655e-06   5.96801285e-04   1.32752454e-03
    4.61281570e-06   4.01389599e-03   3.60039092e-04   3.25077190e-03
    2.67397518e-05   9.74928495e-04   1.81522584e-04   5.96157292e-07
    2.93795529e-05   1.94468303e-05   3.54321674e-03   3.77756777e-07
    2.65151821e-02   1.23719666e-02   9.66191366e-02   1.68944690e-02
    4.91512427e-03   6.78649740e-05   5.38864297e-05   5.19028399e-05
    1.01092004e-03   2.76593096e-03   4.17445034e-01   1.07567132e-06
    2.08869053e-04   4.55267774e-03   7.36612492e-05   1.00750662e-02
    8.44480019e-06   2.67910173e-06   2.50902474e-01   7.91503815e-04
    1.80775067e-04   7.39850975e-07   4.56188485e-04   1.30899148e-02
    2.24814328e-04]]
Log Policy eval: 
[[ -5.51009274e+00  -1.56930151e+01  -9.60546875e+00  -1.35032129e+01
   -1.76015396e+01  -5.74593353e+00  -1.50201540e+01  -1.18649197e+01
   -1.78716488e+01  -1.52448912e+01  -1.89917278e+01  -1.03137751e+01
   -1.51632309e+01  -1.42019730e+01  -1.57245998e+01  -1.62584572e+01
   -1.07316885e+01  -8.73603630e+00  -1.22017612e+01  -1.57507629e+01
   -6.84353065e+00  -1.53194084e+01  -1.04564714e+01  -1.57722178e+01
   -1.45549946e+01  -1.27651491e+01  -9.32906009e-03  -1.97515125e+01
   -1.96658211e+01  -1.20126677e+01  -1.62900867e+01  -1.09098339e+01
   -1.92424145e+01  -1.82518539e+01  -7.80796432e+00  -1.25018291e+01
   -1.25081358e+01  -2.11759491e+01  -1.07958527e+01  -8.96169662e+00
   -9.72549248e+00]]
Action: 0.25
Enter Reward: 0
Backpropping 

Session Number 33
images_for_training/280
(1, 64, 64, 3)
Policy eval: 
[[  9.66805601e-05   8.91843229e-06   7.55760681e-08   8.58444473e-05
    3.24042730e-08   2.99295389e-05   1.59823443e-07   8.72341916e-02
    3.19548086e-08   5.78144522e-07   4.35847358e-09   1.36890803e-05
    2.37938611e-08   1.28247635e-08   1.26063526e-07   3.30338116e-06
    1.43835638e-02   1.22494503e-05   3.30358627e-04   1.24223423e-08
    8.83602202e-01   6.07203901e-07   1.35941286e-06   1.03618678e-08
    6.91953005e-07   1.70973959e-04   2.79923039e-03   1.14512034e-06
    1.85679667e-08   2.09133650e-05   3.71788502e-07   1.25703868e-03
    2.31397974e-11   5.01376519e-07   1.21120924e-04   9.24455002e-03
    2.70915046e-09   1.19927721e-08   2.67476062e-05   1.96280189e-06
    5.50841680e-04]]
Log Policy eval: 
[[ -7.92326498  -7.39339113  -9.69001484  -9.98226738 -13.68110657
   -5.81271362  -6.99193335  -7.84640074  -5.73936939 -11.78150845
  -11.04570675 -13.10173416  -9.97097969 -12.52888012  -5.90603447
   -9.57500744  -0.74976826  -7.27371788  -9.6714983  -14.93698692
   -3.4672308   -8.90978336 -10.75603676 -15.21873951  -8.81190777
   -0.75866318  -4.82143879  -6.5359478  -15.36909008  -8.31001282
  -13.70371628  -7.31894493 -17.52811813 -16.83308029  -9.6507349
   -5.61198425 -15.9729147  -15.96377087  -6.72164679 -10.2349844
   -9.03140926]]
Action: 1.3
Enter Reward: 0
Backpropping 

Session Number 34
images_for_training/81
(1, 64, 64, 3)
Policy eval: 
[[  1.57916371e-03   2.98451196e-04   8.85513364e-05   1.19364136e-04
    2.49127857e-04   4.53417003e-03   8.71190103e-04   7.23753721e-02
    2.68678088e-03   4.16639680e-03   1.03730394e-03   1.19321176e-03
    2.41617221e-04   4.72004940e-05   5.23679017e-04   1.15205163e-04
    6.14708900e-01   1.75262697e-03   3.17353080e-03   4.61473083e-03
    1.57854334e-02   5.25478274e-03   1.28390621e-02   7.88465914e-05
    3.74935509e-04   2.83216927e-02   9.03685465e-02   1.54625867e-02
    5.27670549e-04   3.02524287e-02   2.12925279e-05   4.11490090e-02
    4.48779865e-05   5.27948623e-06   2.79182161e-04   2.96054827e-03
    4.01188532e-04   1.76051282e-04   1.96648971e-03   2.61962786e-03
    3.67338546e-02]]
Log Policy eval: 
[[-2.76175833 -2.39605713 -4.19763803 -3.85859966 -8.11592293 -3.0247345
  -8.34596443 -3.37757874 -4.62919998 -4.71748924 -4.95412207 -5.39241695
  -4.57816887 -9.01733875 -6.90323591 -5.92737055 -1.92173636 -3.2845335
  -4.03557634 -3.76625061 -5.94269991 -6.3835187  -9.50582123 -7.45350266
  -3.76261806 -1.6664139  -5.51645422 -6.32049704 -3.33614254 -3.54659986
  -5.73384953 -2.85692263 -7.38623667 -8.57980251 -4.75539494 -4.80630922
  -4.58022022 -7.53638458 -6.15984249 -2.6368165  -4.92057085]]
Action: 1.3
Enter Reward: 1
Backpropping 

Session Number 35
images_for_training/148
(1, 64, 64, 3)
Policy eval: 
[[ 0.02741952  0.06336997  0.02471831  0.02442804  0.00953259  0.04557916
   0.0131655   0.04118578  0.01806917  0.01941853  0.01087637  0.02594665
   0.01272084  0.0092053   0.0118207   0.01586285  0.06622179  0.04307887
   0.01708417  0.03233851  0.02029732  0.03700807  0.01355858  0.0051292
   0.01479247  0.02691061  0.02786005  0.00941276  0.01449551  0.04297854
   0.01674479  0.05318962  0.00740378  0.01219243  0.027744    0.02616114
   0.01921518  0.00586145  0.01227668  0.02894795  0.04577724]]
Log Policy eval: 
[[-2.17537642 -3.62479544 -3.3300972  -4.32807922 -4.59258747 -2.53756213
  -3.77653313 -3.68585205 -3.61003065 -3.4074502  -4.47811508 -3.49935865
  -4.72110605 -4.23727798 -4.04757261 -3.74469709 -3.69338036 -3.83648896
  -3.3886323  -4.51147366 -3.49136877 -4.05049419 -3.45225191 -4.21792603
  -4.55725384 -3.34298444 -2.89287353 -3.78777766 -3.75186014 -4.06569862
  -3.71444988 -3.48850632 -5.87331629 -5.49697828 -4.25540113 -4.90664577
  -4.10069847 -4.93911362 -3.90124178 -4.80525112 -3.82090378]]
Action: 0.6
Enter Reward: 0
Backpropping 

Session Number 36
images_for_training/119
(1, 64, 64, 3)
Policy eval: 
[[ 0.01890282  0.02581856  0.0139099   0.03254024  0.02286293  0.0530145
   0.03560938  0.04351405  0.0199945   0.02544501  0.01139637  0.01845042
   0.01123504  0.02223835  0.02855763  0.02096877  0.03553523  0.02344952
   0.02525004  0.01451732  0.05658693  0.01760717  0.01904896  0.01634412
   0.0251071   0.04825314  0.0244515   0.01970394  0.02477337  0.01964508
   0.01430839  0.02126944  0.01132713  0.00722799  0.03305057  0.03855876
   0.01393162  0.01299301  0.0171276   0.03062052  0.02485305]]
Log Policy eval: 
[[-2.78081059 -3.13801599 -3.51468396 -3.84939766 -4.33981419 -3.42011166
  -4.2700882  -2.26259923 -3.53708124 -4.05185986 -4.05800724 -4.01625824
  -4.31321096 -4.14136982 -4.29840946 -4.21124506 -2.72949862 -3.87714577
  -3.48224044 -3.93499255 -4.33580685 -3.70149469 -4.43101597 -4.10556555
  -4.2464838  -3.38813424 -3.43981051 -3.78423715 -4.05174112 -4.32671738
  -4.94493866 -3.4758606  -4.96297646 -4.75302696 -4.12152863 -3.4998045
  -4.34506416 -4.448071   -3.75630927 -3.87764931 -3.33668089]]
Action: 1.05
Enter Reward: 0
Backpropping 

Session Number 37
images_for_training/44
(1, 64, 64, 3)
Policy eval: 
[[  3.34435664e-02   1.90766841e-01   3.52750416e-03   1.53421611e-03
    1.85671856e-03   1.16844475e-01   4.62554768e-03   5.55762313e-02
    4.93789837e-03   7.00365461e-04   6.58023776e-03   1.07478257e-03
    2.71358737e-03   2.34175865e-02   2.37196758e-02   7.14074261e-03
    2.00979714e-03   1.54838890e-01   1.60270010e-03   3.09737836e-04
    2.98993774e-02   2.61823554e-03   5.91087155e-03   1.50964735e-02
    7.69324461e-03   1.82788402e-01   6.31395057e-02   1.69963408e-02
    5.14276512e-03   4.66524652e-04   1.72217039e-03   1.49315996e-02
    1.54427136e-04   2.76063307e-04   2.70234421e-03   7.65252858e-03
    1.71939295e-03   9.71898495e-04   8.64597969e-04   2.20556089e-04
    1.81158492e-03]]
Log Policy eval: 
[[ -3.64777708  -1.14889288  -7.09539461  -6.80333757  -8.51808834
   -4.6954689  -10.77986526  -2.41195059  -7.4722271   -6.16266012
  -10.62363243  -5.2889986   -7.84353113  -6.25073433  -7.18660784
   -5.18300056  -2.28124046  -1.30501938  -3.84776402  -7.8499794
   -5.05145741  -6.0438962   -8.70241451  -5.40754652  -4.04364395
   -3.50271034  -6.27738905  -4.42268658  -7.06341791  -5.59066296
  -11.00311279  -4.44015694  -8.15263557  -9.92771149  -4.1708498
   -6.34690619  -4.02299881  -7.18671989  -8.32558823  -8.48828316
   -4.10027409]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 38
images_for_training/174
(1, 64, 64, 3)
Policy eval: 
[[ 0.03415433  0.02266259  0.03051239  0.020544    0.02522981  0.03298761
   0.01885061  0.02580216  0.02529388  0.02774496  0.01885626  0.02894158
   0.02204504  0.01796834  0.02057629  0.02457225  0.03048823  0.02562456
   0.02547158  0.02294711  0.02476642  0.02576802  0.02704701  0.02330115
   0.02265267  0.03004959  0.02532538  0.02608745  0.0272096   0.02374399
   0.02410225  0.02309376  0.01614663  0.01426563  0.01924676  0.0261554
   0.02647935  0.02059371  0.02446112  0.02411007  0.02412042]]
Log Policy eval: 
[[-3.32383823 -3.5486505  -4.06145382 -3.56610847 -3.68317652 -3.47146559
  -3.86068344 -3.63997459 -3.63387918 -3.54862833 -4.08744621 -4.19010544
  -3.77808762 -3.78294802 -3.7446425  -3.92900133 -3.20265365 -3.90434599
  -3.29679155 -3.75423717 -3.77492809 -4.08194304 -3.75580263 -3.70915413
  -3.7679882  -3.5394628  -3.64145684 -3.63058448 -3.57988834 -3.84883022
  -4.08745289 -3.74914598 -4.0146122  -4.06137133 -3.83287549 -3.71633387
  -3.64691591 -4.10092449 -3.65007663 -3.65322852 -3.46926093]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 39
images_for_training/41
(1, 64, 64, 3)
Policy eval: 
[[ 0.16605188  0.08161137  0.00197626  0.00897382  0.00183332  0.03839986
   0.00605632  0.00874967  0.00970745  0.00476774  0.00310849  0.01498354
   0.00305697  0.00403434  0.00079161  0.00467484  0.01096555  0.01248417
   0.06347843  0.02881548  0.28229141  0.00729497  0.0021795   0.00152805
   0.05807089  0.0056611   0.01579365  0.01392841  0.00433207  0.00413571
   0.00787237  0.05990284  0.00138821  0.0017481   0.00490679  0.01284691
   0.00640743  0.0002925   0.01711641  0.00385321  0.0139283 ]]
Log Policy eval: 
[[-5.87189674 -2.16818953 -4.3450737  -4.75040197 -6.1347456  -2.34085369
  -4.72075462 -2.63486433 -4.19773006 -3.01588416 -6.15280342 -5.88280296
  -4.74575949 -5.7862463  -4.3471756  -5.34420013 -2.35193253 -4.35116053
  -3.42907429 -2.55157399 -6.25194693 -5.56341171 -3.97349358 -6.58849287
  -6.92967844 -2.80555558 -2.82834077 -4.81292057 -3.80731583 -3.76899934
  -6.03226995 -3.2277534  -7.46663523 -8.71427917 -5.95601797 -2.68143797
  -6.3631072  -6.05796337 -4.58849287 -4.61511183 -3.59835219]]
Action: 0.8
Enter Reward: 1
Backpropping 

Session Number 40
images_for_training/277
(1, 64, 64, 3)
Policy eval: 
[[  3.39670181e-02   2.40600156e-03   4.43018245e-04   6.66867476e-03
    1.28053260e-04   1.69238955e-01   2.68597680e-04   4.22409410e-03
    2.82386954e-05   1.46728419e-02   5.17177170e-07   3.78786906e-04
    1.69586619e-05   2.40219524e-05   7.29602543e-05   4.80663439e-04
    8.63657221e-02   1.73264896e-04   1.35927811e-01   4.33724672e-01
    2.41800677e-03   1.38698451e-04   6.76135495e-02   1.21421499e-05
    3.15914281e-06   9.89397243e-03   4.34875628e-03   2.99496378e-06
    1.31172055e-05   3.37678299e-04   5.18662432e-07   5.56925125e-03
    5.90106538e-06   6.45514708e-09   1.36366999e-03   5.17680775e-04
    1.77665036e-02   6.66564745e-07   1.21037783e-05   5.98297978e-04
    1.72523563e-04]]
Log Policy eval: 
[[ -2.78617764  -1.6693964   -6.35219336  -6.86373615 -17.59986496
   -8.31406212 -11.34487629  -3.24536228  -6.3566618   -4.70777225
  -11.74362183  -5.26399136 -11.04359245 -12.33615398  -9.21791649
  -11.82481956  -0.56411648  -6.21868896  -5.9638772   -6.19547176
   -9.6288166  -11.06864548 -10.68230724 -13.01653004  -7.00843048
   -2.26495934 -11.69932079  -5.74482584  -8.5872221   -9.64456081
  -10.71232319  -9.75405788 -12.01374817 -22.73639679  -6.53930378
  -11.1397953   -5.29044676  -8.92255402  -8.13025856  -6.80296373
  -10.68073082]]
Action: 0.35
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 41
images_for_training/130
(1, 64, 64, 3)
Policy eval: 
[[ 0.03714669  0.03847364  0.02291371  0.02699803  0.0172435   0.02592524
   0.01868024  0.02278682  0.03510932  0.0217831   0.0245751   0.02961416
   0.01930661  0.01855184  0.01925444  0.01395931  0.03873354  0.0167801
   0.03180137  0.02766566  0.02394947  0.01332599  0.03074523  0.02259858
   0.01925214  0.02232775  0.03627612  0.01692842  0.02232777  0.02945154
   0.02021327  0.02432467  0.02318777  0.0224129   0.02105384  0.02138358
   0.02222517  0.01585434  0.03143767  0.02908259  0.02433869]]
Log Policy eval: 
[[-3.40534329 -3.31156039 -3.79517746 -3.6548388  -4.21667147 -3.33186984
  -3.7761898  -3.5296073  -3.29665756 -3.90977359 -3.89618349 -3.49509215
  -3.91428757 -3.63699841 -3.89216065 -3.89252329 -3.47778893 -3.31202269
  -3.93832064 -3.95370531 -3.4294734  -3.70270157 -3.55220389 -3.76088452
  -3.62690043 -3.75435305 -3.47016072 -3.58275557 -3.88146615 -3.72780848
  -4.18414164 -3.83712673 -4.17884779 -4.27849579 -3.59637427 -3.77644134
  -4.08870411 -3.81149101 -4.13741779 -3.9538548  -3.66416216]]
Action: 0.45
Enter Reward: 0
Backpropping 

Session Number 42
images_for_training/51
(1, 64, 64, 3)
Policy eval: 
[[ 0.02794303  0.06121486  0.04182617  0.01658298  0.00100718  0.05163167
   0.0032137   0.03377764  0.00834056  0.03072487  0.00445323  0.00287053
   0.00352495  0.00284284  0.0095931   0.00757395  0.06268203  0.04590944
   0.13790633  0.01526209  0.02682576  0.01199251  0.00693909  0.00103334
   0.00432565  0.1387191   0.0046055   0.03112755  0.00433305  0.01805975
   0.00736967  0.02671741  0.00338158  0.00230578  0.04715662  0.01685694
   0.02272276  0.00697829  0.02538386  0.01683514  0.00744956]]
Log Policy eval: 
[[-1.98915851 -3.06571627 -4.20270681 -5.21374178 -5.22490025 -3.2477622
  -4.81201935 -2.92804909 -4.69821167 -2.87470436 -4.34327126 -4.91594648
  -5.29557896 -4.98655415 -2.65727949 -4.98330879 -3.51215792 -3.18495178
  -3.53090644 -5.70931101 -2.97643089 -6.34342098 -4.47748661 -4.0234828
  -4.4563117  -2.25204134 -4.5271883  -4.412673   -4.516397   -4.61782932
  -4.23605204 -5.41022205 -6.44135427 -6.28922653 -4.98983335 -4.12064457
  -4.42953348 -4.44409323 -2.84151506 -4.52910852 -3.47186089]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 43
images_for_training/275
(1, 64, 64, 3)
Policy eval: 
[[ 0.17932843  0.02885788  0.0159745   0.0109529   0.01456916  0.27306208
   0.00307034  0.02266786  0.03258755  0.04214032  0.00333391  0.00431647
   0.00164433  0.00285589  0.00170437  0.00599825  0.05644529  0.03161723
   0.01239066  0.00975863  0.01474828  0.00327587  0.01154026  0.0071635
   0.03373348  0.01911996  0.01005764  0.01769238  0.00965389  0.00366929
   0.0029379   0.00616824  0.00662256  0.00058929  0.01331752  0.026969
   0.01096374  0.00237227  0.01646953  0.00915873  0.0205006 ]]
Log Policy eval: 
[[-2.24372292 -1.71102142 -4.64722157 -5.10352993 -3.75332689 -3.72658539
  -4.76659107 -3.86120892 -3.22537661 -4.48064613 -4.3504343  -5.13389254
  -5.47645187 -4.61206341 -4.21054316 -4.39167452 -4.53617859 -3.25181484
  -4.72437477 -3.81871176 -5.13221312 -4.16349983 -4.08503914 -4.35601568
  -5.00669193 -3.06994128 -4.47280884 -3.83775687 -3.19865155 -3.92375922
  -5.11376715 -3.8505702  -5.11106205 -6.83116627 -4.53319216 -4.32851553
  -2.17389393 -4.26913166 -5.42839527 -3.73355484 -4.07662868]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 44
images_for_training/12
(1, 64, 64, 3)
Policy eval: 
[[ 0.03573077  0.02686321  0.04403927  0.01659509  0.01080516  0.06947384
   0.01589593  0.01498754  0.02465975  0.02823283  0.02522447  0.04223089
   0.00600249  0.00953169  0.00994492  0.01881336  0.04705761  0.04238259
   0.02786804  0.02994796  0.02647396  0.02078619  0.01930415  0.00917659
   0.03155743  0.0585065   0.01434249  0.02621974  0.01210052  0.02792042
   0.0237189   0.04828861  0.00749464  0.00290108  0.02710276  0.02501218
   0.00935278  0.01359379  0.01236077  0.01230265  0.02519644]]
Log Policy eval: 
[[-3.12051058 -2.59217715 -3.60293007 -4.8593688  -4.59787941 -2.51069474
  -3.62424684 -3.64862776 -3.89861751 -3.7398479  -4.01664352 -4.52693272
  -4.00728798 -5.27943611 -3.3947072  -4.17370605 -3.64541769 -2.58693457
  -3.64298177 -4.93601179 -4.10663414 -4.48410797 -3.11937809 -4.27548552
  -4.51251602 -2.63081217 -3.61994147 -3.84142184 -4.57749033 -4.3939333
  -5.1942215  -3.66860771 -5.0725975  -4.82970285 -4.78445625 -3.92606115
  -3.34591198 -4.82090759 -3.42590475 -4.40121937 -3.86057544]]
Action: 1.75
Enter Reward: 0
Backpropping 

Session Number 45
images_for_training/83
(1, 64, 64, 3)
Policy eval: 
[[ 0.02837403  0.03825336  0.02374379  0.03108524  0.01664821  0.05062454
   0.02621707  0.05258778  0.02196397  0.02861483  0.02848523  0.01639446
   0.01553866  0.01556418  0.03894712  0.0235172   0.03004068  0.0226972
   0.0493724   0.01421211  0.02507372  0.01525707  0.02604876  0.02149504
   0.02363168  0.03754155  0.02750782  0.02184338  0.01750324  0.01254984
   0.01071248  0.02087313  0.01247092  0.01194433  0.01433681  0.01062109
   0.0297532   0.03584035  0.01226751  0.01746419  0.02238187]]
Log Policy eval: 
[[-3.39828134 -4.20326042 -3.51458168 -3.72676563 -4.26138163 -3.22726679
  -4.11876297 -3.36645484 -3.81037045 -3.81542158 -3.88340068 -4.00038147
  -3.51748037 -3.79539919 -4.24067879 -4.2334733  -3.32861805 -3.27848673
  -3.78334713 -4.09067106 -3.40408111 -4.06138706 -2.8184793  -4.07865858
  -3.59265089 -3.37559795 -3.53041935 -3.60766029 -4.28312492 -3.24879861
  -4.4650569  -4.01314259 -4.34626293 -4.20548582 -4.00596285 -4.07285023
  -3.34021854 -4.20531368 -3.61306977 -3.35662937 -4.30899239]]
Action: 0.75
Enter Reward: 1
Backpropping 

Session Number 46
images_for_training/61
(1, 64, 64, 3)
Policy eval: 
[[ 0.04044711  0.02869345  0.03199884  0.05179749  0.01089993  0.09638219
   0.00602219  0.01328534  0.02647781  0.02777026  0.01072288  0.01178749
   0.01227663  0.01663949  0.02115478  0.00845898  0.0454726   0.03220522
   0.02185575  0.05011272  0.09233379  0.01733077  0.01506004  0.00567348
   0.01623887  0.03190999  0.01912349  0.02001457  0.02796141  0.01977035
   0.00862339  0.04024711  0.00356483  0.00601232  0.01812804  0.02652007
   0.00697221  0.00687597  0.02001569  0.02101098  0.01215144]]
Log Policy eval: 
[[-2.68464637 -2.46657515 -3.64451575 -4.18907356 -4.66988945 -2.515064
  -4.55380774 -4.67722511 -3.90489626 -4.40392876 -4.57994032 -4.45126438
  -4.46714497 -4.31609821 -3.30798984 -3.81905675 -3.16780472 -3.05013824
  -3.34208059 -4.54604149 -3.59524441 -4.19168949 -4.26655674 -3.63765383
  -4.26226425 -2.59161496 -4.33054256 -3.85827541 -4.54475784 -3.55426812
  -3.91092682 -3.53017402 -3.74427271 -4.91238689 -4.8549571  -4.51699543
  -5.05318928 -4.29043961 -3.70226598 -4.02660799 -4.17267418]]
Action: 1.55
Enter Reward: 0
Backpropping 

Session Number 47
images_for_training/153
(1, 64, 64, 3)
Policy eval: 
[[ 0.03485322  0.03026322  0.02396009  0.02301421  0.02283072  0.02945203
   0.02207228  0.02116076  0.02515015  0.02511144  0.02321915  0.02485481
   0.02059766  0.02489     0.02800918  0.02760834  0.02263778  0.02920866
   0.02979486  0.02405437  0.02468107  0.02366205  0.02282916  0.02332349
   0.02468812  0.03182719  0.02271784  0.02161536  0.02554413  0.02321458
   0.02054791  0.0307043   0.02150087  0.01630353  0.01857591  0.02007948
   0.02729829  0.02467469  0.02126714  0.02111263  0.02108938]]
Log Policy eval: 
[[-3.35839987 -3.66788006 -3.58450079 -3.77998376 -3.76429367 -3.38640332
  -3.74130797 -3.64054441 -3.58749151 -3.64607286 -3.82894564 -3.66087532
  -3.81453395 -3.74631929 -3.59934139 -3.92752504 -3.48998117 -3.53754759
  -3.99850368 -3.92852283 -3.7456708  -3.78450441 -3.62498832 -3.72113204
  -3.64405823 -3.60108781 -3.53209448 -3.67217731 -3.70246577 -3.88238668
  -3.89961553 -3.78582311 -4.03086042 -3.89433193 -3.89600945 -3.72054458
  -3.83771467 -3.75388622 -3.71996307 -3.81241608 -3.76468945]]
Action: 1.3
Enter Reward: 0
Backpropping 

Session Number 48
images_for_training/282
(1, 64, 64, 3)
Policy eval: 
[[ 0.03737847  0.30166423  0.0149113   0.00842917  0.00218875  0.03517042
   0.01196522  0.00625349  0.01144088  0.01829801  0.0454575   0.00333452
   0.00404781  0.00852145  0.02170468  0.00730026  0.03629585  0.05446053
   0.02028865  0.00216858  0.0138239   0.00327069  0.00963712  0.0185378
   0.0081003   0.11848236  0.00456987  0.03454448  0.00546407  0.00432258
   0.00073294  0.02840719  0.00304     0.01825054  0.00668093  0.00714811
   0.00332582  0.00506183  0.01523347  0.00850282  0.03158351]]
Log Policy eval: 
[[-3.74606514 -2.14912701 -4.54614115 -6.29410315 -4.1207633  -1.25849879
  -4.35354519 -4.58853483 -3.63956499 -4.31636477 -4.38205528 -3.98846436
  -5.40631676 -4.24673462 -3.1590724  -4.87908411 -3.22114897 -3.37482119
  -4.22644806 -4.52815914 -4.21721172 -4.89894438 -3.68088865 -4.46609831
  -4.3906436  -3.06670475 -3.33271837 -3.99188852 -4.88620663 -4.70836067
  -5.90338421 -3.67748213 -5.73119736 -4.97682714 -5.66953373 -3.39074039
  -5.00517893 -6.18189144 -5.35881996 -5.22941732 -6.09452343]]
Action: 0.85
Enter Reward: 1
Backpropping 

Session Number 49
images_for_training/231
(1, 64, 64, 3)
Policy eval: 
[[ 0.35300386  0.13217449  0.0241005   0.00563929  0.0053071   0.05841493
   0.00293878  0.00795639  0.02391466  0.00324643  0.00890783  0.02634688
   0.00444418  0.00078897  0.01128884  0.00141196  0.01234904  0.04521247
   0.00819587  0.01258823  0.0716951   0.0130034   0.00794912  0.00771896
   0.00154299  0.0163591   0.01626298  0.00299416  0.00274211  0.00825671
   0.00357305  0.00798195  0.00042392  0.00143655  0.00664287  0.01738696
   0.00715782  0.0086695   0.01229931  0.03099648  0.00667628]]
Log Policy eval: 
[[-0.23172385 -3.96151185 -6.09857607 -4.66627598 -5.37892294 -4.68678331
  -6.29442692 -4.20615005 -6.58405399 -7.11173916 -7.31369257 -6.95996523
  -4.6897583  -4.98183537 -6.72345018 -5.12244034 -6.20558596 -5.90712357
  -3.89143682 -5.88590717 -5.9540143  -6.67270088 -4.53309298 -3.98468065
  -5.2333436  -5.41022635 -5.74077272 -5.83866405 -6.27216339 -6.44369507
  -6.0496769  -5.52268028 -6.8071847  -7.08713102 -6.78422356 -4.93272066
  -5.99273729 -5.80109549 -5.40187359 -6.18632555 -4.68077135]]
Action: 0.9
Enter Reward: 1
Backpropping 

Session Number 50
images_for_training/212
(1, 64, 64, 3)
Policy eval: 
[[ 0.37517416  0.04681583  0.00656777  0.01551025  0.00290808  0.02022562
   0.0093682   0.01828901  0.02010981  0.00287215  0.02506904  0.00328377
   0.00102926  0.00187022  0.00218137  0.00070085  0.00154636  0.12687561
   0.02317941  0.00242696  0.04904949  0.01336188  0.04280278  0.00659884
   0.02190454  0.00293827  0.02294263  0.00158008  0.02750636  0.0031289
   0.00056848  0.00411487  0.00121835  0.00468034  0.00395179  0.00350384
   0.00220277  0.00468732  0.00463583  0.03587724  0.03674164]]
Log Policy eval: 
[[-0.17258342 -6.35191441 -3.40058208 -5.09953117 -8.42612743 -5.81209564
  -7.45453835 -5.89951324 -4.85290527 -4.92222881 -6.96997643 -6.83840227
  -7.66032076 -8.05409527 -7.74402332 -6.15877295 -5.25215483 -6.81984234
  -5.5335741  -5.92342377 -6.75240326 -3.66967654 -6.30724096 -7.53610373
  -6.79191303 -5.97144794 -8.15647697 -5.55669785 -5.26867437 -7.32271194
  -8.9790554  -5.39739895 -7.74263334 -8.53187561 -7.23003197 -6.32675934
  -4.71378326 -7.7322402  -6.91194248 -4.29786587 -5.82599258]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 51
images_for_training/204
(1, 64, 64, 3)
Policy eval: 
[[  1.32114053e-01   2.31469013e-02   1.15040422e-03   9.13837357e-05
    2.51916563e-03   1.71909351e-02   4.59521398e-04   1.13190755e-01
    2.66159041e-04   6.12791569e-04   2.77172984e-03   3.36668047e-04
    1.23109176e-05   4.16323674e-05   1.07798318e-03   1.49653433e-03
    8.14126222e-04   3.38028115e-03   2.81562414e-02   1.96994701e-03
    2.00348973e-01   8.56072875e-04   1.34507741e-03   2.02901915e-01
    8.56789201e-03   3.34230979e-04   4.69553620e-02   1.14774029e-03
    1.95666645e-02   1.80953601e-03   1.45547558e-04   1.56056494e-01
    2.67828200e-05   4.13158268e-05   9.40813916e-05   3.09740077e-03
    2.35108193e-02   7.55732326e-05   2.34874096e-04   8.62920424e-04
    1.22123072e-03]]
Log Policy eval: 
[[ -0.56127656  -3.34320736 -10.99991703 -10.61564255  -9.85094166
   -1.09279263  -9.5619154  -12.33041954  -3.78639603 -11.05148029
  -10.9556303   -9.98808384 -10.21151638  -7.81136417  -8.25192451
   -9.97161579  -9.40497112  -7.50176907  -4.85231209  -9.48173332
   -9.36467266 -11.10807037  -8.83189106 -10.88405323 -11.78677082
  -11.31014633 -10.87139702 -12.5845108  -12.67052555  -9.91223049
  -11.26134014  -3.64521313 -12.16546249 -12.3152647  -10.69132137
   -9.98034191 -10.46869946  -9.40141964 -10.32307529 -12.87211323
  -11.79685402]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 52
images_for_training/223
(1, 64, 64, 3)
Policy eval: 
[[  9.91978049e-01   6.64088657e-05   4.35824972e-03   1.18647877e-03
    3.14686375e-08   3.20569889e-05   1.82720541e-07   2.52368082e-08
    2.93895414e-06   1.01647092e-04   2.09830322e-08   2.20209543e-07
    2.40463169e-06   1.89961781e-07   3.15118399e-07   1.25403673e-07
    2.84378602e-05   1.68230326e-04   5.02744690e-04   1.35659147e-05
    9.15257115e-05   1.81923333e-05   1.95504413e-07   1.96474375e-08
    1.49149162e-06   1.13594846e-03   1.14272575e-06   2.31690791e-07
    6.76851528e-07   1.21978246e-06   2.48768345e-07   1.43916433e-04
    1.16430851e-10   1.91628113e-09   4.55297632e-05   1.03027080e-04
    4.52841448e-07   1.35683731e-05   5.76618397e-08   1.61893379e-08
    2.85517189e-07]]
Log Policy eval: 
[[ -1.87260259e-04  -8.91052914e+00  -1.86980515e+01  -1.93719559e+01
   -2.54357185e+01  -1.80296097e+01  -1.79032021e+01  -1.38629255e+01
   -1.86818619e+01  -2.15495167e+01  -1.78050594e+01  -1.93840694e+01
   -2.45890217e+01  -2.49827690e+01  -2.30051003e+01  -1.59321537e+01
   -1.62523212e+01  -1.67249718e+01  -1.75459499e+01  -1.90712757e+01
   -1.81231365e+01  -1.42525463e+01  -1.89316082e+01  -2.15044498e+01
   -1.91220875e+01  -1.52088108e+01  -1.76138821e+01  -1.98210545e+01
   -1.66329308e+01  -1.84252491e+01  -1.58999310e+01  -9.91004467e+00
   -2.50022926e+01  -2.42269802e+01  -2.11908112e+01  -2.42058754e+01
   -1.74776611e+01  -1.77313366e+01  -1.84048901e+01  -2.13284721e+01
   -1.76815376e+01]]
Action: 0.3
Enter Reward: 0
Backpropping 

Session Number 53
images_for_training/185
(1, 64, 64, 3)
Policy eval: 
[[ 0.20395762  0.03177299  0.02960071  0.01984811  0.01051939  0.01166005
   0.01546156  0.0279482   0.02052817  0.03237412  0.01373797  0.01404642
   0.01503426  0.00923396  0.02238147  0.01622343  0.02153529  0.02198781
   0.0264909   0.01172666  0.01221146  0.01746221  0.01286926  0.01188208
   0.03536853  0.03565909  0.02260386  0.02794225  0.01721489  0.02567902
   0.01127088  0.03235673  0.00548442  0.01412114  0.00901636  0.00970939
   0.02492288  0.0113858   0.03010799  0.03025752  0.02640511]]
Log Policy eval: 
[[-1.85042441 -3.03847742 -3.81001544 -3.33002853 -3.67871666 -3.80039835
  -4.08074713 -3.89519358 -3.74942493 -4.01907301 -4.71392441 -4.32131004
  -3.67867136 -4.53984308 -4.11753035 -3.88401079 -3.99691629 -4.29229736
  -4.08434391 -3.30173707 -3.90416765 -3.71390057 -3.22558379 -3.64376593
  -3.50826406 -3.90469027 -3.64854527 -3.50503802 -4.17285013 -3.9914279
  -4.32953072 -3.39496279 -4.52516079 -5.25896502 -4.28273201 -3.67760849
  -3.92925978 -4.98544168 -4.93066216 -3.56878853 -4.15592098]]
Action: 1.55
Enter Reward: 0
Backpropping 

Session Number 54
images_for_training/139
(1, 64, 64, 3)
Policy eval: 
[[ 0.35716063  0.04225386  0.01434222  0.00683261  0.00907981  0.0301905
   0.00402158  0.00408991  0.01986994  0.00526126  0.00568316  0.01318415
   0.01397916  0.0078253   0.01183809  0.00887107  0.02235678  0.00868641
   0.03492945  0.00450819  0.04464604  0.00598279  0.02125571  0.02049109
   0.01244877  0.01272286  0.0320022   0.00837231  0.0211229   0.01635854
   0.01407423  0.09878755  0.00396059  0.0024879   0.01551562  0.01044417
   0.00508808  0.00474526  0.01026811  0.00999599  0.00426524]]
Log Policy eval: 
[[-0.92864364 -2.36492705 -3.34020042 -4.12330008 -4.40590477 -4.55033779
  -4.77880621 -4.83629751 -3.3677175  -3.4030025  -3.73747468 -4.1514039
  -5.8925705  -4.39264822 -4.94535351 -5.70569038 -4.38687992 -3.66801405
  -5.16223955 -5.22021484 -4.6094327  -5.59969902 -5.26619959 -4.59734821
  -3.93883991 -4.95059061 -4.45691872 -3.67524195 -4.20046997 -5.55264091
  -4.89816332 -4.67460346 -5.81376648 -5.04188919 -3.81494379 -4.9039073
  -4.4278965  -5.26721287 -3.99907207 -4.19122458 -3.87543964]]
Action: 1.55
Enter Reward: 0
Backpropping 

Session Number 55
images_for_training/46
(1, 64, 64, 3)
Policy eval: 
[[  9.99511480e-01   2.65353970e-04   7.90345567e-08   7.85648047e-10
    1.49991627e-06   3.56351893e-06   8.33717948e-08   3.14670416e-07
    3.48410722e-05   2.12333447e-07   8.17568235e-10   5.46428112e-07
    1.25326094e-09   3.99100344e-07   1.31060972e-07   2.81560730e-09
    8.75004332e-07   3.10826931e-06   1.11862153e-06   2.54675872e-08
    3.19758641e-07   2.78223133e-09   1.94548738e-06   8.48017407e-08
    4.03588444e-07   2.80683893e-10   1.44234131e-04   1.74866244e-07
    2.23620209e-05   1.77573733e-09   3.38195272e-09   6.43831572e-06
    1.58443869e-10   2.58955968e-08   7.95060628e-10   7.92823229e-08
    8.16066770e-09   2.13956741e-09   2.85033650e-08   1.07224285e-09
    3.59359717e-07]]
Log Policy eval: 
[[ -1.36758701e-03  -1.45899229e+01  -9.56316662e+00  -1.63146057e+01
   -1.38176289e+01  -1.39839191e+01  -1.52848663e+01  -1.15690317e+01
   -1.07960043e+01  -1.52219028e+01  -7.06136608e+00  -1.12658367e+01
   -1.82770672e+01  -1.29578886e+01  -1.28448467e+01  -1.93869667e+01
   -1.16397419e+01  -1.30763826e+01  -1.21574688e+01  -1.63274612e+01
   -1.46136951e+01  -1.45204716e+01  -1.26801128e+01  -1.65807114e+01
   -1.26893511e+01  -1.34477577e+01  -1.13859673e+01  -1.39958601e+01
   -1.54768534e+01  -1.81662502e+01  -2.21942101e+01  -8.99682999e+00
   -2.29015560e+01  -1.55493793e+01  -1.72512970e+01  -2.17211609e+01
   -1.17781115e+01  -1.91000042e+01  -1.57866306e+01  -1.55263281e+01
   -8.42676640e+00]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 56
images_for_training/58
(1, 64, 64, 3)
Policy eval: 
[[  9.99943376e-01   1.46144266e-05   5.86259716e-07   6.42469544e-09
    1.11062633e-07   1.43648364e-08   1.42551087e-07   7.99909472e-09
    1.83331576e-06   1.97167606e-06   1.55238445e-06   3.77938605e-08
    1.52789283e-08   2.01843484e-08   1.95699755e-07   4.55659297e-08
    8.29284446e-08   7.13027418e-07   3.67261759e-06   7.98917199e-08
    1.26638744e-08   3.67720321e-09   2.58299515e-09   2.15952596e-07
    3.75877022e-07   3.83385031e-06   2.16449621e-06   5.37358646e-09
    7.72828855e-07   4.35803349e-09   1.86586053e-08   2.02834090e-05
    4.94937591e-10   3.06277581e-09   4.03889500e-09   3.33013811e-10
    9.69386178e-07   1.27411059e-09   2.07537528e-06   1.49869152e-07
    1.43499463e-07]]
Log Policy eval: 
[[ -1.79392030e-03  -6.61838436e+00  -1.19242907e+01  -1.99876900e+01
   -1.60835342e+01  -1.57560825e+01  -1.73811073e+01  -1.25015879e+01
   -1.14176884e+01  -1.10383425e+01  -1.59517059e+01  -1.51120358e+01
   -2.09647808e+01  -1.48408375e+01  -1.49757509e+01  -1.56618261e+01
   -9.09762096e+00  -1.78059826e+01  -9.19454384e+00  -1.51030331e+01
   -1.54021416e+01  -1.51314039e+01  -1.01384773e+01  -1.40340891e+01
   -1.44417486e+01  -1.41402454e+01  -1.08223667e+01  -1.24470119e+01
   -1.35618620e+01  -1.80166626e+01  -2.09461346e+01  -8.90760517e+00
   -2.22068615e+01  -2.45312481e+01  -1.74739037e+01  -1.83623734e+01
   -1.40450964e+01  -1.92473564e+01  -1.48147459e+01  -1.93943615e+01
   -1.47733650e+01]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 57
images_for_training/223
(1, 64, 64, 3)
Policy eval: 
[[  9.98459458e-01   1.53964921e-03   1.58797346e-12   1.26631537e-20
    1.23665561e-20   2.17169239e-18   6.09434808e-21   2.89317338e-16
    6.64594627e-13   1.63248541e-16   7.83811601e-13   7.63103519e-20
    5.65488046e-18   9.98250691e-22   2.20841964e-16   2.48073399e-13
    4.37273521e-19   3.86876295e-12   2.23159936e-15   2.41747450e-24
    1.63412141e-19   1.23757993e-21   1.43718452e-14   4.63656770e-20
    7.23126751e-18   3.26420210e-11   5.58632162e-15   7.42791970e-20
    6.46747856e-15   9.58921807e-21   1.61644841e-23   9.41384485e-07
    3.95728591e-26   2.41941194e-24   5.54421218e-19   2.88716679e-22
    1.25128476e-21   4.55625640e-16   1.36196241e-12   1.42461958e-21
    1.16460539e-13]]
Log Policy eval: 
[[  0.         -34.26955414 -28.01125336 -41.86930847 -54.95309448
  -30.5991745  -63.27368164 -53.07046127 -39.08805084 -42.66238403
  -52.35613632 -45.5350647  -55.9225235  -47.21784592 -51.29295731
  -47.59859467 -29.61634827 -29.57623863 -37.71430969 -51.54193497
  -37.67780304 -34.1446991  -44.51208115 -39.88174438 -37.45966339
  -46.10551834 -44.80348969 -41.00335312 -42.88023376 -54.71768188
  -67.90634155 -27.87215614 -56.148983   -57.57429123 -48.5187645
  -55.11326218 -37.48918152 -45.34837723 -49.74423218 -37.30001831
  -39.36818695]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 58
images_for_training/112
(1, 64, 64, 3)
Policy eval: 
[[ 0.08240975  0.12104888  0.03830694  0.00732554  0.01023105  0.01488914
   0.01324585  0.03010348  0.01542631  0.00921465  0.0297187   0.03354454
   0.01205186  0.01404609  0.02732381  0.02152185  0.02969905  0.04488495
   0.02880243  0.01360719  0.03237231  0.03045653  0.01054745  0.03106786
   0.00973531  0.02928724  0.04556091  0.01089788  0.01728114  0.02713413
   0.00822807  0.04330438  0.00486237  0.00785295  0.0094758   0.01347155
   0.01334582  0.02544293  0.0120827   0.00727856  0.0129121 ]]
Log Policy eval: 
[[-1.52674353 -2.89967275 -3.6032753  -4.1101613  -4.41412973 -4.14212561
  -3.72611332 -3.30579281 -3.52276373 -4.29120159 -3.92871857 -4.68664694
  -4.61183453 -4.30258942 -3.54774284 -4.58564615 -4.08771658 -4.00265217
  -2.99351382 -4.22156143 -4.34727812 -4.78119946 -4.1857028  -3.63108873
  -3.9288826  -3.90199518 -3.3298943  -3.98412657 -4.7963233  -3.22702336
  -4.34909821 -3.72647858 -4.92593575 -4.67221546 -3.96135235 -3.95369673
  -4.43592262 -4.53631449 -4.46869469 -4.4451375  -4.00991344]]
Action: 1.65
Enter Reward: 0
Backpropping 

Session Number 59
images_for_training/292
(1, 64, 64, 3)
Policy eval: 
[[  9.99999166e-01   1.24660700e-08   5.10931990e-19   6.20867799e-26
    4.58507165e-18   1.20928474e-21   2.66802086e-24   2.06014885e-21
    2.24464376e-08   6.44645741e-14   6.90426243e-16   1.43634355e-17
    2.06233263e-23   1.15857980e-19   3.92954592e-11   7.61426636e-17
    4.88617202e-16   8.25189563e-21   1.70978216e-20   7.74243544e-14
    7.28078248e-26   1.98574749e-24   4.43090044e-11   9.58281167e-22
    5.03234387e-15   5.12811449e-15   8.10464314e-07   6.03132953e-19
    1.08351655e-13   2.04870320e-17   4.38316787e-21   1.33681910e-09
    4.08742177e-26   3.15168565e-29   1.71809046e-22   8.31861120e-22
    4.77360579e-15   3.18013000e-27   1.56635981e-19   9.15263484e-15
    3.82984365e-19]]
Log Policy eval: 
[[ -5.33964625e-03  -5.23630428e+00  -3.22623825e+01  -4.23573761e+01
   -3.11375542e+01  -3.18121052e+01  -3.34393463e+01  -2.92293701e+01
   -2.14344120e+01  -2.39222050e+01  -2.90600548e+01  -3.59786682e+01
   -4.41684685e+01  -2.49013233e+01  -3.59692421e+01  -3.61542587e+01
   -2.56394463e+01  -3.17935162e+01  -2.07818928e+01  -3.94937744e+01
   -3.15960350e+01  -3.51103897e+01  -1.24190931e+01  -4.12064438e+01
   -3.63714714e+01  -3.45328979e+01  -1.47504969e+01  -3.22896461e+01
   -3.86588478e+01  -4.23410187e+01  -5.44741554e+01  -1.37230253e+01
   -5.14464417e+01  -5.81611099e+01  -3.57483368e+01  -3.27214088e+01
   -3.89554253e+01  -4.95853500e+01  -4.36351395e+01  -5.02972069e+01
   -1.92661209e+01]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 60
images_for_training/73
(1, 64, 64, 3)
Policy eval: 
[[  9.98050451e-01   1.92901166e-06   3.62971650e-06   1.00640489e-06
    5.35818145e-08   6.76788070e-10   3.96865835e-06   4.48056526e-05
    1.76553772e-06   1.73712658e-06   1.45777222e-03   3.47551392e-08
    2.13148041e-11   1.37865097e-08   2.15680330e-07   5.49130050e-07
    2.49727896e-06   1.00251666e-04   1.11039990e-05   2.50717244e-06
    3.72968861e-06   5.61208708e-06   3.32095382e-08   8.89946108e-08
    1.48345364e-07   6.28817418e-07   1.07129708e-04   1.41500391e-06
    2.62721242e-05   2.82996461e-05   1.61590030e-08   6.00549611e-05
    8.58113047e-09   1.86543918e-08   7.58129026e-09   6.38805719e-09
    4.22257071e-05   3.98256307e-05   1.06096737e-11   2.15975902e-07
    1.30623938e-08]]
Log Policy eval: 
[[ -3.45051347e-04  -8.05560684e+00  -2.52079964e+01  -2.75833549e+01
   -3.01358719e+01  -1.23491659e+01  -3.14266968e+01  -1.07360687e+01
   -1.33761864e+01  -2.96941109e+01  -2.71586590e+01  -3.31008148e+01
   -3.13965702e+01  -2.36707611e+01  -2.41503792e+01  -2.28728085e+01
   -3.06749191e+01  -1.70340061e+01  -2.57885323e+01  -3.07502918e+01
   -2.16121807e+01  -1.94598007e+01  -2.48393784e+01  -2.13093033e+01
   -2.90332451e+01  -2.39480953e+01  -2.48898430e+01  -2.63292484e+01
   -2.17722034e+01  -2.60265579e+01  -2.77521343e+01  -1.88546963e+01
   -2.81776810e+01  -3.73923225e+01  -2.17396889e+01  -2.55736294e+01
   -1.81412182e+01  -2.23125916e+01  -2.59161720e+01  -2.18752232e+01
   -2.68888512e+01]]
Action: 0.1
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 61
images_for_training/126
(1, 64, 64, 3)
Policy eval: 
[[  8.70138824e-01   5.88743165e-02   4.29945532e-03   2.83769972e-04
    3.24421073e-03   1.13620632e-03   2.60101278e-05   1.77220651e-03
    1.65030602e-02   4.22265206e-04   3.77395627e-04   1.25464503e-04
    1.71457103e-03   4.70049941e-04   1.61002856e-04   2.37097242e-03
    8.11270089e-04   5.75382775e-03   7.71592313e-04   1.82132970e-03
    4.37233743e-04   4.44305391e-04   6.94009359e-04   8.37876723e-05
    8.71118915e-04   2.80716992e-03   3.24738648e-04   3.59572587e-03
    1.32541521e-03   8.64042260e-04   3.45555774e-04   1.41487606e-02
    1.04626315e-05   1.97270747e-05   6.52745308e-04   3.47351364e-04
    6.61964761e-04   4.30211716e-04   1.01196849e-04   5.06207231e-04
    2.50493496e-04]]
Log Policy eval: 
[[-1.52677631 -2.20687294 -4.13864326 -8.32617188 -6.85505486 -6.25572062
  -6.20070076 -3.10836649 -4.89884281 -3.5407548  -2.31324673 -6.58418798
  -7.36976719 -5.13650227 -5.02824354 -4.17550421 -5.30759335 -2.71344018
  -3.19713974 -6.72843552 -4.63853693 -5.2214222  -5.50605106 -2.24530458
  -4.7229538  -2.79634953 -6.13509607 -5.96837664 -4.09128571 -5.0863452
  -7.01741982 -2.95524979 -6.71044302 -7.57661819 -4.4012332  -7.13009024
  -5.39104986 -4.84135628 -3.96508837 -6.08219481 -5.44988441]]
Action: 1.4
Enter Reward: 1
Backpropping 

Session Number 62
images_for_training/74
(1, 64, 64, 3)
Policy eval: 
[[  9.99915123e-01   1.38111691e-05   2.23598614e-12   3.02950581e-11
    3.77330762e-12   1.06369536e-12   5.01054276e-12   1.18300592e-09
    9.43622240e-07   1.87887466e-12   2.25197145e-05   2.65199026e-11
    2.14331564e-13   8.03605190e-07   7.92337862e-11   2.60830078e-08
    1.00218426e-06   4.38428938e-09   1.14412865e-06   1.40643587e-13
    1.09479519e-08   5.59078651e-11   1.86489765e-11   2.37988518e-09
    5.52595303e-09   2.03302797e-09   2.62702002e-07   1.90242336e-11
    4.09036538e-09   6.03545325e-10   2.51992268e-14   4.43602949e-05
    7.26386471e-17   3.30750997e-13   3.94619359e-09   7.66125097e-12
    9.23656290e-12   5.99798396e-14   7.61752467e-12   2.77517237e-15
    1.39601894e-08]]
Log Policy eval: 
[[ -5.97220715e-05  -1.03875418e+01  -1.94066067e+01  -1.44073400e+01
   -3.40050049e+01  -3.27016754e+01  -3.20702629e+01  -2.25010281e+01
   -1.44641800e+01  -2.10312557e+01  -1.19051456e+01  -3.15634689e+01
   -2.63522778e+01  -2.11184998e+01  -2.08030872e+01  -2.39994354e+01
   -1.62211094e+01  -2.87400036e+01  -1.35958700e+01  -1.85767345e+01
   -2.25021782e+01  -2.50326653e+01  -1.43246155e+01  -2.67894096e+01
   -2.70636406e+01  -2.00541439e+01  -2.23087788e+01  -2.25301552e+01
   -1.08868198e+01  -2.54205170e+01  -2.78106632e+01  -1.77844410e+01
   -3.54216652e+01  -3.27850494e+01  -2.02051849e+01  -3.41932182e+01
   -1.50087509e+01  -1.93566303e+01  -2.53524914e+01  -1.57506227e+01
   -1.85147915e+01]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 63
images_for_training/163
(1, 64, 64, 3)
Policy eval: 
[[ 0.1597884   0.10497822  0.02450608  0.01018945  0.01247672  0.03374245
   0.00818782  0.02158962  0.01529371  0.01367005  0.01215539  0.01172683
   0.00826139  0.01130051  0.01227437  0.02797659  0.01651652  0.01759216
   0.02974293  0.01564666  0.03186218  0.01659575  0.04323276  0.01750115
   0.01547072  0.02819098  0.0306092   0.01859041  0.0246065   0.01479211
   0.01464573  0.03892491  0.01098513  0.00959208  0.01664617  0.01234653
   0.01685347  0.00861021  0.02055141  0.02863392  0.01314287]]
Log Policy eval: 
[[-2.37569714 -2.84219217 -3.618999   -4.55815029 -5.34942341 -3.1429534
  -4.31047392 -3.25185132 -4.00744104 -4.2153883  -4.11890697 -3.46015882
  -4.91764212 -3.30331087 -3.96296883 -4.57684612 -3.36451674 -3.59049726
  -3.16642165 -3.75586462 -3.41667843 -4.08073759 -4.12858343 -3.4226172
  -4.03886604 -3.48551464 -3.6089859  -4.08744335 -3.98295832 -4.09068394
  -4.87009525 -3.25510502 -4.73221493 -3.97518826 -4.12117767 -5.26357126
  -3.38683152 -3.47674131 -3.9068284  -4.61408663 -4.28121042]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 64
images_for_training/129
(1, 64, 64, 3)
Policy eval: 
[[  9.90883648e-01   6.01459993e-03   4.83250224e-05   4.43035333e-06
    4.67847985e-06   5.88028815e-05   4.37587232e-07   1.32160710e-06
    1.21315836e-03   3.33674070e-05   1.25502320e-05   2.25175227e-05
    1.18246521e-06   1.28176489e-05   3.24501821e-06   5.60923127e-06
    6.61216427e-06   2.28398185e-05   1.32219393e-05   2.39777000e-06
    1.76377603e-06   7.57589305e-07   9.88292504e-06   2.43118193e-05
    6.91382456e-06   9.49737966e-07   3.32968542e-04   2.50685389e-05
    9.26325447e-05   8.15466478e-07   4.77070944e-06   8.81662301e-04
    1.52979382e-07   5.55174324e-08   9.73025521e-07   2.11383522e-07
    1.63949066e-04   8.10437513e-08   2.73835099e-07   1.19115139e-05
    7.40489486e-05]]
Log Policy eval: 
[[ -0.04255983  -3.49285769  -7.01293945 -11.30696774 -11.65670967
   -6.99718904 -10.68549824  -8.30951786  -9.43079472 -10.70329571
   -6.94564724  -6.57929516 -12.4277668  -11.75819111  -9.72222805
   -9.57319927  -6.3900938  -10.17587376  -8.62419987 -10.43739128
   -7.45968628  -8.82961082  -8.30151463  -9.94727135  -9.48045444
   -9.30378437  -9.08764839 -11.85877323  -9.04506302 -13.59163475
  -11.73704529  -6.40231133 -14.95032787 -12.4819231  -10.08347225
  -13.05235863  -7.33396196 -10.96318531 -12.06180382  -8.59102726
   -7.37439156]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 65
images_for_training/270
(1, 64, 64, 3)
Policy eval: 
[[  9.99262869e-01   1.35786366e-04   1.21333676e-06   8.15050182e-28
    2.46766307e-26   9.30679558e-25   3.16103032e-20   6.00158353e-04
    5.75538601e-15   7.87082242e-15   1.10923962e-15   2.33625928e-16
    1.11536882e-26   8.13228819e-24   4.73093576e-20   3.40888121e-26
    1.04371185e-17   1.08899586e-25   2.13132257e-16   1.20004882e-19
    9.21124529e-27   2.40803659e-26   2.27895636e-23   6.41598465e-18
    9.17211571e-19   3.19654739e-20   1.02447066e-12   3.67728598e-10
    3.00519099e-29   5.79335702e-24   3.72125731e-25   5.10970953e-11
    4.18032079e-38   1.10159611e-27   4.09232691e-30   5.22271082e-25
    3.18755083e-19   7.22914332e-32   1.15219204e-28   1.26514763e-25
    2.88513282e-19]]
Log Policy eval: 
[[ -2.37640701e-02  -3.75144434e+00  -3.02713070e+01  -6.38672333e+01
   -7.76027527e+01  -7.74739380e+01  -6.25703125e+01  -1.62752590e+01
   -6.77126312e+01  -5.60531502e+01  -5.16242065e+01  -8.22189865e+01
   -8.42416306e+01  -8.89682693e+01  -6.53451233e+01  -5.22867737e+01
   -4.79783783e+01  -6.68059616e+01  -3.44993019e+01  -5.94952850e+01
   -2.89683437e+01  -5.38425636e+01  -4.74509964e+01  -5.59650536e+01
   -5.42406921e+01  -4.16339302e+01  -3.65506859e+01  -4.39308624e+01
   -5.63535690e+01  -5.26987000e+01  -4.83585587e+01  -4.12663956e+01
   -7.82215118e+01  -7.21463318e+01  -3.59699173e+01  -6.93257446e+01
   -3.64141922e+01  -6.43008575e+01  -5.65401001e+01  -4.89264450e+01
   -4.75148621e+01]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 66
images_for_training/227
(1, 64, 64, 3)
Policy eval: 
[[  1.00000000e+00   2.29529694e-11   2.37767877e-27   0.00000000e+00
    0.00000000e+00   0.00000000e+00   5.33577629e-38   1.42989343e-10
    4.70684872e-23   0.00000000e+00   3.66240903e-25   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.28833259e-38
    1.04827780e-32   3.09718828e-27   3.26273927e-31   1.33626283e-34
    9.10022854e-19   2.88066903e-28   5.46327501e-36   5.92232426e-29
    0.00000000e+00   2.56213452e-32   4.18637162e-24   6.99025486e-34
    1.10018300e-33   0.00000000e+00   0.00000000e+00   7.46809308e-29
    1.82911645e-36   1.02710648e-36   0.00000000e+00   0.00000000e+00
    8.53705241e-32   3.61822834e-29   0.00000000e+00   2.47338647e-26
    1.51887200e-24]]
Log Policy eval: 
[[ -22.57660675    0.          -75.19107819  -66.6476593  -100.32860565
   -60.27774048  -72.07398987  -60.96374512  -54.83039856  -79.7767868
   -72.74848175  -68.18391418  -77.25272369  -77.27420807  -75.19984436
   -51.44979095  -59.41819     -66.91734314  -38.34839249  -85.07504272
   -38.32752991  -71.54595947  -49.53316498  -66.09461975  -91.93569183
   -62.89819336  -26.91544724  -66.6494751   -81.34855652  -39.92206955
   -67.2936554   -58.43557739  -66.16253662  -78.29763794  -73.27916718
   -75.04936218  -69.83565521  -50.60858154  -49.30008316  -70.78942108
   -64.75346375]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 67
images_for_training/135
(1, 64, 64, 3)
Policy eval: 
[[  3.22797894e-01   4.06817973e-01   5.93297277e-03   4.34859248e-04
    1.06253824e-03   2.62066536e-03   8.72047525e-03   4.40527685e-02
    4.59207396e-04   5.12170955e-04   4.58230963e-03   2.83354195e-04
    2.32201550e-04   4.59304871e-03   2.20212271e-03   1.73845014e-03
    5.04935253e-03   1.83815192e-02   5.86318318e-03   5.53630467e-04
    1.48402564e-02   5.57968672e-03   1.72800459e-02   3.90129201e-02
    1.61133404e-03   5.22852270e-03   9.36261937e-03   5.53296064e-04
    1.26737123e-03   3.04918434e-03   6.68501656e-04   2.38958448e-02
    2.75502505e-04   1.49096607e-03   1.36201142e-03   1.90785783e-03
    2.62122764e-03   3.38082347e-04   2.71319831e-03   2.22380832e-03
    2.78271139e-02]]
Log Policy eval: 
[[-3.56015396 -1.01648235 -5.11589718 -7.46530294 -7.0942812  -3.42156816
  -5.83465862 -4.5543108  -2.98845124 -5.25228691 -5.83742428 -6.64088297
  -4.51269007 -4.35479641 -5.85171604 -4.06202316 -4.7988534  -5.09735918
  -4.55749702 -6.00858784 -5.21626854 -5.15518856 -1.58063936 -4.26724148
  -4.82377434 -2.71933031 -3.85996723 -4.93906736 -4.78688669 -5.05361605
  -6.20472193 -3.78444672 -4.93893242 -7.27745247 -7.25835228 -5.62096786
  -5.34959745 -6.8211441  -4.15319252 -5.23290443 -4.31383181]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 68
images_for_training/99
(1, 64, 64, 3)
Policy eval: 
[[  2.65981071e-10   1.00000000e+00   1.07678608e-18   1.86542121e-20
    1.18255167e-31   5.09062164e-29   5.41650271e-28   1.47489366e-19
    2.34002776e-22   2.57699901e-21   5.46904821e-22   5.59214260e-31
    7.35524343e-25   1.34408267e-22   4.50577720e-21   7.70467588e-24
    2.33363855e-20   2.45327923e-17   8.95363021e-14   3.14947417e-12
    2.88958904e-17   2.16847013e-21   2.21026670e-16   2.14257626e-22
    2.91171160e-22   1.09898174e-21   3.49956555e-13   2.31341324e-19
    9.50862490e-26   5.46656165e-16   1.01429281e-28   1.27159215e-13
    6.61806869e-25   7.07373842e-25   1.39737962e-22   5.34753234e-16
    8.05857716e-18   2.91498344e-19   1.09830520e-24   6.42556588e-19
    3.58974172e-22]]
Log Policy eval: 
[[-44.45503998   0.         -76.24747467 -53.41448212 -71.56506348
  -70.93032837 -55.9230423  -43.71857452 -56.36077118 -75.61685181
  -47.80906677 -83.87371063 -71.66113281 -71.77927399 -62.16780853
  -53.36749649 -52.42569351 -53.9260788  -50.92576599 -70.3319931
  -64.44081116 -49.65550232 -55.14371109 -55.155159   -60.1591301
  -44.0829277  -61.97180176 -53.10383606 -66.89891052 -66.19541168
  -84.33473969 -61.45904922 -78.89333344 -74.00260925 -70.59159088
  -64.38327026 -71.83930206 -61.32954407 -51.45133591 -83.92527008
  -53.64792633]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 69
images_for_training/149
(1, 64, 64, 3)
Policy eval: 
[[  9.77109448e-05   9.97467041e-01   3.07563460e-05   3.77009710e-05
    7.17737905e-08   1.28479883e-06   8.72927330e-07   1.64096582e-05
    1.75220572e-04   6.62122375e-06   1.25217985e-05   2.37118165e-08
    2.34840945e-06   1.37575162e-05   5.33029488e-05   1.40293141e-05
    7.34270714e-07   4.24830569e-06   6.87395459e-06   2.22785502e-06
    6.40161375e-07   2.18923174e-06   1.76347117e-03   3.71817606e-07
    3.94171252e-07   1.61698248e-04   1.75729037e-05   9.52834398e-06
    6.23874803e-06   2.67172823e-06   2.09876106e-07   6.30900540e-05
    1.11354768e-06   1.76209909e-08   3.19131999e-07   1.25186875e-06
    2.09289070e-07   1.43692023e-05   1.03046648e-06   8.26770975e-06
    1.55913813e-06]]
Log Policy eval: 
[[ -1.49200892  -0.88714379  -7.08319283  -9.46436977  -6.68130541
   -6.44174814  -7.73106718  -5.00057364  -5.29483175  -6.4088006
   -7.54217291  -7.50060987 -10.28955746 -10.2830801   -8.67056084
   -8.0955658   -6.0634532   -6.55787611  -3.86849952  -9.01707077
   -4.26989698  -9.29881382  -1.43502975  -6.12885523  -7.28283882
   -6.51818752  -6.22576284  -6.07297277  -6.81944227  -3.95725036
   -9.17600918  -3.36885619 -10.38764668  -9.75809002  -9.81509304
   -7.81888056  -7.30197525  -9.06203938  -6.42238665  -8.51720047
   -7.49672937]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 70
images_for_training/22
(1, 64, 64, 3)
Policy eval: 
[[  2.32642982e-04   9.99766767e-01   3.34292385e-11   7.60392530e-12
    7.43266911e-16   3.65660835e-09   2.00020786e-13   3.69531572e-10
    4.37095221e-11   2.94285292e-15   1.39994769e-11   2.81352823e-21
    1.03497444e-09   9.24638491e-12   9.72065006e-09   6.88796513e-13
    1.76606985e-09   2.63519436e-12   4.29032667e-08   9.75831360e-11
    7.98989662e-15   7.16438288e-14   6.61305092e-15   9.06977249e-09
    1.24457722e-10   5.17799776e-07   2.95257430e-11   6.16834058e-13
    2.31327312e-17   3.52682767e-14   4.31746226e-17   2.29045334e-08
    9.75985751e-15   1.02344327e-17   4.13792178e-12   8.78536393e-12
    2.95634290e-08   6.57333840e-11   4.13773460e-11   2.75781595e-13
    2.33557285e-10]]
Log Policy eval: 
[[-36.09789276   0.         -49.25788498 -48.42658234 -56.52481461
  -52.11022568 -47.95973206 -58.48760605 -36.59513474 -47.97177887
  -29.08658028 -53.63523865 -43.75562668 -44.67851257 -55.35305405
  -48.16471863 -31.50198936 -46.15463638 -40.50866318 -51.79933548
  -47.3396225  -48.88808441 -36.76791763 -46.06242752 -46.65697479
  -50.34789276 -32.52241516 -49.91893768 -48.69425964 -45.26115799
  -51.89497757 -39.93992615 -56.17538452 -51.49248123 -40.49219131
  -57.8554039  -50.66279984 -29.68104172 -54.61122894 -54.53384399
  -49.42515564]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 71
images_for_training/270
(1, 64, 64, 3)
Policy eval: 
[[  2.86834694e-26   1.00000000e+00   1.46018956e-31   4.81062624e-38
    5.12704436e-37   5.10802371e-32   5.22836453e-30   0.00000000e+00
    9.67126830e-26   9.85200507e-28   6.52243134e-24   0.00000000e+00
    2.85271873e-35   2.52851430e-29   3.20698760e-24   3.82839773e-28
    2.77636721e-18   1.86570011e-26   6.77544389e-27   0.00000000e+00
    1.00277533e-26   1.05633594e-29   9.71720260e-10   4.54864655e-26
    2.03005166e-30   1.09136902e-30   6.37899851e-17   3.01667946e-37
    4.38427495e-21   4.27940261e-19   9.69348594e-37   5.37791546e-22
    5.91508126e-35   0.00000000e+00   1.21175689e-35   4.91750190e-29
    0.00000000e+00   5.37937783e-35   5.59544047e-27   2.28690776e-25
    2.03680680e-31]]
Log Policy eval: 
[[ -3.73112335e+01  -1.94309250e-05  -6.44401093e+01  -1.07347389e+02
   -5.01726875e+01  -6.82092896e+01  -7.82230301e+01  -6.08640251e+01
   -4.65804405e+01  -6.37607994e+01  -7.99996109e+01  -7.02461319e+01
   -1.03941193e+02  -8.78276215e+01  -8.76217880e+01  -6.90452805e+01
   -3.84785843e+01  -5.74716339e+01  -6.04115334e+01  -4.97816124e+01
   -5.77871056e+01  -6.83414536e+01  -1.08499107e+01  -6.93060989e+01
   -4.88985214e+01  -5.20812683e+01  -6.69623489e+01  -5.34027100e+01
   -6.27965279e+01  -3.90920906e+01  -8.28149109e+01  -4.21587410e+01
   -1.03715996e+02  -9.63587875e+01  -5.45128212e+01  -5.21443520e+01
   -8.94863281e+01  -9.35965195e+01  -8.21978836e+01  -7.23640213e+01
   -6.42981873e+01]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 72
images_for_training/149
(1, 64, 64, 3)
Policy eval: 
[[  4.57924604e-02   9.45620954e-01   1.16676802e-05   1.30475382e-06
    1.54434385e-08   3.08404015e-05   2.21939968e-06   2.99247884e-04
    8.09530786e-04   7.17618377e-07   1.08990125e-05   7.27634006e-06
    1.46514878e-07   4.78285438e-05   3.76016433e-05   1.57220820e-05
    2.64224000e-05   8.64911271e-06   5.50765265e-03   1.64512653e-06
    2.40048139e-05   1.27453779e-06   5.92303521e-04   1.40888151e-05
    2.03870900e-06   9.91135857e-06   1.67343933e-05   2.73561545e-06
    7.40457324e-07   1.48554436e-05   1.44941055e-06   1.02901692e-03
    5.22209916e-07   2.29752891e-06   3.03795423e-06   2.75327602e-05
    6.79737866e-07   1.31988654e-05   9.83961218e-06   2.99741259e-07
    8.02997249e-07]]
Log Policy eval: 
[[ -4.45162916  -0.05822972 -10.70233154 -10.30659294 -12.83535862
  -12.16406345 -16.24014854 -12.27371311  -8.1018486   -7.3183732
   -9.97396851 -12.20856762 -14.73063278 -11.67800045 -13.93826962
  -11.61223602  -3.43938184  -9.06903076  -4.88473272 -10.35368729
  -11.27927685 -11.86397171  -9.71131229  -9.33400917 -11.66010094
  -11.3175869   -9.91827202 -10.38183022 -13.60369396  -6.1063385
  -14.47504902  -6.64501572 -14.99193192 -17.03287315  -9.55846691
   -9.24239349 -12.79699421 -10.80313301 -11.39352989 -12.19294739
  -13.33974552]]
Action: 0.8
Enter Reward: 0
Backpropping 

Session Number 73
images_for_training/22
(1, 64, 64, 3)
Policy eval: 
[[  2.75240875e-09   9.99023318e-01   8.33778532e-11   9.47795391e-17
    1.22918812e-18   9.02081195e-16   1.85232573e-17   2.31203149e-15
    7.93148186e-12   7.61227995e-13   7.12919136e-05   3.99917135e-18
    1.34075733e-16   9.40606583e-16   3.72501577e-14   1.00992899e-14
    6.52157495e-11   5.82928627e-12   3.44647386e-04   8.23253249e-13
    1.00699093e-12   2.41401002e-16   3.57658519e-06   2.45715448e-10
    1.45731745e-12   9.67953495e-10   5.57188119e-04   1.22451064e-14
    2.27260699e-08   4.16216486e-13   1.22659437e-16   5.13161180e-10
    1.33994948e-16   4.16566118e-16   3.09868403e-14   1.09252464e-18
    1.03134579e-14   6.97360268e-12   8.16475956e-13   2.70055506e-11
    2.83577025e-12]]
Log Policy eval: 
[[ -1.89024258e+01  -1.78813775e-06  -3.49713478e+01  -3.28826904e+01
   -3.59866219e+01  -2.85823803e+01  -4.19529419e+01  -3.38895073e+01
   -2.49996700e+01  -3.37612076e+01  -3.07794323e+01  -3.96547012e+01
   -4.25887985e+01  -4.30584068e+01  -3.33938293e+01  -3.86639214e+01
   -1.32188873e+01  -3.36031456e+01  -2.55500870e+01  -3.51053467e+01
   -4.39515457e+01  -3.37419128e+01  -3.91148415e+01  -2.97421627e+01
   -3.24534378e+01  -3.51607132e+01  -3.80512238e+01  -3.74554596e+01
   -2.90175972e+01  -2.85301380e+01  -3.84840202e+01  -2.06469917e+01
   -4.65913277e+01  -4.72529411e+01  -2.85909023e+01  -2.28161888e+01
   -3.43197174e+01  -3.45940437e+01  -3.38821259e+01  -2.51163597e+01
   -2.84424152e+01]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 74
images_for_training/260
(1, 64, 64, 3)
Policy eval: 
[[  5.49031142e-07   9.99935985e-01   4.82235640e-10   2.55115290e-26
    2.22261005e-26   4.47775553e-33   1.73624645e-20   2.31797918e-14
    5.76402796e-24   9.26855148e-17   6.23132000e-05   5.73154671e-27
    4.18721169e-21   7.33448559e-18   5.43669710e-18   2.97114612e-12
    1.08950911e-10   2.81395928e-15   1.91744641e-11   6.85970054e-30
    3.66414798e-12   6.85276705e-12   2.37760229e-17   1.20672917e-06
    1.35272822e-14   2.52626226e-20   5.18332415e-17   3.50171273e-20
    7.73784748e-24   1.01113266e-15   2.13617235e-10   7.07669871e-14
    1.12135222e-26   7.86304578e-20   4.23058891e-16   1.77613068e-22
    1.42900612e-17   4.84235438e-15   1.44304207e-15   2.21534215e-23
    2.24864933e-16]]
Log Policy eval: 
[[-18.08908081  -1.17543411 -34.58351517 -36.58671188 -27.5170784
  -70.55656433 -44.36922073 -39.72616959 -45.69747925 -30.09219933
   -0.41608042 -67.72429657 -87.31668091 -32.74688721 -22.66338348
  -27.85867691  -3.75422668 -39.59067917 -20.15990448 -78.75444794
  -40.90245438 -35.60918045 -39.78440475 -56.55812454 -38.79159546
  -30.98295784 -33.14828873 -69.04337311 -53.83358383 -41.12400055
  -51.56800461  -4.79522324 -74.28469849 -76.02166748 -71.78759003
  -32.45227432 -69.15553284 -54.24071503 -58.11686325 -48.88688278
  -16.77534485]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 75
images_for_training/10
(1, 64, 64, 3)
Policy eval: 
[[  2.86018235e-07   9.98251498e-01   9.86689120e-05   6.95311929e-16
    3.59834038e-15   1.81402948e-13   1.63741817e-12   9.05877243e-07
    1.81498494e-09   5.51622970e-10   1.57570338e-03   8.26079046e-14
    3.81887100e-12   9.22044762e-14   5.30575694e-10   1.18053312e-09
    2.29273926e-11   5.01550244e-13   3.11344138e-06   9.02430214e-12
    9.20021031e-14   2.97121034e-07   6.74673442e-11   1.07806659e-06
    2.06917025e-10   6.41435655e-11   5.99399252e-10   4.82798887e-14
    3.38839901e-10   1.23499775e-13   1.22507324e-10   6.19093407e-05
    3.32013849e-13   1.81619132e-15   2.07844766e-12   8.27357795e-18
    7.15262161e-07   3.65954293e-06   5.34925715e-10   2.14054489e-06
    2.62115606e-13]]
Log Policy eval: 
[[ -0.59072989  -1.08856893  -2.23013425 -19.13021278 -31.65890312
  -24.37301254 -17.70307541  -6.36838055 -19.60241127 -18.63215256
   -9.44068909 -27.20075226 -34.71204376 -15.16373062 -25.36454582
  -12.41165257 -24.14351845 -21.19109154 -10.09657288 -28.4113903
  -14.83991909 -14.20497513 -13.04456139 -19.51300812 -26.66193008
  -23.33672142 -10.84506512 -14.49251556 -17.9104805  -32.51384354
  -22.99565887 -17.15636826 -32.24856186 -27.67144775 -16.90373039
  -27.15486336 -24.28277397 -18.49894714 -27.04556274 -18.56682396
  -13.1520195 ]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 76
images_for_training/36
(1, 64, 64, 3)
Policy eval: 
[[  6.44538339e-17   1.00000000e+00   3.71570405e-16   1.27295199e-19
    5.51561191e-26   1.12617570e-23   5.33382558e-22   1.86796091e-15
    2.84935582e-14   1.06423759e-17   7.69716235e-11   1.06967086e-25
    5.52878469e-16   2.60535882e-20   9.89502012e-20   4.52196657e-12
    4.14899053e-11   6.17180054e-14   7.21996907e-11   4.12961690e-18
    8.62638727e-25   3.83508074e-19   1.22437602e-10   1.75473070e-18
    7.01452018e-16   1.81634209e-15   3.68312999e-14   1.05449948e-15
    1.97957688e-17   2.95052740e-18   1.60463824e-19   1.20731980e-10
    1.70582818e-21   1.24470497e-23   1.67989526e-20   2.91601928e-18
    2.43094115e-16   4.94640371e-20   5.12844433e-14   1.05281642e-13
    1.36495768e-14]]
Log Policy eval: 
[[ -1.32617245e+01  -3.20776291e-02  -1.59574604e+01  -3.66200180e+01
   -2.01295776e+01  -3.39214134e+01  -2.23018246e+01  -2.11487732e+01
   -1.80719204e+01  -3.44585648e+01  -7.12216377e+00  -2.70285835e+01
   -2.33970242e+01  -2.56728058e+01  -1.80352039e+01  -7.57275391e+00
   -2.39904346e+01  -2.76612511e+01  -6.69403648e+00  -2.80370979e+01
   -1.11279163e+01  -2.59718361e+01  -1.16331768e+01  -3.55753875e+00
   -1.83860550e+01  -1.48224220e+01  -8.26113129e+00  -2.91703014e+01
   -2.81910744e+01  -1.09084568e+01  -2.23520432e+01  -8.53064537e+00
   -3.20591049e+01  -3.00677471e+01  -2.81685333e+01  -2.62208023e+01
   -2.15804291e+01  -2.14855690e+01  -2.38512096e+01  -1.56124334e+01
   -1.63034992e+01]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 77
images_for_training/181
(1, 64, 64, 3)
Policy eval: 
[[  7.64398792e-05   9.95379448e-01   2.75262687e-06   2.68081999e-06
    8.04143565e-06   4.21130952e-09   7.72840067e-05   1.17335076e-05
    3.18947536e-06   2.58707200e-06   6.04275614e-04   1.64631430e-07
    1.64750080e-08   6.29414080e-06   1.02887975e-06   3.92571732e-04
    1.10171735e-03   2.51530906e-07   2.64573173e-04   4.88708793e-07
    2.66910797e-06   1.37821608e-03   1.99292510e-04   1.18380713e-05
    6.21618074e-06   9.87313911e-07   2.77586747e-04   3.62711103e-06
    2.27669079e-06   7.64252982e-05   3.37250208e-06   6.17404148e-05
    1.21185840e-05   1.49860534e-06   3.81701227e-07   2.86799377e-07
    4.34427238e-06   1.67762319e-05   4.13625287e-07   2.91165134e-06
    1.40809937e-06]]
Log Policy eval: 
[[ -4.51110649  -0.13367203  -9.12000942  -9.11780262  -9.25643635
   -9.8152914   -7.68123007  -7.33494139  -6.40426731  -9.53536701
   -8.55249119 -10.58782578  -9.15892506  -4.09468651  -9.83511162
   -7.17833185  -4.50784349  -6.19593048  -2.95135903  -8.38001537
   -6.47862577  -7.83858156  -7.53644991  -5.8940506   -8.86150455
   -9.24647427  -5.0906086   -9.84038067 -13.28991222  -4.92167854
   -8.43671322  -5.55569458 -10.20776081 -11.92995548  -9.77636242
   -5.7750864   -8.2209959   -6.98281717 -11.67507267 -12.5091362
   -9.03411388]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 78
images_for_training/191
(1, 64, 64, 3)
Policy eval: 
[[  1.00135116e-03   9.40791011e-01   2.45198521e-06   1.55424834e-06
    6.74000330e-05   1.15477155e-06   1.71980400e-06   1.64325684e-04
    1.12405169e-05   7.18894153e-05   1.67797296e-03   4.56993696e-08
    6.96855817e-09   1.53237909e-06   1.31991101e-07   1.76699017e-04
    6.37916476e-03   2.00112436e-06   4.09558713e-02   1.18683110e-05
    2.28610681e-03   3.10492818e-04   2.70137243e-04   1.42529185e-04
    2.41946685e-03   4.09586562e-07   5.89481671e-04   2.10362214e-06
    4.99857124e-04   8.84707424e-06   1.90154094e-06   4.37999770e-05
    2.09905513e-04   4.41886527e-07   3.00648082e-07   3.50045752e-07
    6.37118792e-05   2.18355876e-06   3.72866157e-06   1.96956516e-05
    1.80503645e-03]]
Log Policy eval: 
[[ -7.14353895e+00  -2.49432120e-03  -1.20231180e+01  -1.59603119e+01
   -1.59834900e+01  -1.43832932e+01  -2.12070580e+01  -1.00130129e+01
   -1.32785101e+01  -1.77152271e+01  -1.40637531e+01  -8.98153877e+00
   -1.35552282e+01  -1.66190109e+01  -1.72578888e+01  -1.50193911e+01
   -7.13965368e+00  -1.52183495e+01  -7.84063101e+00  -1.49014711e+01
   -1.70447788e+01  -1.77111111e+01  -1.50224943e+01  -1.07713575e+01
   -1.26103239e+01  -1.55985832e+01  -1.43450460e+01  -1.75653286e+01
   -1.72932987e+01  -1.46144781e+01  -1.83790321e+01  -1.09643412e+01
   -1.98986015e+01  -2.04992199e+01  -1.52483912e+01  -1.92347794e+01
   -8.22175217e+00  -1.20704012e+01  -1.15187769e+01  -1.23790207e+01
   -1.42132502e+01]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 79
images_for_training/212
(1, 64, 64, 3)
Policy eval: 
[[  9.72610178e-06   9.99990225e-01   3.44114005e-31   0.00000000e+00
    2.22860633e-33   1.38584542e-31   1.66221720e-25   3.42304897e-22
    1.42310641e-30   8.50810941e-37   1.36852822e-26   9.01616852e-35
    0.00000000e+00   1.54100769e-21   1.12747829e-26   6.52951215e-24
    5.12040916e-29   8.06438868e-29   2.79580851e-12   1.47345052e-27
    1.68677098e-25   1.64996214e-24   3.84608659e-13   4.27460107e-17
    1.30765483e-31   1.28957211e-26   2.43879066e-11   1.88179880e-27
    1.04531395e-37   8.85862052e-29   5.35813659e-32   2.48938203e-08
    0.00000000e+00   1.81197461e-34   0.00000000e+00   0.00000000e+00
    3.40400202e-20   2.62605090e-25   7.62268256e-25   0.00000000e+00
    3.57036958e-29]]
Log Policy eval: 
[[ -3.43373222e+01  -4.76836021e-06  -5.19914513e+01  -7.08663635e+01
   -9.87540665e+01  -9.29609680e+01  -7.17189636e+01  -3.19839096e+01
   -6.65612869e+01  -7.73798447e+01  -3.54538803e+01  -8.29748383e+01
   -8.13241882e+01  -6.84994202e+01  -7.11050110e+01  -3.48772812e+01
   -5.62390099e+01  -9.27083969e+01  -1.22451296e+01  -8.37977676e+01
   -5.79641991e+01  -4.29254303e+01  -4.39755211e+01  -6.56553574e+01
   -6.31073189e+01  -6.75795670e+01  -7.06097641e+01  -3.65185814e+01
   -7.33941345e+01  -6.56280594e+01  -8.23481293e+01  -4.25807800e+01
   -8.14208984e+01  -8.44512329e+01  -6.77679520e+01  -1.03507851e+02
   -4.84809723e+01  -7.16606598e+01  -6.96585159e+01  -4.87391739e+01
   -5.26067848e+01]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 80
images_for_training/206
(1, 64, 64, 3)
Policy eval: 
[[  5.54609212e-21   1.00000000e+00   1.54612813e-28   8.68331521e-38
    3.75089433e-31   2.93946174e-33   1.49912264e-31   2.61557386e-29
    1.51702723e-21   0.00000000e+00   3.99581400e-28   2.45386068e-31
    6.87964612e-35   0.00000000e+00   6.78196231e-34   2.64708385e-35
    5.73736969e-09   5.20554308e-28   1.39330420e-27   2.78412134e-32
    0.00000000e+00   1.47308456e-32   2.35065404e-24   3.37602053e-30
    8.60459984e-32   1.03129276e-34   5.36564356e-21   0.00000000e+00
    0.00000000e+00   2.72711858e-24   9.71069119e-38   6.35581765e-27
    5.64475142e-34   0.00000000e+00   0.00000000e+00   3.43621278e-25
    6.40758773e-30   3.32838569e-31   1.07797378e-33   2.29079834e-28
    5.19038098e-33]]
Log Policy eval: 
[[-14.22589207  -1.15827262 -30.97812653 -56.94262695 -49.97693253
  -29.96336174 -53.2232399  -38.09240341 -35.89997482 -28.7005043
  -36.39690399 -57.93204117 -63.21019363 -43.81171799 -35.1900444
  -33.38815689 -35.25675583 -31.12635803  -0.37691963 -38.26439285
  -52.36823273 -43.27190399 -33.88993454 -24.90356827 -32.85728836
  -39.50080109 -37.92919159 -39.59420395 -45.79574203 -42.24887085
  -50.22822952 -39.90730286 -54.92664337 -58.6962738  -37.92067337
  -70.18083191 -32.6880455  -44.58543396 -34.72148132 -41.51358414
  -38.75766373]]
Action: 0.05
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 81
images_for_training/47
(1, 64, 64, 3)
Policy eval: 
[[  2.58067084e-05   9.99973774e-01   9.93416968e-20   2.02116593e-23
    2.68046739e-26   1.02517405e-27   1.18551997e-23   1.07399254e-11
    7.11215061e-21   0.00000000e+00   9.89363586e-26   1.77579369e-27
    1.40265401e-26   1.41941250e-15   8.42074760e-17   4.23315305e-24
    1.02852161e-15   2.49731715e-26   5.77355438e-13   2.20561610e-18
    1.06807435e-15   4.76083966e-25   3.14237326e-07   4.51430709e-16
    3.54954236e-24   1.09264782e-16   8.09793510e-10   5.25921514e-29
    3.32383821e-20   3.70286270e-21   6.20745463e-26   7.41528936e-08
    3.72601626e-28   2.50759838e-26   2.05941189e-22   9.73886921e-27
    4.49468942e-21   2.41947543e-12   5.00011750e-26   3.80106395e-24
    1.55868774e-30]]
Log Policy eval: 
[[ -1.01418648e+01  -2.73094401e-02  -2.95370045e+01  -5.65242729e+01
   -2.33650646e+01  -6.54174347e+01  -2.80698986e+01  -2.39651413e+01
   -4.30507774e+01  -2.81922722e+01  -3.62403107e+00  -5.94433861e+01
   -4.45694389e+01  -6.62275543e+01  -1.85847893e+01  -2.61336365e+01
   -2.64369526e+01  -3.10799904e+01  -1.62982693e+01  -6.66971893e+01
   -4.51240082e+01  -4.73010445e+01  -2.13160934e+01  -1.83008537e+01
   -2.15616150e+01  -3.39220695e+01  -8.39926529e+00  -3.93238144e+01
   -2.67358418e+01  -3.28448181e+01  -3.77327614e+01  -4.99720039e+01
   -5.26588097e+01  -4.18020210e+01  -4.11612244e+01  -5.68966599e+01
   -3.73019524e+01  -2.90664673e+01  -4.03591805e+01  -2.15299702e+01
   -1.46945610e+01]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 82
images_for_training/75
(1, 64, 64, 3)
Policy eval: 
[[  7.24283532e-19   1.00000000e+00   2.50668719e-27   3.67050905e-24
    4.64508110e-22   9.93867828e-27   1.95012801e-25   3.37365264e-22
    1.66921558e-19   3.00665168e-21   1.06905980e-16   1.42111458e-28
    4.23946538e-11   3.33732434e-23   3.16758222e-24   1.93937545e-13
    6.70169892e-11   4.95289659e-21   2.09238334e-12   5.32825054e-23
    2.46148327e-12   2.58996629e-15   2.56345670e-15   1.90521665e-12
    6.52395592e-22   4.70760533e-22   3.74250443e-16   1.58770351e-21
    2.36250110e-25   6.37710692e-15   1.80025210e-19   8.95204571e-17
    1.51793947e-24   4.20580910e-29   3.86113057e-22   5.67759381e-28
    1.32950556e-19   2.54813667e-14   4.32261614e-20   7.14022466e-22
    1.78011991e-27]]
Log Policy eval: 
[[ -0.53162849  -0.88587654 -29.80591583 -58.16007614 -45.83509827
  -42.78641129 -36.62719345 -24.02206039 -36.11996841 -55.65263748
  -33.27965164 -44.30237961 -56.88782883 -52.69483185 -40.02881622
  -38.80288696 -26.30443573 -59.2997551  -15.25724506 -55.91635132
  -34.42281723 -34.33946228 -29.13533211 -23.94179535 -42.27912521
  -58.88280106 -43.04075623 -51.75853348 -53.87699509 -38.7322998
  -27.42725182 -35.59521103 -42.24508286 -69.85584259 -45.71791458
  -40.30056    -22.83074188 -26.76245689 -30.35909271 -40.52125168
  -34.23810959]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 83
images_for_training/108
(1, 64, 64, 3)
Policy eval: 
[[ 0.17980587  0.06511392  0.01151925  0.02108126  0.00315935  0.00180924
   0.00499607  0.01115154  0.00654551  0.01035439  0.03135809  0.00241914
   0.00685029  0.00376317  0.00899658  0.02038021  0.05099607  0.00224137
   0.16697811  0.00246353  0.00792811  0.00829408  0.02037618  0.01545116
   0.02660155  0.00510606  0.07899684  0.00387435  0.01051155  0.00586253
   0.0118135   0.03803226  0.00115505  0.00176747  0.00746676  0.00301234
   0.01379916  0.00360944  0.10268968  0.00607359  0.01559529]]
Log Policy eval: 
[[-4.37334681 -1.55938709 -5.82178593 -7.02793169 -5.89544153 -6.78659582
  -4.05439472 -6.14907217 -4.41898346 -6.1869154  -5.23491192 -6.81086636
  -6.55657053 -4.58226824 -5.48372555 -4.17431927 -4.91250086 -4.19973278
  -2.93184185 -6.54063892 -3.63971758 -3.64856005 -1.91275632 -1.83500707
  -5.90217113 -6.34668779 -2.83480358 -6.12952185 -6.27843523 -2.47561407
  -5.8222065  -2.91495609 -5.63561821 -5.982059   -7.06127548 -6.57544756
  -5.40731716 -4.12768269 -5.39693213 -6.0135603  -4.07164621]]
Action: 0.45
Enter Reward: 0
Backpropping 

Session Number 84
images_for_training/123
(1, 64, 64, 3)
Policy eval: 
[[  1.01824589e-04   9.87370729e-01   2.74228405e-05   1.22190079e-06
    2.51711385e-09   4.16875992e-08   1.76898466e-04   3.73654785e-07
    6.68059670e-07   5.29710364e-09   6.58464339e-03   9.82603665e-10
    1.01827055e-07   1.90421770e-06   4.41521524e-06   4.96208013e-05
    2.74330941e-05   2.28991066e-08   4.95003723e-03   1.13150991e-08
    1.30720039e-08   4.60739248e-04   1.36509916e-05   9.19332251e-07
    1.58289559e-08   2.73498927e-07   1.30862497e-06   2.06955519e-08
    1.29306317e-08   4.37688215e-07   1.12212810e-07   2.05780409e-04
    1.00092663e-07   2.11091695e-08   1.38191524e-07   1.12667886e-09
    5.34661058e-06   4.08526262e-07   3.44015098e-06   5.60463942e-09
    9.83469090e-06]]
Log Policy eval: 
[[ -4.09487009  -0.10849244  -9.5320549  -15.89883232  -9.93752384
  -10.02926064  -9.15188408  -9.60456657 -10.3300066  -13.38677883
  -10.33368874 -11.38696671  -8.55573368 -14.71770763  -9.75305843
   -4.60568571  -7.05822277 -13.86931801  -3.76755381 -12.12958241
   -9.85130501  -6.01284266  -3.34985781  -4.75404167 -11.2863512
   -7.23227167  -6.82108641 -11.4116621  -14.53988457  -7.61192131
   -9.54246044  -5.97790527 -10.72634029 -17.07831001 -12.50849247
  -10.70460701  -9.97588253 -10.96037388 -11.93693924 -10.35968494
   -8.40037155]]
Action: 0.05
Enter Reward: 0
Backpropping 

Session Number 85
images_for_training/207
(1, 64, 64, 3)
Policy eval: 
[[  7.28295618e-06   1.28499295e-07   3.81140474e-17   4.68898904e-30
    1.35327634e-25   3.01554945e-04   2.02769079e-18   4.79980530e-13
    2.19570351e-11   3.73946539e-26   6.88493947e-33   1.07402067e-14
    9.02662459e-21   2.12411233e-16   3.53183702e-25   1.58861213e-24
    2.69678549e-05   1.62151844e-20   2.43756291e-03   1.60943200e-22
    1.07363591e-21   1.02660454e-25   2.45802568e-07   9.64230299e-01
    2.16604973e-22   2.16121373e-29   8.43164167e-12   2.09733001e-26
    5.53209787e-26   6.97370009e-11   1.61999290e-18   3.29959095e-02
    1.19699743e-27   2.24161251e-22   1.12284426e-23   6.51528850e-21
    6.31701080e-11   1.48496991e-23   3.86809136e-16   5.29348339e-19
    2.36265948e-31]]
Log Policy eval: 
[[-21.11652946  -0.21468887 -28.11575508 -99.77932739 -77.86730194
  -45.90443039 -37.50078964  -1.64526141 -67.7927475  -79.17442322
  -48.84341049 -70.80111694 -62.71635437 -73.59103394 -59.77091599
  -14.13875389 -23.11607933 -35.97773361  -8.64303017 -79.43010712
   -9.60967445 -14.38878059 -14.12859154 -17.86492729 -47.4432106
  -20.97826576 -63.50537109 -48.52814865 -81.82626343 -66.43392944
  -49.66237259 -52.97421265 -63.92749405 -57.73657608 -63.35150909
  -67.4899292  -34.17819977 -52.73563385 -55.31377792 -80.43663025
  -37.29013062]]
Action: 0.9
Enter Reward: 1
Backpropping 

Session Number 86
images_for_training/299
(1, 64, 64, 3)
Policy eval: 
[[  9.08955371e-07   4.92304973e-02   8.92794034e-08   6.88541631e-14
    3.18083267e-14   5.08314169e-10   6.45025864e-08   2.00300401e-05
    2.20298863e-13   7.47652393e-08   2.54198034e-11   3.13456184e-13
    6.31710555e-16   3.44294343e-10   1.78532821e-13   1.07936958e-05
    9.47575808e-01   1.98563770e-03   4.74366563e-04   3.32618888e-09
    2.50722767e-08   1.71506224e-06   5.08637691e-04   7.43130272e-07
    9.48499689e-07   1.64889602e-09   3.37088841e-06   9.66866656e-11
    1.18631992e-12   1.85706507e-04   6.05665637e-13   6.99189684e-07
    1.37877566e-18   8.06098081e-13   1.77046759e-14   1.21976334e-17
    2.63497224e-10   1.94832808e-14   5.66193203e-10   6.87218794e-15
    1.67823741e-11]]
Log Policy eval: 
[[ -1.11739845e+01  -5.02628708e+00  -2.08639183e+01  -3.77318001e+01
   -2.74005432e+01  -1.25035725e+01  -1.47286873e+01  -1.08410492e+01
   -1.11535740e+01  -2.37849541e+01  -1.48240948e+01  -2.61083298e+01
   -3.25500717e+01  -3.09418392e+01  -2.42696877e+01  -2.18595123e+01
   -8.88745880e+00  -2.23621273e+01  -1.36023312e+01  -2.15050488e+01
   -4.14389446e-02  -1.07474251e+01  -1.57431841e+01  -3.84477043e+00
   -4.51697540e+00  -1.74773006e+01  -2.89952183e+01  -2.10652237e+01
   -1.85988541e+01  -3.33917503e+01  -2.17388935e+01  -6.55383873e+00
   -2.17218513e+01  -3.68452148e+01  -4.37758827e+01  -2.69895954e+01
   -1.41817169e+01  -2.23604660e+01  -1.43865242e+01  -2.52570953e+01
   -9.48106575e+00]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 87
images_for_training/282
(1, 64, 64, 3)
Policy eval: 
[[  9.35151577e-01   2.91987163e-07   3.20779208e-08   9.37112734e-22
    8.93525740e-11   4.04526723e-18   4.37798588e-13   1.17386734e-11
    1.94925964e-09   4.16507412e-10   9.77843320e-06   2.35165665e-19
    2.97085805e-18   6.65691928e-08   2.14106755e-09   1.23826135e-06
    2.43998412e-03   1.49781326e-10   6.72394002e-04   3.30372708e-12
    1.06436877e-08   1.78457782e-08   1.52076723e-07   4.43976860e-05
    1.14820778e-13   1.50105794e-08   4.29924019e-02   1.22046311e-08
    1.85617282e-05   3.11315250e-15   1.03387147e-15   1.86687354e-02
    3.37116198e-20   1.13658648e-11   7.17142351e-16   3.56523351e-22
    2.13548233e-07   1.00426633e-12   2.35635011e-14   3.21914126e-13
    6.72149281e-11]]
Log Policy eval: 
[[ -3.87702859e-03  -7.74444723e+00  -2.61308727e+01  -2.91230297e+01
   -1.66169987e+01  -2.56663628e+01  -1.32887955e+01  -2.39007950e+01
   -3.07518501e+01  -1.88374081e+01  -2.22197914e+01  -3.50116272e+01
   -1.68377666e+01  -2.20562744e+01  -2.90415058e+01  -2.12211475e+01
   -6.72881842e+00  -1.99700966e+01  -8.22567844e+00  -2.21175289e+01
   -1.31604891e+01  -1.15828810e+01  -8.69820309e+00  -1.38794880e+01
   -1.11388941e+01  -2.00720539e+01  -6.33267736e+00  -2.68624763e+01
   -3.25146484e+01  -2.01923199e+01  -2.96430511e+01  -2.29622173e+01
   -2.04910679e+01  -2.49975147e+01  -3.99700546e+01  -1.56634960e+01
   -2.43117924e+01  -2.33404789e+01  -2.99888210e+01  -2.42738285e+01
   -3.05979652e+01]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 88
images_for_training/18
(1, 64, 64, 3)
Policy eval: 
[[  8.96390751e-02   1.94320008e-01   9.68407188e-03   3.41962914e-05
    1.02159393e-03   7.57975329e-04   4.32953332e-03   1.92428567e-02
    2.83861882e-05   3.95660405e-04   3.81413905e-04   9.73166698e-06
    5.40117384e-04   1.11945017e-04   5.26033808e-03   2.00378951e-02
    6.96004853e-02   4.83089453e-03   8.27041492e-02   3.23625204e-06
    8.47281717e-06   9.13748809e-04   7.91208073e-02   2.18587182e-03
    3.09908032e-01   5.15862145e-02   9.63171944e-03   5.82826324e-03
    1.52019900e-04   2.06168294e-02   3.98224546e-03   7.38499407e-03
    2.95802904e-03   2.42298702e-05   5.58135844e-06   3.77760771e-05
    1.61896029e-03   6.01262727e-04   2.20288028e-04   2.80606066e-04
    4.42808528e-07]]
Log Policy eval: 
[[ -0.06753558  -5.72514772  -3.37038922 -11.00783062 -10.47817993
   -6.08075237 -12.78049755 -10.0366354  -10.2976284  -11.56486034
  -12.55384636 -13.89268208 -11.04110813  -7.83163071  -9.33399296
  -11.15230751  -8.03101158 -10.22301865  -7.58720398 -11.86375523
   -6.73020172  -7.35385942  -4.13108635  -9.22589207 -10.50389957
   -7.95534039  -6.95200968  -7.8521781  -12.0420475  -13.02372456
  -15.62944031  -5.93320179 -16.16944122 -13.11680603  -7.97750854
   -8.48232555  -9.35490704 -13.20699883 -12.62097549  -8.13252831
   -7.53952932]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 89
images_for_training/181
(1, 64, 64, 3)
Policy eval: 
[[ 0.04750265  0.04008139  0.0229305   0.00532494  0.01394301  0.02727575
   0.02257087  0.02200054  0.01443841  0.0238371   0.01551723  0.01602204
   0.00890953  0.02843092  0.04246853  0.0166118   0.03542994  0.01967097
   0.07528223  0.01410924  0.03481179  0.01724668  0.03679714  0.09878599
   0.01886104  0.02036951  0.03612585  0.01531876  0.00679443  0.02231337
   0.02596266  0.03396295  0.01003649  0.01665482  0.01764074  0.00831719
   0.01639224  0.01342289  0.01672477  0.0099265   0.01117652]]
Log Policy eval: 
[[-2.25666952 -3.24117088 -4.1889286  -5.00645256 -4.01138592 -4.3185544
  -4.98332691 -4.32214689 -3.65459299 -4.23458004 -4.56210613 -4.75123358
  -4.60067844 -4.3631382  -4.52325249 -3.82021785 -3.40271688 -4.15338421
  -3.06150579 -3.95791554 -3.25376177 -2.37612319 -3.5318203  -3.0413661
  -3.76591945 -4.11302137 -3.7248497  -3.40003443 -4.39862156 -3.50905776
  -3.74983311 -3.06285286 -4.72171116 -4.97614574 -4.24645805 -4.68907022
  -4.16161537 -3.98180103 -3.72959518 -4.13109064 -3.8536644 ]]
Action: 1.85
Enter Reward: 1
Backpropping 

Session Number 90
images_for_training/54
(1, 64, 64, 3)
Policy eval: 
[[  9.91933525e-01   1.75936686e-04   6.28797163e-04   3.17656850e-05
    7.89987553e-06   8.33263948e-06   2.19473964e-06   4.52102715e-04
    8.07276447e-05   3.09997381e-06   3.27205998e-05   4.08310434e-08
    4.30789732e-05   2.39315068e-05   1.08942986e-04   2.75779039e-05
    2.67006817e-05   9.85579732e-07   2.07863432e-05   2.91053584e-05
    1.18564267e-05   3.37619684e-04   2.27788350e-05   9.56737320e-04
    7.25896025e-05   2.93862172e-07   2.58118253e-05   7.53326021e-05
    6.98806389e-06   1.11111458e-05   1.02993181e-04   5.05643897e-04
    8.07870965e-05   2.47093340e-07   2.13994299e-05   4.69548297e-07
    2.78955069e-03   2.42508235e-04   1.65199701e-04   8.95553676e-04
    3.63380423e-05]]
Log Policy eval: 
[[ -0.35229111  -2.11285877  -9.99498558  -8.94912624  -9.30230904
   -4.96384621 -11.65018654  -7.24849272  -8.52531433  -8.79768562
  -11.12906265 -11.62537003  -8.49814987  -7.18373585  -7.49421549
   -9.82305622  -2.87448454  -4.94309568  -5.57207298  -5.21499109
   -8.1873436   -3.52416468  -4.67633772  -6.83201027  -6.61536407
   -9.61931896  -7.27997875  -8.06344318 -11.45336533  -7.86433601
  -13.10160542  -6.92086077  -6.97374535 -11.79706573  -9.05138302
  -10.30687809  -3.8087945   -9.78784752  -7.3864255   -3.67863989
   -8.76214218]]
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 91
images_for_training/26
(1, 64, 64, 3)
Policy eval: 
[[ 0.16680816  0.08747746  0.01713985  0.00914219  0.01987368  0.00659779
   0.00842737  0.00496798  0.01660618  0.01408957  0.01224652  0.00255124
   0.00305742  0.00960105  0.0008937   0.03637394  0.08506141  0.03735241
   0.03820757  0.00513552  0.06003851  0.04293589  0.03550195  0.02656035
   0.00951271  0.00790095  0.00682324  0.04464084  0.00849121  0.02648261
   0.00661695  0.01092293  0.07330193  0.00958463  0.00236184  0.00229177
   0.00876635  0.00512048  0.01786184  0.00843049  0.00424155]]
Log Policy eval: 
[[-0.89701539 -5.40796185 -4.20306301 -5.60912561 -6.25146484 -4.20606422
  -5.41920757 -4.84689522 -4.91267538 -5.30569792 -5.59325123 -4.00725365
  -4.42745113 -6.37369394 -5.63218975 -4.95068169 -3.97434497 -4.84694052
  -3.16460085 -3.19950795 -2.45959663 -4.67822886 -4.70925808 -2.92323184
  -4.15762281 -5.10881853 -3.01810098 -4.64841795 -7.59119892 -3.90315342
  -5.32910728 -3.00953746 -7.19388199 -4.94871616 -4.96449709 -5.12185955
  -4.22998619 -6.0786047  -5.00762224 -4.33481264 -6.29295349]]
Action: 1.95
Enter Reward: 0
Backpropping 

Session Number 92
images_for_training/145
(1, 64, 64, 3)
Policy eval: 
[[ 0.05502064  0.02809109  0.02403727  0.02112755  0.02475477  0.0203087
   0.01720856  0.01966088  0.01822255  0.0181077   0.02275525  0.01391689
   0.01515147  0.0287121   0.01645307  0.03111147  0.04069401  0.02494433
   0.02692528  0.02392782  0.04161495  0.04334512  0.02793077  0.04064051
   0.02146281  0.01659384  0.02326232  0.02096959  0.02146087  0.02037222
   0.01964919  0.02962741  0.02263928  0.01367919  0.02241224  0.01469149
   0.02374105  0.01854927  0.01955485  0.02252735  0.0241443 ]]
Log Policy eval: 
[[-2.67407179 -3.08565807 -3.59766006 -3.63471317 -4.00572252 -3.97916555
  -3.98781538 -3.66232467 -3.86141682 -4.08037949 -3.71370435 -4.18335056
  -3.91600084 -3.7580812  -3.90529656 -3.44546366 -3.64057517 -3.63283849
  -3.32459831 -4.25073528 -3.59775496 -3.47539711 -3.59434891 -3.78751516
  -3.70116234 -3.64147449 -3.87741995 -3.72354507 -3.97201705 -3.92405891
  -4.1350975  -3.61672831 -3.7124598  -4.19354105 -3.88354015 -3.9265635
  -3.8612237  -3.60540867 -3.94833183 -3.89913201 -3.84434748]]
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 93
images_for_training/213
(1, 64, 64, 3)
Policy eval: 
[[  5.80277860e-01   2.62957569e-02   6.94019627e-03   6.72426308e-04
    8.13517254e-03   2.56861746e-03   4.05679131e-03   3.33798677e-03
    2.50499579e-03   3.60579067e-03   5.06460434e-04   5.42103313e-04
    1.11337076e-03   3.20705207e-04   7.93970656e-03   1.81018524e-02
    5.30201662e-03   7.99820572e-03   1.02485847e-02   7.12996721e-03
    2.76006479e-02   2.49320678e-02   6.97771758e-02   1.81023311e-02
    1.03394613e-02   9.42200050e-03   8.23085103e-03   1.78831164e-02
    2.38925708e-03   6.57875556e-03   2.65211845e-03   6.70235381e-02
    9.41264722e-03   3.25815228e-04   3.30846827e-03   2.78078020e-03
    4.65720380e-03   3.03258630e-03   3.46227060e-03   5.77434013e-03
    4.71596094e-03]]
Log Policy eval: 
[[-2.16430426 -3.61398077 -4.94248295 -4.74836874 -4.99051428 -4.77991819
  -6.48275375 -3.65520763 -3.8981986  -5.17540312 -4.98224592 -4.77685833
  -4.50248814 -5.74529648 -6.23031807 -4.7260437  -1.52352798 -3.29405069
  -3.83188725 -4.03820229 -3.95659637 -1.948048   -3.72098541 -2.84019232
  -5.37584829 -6.00131035 -3.79607105 -4.48737001 -5.23304319 -3.43891144
  -5.49937582 -5.46442509 -5.37890244 -5.81820822 -4.24854469 -5.15429783
  -4.07609081 -5.86215305 -4.70568848 -3.07643509 -5.17354059]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 94
images_for_training/80
(1, 64, 64, 3)
Policy eval: 
[[ 0.09547125  0.01860087  0.00465359  0.00831626  0.0319577   0.00892352
   0.01109037  0.02632292  0.00659085  0.00482371  0.01397418  0.00488735
   0.00654129  0.01050771  0.02888256  0.04256178  0.01008135  0.00736513
   0.01254457  0.01072137  0.07894525  0.08442885  0.11494432  0.0683729
   0.01943097  0.0231691   0.00576341  0.06279811  0.00199525  0.03161172
   0.00588953  0.02721739  0.01589933  0.00195537  0.01189783  0.00865418
   0.0114645   0.00512655  0.00309512  0.04281306  0.00970903]]
Log Policy eval: 
[[-1.47388804 -3.42982292 -3.17931008 -5.16730213 -3.71069145 -4.80067968
  -4.48938084 -3.47645283 -3.88135672 -4.52653074 -4.10885239 -4.36316729
  -5.2152195  -4.88009977 -4.366364   -4.09862518 -2.43960571 -3.88051462
  -4.5485568  -3.56246901 -3.61147738 -4.42986965 -4.27855539 -2.70050812
  -3.65411091 -4.81249189 -3.67448854 -4.13305616 -4.89910793 -3.99766111
  -5.32940435 -3.30423689 -3.93789673 -6.08125925 -5.61855507 -4.91313744
  -5.42815351 -5.82846403 -3.7699275  -3.79734135 -3.99603891]]
Action: 0.75
Enter Reward: 1
Backpropping 

Session Number 95
images_for_training/161
(1, 64, 64, 3)
Policy eval: 
[[ 0.03850054  0.0309949   0.02503686  0.02032488  0.02489004  0.02378204
   0.0212973   0.02599786  0.02259566  0.02080944  0.02210367  0.02320319
   0.02038943  0.0233403   0.02697844  0.02476922  0.02712575  0.02943915
   0.02530169  0.0208534   0.02453624  0.03030343  0.0252201   0.02315863
   0.02261872  0.02661446  0.02911408  0.02385495  0.02128771  0.02332821
   0.02374158  0.0226244   0.02338824  0.0205489   0.02192654  0.02568919
   0.02496075  0.02445674  0.01915147  0.02340365  0.02233821]]
Log Policy eval: 
[[-3.2814765  -3.60889459 -3.82794213 -3.74797845 -3.75294924 -3.74153447
  -3.84008837 -3.71477175 -3.71177244 -3.84426117 -3.81745315 -3.90648127
  -3.81574583 -3.82619238 -3.75370646 -3.82273364 -3.59491706 -3.91505384
  -3.68536234 -3.67190838 -3.48850298 -3.5194037  -3.60658216 -3.6375432
  -3.64041829 -3.72422194 -3.67966866 -3.55549502 -3.76816225 -3.7338419
  -3.9025526  -3.61924815 -3.86259651 -3.96900272 -3.71085143 -3.58823609
  -3.85493803 -3.85975957 -3.65402055 -3.65437841 -3.7198422 ]]
Action: 0.1
Enter Reward: 0
Backpropping 

Session Number 96
images_for_training/156
(1, 64, 64, 3)
Policy eval: 
[[ 0.03389906  0.02673438  0.02461038  0.0208807   0.02573738  0.02509345
   0.02250952  0.02469424  0.02273997  0.02376351  0.02158173  0.01873776
   0.02123904  0.02457302  0.02500488  0.02488325  0.02654648  0.02493863
   0.02445623  0.02403433  0.02678248  0.02614304  0.02570789  0.02771527
   0.02476036  0.0250952   0.02570892  0.02669121  0.02273298  0.02384732
   0.02265118  0.02825151  0.02387595  0.02041889  0.02371043  0.02375106
   0.02287319  0.02268502  0.0238963   0.02391989  0.02212392]]
Log Policy eval: 
[[-3.50770998 -3.58203554 -3.747473   -3.7286787  -3.72554922 -3.67971325
  -3.8202107  -3.69713354 -3.79647613 -3.7971046  -3.85326648 -3.84510255
  -3.90523982 -3.84101486 -3.74143434 -3.60541439 -3.563694   -3.66053367
  -3.63127279 -3.73617983 -3.59130716 -3.49261165 -3.59609079 -3.71099901
  -3.69963646 -3.55036521 -3.8509326  -3.62938356 -3.79442334 -3.71236467
  -3.83765078 -3.67317557 -3.69979525 -3.99158835 -3.87580967 -3.73979902
  -3.77994752 -3.78320169 -3.71377873 -3.70456862 -3.6128602 ]]
Action: 0.2
Enter Reward: 0
Backpropping 

Session Number 97
images_for_training/93
(1, 64, 64, 3)
Policy eval: 
[[ 0.54413098  0.02043121  0.01161314  0.00613388  0.01250769  0.00556439
   0.00378558  0.01437155  0.01162768  0.00657545  0.00241637  0.01625254
   0.00520153  0.00272494  0.00353232  0.0134217   0.03545371  0.02023257
   0.03262428  0.00708229  0.02336228  0.0155038   0.01702433  0.03085999
   0.01283903  0.01140959  0.01095231  0.01481026  0.00355964  0.00766754
   0.0078595   0.00670334  0.00494327  0.002805    0.00348127  0.01789129
   0.00297561  0.00366554  0.01580916  0.00332502  0.00686841]]
Log Policy eval: 
[[-0.48043993 -4.50419521 -4.95177126 -4.79525471 -4.80997086 -5.00814581
  -5.40314007 -4.03521395 -6.15838909 -6.21966362 -6.33455086 -5.17427301
  -5.4900341  -7.51247454 -6.00339746 -3.79062867 -4.30504227 -4.50728083
  -4.85946035 -5.09768581 -3.82134438 -3.42052674 -3.25069094 -4.08764076
  -4.52882481 -4.72436476 -5.56034565 -4.67173004 -6.93933964 -4.04865599
  -6.21191883 -4.27188778 -4.2005887  -7.89568377 -5.61090994 -4.27067423
  -4.44512272 -5.90690708 -6.54872179 -4.85319996 -5.43487167]]
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 98
images_for_training/180
(1, 64, 64, 3)
Policy eval: 
[[ 0.03375103  0.02928075  0.02344564  0.02245565  0.02623947  0.02430096
   0.02059869  0.02461808  0.02448239  0.02149517  0.02180443  0.01851081
   0.0217237   0.02371299  0.02108432  0.026597    0.02554348  0.022025
   0.02571601  0.02841629  0.0257652   0.0329162   0.02716174  0.0282659
   0.02793238  0.02428881  0.02199225  0.02801046  0.02449427  0.02457688
   0.02035484  0.0244434   0.02240901  0.0179197   0.02489597  0.02386897
   0.02407738  0.02031118  0.02119402  0.02568862  0.02363095]]
Log Policy eval: 
[[-3.25944805 -3.65764427 -3.71503711 -3.69831562 -3.84505248 -3.71754599
  -3.79807901 -3.82757211 -3.78565454 -3.87489748 -3.65399313 -3.83935571
  -3.95501947 -3.76991796 -3.74770355 -3.64472389 -3.69562888 -3.75528145
  -3.61848736 -3.76057458 -3.51226568 -3.47193837 -3.63209534 -3.56250763
  -3.7531507  -3.77815318 -3.66364741 -3.65743542 -3.90439272 -3.75120401
  -3.86446905 -3.68762565 -3.4990499  -3.94463372 -3.84087205 -3.77790236
  -3.7954905  -3.91371584 -3.76108861 -3.61962628 -3.64132881]]
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 99
images_for_training/132
(1, 64, 64, 3)
Policy eval: 
[[ 0.0781618   0.03422195  0.02192837  0.02220845  0.01509736  0.03907738
   0.01463884  0.02688844  0.01967189  0.01309724  0.0143243   0.01748466
   0.01425741  0.02096904  0.01874532  0.02601822  0.02397994  0.01899866
   0.04020799  0.01875998  0.01899574  0.03465498  0.02942225  0.03363468
   0.02951576  0.02746224  0.01864186  0.03002592  0.01982286  0.01870544
   0.01907562  0.02837891  0.01459386  0.0212003   0.02654275  0.01620811
   0.03260433  0.01510457  0.02027737  0.02555679  0.02083851]]
Log Policy eval: 
[[-1.9733541  -3.84925508 -3.75309134 -4.04896355 -3.69623113 -3.61478376
  -4.50266075 -3.25915718 -3.91145754 -4.3534832  -4.25314093 -4.36641979
  -4.32440948 -3.9869442  -3.96943998 -3.83513117 -3.54031205 -3.92287445
  -3.8594842  -3.88029814 -3.42482805 -3.07085443 -3.76276398 -3.52163172
  -3.61793113 -4.0637784  -3.87258291 -3.5055728  -4.47723579 -4.29640484
  -4.34769344 -4.09803486 -4.09735203 -4.62473488 -3.96447182 -4.27451611
  -3.31934738 -3.9289372  -4.33442974 -3.01524782 -4.097363  ]]
Action: 1.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 21:57:20.086980: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/259
[[  0.00000000e+00   1.04971179e-35   9.48457655e-38   9.99999046e-01
    8.32846564e-34   0.00000000e+00   2.12153502e-36   1.25063026e-14
    5.08614842e-38   8.05496780e-27   9.72829570e-30   1.06221482e-13
    4.20093508e-27   0.00000000e+00   3.15943836e-21   3.80420351e-33
    0.00000000e+00   9.14544728e-07   7.31567087e-32   4.27750643e-26
    0.00000000e+00   0.00000000e+00   1.62167874e-31   0.00000000e+00
    0.00000000e+00   0.00000000e+00   2.08363687e-37   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.37671489e-32
    0.00000000e+00   0.00000000e+00   1.24219648e-35   6.81309284e-13
    0.00000000e+00   2.81626183e-31   6.72257207e-30   0.00000000e+00
    2.43283380e-29]]


[  0.00000000e+00   0.00000000e+00   5.21203550e-30   1.00000000e+00
   7.34381934e-21   1.07584084e-27   0.00000000e+00   1.39070787e-19
   5.07265943e-26   6.99984505e-31   0.00000000e+00   5.68884416e-36
   1.32328000e-37   0.00000000e+00   0.00000000e+00   2.14974302e-19
   5.52686036e-33   9.15475161e-27   6.02815716e-35   6.05527467e-38
   0.00000000e+00   0.00000000e+00   0.00000000e+00   6.50364290e-33
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   3.05108136e-33
   0.00000000e+00   0.00000000e+00   2.23976354e-29   6.42312965e-22
   0.00000000e+00   2.13952961e-22   0.00000000e+00   9.70526133e-35
   3.02685109e-19]
2018-10-05 21:57:21.347 Python[36311:13919440] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 0.35
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 22:02:35.603284: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/152
[-18.86264992  -8.45759296 -14.6785965  -13.34700298 -19.56065178
 -19.42166901 -28.36836433 -23.29914093 -17.63306999 -14.06186581
 -19.11785316 -27.53760147  -9.76494694  -5.27615738 -17.0390377
 -20.82597542 -10.87073421 -30.56030273  -1.21406269 -12.93382645
 -19.77116203 -23.54000282 -18.16125679 -12.75092888 -19.45140648
 -17.89208794 -25.81315231 -19.6633873  -24.55824661 -14.17683506
 -24.98259354 -16.25368309 -16.10341644 -10.55879498 -16.73358536
 -14.91169643 -12.92910099 -16.49852943  -0.36014849 -14.94335365
 -20.43674088]
-655.727
2018-10-05 22:02:36.744 Python[36468:13922698] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
-1
Action: 1.65
Enter Reward: Breaking 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 22:10:20.718811: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/214
[-119.72684479 -152.40255737 -200.93487549    0.         -191.2203064
 -111.91413879 -144.98345947 -105.55688477  -65.53433228 -189.6254425
  -97.51225281 -154.30032349 -127.52011871 -153.08766174 -108.95826721
 -129.4490509  -125.00326538  -58.36903381 -153.69572449 -254.95158386
 -204.28097534  -75.42500305 -225.6583252  -145.14399719 -216.76593018
 -132.71990967 -257.18154907 -118.65080261 -160.41085815  -98.81188202
 -185.90960693 -115.25309753 -143.70941162 -164.06906128 -121.23849487
  -70.75473022  -46.22631073  -72.40503693  -98.45426941  -71.30603027
 -184.06326294]
Sum of Policy eval
1.0
2018-10-05 22:10:21.914 Python[36700:13927831] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 1.75
Enter Reward: -1
Breaking 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 22:22:54.772877: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/110
[ -6.69803095e+00  -3.32181091e+01  -3.71102409e+01  -1.65707512e+01
  -6.07665491e+00  -4.55461769e+01  -2.85780087e+01  -4.58143959e+01
  -8.89866638e+00  -1.35607214e+01  -3.00395908e+01  -4.57290764e+01
  -5.63585901e+00  -4.18634644e+01  -3.73748856e+01  -2.76374950e+01
  -2.74671345e+01  -4.99534912e+01  -1.65338192e+01  -2.82707539e+01
  -3.44225235e+01  -5.07462425e+01  -4.50099068e+01  -2.47691612e+01
  -3.02321911e+01  -3.41963425e+01  -2.87416291e+00  -2.55409966e+01
  -3.48260460e+01  -8.99196815e+00  -3.04627514e+01  -1.72822418e+01
  -6.59525469e-02  -6.16246681e+01  -3.25602760e+01  -2.39848499e+01
  -2.72561092e+01  -7.11333008e+01  -3.67466316e+01  -1.30867786e+01
  -1.78369770e+01]
Sum of Policy eval
1.0
Indices
Traceback (most recent call last):
  File "Loader.py", line 189, in <module>
    rewards,flag = generate_session()  #generate new sessions
  File "Loader.py", line 136, in generate_session
    print(indices.eval({states:s}))
TypeError: unhashable type: 'numpy.ndarray'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 22:33:51.690603: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/68
[  4.97371075e-04   6.21314278e-10   4.29193278e-05   8.02841613e-11
   1.23679172e-04   2.78311263e-10   8.16737338e-06   2.57203221e-12
   2.37407605e-09   1.93274516e-08   1.60206977e-08   2.59733248e-08
   5.60024288e-04   6.89641893e-05   1.92298488e-13   5.14005817e-11
   1.34791023e-08   2.73647231e-07   1.49505075e-09   2.26612600e-11
   5.12588166e-11   8.63475236e-10   8.97038138e-11   9.68424141e-01
   9.33952915e-10   7.05459025e-11   5.18285844e-07   9.04267095e-03
   3.91804997e-06   3.35211251e-16   3.80089987e-11   5.46455290e-08
   3.09826253e-04   2.16723447e-06   6.10019035e-10   9.79297532e-09
   2.09148098e-02   4.19389697e-11   3.40884525e-12   4.72778993e-07
   2.77981566e-12]
Sum of Policy eval
1.0
Indices
Tensor("stack:0", shape=(?, 2), dtype=int32)
2018-10-05 22:33:52.880 Python[37270:13940708] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 0.55
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 22:36:52.838407: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/290
[  0.00000000e+00   0.00000000e+00   0.00000000e+00   4.65989213e-14
   0.00000000e+00   7.85410136e-32   0.00000000e+00   4.06878780e-37
   0.00000000e+00   3.55371976e-09   0.00000000e+00   0.00000000e+00
   2.92464331e-28   9.63771638e-22   0.00000000e+00   2.63613895e-32
   2.69366064e-05   1.25508212e-23   0.00000000e+00   0.00000000e+00
   7.98192564e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   8.86180924e-19   1.09517691e-03   0.00000000e+00   7.00199366e-01
   0.00000000e+00   0.00000000e+00   0.00000000e+00   3.42445456e-25
   0.00000000e+00   4.51781678e-13   2.92374250e-11   2.98678488e-01
   4.19149868e-36   0.00000000e+00   4.29200365e-24   5.28353301e-14
   6.41334248e-31]
Sum of Policy eval
Indices
Traceback (most recent call last):
  File "Loader.py", line 188, in <module>
    rewards,flag = generate_session()  #generate new sessions
  File "Loader.py", line 135, in generate_session
    print(tf.stack([tf.range(tf.shape(log_policy.eval({states:s}))[0]),actions],axis=-1))
TypeError: unhashable type: 'numpy.ndarray'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 22:38:01.033193: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/248
[  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.99981046e-01
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.15065413e-37   0.00000000e+00   0.00000000e+00
   1.56335061e-29   4.05438565e-23   0.00000000e+00   0.00000000e+00
   2.99677164e-20   0.00000000e+00   0.00000000e+00   0.00000000e+00
   3.75785720e-30   1.89329457e-05   1.92599142e-31   0.00000000e+00
   1.52785310e-28   0.00000000e+00   3.83324405e-31   0.00000000e+00
   0.00000000e+00   0.00000000e+00   6.32344591e-24   0.00000000e+00
   5.79367924e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.35153937e-20   0.00000000e+00   2.33308453e-22   0.00000000e+00
   6.75655342e-19]
Sum of Policy eval
2018-10-05 22:38:02.136 Python[37493:13943885] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 0.05
Indices
Traceback (most recent call last):
  File "Loader.py", line 192, in <module>
    rewards,flag = generate_session()  #generate new sessions
  File "Loader.py", line 149, in generate_session
    print(tf.stack([tf.range(tf.shape(log_policy.eval({states:s}))[0]),a1],axis=-1))
TypeError: unhashable type: 'numpy.ndarray'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
  File "Loader.py", line 144
    print(tf.stack([tf.range(tf.shape(log_policy.eval({states:s})[0]),a1],axis=-1)))
                                                                        ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py 
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-05 22:44:21.086880: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/222
[  0.00000000e+00   0.00000000e+00   0.00000000e+00   3.44559067e-34
   0.00000000e+00   2.41473668e-23   0.00000000e+00   0.00000000e+00
   1.95889492e-31   0.00000000e+00   2.19748106e-27   0.00000000e+00
   0.00000000e+00   1.54434481e-37   0.00000000e+00   0.00000000e+00
   0.00000000e+00   7.03283520e-09   7.15898821e-27   9.01556403e-26
   0.00000000e+00   3.94886556e-05   0.00000000e+00   1.04390037e-29
   0.00000000e+00   1.69774537e-34   0.00000000e+00   0.00000000e+00
   1.18755799e-25   0.00000000e+00   1.68326503e-30   0.00000000e+00
   1.88695844e-23   5.49393513e-33   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   9.99960542e-01]
Sum of Policy eval
2018-10-05 22:44:22.352 Python[37695:13947475] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 0.75
Indices
Traceback (most recent call last):
  File "Loader.py", line 189, in <module>
    rewards,flag = generate_session()  #generate new sessions
  File "Loader.py", line 145, in generate_session
    print(tf.stack([tf.range(tf.shape(log_policy.eval({states:s}))[0]),a1],axis=-1))
TypeError: unhashable type: 'numpy.ndarray'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-07 20:32:08.164699: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/127
[  1.20850120e-04   7.04470294e-05   1.61360759e-07   1.56000340e-06
   2.49057834e-04   1.27328633e-06   4.50255300e-08   5.98690076e-06
   2.98302166e-06   2.15841900e-03   2.46164327e-05   1.85511988e-02
   9.19250379e-05   1.57549512e-05   1.37044162e-01   5.48842718e-06
   1.75036888e-07   5.76073171e-06   1.01619959e-02   1.25814672e-03
   5.73984107e-05   1.38935357e-04   8.15747713e-04   6.20720994e-06
   4.91524297e-05   4.94357675e-01   7.20902020e-03   4.17193791e-09
   3.24632794e-01   8.60580127e-04   2.79042615e-05   9.09658684e-06
   4.12033998e-08   6.62656987e-07   8.02282375e-05   1.19972510e-05
   3.47098685e-05   1.43041252e-03   1.17169271e-04   4.48396240e-05
   3.45404202e-04]
Sum of Policy eval
2018-10-07 20:32:09.385 Python[58563:14502008] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 1.4
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Saving Weights
##################################################
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Loader.py
Using TensorFlow backend.
Loading Model 

WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-10-07 20:32:38.185433: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/usr/local/lib/python3.6/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
Session Number 0
images_for_training/202
[  9.63941921e-21   0.00000000e+00   9.99826968e-01   0.00000000e+00
   2.58701368e-35   0.00000000e+00   1.73107837e-04   1.19286767e-29
   0.00000000e+00   1.18852448e-08   1.51129941e-23   1.00570352e-28
   7.49205744e-35   0.00000000e+00   3.56438924e-19   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.85720687e-24   8.17540334e-30
   0.00000000e+00   0.00000000e+00   0.00000000e+00   5.61693703e-23
   1.89998234e-22   0.00000000e+00   0.00000000e+00   1.16547144e-35
   0.00000000e+00   4.23614626e-33   0.00000000e+00   1.15781408e-35
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.67953954e-21]
Sum of Policy eval
2018-10-07 20:32:39.380 Python[58630:14502567] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action: 1.65
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 1
images_for_training/110
[  2.25110711e-11   4.04609863e-21   1.36314469e-07   1.08386189e-10
   2.45965755e-04   1.62445990e-12   1.00989775e-04   1.75517302e-13
   3.99775724e-09   3.08210705e-12   2.84265316e-05   9.98488307e-01
   1.07026128e-12   1.14074421e-08   6.73230807e-06   2.64937182e-12
   1.06440503e-07   1.00983790e-08   1.07662211e-13   1.41188415e-14
   1.65672445e-15   9.55863420e-21   4.12167262e-12   3.92657545e-10
   5.00386420e-07   4.37423643e-16   1.30603796e-26   5.72427565e-12
   2.64112824e-19   7.77605447e-09   1.12630276e-03   3.30948371e-19
   6.71113606e-15   2.12315149e-06   1.21576438e-08   2.63910797e-16
   3.22979133e-07   4.90371327e-14   5.24896805e-18   7.54530396e-11
   9.64589478e-19]
Sum of Policy eval
Action: 1.15
Enter Reward: 0
Backpropping 

Session Number 2
images_for_training/192
[  1.04290086e-25   1.97859021e-11   4.32778938e-16   9.63396477e-19
   7.21967972e-11   2.42340991e-19   4.00767214e-22   2.28552109e-25
   6.52870597e-31   3.17583789e-14   1.09649872e-13   2.65444663e-19
   9.16566544e-17   1.44714957e-20   1.03436876e-21   4.85485227e-23
   3.95075913e-25   1.24927985e-10   1.00000000e+00   2.53901745e-24
   3.35669578e-29   7.57509568e-19   1.28539954e-27   1.64794262e-10
   2.17608561e-21   4.24185618e-20   7.57567759e-33   2.67502544e-23
   6.95168564e-22   6.20722461e-23   3.21153672e-27   1.55231622e-20
   9.28351471e-24   3.74868560e-19   1.82089214e-16   2.87429958e-15
   3.90310627e-26   6.38930443e-23   1.67954066e-15   3.45900152e-19
   4.19952053e-16]
Sum of Policy eval
Action: 1.15
Enter Reward: 0
Backpropping 

Session Number 3
images_for_training/214
[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   7.25781666e-34   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   9.99964356e-01   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   4.53664777e-19
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.56286509e-05   0.00000000e+00   0.00000000e+00
   1.78802938e-38]
Sum of Policy eval
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 4
images_for_training/80
[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   1.03793848e-20   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 5
images_for_training/6
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.]
Sum of Policy eval
Action: 1.15
Enter Reward: 1
Backpropping 

Session Number 6
images_for_training/186
[  9.80112873e-07   5.80891411e-11   1.32025484e-14   3.77556450e-12
   3.64588954e-18   1.93847810e-15   4.63238159e-08   2.14337804e-21
   1.20817960e-20   1.91629879e-20   1.41032388e-06   5.08008350e-04
   4.62271032e-07   1.75359639e-14   8.72948379e-22   1.08201252e-08
   3.62003121e-17   1.44016967e-08   9.99488831e-01   4.66905980e-31
   3.06982720e-20   6.51605714e-11   7.90967214e-19   6.99186819e-15
   4.85840231e-18   1.39478401e-17   9.97239253e-21   3.01158241e-24
   2.67022266e-16   2.78131795e-25   8.74787782e-16   1.07036079e-17
   1.90490212e-25   1.91024564e-15   1.94768819e-11   2.13914316e-17
   9.83019437e-20   2.18331394e-07   1.14930129e-19   8.29986689e-26
   3.44174550e-19]
Sum of Policy eval
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 7
images_for_training/158
[  4.50385931e-13   4.94348387e-06   3.68575104e-09   1.90478588e-09
   3.27822926e-14   9.29391199e-12   4.36327845e-08   1.07681986e-15
   1.42172526e-22   5.68349590e-09   6.93276503e-09   9.07773435e-01
   4.24998535e-12   1.06624320e-04   2.76558507e-17   3.88729361e-11
   2.43597226e-11   1.45661732e-08   2.08029604e-07   1.86595747e-16
   4.20650514e-10   8.43767244e-12   1.96531522e-19   6.87500171e-04
   3.68799369e-17   3.21897955e-12   2.95736842e-16   8.79342692e-12
   1.37813491e-12   5.58843158e-15   5.49472794e-13   3.06230504e-07
   4.00363920e-09   1.41034909e-11   3.11271942e-05   2.93026066e-08
   6.84444867e-16   9.13957879e-02   2.01828152e-16   3.96339794e-14
   8.67244276e-10]
Sum of Policy eval
Action: 0.9
Enter Reward: 0
Backpropping 

Session Number 8
images_for_training/266
[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.02417780e-17   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.16821298e-06
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   9.99998808e-01   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.45
Enter Reward: 1
Backpropping 

Session Number 9
images_for_training/183
[  2.19264757e-06   5.64051277e-08   3.24846677e-11   1.47406219e-11
   9.73798678e-14   9.94749124e-14   1.08611388e-07   4.01792011e-12
   1.31731749e-18   4.58356197e-08   1.91659841e-10   9.99975681e-01
   3.95801329e-08   2.30057310e-07   1.33563247e-14   5.94917404e-09
   3.04511407e-13   9.70386271e-12   1.25394150e-12   6.36825553e-13
   2.38465355e-14   2.66393869e-07   1.73364417e-17   2.13799285e-05
   1.08073888e-11   4.93609890e-15   8.72111151e-12   4.90469265e-09
   2.73568137e-15   3.79150595e-13   8.58492032e-16   1.73703621e-14
   6.01816394e-13   3.22111456e-12   6.32116637e-10   3.84788165e-12
   8.29484701e-13   5.50055168e-10   4.80959019e-16   4.46850571e-14
   2.89302783e-12]
Sum of Policy eval
Action: 1.7
Enter Reward: 0
Backpropping 

Session Number 10
images_for_training/243
[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.69123903e-15   1.78635424e-16
   0.00000000e+00   0.00000000e+00   0.00000000e+00   3.89638691e-31
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   1.71575311e-15   1.35324097e-36
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.5
Enter Reward: 1
Backpropping 

Saving Weights
##################################################
Session Number 11
images_for_training/134
[  9.96291637e-01   4.83115082e-06   7.95962569e-06   7.72074136e-13
   2.44105691e-12   7.60097749e-11   2.10696771e-06   2.65627641e-11
   3.28189621e-19   6.50526601e-08   2.32387637e-03   6.88501677e-05
   1.80487914e-09   1.04728963e-06   2.44251130e-11   3.61724710e-06
   1.95766389e-10   5.35543841e-05   5.24453696e-07   4.93552580e-14
   8.28995983e-09   1.87480794e-07   5.77293876e-16   3.27732323e-06
   1.72444892e-10   4.69155535e-17   6.83634278e-15   2.65507727e-10
   7.26053706e-09   6.15035282e-15   3.14630600e-15   1.34427067e-10
   7.03303416e-09   2.92822833e-09   1.23517634e-03   1.93265123e-06
   4.39878467e-13   1.31233708e-06   5.82887782e-09   2.19982059e-08
   4.11221102e-09]
Sum of Policy eval
Action: 0.5
Enter Reward: 0
Backpropping 

Session Number 12
images_for_training/70
[  2.62674644e-06   1.75226757e-37   2.61222923e-12   0.00000000e+00
   5.12871070e-23   0.00000000e+00   8.82202263e-15   6.79530010e-36
   0.00000000e+00   7.59697210e-29   1.17326444e-25   9.99997377e-01
   0.00000000e+00   2.42430900e-27   0.00000000e+00   5.39297068e-18
   8.95829173e-28   7.35552551e-27   7.90791658e-23   0.00000000e+00
   2.90910889e-35   3.14125827e-31   9.05418262e-27   1.13668686e-30
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.03790243e-26   0.00000000e+00   1.50936911e-36   3.25319749e-09
   4.17723720e-31   2.23375334e-34   1.22644408e-13   1.10023413e-34
   0.00000000e+00   9.57660165e-18   0.00000000e+00   4.15453422e-28
   5.94324778e-35]
Sum of Policy eval
Action: 0.55
Enter Reward: 0
Backpropping 

Session Number 13
images_for_training/298
[  3.80306737e-04   5.53731537e-34   2.23096397e-25   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.28467923e-26   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.91563617e-03   2.04008342e-25
   6.23220578e-28   0.00000000e+00   0.00000000e+00   1.22426635e-14
   0.00000000e+00   0.00000000e+00   3.31655259e-10   0.00000000e+00
   0.00000000e+00   1.23487931e-24   0.00000000e+00   9.58992213e-32
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.32552128e-29   0.00000000e+00   5.53914379e-30   3.89479633e-28
   0.00000000e+00   0.00000000e+00   9.96704042e-01   3.56951416e-21
   0.00000000e+00   9.15485721e-31   0.00000000e+00   7.49416398e-14
   0.00000000e+00]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 14
images_for_training/271
[  9.99999166e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.42038657e-19   0.00000000e+00
   0.00000000e+00   1.02858195e-32   6.64966547e-34   2.08223438e-11
   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.86548945e-29
   0.00000000e+00   3.72691147e-18   3.20896154e-35   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   5.86656442e-26
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   8.00136896e-21   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.29994467e-37   0.00000000e+00   0.00000000e+00   8.73810620e-07
   0.00000000e+00   2.22752139e-33   0.00000000e+00   4.33462366e-32
   0.00000000e+00]
Sum of Policy eval
Action: 0.55
Enter Reward: 1
Backpropping 

Session Number 15
images_for_training/263
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.07661377e-17   1.88649504e-21
   2.31519236e-30   0.00000000e+00   0.00000000e+00   1.08992807e-25
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.48980770e-38
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.85054845e-38   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.9
Enter Reward: 1
Backpropping 

Session Number 16
images_for_training/154
[  7.62290955e-01   5.05926204e-04   1.57293223e-03   5.72711033e-05
   5.22835937e-04   1.40238099e-05   5.30729257e-02   1.27018141e-02
   1.22809467e-07   1.55355334e-02   3.60471022e-04   6.47388538e-03
   1.32670533e-03   3.90565459e-04   4.60164301e-05   6.72641443e-03
   3.73547710e-03   7.32130185e-02   8.08232217e-05   3.62983090e-04
   2.24931568e-06   2.42832303e-03   6.66571359e-05   3.01371310e-02
   3.46372399e-05   3.84212653e-05   1.40908815e-05   8.36258732e-06
   3.28468764e-03   2.39578440e-04   1.18990492e-05   1.43783127e-05
   1.59849774e-03   1.46468055e-05   2.67582102e-04   1.05910338e-04
   8.17233231e-05   5.73919993e-03   1.59381551e-03   1.44693684e-02
   8.58237967e-04]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 17
images_for_training/11
[  9.99781430e-01   3.83573279e-20   1.10387777e-09   2.88849169e-19
   2.16059859e-21   1.82124535e-15   4.26864881e-06   3.10546995e-17
   4.82752697e-18   2.79285987e-11   4.70077102e-11   5.24777442e-06
   1.66068718e-15   2.91449191e-11   2.78771333e-15   1.23946720e-09
   3.38961986e-14   1.69614751e-07   2.67041733e-13   3.61727860e-18
   1.60236147e-11   1.99739642e-21   1.37292808e-17   2.00997504e-16
   2.11871789e-23   6.45274347e-21   1.00817903e-25   3.92998240e-17
   5.51468186e-14   8.34352456e-22   2.37789082e-22   4.38070154e-17
   2.08909143e-04   1.45248017e-19   1.22059030e-10   8.43490859e-14
   3.75329108e-14   2.69738637e-12   1.20011958e-23   3.14806514e-12
   1.41150457e-16]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 18
images_for_training/5
[  9.99910355e-01   0.00000000e+00   1.46545476e-23   4.96705086e-24
   1.35260428e-20   1.07631683e-31   3.71800211e-19   2.02948194e-23
   0.00000000e+00   2.14885029e-22   7.05214909e-16   5.97090137e-37
   0.00000000e+00   5.02886126e-24   9.59795227e-36   8.24832268e-23
   1.14929019e-12   5.84179860e-09   9.98437860e-11   0.00000000e+00
   2.13476394e-30   1.89482544e-17   2.94932298e-22   1.34443941e-14
   0.00000000e+00   0.00000000e+00   6.07617025e-34   8.53272523e-35
   1.07693050e-13   5.86373489e-35   9.79566642e-27   3.89055817e-23
   4.35934770e-30   1.75696025e-30   8.95809499e-05   2.51339841e-24
   0.00000000e+00   1.00476220e-23   0.00000000e+00   3.06054002e-11
   1.50763877e-20]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 19
images_for_training/141
[  9.26892698e-01   9.61172191e-07   3.31465446e-04   5.79816378e-06
   5.02285984e-05   2.68363465e-07   2.19070981e-03   1.79534054e-05
   4.47323004e-07   1.08853513e-02   7.62208074e-04   2.86099239e-05
   9.01029307e-06   3.57656623e-04   4.76694950e-05   3.05781397e-03
   5.78607469e-05   1.44847215e-03   4.29175086e-02   5.69819567e-05
   3.16007499e-05   1.07029534e-03   9.04104381e-05   2.44898074e-05
   3.42041239e-05   2.38418281e-07   2.69017028e-06   4.05506125e-06
   3.17025068e-03   8.98008784e-06   3.48440990e-05   4.36984155e-05
   7.17144503e-05   1.25560405e-06   6.10335730e-03   2.21728151e-05
   1.23124585e-06   1.09947150e-05   2.32129551e-08   7.57820380e-05
   7.79439506e-05]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 20
images_for_training/65
[  1.00000000e+00   0.00000000e+00   7.75969136e-30   0.00000000e+00
   1.64683431e-24   0.00000000e+00   8.15202720e-15   7.45716354e-36
   0.00000000e+00   2.48606523e-31   2.94759121e-33   0.00000000e+00
   0.00000000e+00   8.55887318e-38   0.00000000e+00   1.88551547e-37
   3.08490068e-35   9.10614566e-31   2.17729163e-19   0.00000000e+00
   0.00000000e+00   2.69916049e-34   0.00000000e+00   1.80562026e-30
   0.00000000e+00   7.77338060e-37   0.00000000e+00   0.00000000e+00
   1.36075419e-33   7.85718820e-36   0.00000000e+00   4.59415978e-34
   5.38508008e-22   0.00000000e+00   0.00000000e+00   1.16832989e-29
   1.02951501e-36   1.12045224e-28   0.00000000e+00   6.96719319e-36
   8.29116203e-12]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 21
images_for_training/257
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   7.38562756e-35   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   3.48618426e-34]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 22
images_for_training/29
[  9.99720991e-01   0.00000000e+00   2.09750384e-24   4.53645407e-22
   1.20246476e-26   1.34501064e-29   1.30998023e-06   3.02374312e-35
   0.00000000e+00   7.33327464e-25   8.11666220e-19   0.00000000e+00
   1.46523211e-32   1.82157011e-33   0.00000000e+00   8.29904451e-25
   1.04339854e-16   2.77678773e-04   2.57561808e-16   1.17008473e-32
   4.01509670e-27   2.28707267e-32   0.00000000e+00   3.52250438e-18
   1.20432309e-35   9.29900517e-30   0.00000000e+00   1.16384830e-24
   8.45484930e-19   4.08146576e-36   1.03349945e-23   7.37046052e-33
   1.50461523e-17   2.73275987e-25   4.38183691e-11   1.16048149e-20
   1.21394144e-25   1.42603333e-36   0.00000000e+00   6.24609403e-26
   3.51227136e-08]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 23
images_for_training/15
[  1.00000000e+00   1.02582089e-31   0.00000000e+00   4.68075459e-33
   0.00000000e+00   0.00000000e+00   1.03038696e-29   8.33125355e-38
   0.00000000e+00   1.47785606e-34   8.36633079e-35   0.00000000e+00
   1.79554356e-38   4.64586305e-36   0.00000000e+00   4.22599905e-26
   4.74215487e-38   3.48989387e-28   2.68764757e-38   0.00000000e+00
   1.11207125e-37   0.00000000e+00   0.00000000e+00   2.34773607e-36
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   9.22953839e-36   0.00000000e+00   3.95450462e-37   1.83806952e-36
   6.65485438e-32   3.18054448e-35   1.04915528e-22   2.15663764e-31
   4.36591109e-31   7.88923850e-35   0.00000000e+00   6.01985839e-36
   1.18503957e-24]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 24
images_for_training/67
[  1.00000000e+00   0.00000000e+00   9.25949243e-33   0.00000000e+00
   1.71386313e-37   0.00000000e+00   5.12314868e-24   2.05460229e-28
   0.00000000e+00   5.44412811e-31   1.96578493e-38   0.00000000e+00
   3.58095016e-28   0.00000000e+00   0.00000000e+00   8.36927433e-26
   3.22150993e-36   2.49418516e-25   5.37653963e-30   0.00000000e+00
   0.00000000e+00   3.06916874e-37   1.22908298e-30   2.67245796e-36
   0.00000000e+00   7.36277817e-37   0.00000000e+00   1.60607830e-33
   1.11532872e-24   0.00000000e+00   2.53206112e-33   0.00000000e+00
   9.96460592e-27   1.31522791e-37   1.65131489e-37   0.00000000e+00
   5.69053125e-38   6.02986541e-33   0.00000000e+00   1.60157524e-33
   3.62205206e-30]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 25
images_for_training/283
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.86090366e-38   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   7.13401374e-23   3.13009778e-29   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   8.03392188e-35
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   4.04134355e-35   0.00000000e+00   1.48112270e-28   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.81572506e-38]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 26
images_for_training/26
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.14250802e-32   0.00000000e+00
   0.00000000e+00   0.00000000e+00   8.45816399e-37   0.00000000e+00
   0.00000000e+00   8.76297791e-38   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.40558156e-21   1.46454077e-31   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.19954523e-29   0.00000000e+00   4.88799190e-28   8.43856913e-37
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.13546053e-35]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 27
images_for_training/289
[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 28
images_for_training/279
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.64293814e-31   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.29325561e-25   3.08942300e-35   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   9.04603839e-24   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 29
images_for_training/204
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   3.75922165e-21   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   4.07632414e-18   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   3.15531153e-35   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.05134190e-38   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 30
images_for_training/218
[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 31
images_for_training/270
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   6.31467892e-29   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.13941658e-36   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.83642939e-36   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   8.98623693e-37]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 32
images_for_training/1
[  1.00000000e+00   0.00000000e+00   2.32613949e-33   1.61335236e-36
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.80162021e-29   0.00000000e+00   0.00000000e+00
   0.00000000e+00   6.64732383e-38   0.00000000e+00   6.02340820e-32
   1.32851995e-37   1.04890104e-26   1.10031616e-35   9.48677095e-20
   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.71128911e-37
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   5.03951877e-28   0.00000000e+00   0.00000000e+00   0.00000000e+00
   5.57088092e-28   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.30756310e-32   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 33
images_for_training/242
[  1.00000000e+00   0.00000000e+00   2.24072808e-30   0.00000000e+00
   0.00000000e+00   0.00000000e+00   3.74001732e-18   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.04767945e-37   1.05259020e-23   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   6.95568934e-30   6.60948882e-33   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 34
images_for_training/202
[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.]
Sum of Policy eval
Action: 1.7
Enter Reward: 0
Backpropping 

Session Number 35
images_for_training/69
[  1.00000000e+00   0.00000000e+00   1.40663243e-29   0.00000000e+00
   1.94868279e-35   0.00000000e+00   1.57804970e-27   3.09242749e-29
   0.00000000e+00   8.33782210e-11   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.68998821e-33   0.00000000e+00   2.98550326e-24
   0.00000000e+00   3.25734118e-24   5.48910739e-09   0.00000000e+00
   0.00000000e+00   0.00000000e+00   1.15455966e-22   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.56230045e-30   0.00000000e+00   0.00000000e+00   0.00000000e+00
   4.42966507e-36   0.00000000e+00   2.10649767e-28   0.00000000e+00
   0.00000000e+00   2.91318412e-33   0.00000000e+00   3.11162817e-32
   0.00000000e+00]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 36
images_for_training/28
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.23097829e-26   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   4.63900118e-32
   0.00000000e+00   1.61464159e-33   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.15160804e-37   0.00000000e+00   0.00000000e+00   0.00000000e+00
   6.83785222e-38   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.97397780e-36   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.48579731e-35   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 37
images_for_training/72
[  1.00000000e+00   0.00000000e+00   7.01118667e-28   0.00000000e+00
   2.00856284e-35   0.00000000e+00   8.18553167e-36   2.42062323e-16
   0.00000000e+00   8.99448850e-25   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.50799176e-36   0.00000000e+00   4.80291857e-33
   9.42952892e-24   4.86635322e-21   1.65290306e-37   0.00000000e+00
   0.00000000e+00   2.97121181e-38   2.17316873e-33   2.46603351e-37
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.28663375e-28   0.00000000e+00   0.00000000e+00   0.00000000e+00
   4.23696055e-18   0.00000000e+00   3.40077604e-36   2.54019090e-38
   0.00000000e+00   7.39051401e-32   0.00000000e+00   1.89809952e-24
   1.12868884e-28]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 38
images_for_training/4
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   2.07873462e-35   9.38285596e-37
   0.00000000e+00   5.83457580e-30   6.23015606e-33   0.00000000e+00
   0.00000000e+00   1.36908806e-36   0.00000000e+00   0.00000000e+00
   2.05601375e-28   5.56042945e-30   1.89057300e-28   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.13617111e-35   0.00000000e+00   1.07686188e-37   0.00000000e+00
   3.26520115e-33   0.00000000e+00   1.18233903e-32   0.00000000e+00
   0.00000000e+00   3.50661743e-34   0.00000000e+00   1.15236396e-37
   9.03744801e-32]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 39
images_for_training/16
[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.62845671e-30   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   7.35296916e-33   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 40
images_for_training/139
[  9.99977827e-01   5.65396451e-24   1.44710182e-19   1.59330190e-17
   6.01417053e-21   8.97020145e-25   1.70904286e-07   1.69286059e-18
   6.52376468e-21   2.20980019e-05   1.63619777e-15   7.34154506e-24
   1.30156520e-19   3.53497444e-14   1.42738497e-21   2.89071698e-16
   4.36292387e-13   1.43672074e-10   4.29853422e-18   1.72115520e-16
   1.81152647e-16   6.78239635e-22   3.06268166e-21   3.62305346e-13
   2.06679671e-20   1.62672160e-20   4.76022888e-30   8.36206549e-19
   9.70707042e-15   1.86304897e-18   1.42425066e-23   9.16593861e-20
   3.18150606e-12   5.31474555e-19   9.32152982e-16   1.01773492e-10
   2.80855692e-28   1.07906073e-18   6.48038172e-29   5.26462774e-17
   4.74868938e-17]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Saving Weights
##################################################
Session Number 41
images_for_training/102
[  1.00000000e+00   7.26027394e-31   8.47222785e-18   2.40431899e-21
   2.80638813e-23   4.58826899e-29   1.07850387e-19   5.12697811e-25
   1.03736133e-26   2.43030059e-24   8.94332330e-21   8.99370199e-32
   3.30059255e-25   7.38351075e-36   6.28206115e-26   7.61841803e-27
   1.10375335e-23   2.15986506e-16   2.36313687e-21   1.63178939e-23
   3.17406705e-23   5.22119311e-21   1.04240080e-23   5.06953969e-28
   4.47118507e-31   2.26773667e-31   2.85041251e-35   1.99652065e-23
   5.39659861e-21   3.79198369e-23   5.23786539e-23   2.89661836e-25
   4.73291244e-26   1.81492866e-23   2.21740675e-20   2.91226696e-22
   1.53666382e-25   1.05660216e-21   9.98402365e-32   1.24225174e-13
   1.18433604e-14]
Sum of Policy eval
Action: 0.0
Enter Reward: 0
Backpropping 

Session Number 42
images_for_training/195
[  1.00000000e+00   2.43168740e-20   3.15717386e-15   3.60433488e-18
   9.06824788e-18   2.42938494e-15   1.60883262e-09   7.48884659e-18
   4.28275143e-26   1.70916595e-14   1.70299955e-14   2.55126820e-18
   1.18440528e-19   4.89532019e-15   2.82461429e-23   7.49537422e-15
   2.11593374e-08   3.00535812e-12   6.55013821e-11   6.32547688e-15
   2.27991085e-12   1.49501230e-14   6.69248821e-15   1.58334069e-16
   4.48426242e-19   1.07591505e-19   4.71417037e-27   8.44081170e-17
   4.48206739e-14   6.42346112e-18   1.07267202e-14   1.73538861e-15
   5.03133819e-12   3.55777216e-15   9.25513260e-14   3.44434903e-14
   1.11914652e-18   7.57614891e-12   2.09949668e-18   9.10867383e-14
   1.02863698e-11]
Sum of Policy eval
Action: 0.0
Enter Reward: -1
Breaking 

Saving Weights
##################################################
Saving Weights
##################################################

 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       

 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       


 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       


 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       



 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py 
Traceback (most recent call last):
  File "Reinforce_torch.py", line 187, in <module>
    main()
  File "Reinforce_torch.py", line 158, in main
    index_img = np.random.uniform(low = 1, high = 300, size = (t_max,)).astype(int)
NameError: name 't_max' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Traceback (most recent call last):
  File "Reinforce_torch.py", line 187, in <module>
    main()
  File "Reinforce_torch.py", line 157, in main
    for t in range(t_max = 100):  # Don't infinite loop while learning
TypeError: range() does not take keyword arguments
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/55
2018-10-07 22:54:20.104 Python[62293:14578062] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 188, in <module>
    main()
  File "Reinforce_torch.py", line 167, in main
    action = select_action(state)
  File "Reinforce_torch.py", line 130, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "Reinforce_torch.py", line 67, in forward
    out = self.layer1(x)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [32, 1, 5, 5], expected input[1, 64, 64, 3] to have 1 channels, but got 64 channels instead
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/225
2018-10-07 23:36:03.335 Python[62440:14582535] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 188, in <module>
    main()
  File "Reinforce_torch.py", line 167, in main
    action = select_action(state)
  File "Reinforce_torch.py", line 130, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "Reinforce_torch.py", line 67, in forward
    out = self.layer1(x)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [32, 3, 5, 5], expected input[1, 64, 64, 3] to have 3 channels, but got 64 channels instead
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/149
2018-10-07 23:42:51.038 Python[62612:14586836] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 188, in <module>
    main()
  File "Reinforce_torch.py", line 167, in main
    action = select_action(state.view(1,3,64,64))
TypeError: view() takes at most 2 arguments (4 given)
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
  File "Reinforce_torch.py", line 168
    print(action)
        ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/37
2018-10-07 23:48:32.544 Python[62784:14590276] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 188, in <module>
    main()
  File "Reinforce_torch.py", line 167, in main
    action = select_action(np.reshape(state,(1,3,64,64)))
  File "Reinforce_torch.py", line 130, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "Reinforce_torch.py", line 67, in forward
    out = self.layer1(x)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected 4-dimensional input for 4-dimensional weight [32, 3, 5, 5], but got input of size [1, 1, 3, 64, 64] instead
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/157
2018-10-07 23:49:13.131 Python[62831:14590812] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
25
Traceback (most recent call last):
  File "Reinforce_torch.py", line 188, in <module>
    main()
  File "Reinforce_torch.py", line 170, in main
    new_image = change_brightness(img,a)
  File "Reinforce_torch.py", line 81, in change_brightness
    image = brightness.enhance(brightness_factor)
  File "/usr/local/lib/python3.6/site-packages/PIL/ImageEnhance.py", line 37, in enhance
    return Image.blend(self.degenerate, self.image, factor)
  File "/usr/local/lib/python3.6/site-packages/PIL/Image.py", line 2613, in blend
    return im1._new(core.blend(im1.im, im2.im, alpha))
TypeError: must be real number, not tuple
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/190
2018-10-07 23:50:04.001 Python[62881:14591455] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

25
Traceback (most recent call last):
  File "Reinforce_torch.py", line 189, in <module>
    main()
  File "Reinforce_torch.py", line 171, in main
    new_image = change_brightness(img,a)
  File "Reinforce_torch.py", line 81, in change_brightness
    image = brightness.enhance(brightness_factor)
  File "/usr/local/lib/python3.6/site-packages/PIL/ImageEnhance.py", line 37, in enhance
    return Image.blend(self.degenerate, self.image, factor)
  File "/usr/local/lib/python3.6/site-packages/PIL/Image.py", line 2613, in blend
    return im1._new(core.blend(im1.im, im2.im, alpha))
TypeError: must be real number, not tuple
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/86
[[[ 1  1  1]
  [ 1  1  1]
  [ 1  1  1]
  ..., 
  [ 6  6  6]
  [ 4  4  4]
  [ 4  4  4]]

 [[ 1  1  1]
  [ 1  1  1]
  [ 1  1  1]
  ..., 
  [ 4  5  5]
  [ 3  3  3]
  [ 3  3  3]]

 [[ 1  1  1]
  [ 1  1  1]
  [ 1  1  1]
  ..., 
  [ 2  3  4]
  [ 2  2  2]
  [ 2  2  2]]

 ..., 
 [[ 4  3  4]
  [ 0  0  0]
  [ 0  0  0]
  ..., 
  [48 39 39]
  [47 38 39]
  [47 38 40]]

 [[ 4  3  4]
  [ 0  1  1]
  [ 0  0  0]
  ..., 
  [46 38 38]
  [48 39 40]
  [48 39 40]]

 [[ 4  3  4]
  [ 0  1  1]
  [ 0  0  0]
  ..., 
  [46 38 38]
  [48 39 40]
  [48 39 40]]]
2018-10-07 23:54:32.224 Python[63009:14594854] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

28
Traceback (most recent call last):
  File "Reinforce_torch.py", line 190, in <module>
    main()
  File "Reinforce_torch.py", line 172, in main
    new_image = change_brightness(img,a)
  File "Reinforce_torch.py", line 81, in change_brightness
    image = brightness.enhance(brightness_factor)
  File "/usr/local/lib/python3.6/site-packages/PIL/ImageEnhance.py", line 37, in enhance
    return Image.blend(self.degenerate, self.image, factor)
  File "/usr/local/lib/python3.6/site-packages/PIL/Image.py", line 2613, in blend
    return im1._new(core.blend(im1.im, im2.im, alpha))
TypeError: must be real number, not tuple
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/109
<class 'numpy.ndarray'>
2018-10-07 23:54:51.914 Python[63054:14595231] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

25
Traceback (most recent call last):
  File "Reinforce_torch.py", line 190, in <module>
    main()
  File "Reinforce_torch.py", line 172, in main
    new_image = change_brightness(img,a)
  File "Reinforce_torch.py", line 81, in change_brightness
    image = brightness.enhance(brightness_factor)
  File "/usr/local/lib/python3.6/site-packages/PIL/ImageEnhance.py", line 37, in enhance
    return Image.blend(self.degenerate, self.image, factor)
  File "/usr/local/lib/python3.6/site-packages/PIL/Image.py", line 2613, in blend
    return im1._new(core.blend(im1.im, im2.im, alpha))
TypeError: must be real number, not tuple
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/247
<class 'numpy.ndarray'>
2018-10-07 23:56:06.865 Python[63116:14596187] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

32
Traceback (most recent call last):
  File "Reinforce_torch.py", line 190, in <module>
    main()
  File "Reinforce_torch.py", line 173, in main
    plt.imshow(np.array(new_s))
NameError: name 'new_s' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/140
<class 'numpy.ndarray'>
2018-10-07 23:56:47.172 Python[63163:14596637] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

25
Enter Reward: 0
Traceback (most recent call last):
  File "Reinforce_torch.py", line 190, in <module>
    main()
  File "Reinforce_torch.py", line 177, in main
    if r==-1:
NameError: name 'r' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/150
<class 'numpy.ndarray'>
2018-10-07 23:57:10.523 Python[63207:14596984] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

25
Enter Reward: 0
images_for_training/81
<class 'numpy.ndarray'>
Action

1
Enter Reward: 0
images_for_training/285
<class 'numpy.ndarray'>
Action

1
Enter Reward: 0
images_for_training/196
<class 'numpy.ndarray'>
Action

16
Enter Reward: 0
images_for_training/173
<class 'numpy.ndarray'>
Action

26
Enter Reward: 0
images_for_training/69
<class 'numpy.ndarray'>
Action

21
Enter Reward: 1
images_for_training/228
<class 'numpy.ndarray'>
Action

25
Enter Reward: 0
images_for_training/91
<class 'numpy.ndarray'>
^CTraceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/matplotlib/backend_bases.py", line 1953, in motion_notify_event
    def motion_notify_event(self, x, y, guiEvent=None):
KeyboardInterrupt
Action

10
Enter Reward: xm
Traceback (most recent call last):
  File "Reinforce_torch.py", line 190, in <module>
    main()
  File "Reinforce_torch.py", line 176, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: 'xm'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/156
<class 'numpy.ndarray'>
2018-10-08 00:04:57.276 Python[63382:14603505] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

25
Enter Reward: 0
images_for_training/172
<class 'numpy.ndarray'>
Action

0
Enter Reward: biuhbihubi
Traceback (most recent call last):
  File "Reinforce_torch.py", line 190, in <module>
    main()
  File "Reinforce_torch.py", line 176, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: 'biuhbihubi'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
  File "Reinforce_torch.py", line 64
    def forward(self, x):
    ^
IndentationError: unexpected indent
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
  File "Reinforce_torch.py", line 64
    def forward(self, x):
    ^
IndentationError: unexpected indent
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Traceback (most recent call last):
  File "Reinforce_torch.py", line 123, in <module>
    policy = Policy()
TypeError: 'module' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Traceback (most recent call last):
  File "Reinforce_torch.py", line 125, in <module>
    optimizer = optim.Adam(policy.parameters(), lr=1e-2)
AttributeError: module 'Policy' has no attribute 'parameters'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Traceback (most recent call last):
  File "Reinforce_torch.py", line 125, in <module>
    optimizer = optim.Adam(policy.parameters(), lr=1e-2)
TypeError: parameters() missing 1 required positional argument: 'self'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Traceback (most recent call last):
  File "Reinforce_torch.py", line 125, in <module>
    optimizer = optim.Adam(policy.parameters(), lr=1e-2)
TypeError: parameters() missing 1 required positional argument: 'self'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Traceback (most recent call last):
  File "Reinforce_torch.py", line 124, in <module>
    optimizer = optim.Adam(policy.parameters(), lr=1e-2)
TypeError: parameters() missing 1 required positional argument: 'self'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/136
<class 'numpy.ndarray'>
2018-10-08 00:21:16.140 Python[64010:14614824] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

25
Enter Reward: x
Traceback (most recent call last):
  File "Reinforce_torch.py", line 190, in <module>
    main()
  File "Reinforce_torch.py", line 176, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: 'x'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/12
<class 'numpy.ndarray'>
2018-10-08 00:24:04.394 Python[64103:14616725] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

31
Enter Reward: -1
Breaking 

Saved the weights 

Traceback (most recent call last):
  File "Reinforce_torch.py", line 192, in <module>
    main()
  File "Reinforce_torch.py", line 187, in main
    finish_episode()
  File "Reinforce_torch.py", line 149, in finish_episode
    policy_loss = torch.cat(policy_loss).sum()
RuntimeError: expected a non-empty list of Tensors
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/88
<class 'numpy.ndarray'>
2018-10-08 00:24:56.444 Python[64156:14617344] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

28
Enter Reward: -1
Breaking 

Saved the weights 

Traceback (most recent call last):
  File "Reinforce_torch.py", line 194, in <module>
    main()
  File "Reinforce_torch.py", line 189, in main
    finish_episode()
  File "Reinforce_torch.py", line 149, in finish_episode
    policy_loss = torch.cat(policy_loss).sum()
RuntimeError: expected a non-empty list of Tensors
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
images_for_training/36
<class 'numpy.ndarray'>
2018-10-08 00:25:23.583 Python[64200:14617783] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

29
Enter Reward: -1
Breaking 

Saved the weights 

 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
images_for_training/277
<class 'numpy.ndarray'>
2018-10-08 00:30:02.666 Python[64348:14620690] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Action

1.6
Enter Reward: 0
images_for_training/61
<class 'numpy.ndarray'>
Action

0.05
Enter Reward: 0
images_for_training/13
<class 'numpy.ndarray'>
Action

0.0
Enter Reward: 0
images_for_training/247
<class 'numpy.ndarray'>
Action

1.45
Enter Reward: 0
images_for_training/281
<class 'numpy.ndarray'>
Action

1.55
Enter Reward: 0
images_for_training/270
<class 'numpy.ndarray'>
Action

1.15
Enter Reward: 0
images_for_training/192
<class 'numpy.ndarray'>
Action

1.15
Enter Reward: 0
images_for_training/212
<class 'numpy.ndarray'>
Action

0.5
Enter Reward: 1
images_for_training/173
<class 'numpy.ndarray'>
Action

0.05
Enter Reward: 0
images_for_training/261
<class 'numpy.ndarray'>
Action

0.35
Enter Reward: 
Traceback (most recent call last):
  File "Reinforce_torch.py", line 196, in <module>
    main()
  File "Reinforce_torch.py", line 178, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: ''
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
images_for_training/162
2018-10-08 00:32:58.625 Python[64451:14622452] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)


Action: 1.25
Enter Reward: 0
Saving Weights
##################################################
##################################################
images_for_training/42


Action: 0.05
Enter Reward: 0
images_for_training/297


Action: 0.05
Enter Reward: -1
Breaking 

Saved the weights 

 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
images_for_training/183
2018-10-08 00:36:03.611 Python[64543:14624396] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)


Action: 1.25
Enter Reward: -1
Breaking 

Saved the weights 

 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
images_for_training/271
2018-10-08 00:46:52.223 Python[64782:14629577] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)


Action: 1.6
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/200


Action: 0.0
Enter Reward: 0
images_for_training/143


Action: 0.0
Enter Reward: 0
images_for_training/47


Action: 0.65
Enter Reward: 0
images_for_training/70


Action: 1.4
Enter Reward: 0
images_for_training/207


Action: 1.05
Enter Reward: 0
images_for_training/166


Action: 1.15
Enter Reward: 0
images_for_training/48


Action: 0.45
Enter Reward: 0
images_for_training/239


Action: 0.05
Enter Reward: 0
images_for_training/153


Action: 0.3
Enter Reward: 0
images_for_training/131


Action: 0.15
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/286


Action: 0.75
Enter Reward: 1
images_for_training/251


Action: 0.3
Enter Reward: 0
images_for_training/29


Action: 0.5
Enter Reward: 1
images_for_training/147


Action: 0.95
Enter Reward: 0
images_for_training/113


Action: 1.85
Enter Reward: 0
images_for_training/294


Action: 1.6
Enter Reward: 0
images_for_training/16


Action: 0.75
Enter Reward: 1
images_for_training/131


Action: 1.35
Enter Reward: 0
images_for_training/136


Action: 1.95
Enter Reward: 1
images_for_training/246


Action: 1.55
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/171


Action: 1.6
Enter Reward: 0
images_for_training/65


Action: 0.35
Enter Reward: 0
images_for_training/164


Action: 0.8
Enter Reward: 0
images_for_training/144


Action: 0.95
Enter Reward: 0
images_for_training/89


Action: 0.85
Enter Reward: 1
images_for_training/90


Action: 0.0
Enter Reward: 0
images_for_training/51


Action: 0.25
Enter Reward: 0
images_for_training/23


Action: 1.9
Enter Reward: 0
images_for_training/272


Action: 0.3
Enter Reward: 0
images_for_training/72


Action: 0.5
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/284


Action: 1.65
Enter Reward: 0
images_for_training/221


Action: 0.15
Enter Reward: 0
images_for_training/60


Action: 0.5
Enter Reward: 0
images_for_training/270


Action: 0.6
Enter Reward: 0
images_for_training/110


Action: 0.25
Enter Reward: 0
images_for_training/283


Action: 1.9
Enter Reward: 0
images_for_training/94


Action: 1.2
Enter Reward: 1
images_for_training/42


Action: 1.35
Enter Reward: 0
images_for_training/108


Action: 0.2
Enter Reward: 0
images_for_training/190


Action: 1.45
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/185


Action: 0.5
Enter Reward: 0
images_for_training/32


Action: 0.25
Enter Reward: 0
images_for_training/264


Action: 1.65
Enter Reward: 0
images_for_training/280


Action: 0.5
Enter Reward: 1
images_for_training/153


Action: 0.2
Enter Reward: 0
images_for_training/54


Action: 0.35
Enter Reward: 0
images_for_training/30


Action: 0.5
Enter Reward: 0
images_for_training/88


Action: 0.65
Enter Reward: 0
images_for_training/282


Action: 0.75
Enter Reward: 1
images_for_training/115


Action: 0.4
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/227


Action: 0.4
Enter Reward: 0
images_for_training/210


Action: 0.15
Enter Reward: 0
images_for_training/252


Action: 0.0
Enter Reward: 0
images_for_training/31


Action: 0.5
Enter Reward: 0
images_for_training/170


Action: 0.4
Enter Reward: 0
images_for_training/248


Action: 1.05
Enter Reward: 0
images_for_training/192


Action: 1.15
Enter Reward: 0
images_for_training/50


Action: 1.9
Enter Reward: 0
images_for_training/181


Action: 1.6
Enter Reward: 0
images_for_training/251


Action: 0.9
Enter Reward: 1
Saving Weights
**************************************************
images_for_training/87


Action: 0.9
Enter Reward: 0
images_for_training/242


Action: 0.3
Enter Reward: 0
images_for_training/112


Action: 0.25
Enter Reward: 0
images_for_training/234


Action: 0.45
Enter Reward: 0
images_for_training/86


Action: 1.3
Enter Reward: 1
images_for_training/30


Action: 1.25
Enter Reward: 1
images_for_training/249


Action: 0.5
Enter Reward: 1
images_for_training/181


Action: 0.6
Enter Reward: 0
images_for_training/283


Action: 1.1
Enter Reward: 0
images_for_training/293


Action: 1.45
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/164


Action: 0.05
Enter Reward: 0
images_for_training/167


Action: 1.55
Enter Reward: 0
images_for_training/108


Action: 0.3
Enter Reward: 0
images_for_training/74


Action: 0.75
Enter Reward: 0
images_for_training/256


Action: 0.75
Enter Reward: 1
images_for_training/5


Action: 0.5
Enter Reward: 0
images_for_training/168


Action: 1.8
Enter Reward: 1
images_for_training/41


Action: 1.95
Enter Reward: 0 
images_for_training/13


Action: 0.35
Enter Reward: 0
images_for_training/1


Action: 0.6
Enter Reward: 1
Saving Weights
**************************************************
images_for_training/248


Action: 1.15
Enter Reward: 0
images_for_training/211


Action: 0.6
Enter Reward: 0
images_for_training/15


Action: 1.95
Enter Reward: 0
images_for_training/224


Action: 0.45
Enter Reward: 1
images_for_training/279


Action: 1.9
Enter Reward: 0
images_for_training/175


Action: 0.3
Enter Reward: 0
images_for_training/60


Action: 1.9
Enter Reward: 0
images_for_training/32


Action: 1.6
Enter Reward: 0
images_for_training/101


Action: 0.85
Enter Reward: 0
images_for_training/10


Action: 1.25
Enter Reward: 1
Saving Weights
**************************************************
images_for_training/134


Action: 1.9
Enter Reward: 1
images_for_training/176


Action: 0.1
Enter Reward: 0
images_for_training/145


Action: 1.0
Enter Reward: 0
images_for_training/279


Action: 1.9
Enter Reward: 0
images_for_training/255


Action: 1.6
Enter Reward: 0
images_for_training/135


Action: 1.8
Enter Reward: 1
images_for_training/42


Action: 1.9
Enter Reward: 0
images_for_training/111


Action: 0.1
Enter Reward: 0
images_for_training/189


Action: 1.7
Enter Reward: 1
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
images_for_training/132
2018-10-08 23:54:48.021 Python[71689:14831247] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)


Action: 1.25
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/230


Action: 0.05
Enter Reward: 0
images_for_training/75


Action: 0.0
Enter Reward: 0
images_for_training/250


Action: 0.8
Enter Reward: 1
images_for_training/61


Action: 1.4
Enter Reward: 0
images_for_training/232


Action: 1.15
Enter Reward: 0
images_for_training/135


Action: 1.15
Enter Reward: 0
images_for_training/201


Action: 0.45
Enter Reward: 1
images_for_training/195


Action: 0.05
Enter Reward: 0
images_for_training/159


Action: 0.3
Enter Reward: 0
images_for_training/291


Action: 0.25
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/297


Action: 0.7
Enter Reward: 1
images_for_training/51


Action: 0.2
Enter Reward: 0
images_for_training/152


Action: 0.45
Enter Reward: 0
images_for_training/271


Action: 0.95
Enter Reward: 0
images_for_training/169


Action: 1.85
Enter Reward: 1
images_for_training/142


Action: 1.3
Enter Reward: 0
images_for_training/3


Action: 0.85
Enter Reward: 1
images_for_training/73


Action: 1.8
Enter Reward: 0
images_for_training/245


Action: 1.95
Enter Reward: 0
images_for_training/284


Action: 1.35
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/263


Action: 1.45
Enter Reward: 0
images_for_training/159


Action: 0.4
Enter Reward: 0
images_for_training/192


Action: 0.85
Enter Reward: 0
images_for_training/21


Action: 1.05
Enter Reward: 1
images_for_training/163


Action: 0.75
Enter Reward: 0
images_for_training/212


Action: 0.0
Enter Reward: 0
images_for_training/106


Action: 0.25
Enter Reward: 0
images_for_training/101


Action: 1.9
Enter Reward: 1
images_for_training/264


Action: 0.4
Enter Reward: 1
images_for_training/285


Action: 0.55
Enter Reward: 1
Saving Weights
**************************************************
images_for_training/56


Action: 1.6
Enter Reward: 0
images_for_training/243


Action: 0.15
Enter Reward: 0
images_for_training/108


Action: 0.65
Enter Reward: 0
images_for_training/255


Action: 0.6
Enter Reward: 0
images_for_training/67


Action: 0.3
Enter Reward: 0
images_for_training/211


Action: 1.9
Enter Reward: 0
images_for_training/296


Action: 1.45
Enter Reward: 0
images_for_training/157


Action: 1.25
Enter Reward: 0
images_for_training/88


Action: 0.15
Enter Reward: 0
images_for_training/208


Action: 1.6
Enter Reward: 0
Saving Weights
**************************************************
images_for_training/212


Action: 0.55
Enter Reward: 0
images_for_training/197


Action: 0.15
Enter Reward: 0
images_for_training/134


Action: 1.45
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images_for_training/243
2018-10-09 00:03:49.002 Python[71910:14836022] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)


Action: 1.6
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images/275
2018-10-09 00:20:36.314 Python[72330:14846221] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 203, in <module>
    main()
  File "Reinforce_torch.py", line 170, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 133, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images/79
2018-10-09 00:21:21.287 Python[72380:14846768] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 203, in <module>
    main()
  File "Reinforce_torch.py", line 170, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 133, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images/84
(64, 64, 3)
2018-10-09 00:22:36.497 Python[72438:14847559] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 204, in <module>
    main()
  File "Reinforce_torch.py", line 171, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 133, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images/520
(64, 64, 3)
2018-10-09 00:24:36.572 Python[72509:14848669] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 204, in <module>
    main()
  File "Reinforce_torch.py", line 171, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 133, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images_for_training/264
(64, 64, 3)
2018-10-09 00:24:59.536 Python[72550:14849064] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 204, in <module>
    main()
  File "Reinforce_torch.py", line 171, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 133, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images_for_training/73
(64, 64, 3)
2018-10-09 00:26:23.199 Python[72612:14849870] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
[[[230 232 235 ...,  71  72  82]
  [ 79  81 112 ..., 238 235 236]
  [237 237 239 ..., 212 217 222]
  ..., 
  [ 71  70  91 ...,  70 103  82]
  [ 77 108  89 ..., 159 167 179]
  [ 48  46  48 ...,  59  61  74]]

 [[ 65  65  85 ...,  75  97  78]
  [ 73  97  78 ..., 156 164 176]
  [ 52  51  53 ...,  48  49  63]
  ..., 
  [ 17  30  25 ..., 126 126 130]
  [108 116 128 ...,   7   7  10]
  [ 10  10  10 ...,  35  30  25]]

 [[ 23  41  37 ..., 137 139 144]
  [128 136 147 ...,   4   5   6]
  [  6   6   7 ...,  34  29  26]
  ..., 
  [236 236 236 ..., 224 225 236]
  [236 235 236 ..., 203 159 160]
  [158 105 105 ..., 170 178 187]]]
Traceback (most recent call last):
  File "Reinforce_torch.py", line 204, in <module>
    main()
  File "Reinforce_torch.py", line 171, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 133, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images_for_training/187
(64, 64, 3)
2018-10-09 00:29:10.080 Python[72699:14851694] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)


Action: 1.25
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images/242
(64, 64, 3)
2018-10-09 00:29:54.754 Python[72753:14852227] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)


Action: 1.25
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 1
images/237
(64, 64, 3)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/360
(64, 64, 3)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/24
(64, 64, 3)


Action: 0.9
Enter Reward: 1
Session Number: 4
images/150
(64, 64, 3)


Action: 1.4
Enter Reward: 0
Session Number: 5
images/108
(64, 64, 3)


Action: 1.05
Enter Reward: 1
Session Number: 6
images/177
(64, 64, 3)


Action: 1.15
Enter Reward: 1
Session Number: 7
images/350
(64, 64, 3)


Action: 0.45
Enter Reward: 0
Session Number: 8
images/159
(64, 64, 3)


Action: 0.05
Enter Reward: 0
Session Number: 9
images/399
(64, 64, 3)


Action: 0.35
Enter Reward: 0
Session Number: 10
images/268
(64, 64, 3)


Action: 0.15
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 11
images/85
(64, 64, 3)


Action: 0.55
Enter Reward: 0
Session Number: 12
images/254
(64, 64, 3)


Action: 0.25
Enter Reward: 0
Session Number: 13
images/90
(64, 64, 3)


Action: 0.5
Enter Reward: 0
Session Number: 14
images/147
(64, 64, 3)


Action: 0.95
Enter Reward: 1
Session Number: 15
images/6
(64, 64, 3)


Action: 1.9
Enter Reward: 0
Session Number: 16
images/114
(64, 64, 3)


Action: 1.6
Enter Reward: 0
Session Number: 17
images/448
(64, 64, 3)


Action: 0.75
Enter Reward: 0
Session Number: 18
images/56
(64, 64, 3)


Action: 1.8
Enter Reward: 0
Session Number: 19
images/515
(64, 64, 3)


Action: 1.95
Enter Reward: 0
Session Number: 20
images/549
(64, 64, 3)


Action: 1.25
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 21
images/390
(64, 64, 3)


Action: 1.6
Enter Reward: 0
Session Number: 22
images/24
(64, 64, 3)


Action: 0.4
Enter Reward: 0
Session Number: 23
images/203
(64, 64, 3)


Action: 0.85
Enter Reward: 0
Session Number: 24
images/84
(64, 64, 3)


Action: 1.05
Enter Reward: 1
Session Number: 25
images/435
(64, 64, 3)


Action: 0.5
Enter Reward: 0
Session Number: 26
images/392
(64, 64, 3)


Action: 0.0
Enter Reward: 0
Session Number: 27
images/264
(64, 64, 3)


Action: 0.25
Enter Reward: 0
Session Number: 28
images/443
(64, 64, 3)


Action: 1.9
Enter Reward: 0
Session Number: 29
images/476
(64, 64, 3)


Action: 0.3
Enter Reward: 0
Session Number: 30
images/110
(64, 64, 3)


Action: 0.55
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 31
images/23
(64, 64, 3)


Action: 1.6
Enter Reward: 1
Session Number: 32
images/481
(64, 64, 3)


Action: 0.25
Enter Reward: 0
Session Number: 33
images/363
(64, 64, 3)


Action: 0.65
Enter Reward: 0
Session Number: 34
images/329
(64, 64, 3)


Action: 0.5
Enter Reward: 0
Session Number: 35
images/304
(64, 64, 3)


Action: 0.25
Enter Reward: 0
Session Number: 36
images/291
(64, 64, 3)


Action: 1.8
Enter Reward: 1
Session Number: 37
images/552
(64, 64, 3)


Action: 1.25
Enter Reward: 0
Session Number: 38
images/246
(64, 64, 3)


Action: 1.25
Enter Reward: 0
Session Number: 39
images/208
(64, 64, 3)


Action: 0.2
Enter Reward: 0
Session Number: 40
images/211
(64, 64, 3)


Action: 1.45
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 41
images/478
(64, 64, 3)


Action: 0.5
Enter Reward: 0
Session Number: 42
images/486
(64, 64, 3)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/454
(64, 64, 3)


Action: 1.75
Enter Reward: 0
Session Number: 44
images/253
(64, 64, 3)


Action: 0.9
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model
Session Number: 0
images/237
(64, 64, 3)
2018-10-09 00:33:28.660 Python[72906:14855585] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 205, in <module>
    main()
  File "Reinforce_torch.py", line 172, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 133, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/172
(64, 64, 3)
2018-10-09 00:37:07.125 Python[73038:14858605] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)


Action: 1.45
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 1
images/262
(64, 64, 3)


Action: 0.0
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/25
(64, 64, 3)
2018-10-09 00:37:22.566 Python[73080:14858947] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 206, in <module>
    main()
  File "Reinforce_torch.py", line 173, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 134, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/5
(64, 64, 3)
2018-10-09 01:11:53.200 Python[73788:14875276] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 206, in <module>
    main()
  File "Reinforce_torch.py", line 173, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 134, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/224
(64, 64, 3)
2018-10-09 01:27:00.719 Python[74207:14884812] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 207, in <module>
    main()
  File "Reinforce_torch.py", line 174, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 135, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/164
(64, 64, 3)
2018-10-09 01:27:26.236 Python[74252:14885143] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0245, 0.0352, 0.0325, 0.0232, 0.0243, 0.0255, 0.0118, 0.0178, 0.0226,
         0.0254, 0.0536, 0.0157, 0.0140, 0.0312, 0.0197, 0.0201, 0.0117, 0.0149,
         0.0222, 0.0289, 0.0160, 0.0212, 0.0363, 0.0272, 0.0131, 0.0221, 0.0068,
         0.0261, 0.0218, 0.0156, 0.0121, 0.0189, 0.0784, 0.0313, 0.0144, 0.0151,
         0.0664, 0.0299, 0.0169, 0.0356]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Saving Weights
**************************************************
Session Number: 1
images/191
(64, 64, 3)
tensor([[0.0154, 0.0198, 0.0167, 0.0096, 0.0102, 0.0130, 0.1278, 0.0308, 0.0284,
         0.0122, 0.0805, 0.0178, 0.0127, 0.0101, 0.0214, 0.0186, 0.0062, 0.0267,
         0.0432, 0.0097, 0.0244, 0.0056, 0.0125, 0.0064, 0.0167, 0.0605, 0.0023,
         0.0041, 0.0112, 0.0092, 0.0084, 0.0106, 0.0708, 0.0280, 0.0089, 0.0144,
         0.0484, 0.0191, 0.0905, 0.0172]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/489
(64, 64, 3)
tensor([[0.0115, 0.0205, 0.0156, 0.0057, 0.0130, 0.0212, 0.0910, 0.0138, 0.0616,
         0.0180, 0.0884, 0.0171, 0.0279, 0.0222, 0.0025, 0.0110, 0.0077, 0.0059,
         0.0041, 0.0018, 0.0095, 0.0111, 0.0147, 0.0060, 0.0050, 0.0337, 0.0037,
         0.0111, 0.0041, 0.0341, 0.0082, 0.0143, 0.0923, 0.0263, 0.0517, 0.0048,
         0.0163, 0.0040, 0.1338, 0.0546]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/594
(64, 64, 3)
2018-10-09 01:27:52.462 Python[74298:14885453] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 208, in <module>
    main()
  File "Reinforce_torch.py", line 175, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 136, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/78
(64, 64, 3)
2018-10-09 01:34:14.019 Python[74476:14889480] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0286, 0.0246, 0.0238, 0.0190, 0.0275, 0.0363, 0.0133, 0.0180, 0.0231,
         0.0171, 0.0526, 0.0194, 0.0209, 0.0202, 0.0202, 0.0222, 0.0085, 0.0312,
         0.0204, 0.0250, 0.0169, 0.0216, 0.0268, 0.0211, 0.0131, 0.0249, 0.0074,
         0.0280, 0.0223, 0.0169, 0.0093, 0.0131, 0.0801, 0.0424, 0.0122, 0.0255,
         0.0564, 0.0287, 0.0201, 0.0414]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Saving Weights
Traceback (most recent call last):
  File "Reinforce_torch.py", line 222, in <module>
    main()
  File "Reinforce_torch.py", line 208, in main
    save_model()
  File "Reinforce_torch.py", line 136, in save_model
    'state_dict': model.state_dict(),
NameError: name 'model' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/62
(64, 64, 3)
2018-10-09 01:34:48.815 Python[74524:14890044] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0202, 0.0298, 0.0262, 0.0141, 0.0356, 0.0233, 0.0072, 0.0149, 0.0156,
         0.0229, 0.0588, 0.0131, 0.0094, 0.0199, 0.0255, 0.0315, 0.0095, 0.0212,
         0.0216, 0.0239, 0.0146, 0.0241, 0.0333, 0.0261, 0.0143, 0.0253, 0.0085,
         0.0185, 0.0228, 0.0165, 0.0142, 0.0132, 0.0777, 0.0336, 0.0127, 0.0134,
         0.0746, 0.0477, 0.0310, 0.0335]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 1
images/501
(64, 64, 3)
tensor([[0.0046, 0.0103, 0.0070, 0.0071, 0.0027, 0.0079, 0.2306, 0.0241, 0.0192,
         0.0120, 0.1938, 0.0117, 0.0061, 0.0098, 0.0064, 0.0118, 0.0046, 0.0360,
         0.0310, 0.0044, 0.0142, 0.0022, 0.0050, 0.0011, 0.0155, 0.0242, 0.0005,
         0.0021, 0.0076, 0.0075, 0.0021, 0.0071, 0.0659, 0.0113, 0.0096, 0.0136,
         0.0787, 0.0087, 0.0737, 0.0080]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 2
images/150
(64, 64, 3)
tensor([[0.0136, 0.0227, 0.0284, 0.0148, 0.0211, 0.0199, 0.0646, 0.0185, 0.0478,
         0.0269, 0.0499, 0.0203, 0.0262, 0.0275, 0.0095, 0.0180, 0.0105, 0.0114,
         0.0106, 0.0089, 0.0167, 0.0183, 0.0195, 0.0096, 0.0139, 0.0251, 0.0086,
         0.0181, 0.0094, 0.0406, 0.0185, 0.0273, 0.0677, 0.0314, 0.0379, 0.0103,
         0.0262, 0.0108, 0.0813, 0.0377]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Traceback (most recent call last):
  File "Reinforce_torch.py", line 128, in <module>
    optimizer.load_state_dict(state['optimizer'])
NameError: name 'optimizer' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Traceback (most recent call last):
  File "Reinforce_torch.py", line 120, in <module>
    optimizer = optim.Adam(policy.parameters(), lr=1e-2)
NameError: name 'policy' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/486
(64, 64, 3)
2018-10-09 01:38:30.252 Python[74710:14892376] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 221, in <module>
    main()
  File "Reinforce_torch.py", line 185, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 146, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/176
(64, 64, 3)
2018-10-09 01:40:22.112 Python[74782:14893262] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0234, 0.0406, 0.0401, 0.0179, 0.0368, 0.0177, 0.0121, 0.0098, 0.0245,
         0.0479, 0.0660, 0.0162, 0.0157, 0.0301, 0.0273, 0.0261, 0.0079, 0.0135,
         0.0173, 0.0205, 0.0105, 0.0298, 0.0319, 0.0153, 0.0084, 0.0186, 0.0039,
         0.0154, 0.0272, 0.0205, 0.0085, 0.0208, 0.1001, 0.0212, 0.0212, 0.0127,
         0.0409, 0.0340, 0.0173, 0.0303]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Saving Weights
**************************************************
Session Number: 1
images/163
(64, 64, 3)
tensor([[0.0350, 0.0286, 0.0153, 0.0186, 0.0174, 0.0309, 0.1005, 0.0323, 0.0357,
         0.0216, 0.0493, 0.0240, 0.0273, 0.0345, 0.0199, 0.0212, 0.0148, 0.0262,
         0.0352, 0.0194, 0.0184, 0.0100, 0.0149, 0.0134, 0.0289, 0.0208, 0.0053,
         0.0238, 0.0154, 0.0187, 0.0104, 0.0193, 0.0305, 0.0265, 0.0193, 0.0174,
         0.0370, 0.0142, 0.0373, 0.0109]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/276
(64, 64, 3)
tensor([[0.0242, 0.0255, 0.0256, 0.0234, 0.0230, 0.0267, 0.0298, 0.0213, 0.0284,
         0.0259, 0.0314, 0.0244, 0.0293, 0.0274, 0.0196, 0.0222, 0.0227, 0.0248,
         0.0215, 0.0228, 0.0234, 0.0236, 0.0237, 0.0228, 0.0227, 0.0254, 0.0208,
         0.0279, 0.0225, 0.0277, 0.0231, 0.0243, 0.0291, 0.0292, 0.0282, 0.0213,
         0.0261, 0.0241, 0.0283, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/445
(64, 64, 3)
tensor([[0.0111, 0.0104, 0.0167, 0.0114, 0.0173, 0.0116, 0.0366, 0.0078, 0.0766,
         0.0128, 0.0303, 0.0124, 0.0122, 0.0395, 0.0018, 0.0005, 0.0056, 0.0281,
         0.0233, 0.0210, 0.0105, 0.0117, 0.0028, 0.0069, 0.0027, 0.0206, 0.0043,
         0.0022, 0.0056, 0.0119, 0.0007, 0.0019, 0.0570, 0.0082, 0.0141, 0.1068,
         0.2426, 0.0084, 0.0224, 0.0719]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 4
images/437
(64, 64, 3)
tensor([[0.0297, 0.0309, 0.0221, 0.0175, 0.0145, 0.0265, 0.0324, 0.0086, 0.0086,
         0.0033, 0.0209, 0.0104, 0.0554, 0.0286, 0.0053, 0.0095, 0.0158, 0.0201,
         0.0066, 0.0096, 0.0142, 0.0306, 0.0151, 0.0300, 0.0090, 0.0198, 0.0100,
         0.0188, 0.0211, 0.0391, 0.0035, 0.0089, 0.0294, 0.0121, 0.0798, 0.0053,
         0.0868, 0.0230, 0.1461, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 5
images/457
(64, 64, 3)
tensor([[0.0073, 0.0222, 0.0239, 0.0041, 0.0155, 0.0325, 0.0154, 0.0143, 0.0058,
         0.0055, 0.1266, 0.0181, 0.0304, 0.0082, 0.0114, 0.0257, 0.0071, 0.0183,
         0.0299, 0.0254, 0.0076, 0.0335, 0.0052, 0.0268, 0.0131, 0.0310, 0.0030,
         0.0094, 0.0056, 0.0997, 0.0054, 0.0100, 0.0490, 0.0106, 0.0430, 0.0299,
         0.0705, 0.0090, 0.0794, 0.0103]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 6
images/81
(64, 64, 3)
tensor([[0.0074, 0.0269, 0.0201, 0.0102, 0.0627, 0.0522, 0.0346, 0.0149, 0.0060,
         0.0361, 0.0503, 0.0233, 0.0144, 0.0168, 0.0143, 0.0172, 0.0138, 0.0174,
         0.0328, 0.0215, 0.0094, 0.0172, 0.0180, 0.0471, 0.0068, 0.0522, 0.0076,
         0.0189, 0.0127, 0.0201, 0.0058, 0.0131, 0.0360, 0.0202, 0.0179, 0.0124,
         0.0793, 0.0119, 0.0860, 0.0142]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 7
images/299
(64, 64, 3)
tensor([[0.0278, 0.0227, 0.0235, 0.0253, 0.0258, 0.0253, 0.0255, 0.0279, 0.0233,
         0.0248, 0.0285, 0.0302, 0.0274, 0.0233, 0.0244, 0.0243, 0.0257, 0.0244,
         0.0233, 0.0231, 0.0233, 0.0243, 0.0253, 0.0243, 0.0226, 0.0281, 0.0222,
         0.0243, 0.0227, 0.0266, 0.0207, 0.0287, 0.0245, 0.0269, 0.0250, 0.0230,
         0.0262, 0.0257, 0.0260, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 8
images/167
(64, 64, 3)
tensor([[0.0200, 0.0137, 0.0161, 0.0131, 0.0157, 0.0577, 0.0186, 0.0294, 0.0060,
         0.0148, 0.0332, 0.0376, 0.0154, 0.0057, 0.0095, 0.0326, 0.0051, 0.0117,
         0.0856, 0.0250, 0.0061, 0.0310, 0.0113, 0.0175, 0.0094, 0.0303, 0.0022,
         0.0502, 0.0137, 0.0172, 0.0134, 0.0152, 0.0442, 0.0074, 0.0373, 0.0114,
         0.0252, 0.0136, 0.1417, 0.0353]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 9
images/356
(64, 64, 3)
tensor([[0.0248, 0.0249, 0.0266, 0.0249, 0.0320, 0.0207, 0.0276, 0.0271, 0.0200,
         0.0205, 0.0248, 0.0325, 0.0312, 0.0254, 0.0233, 0.0207, 0.0212, 0.0255,
         0.0283, 0.0189, 0.0269, 0.0246, 0.0257, 0.0249, 0.0209, 0.0259, 0.0238,
         0.0253, 0.0230, 0.0283, 0.0218, 0.0320, 0.0243, 0.0174, 0.0180, 0.0243,
         0.0311, 0.0218, 0.0303, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 10
images/409
(64, 64, 3)
tensor([[0.0080, 0.0261, 0.0047, 0.0058, 0.0401, 0.0141, 0.0810, 0.0119, 0.0204,
         0.0753, 0.0603, 0.0149, 0.1076, 0.0448, 0.0173, 0.0257, 0.0049, 0.0027,
         0.0099, 0.0018, 0.0230, 0.0153, 0.0212, 0.0031, 0.0068, 0.0191, 0.0009,
         0.0163, 0.0079, 0.0490, 0.0008, 0.0184, 0.0778, 0.0082, 0.0156, 0.0257,
         0.0192, 0.0202, 0.0685, 0.0057]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 11
images/367
(64, 64, 3)
tensor([[0.0259, 0.0239, 0.0248, 0.0245, 0.0281, 0.0259, 0.0276, 0.0256, 0.0218,
         0.0217, 0.0274, 0.0258, 0.0220, 0.0274, 0.0259, 0.0265, 0.0217, 0.0225,
         0.0278, 0.0268, 0.0189, 0.0268, 0.0196, 0.0254, 0.0235, 0.0289, 0.0173,
         0.0254, 0.0228, 0.0248, 0.0210, 0.0263, 0.0268, 0.0265, 0.0210, 0.0247,
         0.0289, 0.0279, 0.0342, 0.0257]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 12
images/211
(64, 64, 3)
tensor([[0.0258, 0.0295, 0.0218, 0.0233, 0.0290, 0.0235, 0.0280, 0.0242, 0.0219,
         0.0256, 0.0304, 0.0306, 0.0260, 0.0255, 0.0209, 0.0236, 0.0223, 0.0236,
         0.0247, 0.0279, 0.0228, 0.0269, 0.0226, 0.0226, 0.0253, 0.0264, 0.0222,
         0.0238, 0.0280, 0.0221, 0.0214, 0.0206, 0.0294, 0.0257, 0.0194, 0.0268,
         0.0268, 0.0265, 0.0281, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 13
images/363
(64, 64, 3)
tensor([[0.0212, 0.0274, 0.0182, 0.0268, 0.0223, 0.0288, 0.0242, 0.0240, 0.0205,
         0.0248, 0.0265, 0.0296, 0.0294, 0.0235, 0.0204, 0.0234, 0.0240, 0.0228,
         0.0225, 0.0277, 0.0231, 0.0228, 0.0271, 0.0250, 0.0246, 0.0260, 0.0177,
         0.0233, 0.0215, 0.0221, 0.0217, 0.0242, 0.0367, 0.0274, 0.0314, 0.0275,
         0.0235, 0.0260, 0.0325, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 14
images/37
(64, 64, 3)
tensor([[0.0040, 0.0170, 0.0043, 0.0196, 0.0240, 0.0186, 0.0144, 0.0308, 0.0293,
         0.0103, 0.0756, 0.0544, 0.0137, 0.0163, 0.0156, 0.0207, 0.0055, 0.0123,
         0.0495, 0.0254, 0.0046, 0.0149, 0.0342, 0.0147, 0.0121, 0.0343, 0.0116,
         0.0083, 0.0099, 0.0216, 0.0121, 0.0128, 0.0334, 0.0183, 0.0229, 0.0110,
         0.0926, 0.0130, 0.1293, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 15
images/85
(64, 64, 3)
tensor([[0.0255, 0.0205, 0.0219, 0.0081, 0.0094, 0.0245, 0.0106, 0.0072, 0.0137,
         0.0076, 0.1692, 0.0267, 0.0100, 0.0178, 0.0334, 0.0984, 0.0076, 0.0041,
         0.0208, 0.0111, 0.0049, 0.0125, 0.0199, 0.0127, 0.0158, 0.0168, 0.0029,
         0.0258, 0.0401, 0.0111, 0.0028, 0.0297, 0.0788, 0.0106, 0.0097, 0.0043,
         0.0333, 0.0384, 0.0315, 0.0502]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 16
images/93
(64, 64, 3)
tensor([[0.0193, 0.0134, 0.0253, 0.0066, 0.0103, 0.0115, 0.0245, 0.0043, 0.0142,
         0.0117, 0.0636, 0.0292, 0.0244, 0.0288, 0.0112, 0.0032, 0.0178, 0.0181,
         0.0169, 0.0591, 0.0125, 0.0266, 0.0065, 0.0078, 0.0055, 0.0325, 0.0067,
         0.0268, 0.0081, 0.0207, 0.0079, 0.0122, 0.1317, 0.0176, 0.0303, 0.0089,
         0.0910, 0.0140, 0.0821, 0.0372]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 17
images/43
(64, 64, 3)
tensor([[0.0154, 0.0226, 0.0072, 0.0197, 0.0242, 0.0313, 0.0246, 0.0269, 0.0266,
         0.0100, 0.0423, 0.0423, 0.0463, 0.0180, 0.0120, 0.0853, 0.0098, 0.0077,
         0.0293, 0.0101, 0.0129, 0.0075, 0.0112, 0.0197, 0.0261, 0.0503, 0.0079,
         0.0076, 0.0137, 0.0111, 0.0098, 0.0120, 0.0725, 0.0193, 0.0151, 0.0301,
         0.0357, 0.0227, 0.0791, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 18
images/323
(64, 64, 3)
tensor([[0.0252, 0.0259, 0.0271, 0.0254, 0.0255, 0.0261, 0.0255, 0.0263, 0.0241,
         0.0231, 0.0247, 0.0269, 0.0263, 0.0270, 0.0236, 0.0241, 0.0255, 0.0274,
         0.0264, 0.0265, 0.0230, 0.0251, 0.0241, 0.0246, 0.0244, 0.0255, 0.0209,
         0.0245, 0.0231, 0.0248, 0.0229, 0.0246, 0.0271, 0.0265, 0.0234, 0.0217,
         0.0283, 0.0217, 0.0253, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 19
images/99
(64, 64, 3)
tensor([[0.0076, 0.0545, 0.0270, 0.0183, 0.0367, 0.0299, 0.0166, 0.0284, 0.0192,
         0.0152, 0.1327, 0.0270, 0.0362, 0.0167, 0.0131, 0.0087, 0.0136, 0.0159,
         0.0360, 0.0595, 0.0102, 0.0108, 0.0186, 0.0171, 0.0102, 0.0100, 0.0043,
         0.0225, 0.0370, 0.0108, 0.0125, 0.0166, 0.0361, 0.0207, 0.0145, 0.0134,
         0.0550, 0.0090, 0.0382, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 20
images/523
(64, 64, 3)
tensor([[0.0110, 0.0129, 0.0018, 0.0158, 0.0154, 0.1906, 0.0093, 0.0198, 0.0047,
         0.0200, 0.0763, 0.0163, 0.0433, 0.0043, 0.0189, 0.0216, 0.0044, 0.0083,
         0.0210, 0.0053, 0.0062, 0.0016, 0.0150, 0.0247, 0.0062, 0.1353, 0.0226,
         0.0218, 0.0029, 0.0217, 0.0065, 0.0255, 0.0170, 0.0027, 0.0125, 0.0057,
         0.0346, 0.0046, 0.0492, 0.0625]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 21
images/595
(64, 64, 3)
tensor([[0.0023, 0.0181, 0.0015, 0.0307, 0.0133, 0.0102, 0.1371, 0.0103, 0.0007,
         0.0023, 0.2921, 0.0037, 0.0029, 0.0028, 0.0271, 0.0108, 0.0016, 0.0016,
         0.1522, 0.0023, 0.0111, 0.0024, 0.0042, 0.0110, 0.0119, 0.0075, 0.0056,
         0.0045, 0.0045, 0.0639, 0.0030, 0.0384, 0.0262, 0.0025, 0.0052, 0.0025,
         0.0140, 0.0025, 0.0459, 0.0092]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 22
images/225
(64, 64, 3)
tensor([[0.0210, 0.0285, 0.0230, 0.0242, 0.0248, 0.0276, 0.0276, 0.0244, 0.0245,
         0.0242, 0.0301, 0.0263, 0.0286, 0.0229, 0.0240, 0.0228, 0.0257, 0.0262,
         0.0244, 0.0230, 0.0248, 0.0271, 0.0251, 0.0222, 0.0244, 0.0225, 0.0209,
         0.0293, 0.0243, 0.0264, 0.0185, 0.0245, 0.0276, 0.0242, 0.0262, 0.0258,
         0.0269, 0.0253, 0.0247, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 23
images/198
(64, 64, 3)
tensor([[0.0394, 0.0419, 0.0194, 0.0219, 0.0270, 0.0292, 0.0207, 0.0274, 0.0160,
         0.0130, 0.0298, 0.0129, 0.0164, 0.0356, 0.0253, 0.0176, 0.0282, 0.0085,
         0.0126, 0.0147, 0.0186, 0.0235, 0.0337, 0.0136, 0.0164, 0.0367, 0.0126,
         0.0200, 0.0137, 0.0314, 0.0059, 0.0398, 0.0473, 0.0521, 0.0373, 0.0200,
         0.0518, 0.0073, 0.0331, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 24
images/145
(64, 64, 3)
tensor([[0.0062, 0.0252, 0.0027, 0.0057, 0.0176, 0.0268, 0.0224, 0.0212, 0.0153,
         0.0121, 0.0566, 0.0384, 0.0422, 0.0095, 0.0076, 0.0245, 0.0134, 0.0711,
         0.0507, 0.0067, 0.0093, 0.0143, 0.0255, 0.0247, 0.0116, 0.0456, 0.0227,
         0.0309, 0.0085, 0.0199, 0.0149, 0.0165, 0.0780, 0.0178, 0.0201, 0.0077,
         0.0338, 0.0071, 0.0932, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 1
Session Number: 25
images/175
(64, 64, 3)
tensor([[0.0077, 0.0206, 0.0068, 0.0235, 0.0497, 0.0352, 0.0100, 0.0442, 0.0103,
         0.0154, 0.0813, 0.0321, 0.0064, 0.0123, 0.0121, 0.0221, 0.0105, 0.0479,
         0.0235, 0.0257, 0.0152, 0.0149, 0.0092, 0.0203, 0.0115, 0.0516, 0.0096,
         0.0263, 0.0064, 0.0340, 0.0090, 0.0164, 0.0604, 0.0092, 0.0082, 0.0188,
         0.0160, 0.0079, 0.0703, 0.0876]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 26
images/434
(64, 64, 3)
tensor([[0.0198, 0.0536, 0.0023, 0.0293, 0.0212, 0.0377, 0.0296, 0.0112, 0.0059,
         0.0140, 0.3394, 0.0341, 0.0107, 0.0112, 0.0074, 0.0583, 0.0058, 0.0027,
         0.0089, 0.0016, 0.0158, 0.0021, 0.0044, 0.0395, 0.0054, 0.0174, 0.0040,
         0.0108, 0.0047, 0.0453, 0.0028, 0.0077, 0.0495, 0.0307, 0.0075, 0.0056,
         0.0074, 0.0146, 0.0152, 0.0048]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 27
images/332
(64, 64, 3)
tensor([[0.0282, 0.0298, 0.0259, 0.0186, 0.0252, 0.0260, 0.0268, 0.0267, 0.0241,
         0.0217, 0.0315, 0.0234, 0.0242, 0.0262, 0.0267, 0.0236, 0.0219, 0.0237,
         0.0270, 0.0240, 0.0230, 0.0290, 0.0267, 0.0254, 0.0264, 0.0286, 0.0198,
         0.0244, 0.0252, 0.0230, 0.0235, 0.0219, 0.0285, 0.0230, 0.0226, 0.0255,
         0.0228, 0.0258, 0.0283, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 28
images/391
(64, 64, 3)
tensor([[0.0223, 0.0224, 0.0250, 0.0180, 0.0234, 0.0202, 0.0313, 0.0244, 0.0234,
         0.0231, 0.0321, 0.0394, 0.0272, 0.0217, 0.0213, 0.0239, 0.0214, 0.0246,
         0.0276, 0.0266, 0.0240, 0.0229, 0.0221, 0.0331, 0.0230, 0.0335, 0.0203,
         0.0248, 0.0221, 0.0261, 0.0185, 0.0259, 0.0241, 0.0276, 0.0232, 0.0213,
         0.0359, 0.0201, 0.0248, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 1
Session Number: 29
images/351
(64, 64, 3)
tensor([[0.0274, 0.0209, 0.0217, 0.0250, 0.0284, 0.0260, 0.0228, 0.0223, 0.0233,
         0.0212, 0.0347, 0.0284, 0.0249, 0.0203, 0.0281, 0.0351, 0.0216, 0.0246,
         0.0237, 0.0171, 0.0202, 0.0279, 0.0281, 0.0158, 0.0216, 0.0254, 0.0163,
         0.0295, 0.0356, 0.0294, 0.0163, 0.0287, 0.0250, 0.0204, 0.0308, 0.0198,
         0.0281, 0.0189, 0.0302, 0.0346]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 30
images/260
(64, 64, 3)
tensor([[0.0192, 0.0215, 0.0251, 0.0315, 0.0247, 0.0226, 0.0302, 0.0255, 0.0279,
         0.0275, 0.0281, 0.0233, 0.0266, 0.0227, 0.0204, 0.0268, 0.0223, 0.0211,
         0.0241, 0.0240, 0.0256, 0.0263, 0.0245, 0.0196, 0.0245, 0.0211, 0.0218,
         0.0246, 0.0192, 0.0291, 0.0218, 0.0404, 0.0275, 0.0225, 0.0226, 0.0189,
         0.0258, 0.0243, 0.0295, 0.0354]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 31
images/276
(64, 64, 3)
tensor([[0.0238, 0.0239, 0.0226, 0.0228, 0.0230, 0.0209, 0.0233, 0.0195, 0.0217,
         0.0274, 0.0325, 0.0238, 0.0296, 0.0264, 0.0228, 0.0295, 0.0240, 0.0282,
         0.0256, 0.0289, 0.0231, 0.0269, 0.0242, 0.0235, 0.0226, 0.0298, 0.0201,
         0.0220, 0.0224, 0.0281, 0.0198, 0.0321, 0.0264, 0.0289, 0.0247, 0.0228,
         0.0284, 0.0237, 0.0282, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 32
images/171
(64, 64, 3)
tensor([[0.0309, 0.0179, 0.0180, 0.0158, 0.0144, 0.0497, 0.0248, 0.0157, 0.0272,
         0.0310, 0.0576, 0.0237, 0.0303, 0.0221, 0.0064, 0.0131, 0.0266, 0.0428,
         0.0343, 0.0174, 0.0154, 0.0268, 0.0305, 0.0340, 0.0203, 0.0472, 0.0120,
         0.0270, 0.0124, 0.0293, 0.0140, 0.0176, 0.0395, 0.0190, 0.0148, 0.0133,
         0.0298, 0.0211, 0.0142, 0.0422]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 33
images/169
(64, 64, 3)
tensor([[0.0256, 0.0226, 0.0225, 0.0172, 0.0309, 0.0801, 0.0492, 0.0169, 0.0185,
         0.0072, 0.0318, 0.0601, 0.0156, 0.0181, 0.0173, 0.0112, 0.0123, 0.0087,
         0.0364, 0.0071, 0.0127, 0.0089, 0.0231, 0.0221, 0.0200, 0.0336, 0.0217,
         0.0073, 0.0158, 0.0150, 0.0109, 0.0146, 0.0309, 0.0094, 0.0198, 0.0073,
         0.0239, 0.0255, 0.0314, 0.1368]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 34
images/391
(64, 64, 3)
tensor([[0.0225, 0.0290, 0.0237, 0.0224, 0.0232, 0.0261, 0.0261, 0.0264, 0.0242,
         0.0241, 0.0288, 0.0280, 0.0341, 0.0246, 0.0216, 0.0230, 0.0240, 0.0214,
         0.0268, 0.0275, 0.0230, 0.0285, 0.0244, 0.0272, 0.0249, 0.0339, 0.0170,
         0.0219, 0.0211, 0.0172, 0.0220, 0.0249, 0.0311, 0.0251, 0.0272, 0.0203,
         0.0293, 0.0185, 0.0256, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 35
images/19
(64, 64, 3)
tensor([[0.0160, 0.0113, 0.0109, 0.0148, 0.0148, 0.0165, 0.0414, 0.0726, 0.0182,
         0.0103, 0.0832, 0.0452, 0.0138, 0.0665, 0.0105, 0.0406, 0.0091, 0.0207,
         0.0171, 0.0262, 0.0108, 0.0078, 0.0274, 0.0141, 0.0074, 0.0172, 0.0031,
         0.0105, 0.0128, 0.0437, 0.0079, 0.0237, 0.0485, 0.0088, 0.0271, 0.0611,
         0.0303, 0.0111, 0.0233, 0.0438]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 36
images/127
(64, 64, 3)
tensor([[0.0127, 0.0147, 0.0043, 0.0135, 0.0104, 0.0258, 0.0599, 0.0241, 0.0791,
         0.0086, 0.0523, 0.0152, 0.0342, 0.0232, 0.0103, 0.0124, 0.0171, 0.0191,
         0.0870, 0.0177, 0.0164, 0.0172, 0.0170, 0.0183, 0.0118, 0.0201, 0.0017,
         0.0113, 0.0065, 0.0207, 0.0049, 0.0239, 0.0621, 0.0085, 0.0335, 0.0209,
         0.0774, 0.0094, 0.0600, 0.0169]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 37
images/442
(64, 64, 3)
tensor([[0.0088, 0.0194, 0.0265, 0.0105, 0.0248, 0.0101, 0.0468, 0.1021, 0.0139,
         0.0163, 0.0297, 0.0278, 0.0299, 0.0076, 0.0146, 0.0066, 0.0129, 0.0134,
         0.0162, 0.0042, 0.0086, 0.0070, 0.0721, 0.0051, 0.0163, 0.0463, 0.0032,
         0.0164, 0.0086, 0.0535, 0.0042, 0.0266, 0.0323, 0.0267, 0.0226, 0.0300,
         0.0810, 0.0449, 0.0368, 0.0158]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 38
images/127
(64, 64, 3)
tensor([[0.0055, 0.0199, 0.0121, 0.0419, 0.0253, 0.0431, 0.0271, 0.0273, 0.0175,
         0.0169, 0.0908, 0.0350, 0.0190, 0.0311, 0.0137, 0.0138, 0.0147, 0.0112,
         0.0185, 0.0313, 0.0194, 0.0157, 0.0130, 0.0228, 0.0075, 0.1213, 0.0072,
         0.0168, 0.0046, 0.0171, 0.0077, 0.0084, 0.0326, 0.0062, 0.0055, 0.0118,
         0.0494, 0.0463, 0.0410, 0.0302]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 39
images/365
(64, 64, 3)
tensor([[0.0275, 0.0278, 0.0235, 0.0287, 0.0254, 0.0254, 0.0263, 0.0308, 0.0252,
         0.0196, 0.0322, 0.0341, 0.0206, 0.0287, 0.0219, 0.0187, 0.0222, 0.0242,
         0.0294, 0.0195, 0.0260, 0.0225, 0.0267, 0.0229, 0.0238, 0.0309, 0.0185,
         0.0248, 0.0211, 0.0255, 0.0221, 0.0316, 0.0235, 0.0260, 0.0292, 0.0206,
         0.0198, 0.0248, 0.0247, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/280
(64, 64, 3)
2018-10-09 01:43:09.787 Python[74879:14894522] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 221, in <module>
    main()
  File "Reinforce_torch.py", line 185, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 146, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/291
(64, 64, 3)
2018-10-09 01:46:21.730 Python[74975:14896280] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 221, in <module>
    main()
  File "Reinforce_torch.py", line 185, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 146, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Traceback (most recent call last):
  File "Reinforce_torch.py", line 94, in <module>
    a=list(img.size)
NameError: name 'img' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/577
(64, 64, 3)
2018-10-09 01:47:30.781 Python[75067:14896970] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 214, in <module>
    main()
  File "Reinforce_torch.py", line 178, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 139, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/38
(64, 64, 3)
2018-10-09 12:25:00.370 Python[75528:14908703] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 214, in <module>
    main()
  File "Reinforce_torch.py", line 178, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 139, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/76
(64, 64, 3)
2018-10-09 12:25:19.192 Python[75568:14908977] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0249, 0.0247, 0.0237, 0.0141, 0.0266, 0.0247, 0.0107, 0.0197, 0.0185,
         0.0277, 0.0399, 0.0209, 0.0210, 0.0234, 0.0188, 0.0279, 0.0102, 0.0185,
         0.0227, 0.0232, 0.0230, 0.0253, 0.0319, 0.0256, 0.0150, 0.0218, 0.0089,
         0.0240, 0.0260, 0.0193, 0.0091, 0.0186, 0.0614, 0.0459, 0.0196, 0.0159,
         0.0644, 0.0389, 0.0324, 0.0312]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Saving Weights
**************************************************
Session Number: 1
images/487
(64, 64, 3)
tensor([[0.0116, 0.0256, 0.0053, 0.0090, 0.0070, 0.0087, 0.2936, 0.0205, 0.0220,
         0.0101, 0.0874, 0.0142, 0.0128, 0.0071, 0.0068, 0.0190, 0.0096, 0.0240,
         0.0346, 0.0096, 0.0172, 0.0025, 0.0065, 0.0027, 0.0047, 0.0145, 0.0008,
         0.0032, 0.0145, 0.0084, 0.0035, 0.0038, 0.0390, 0.0217, 0.0148, 0.0157,
         0.0902, 0.0113, 0.0817, 0.0045]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/590
(64, 64, 3)
tensor([[0.0217, 0.0124, 0.0110, 0.0072, 0.0192, 0.0119, 0.0638, 0.0120, 0.0294,
         0.0306, 0.1098, 0.0148, 0.0392, 0.0348, 0.0025, 0.0074, 0.0042, 0.0081,
         0.0029, 0.0035, 0.0135, 0.0181, 0.0129, 0.0027, 0.0036, 0.0120, 0.0020,
         0.0106, 0.0035, 0.0400, 0.0126, 0.0256, 0.0852, 0.0589, 0.0678, 0.0083,
         0.0180, 0.0109, 0.1178, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/16
(64, 64, 3)
tensor([[0.0108, 0.0147, 0.0198, 0.0176, 0.0247, 0.0135, 0.0266, 0.0118, 0.0670,
         0.0219, 0.0238, 0.0140, 0.0246, 0.0440, 0.0026, 0.0012, 0.0085, 0.0200,
         0.0314, 0.0200, 0.0140, 0.0122, 0.0050, 0.0088, 0.0037, 0.0178, 0.0044,
         0.0041, 0.0050, 0.0246, 0.0015, 0.0048, 0.0479, 0.0221, 0.0204, 0.0590,
         0.2429, 0.0125, 0.0336, 0.0370]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 4
images/439
(64, 64, 3)
tensor([[0.0228, 0.0197, 0.0361, 0.0215, 0.0065, 0.0202, 0.0214, 0.0055, 0.0082,
         0.0024, 0.0290, 0.0073, 0.0274, 0.0218, 0.0034, 0.0061, 0.0231, 0.0189,
         0.0032, 0.0117, 0.0089, 0.0402, 0.0181, 0.0246, 0.0045, 0.0140, 0.0068,
         0.0140, 0.0142, 0.0271, 0.0016, 0.0085, 0.0255, 0.0049, 0.0594, 0.0051,
         0.1859, 0.0261, 0.1782, 0.0158]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 5
images/346
(64, 64, 3)
tensor([[0.0232, 0.0266, 0.0251, 0.0207, 0.0245, 0.0276, 0.0254, 0.0224, 0.0211,
         0.0199, 0.0297, 0.0262, 0.0279, 0.0226, 0.0242, 0.0247, 0.0235, 0.0259,
         0.0271, 0.0267, 0.0228, 0.0259, 0.0238, 0.0257, 0.0249, 0.0265, 0.0225,
         0.0245, 0.0230, 0.0301, 0.0215, 0.0232, 0.0271, 0.0242, 0.0266, 0.0258,
         0.0312, 0.0230, 0.0297, 0.0228]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 0
Session Number: 6
images/148
(64, 64, 3)
tensor([[0.0075, 0.0364, 0.0210, 0.0136, 0.0764, 0.0704, 0.0396, 0.0127, 0.0076,
         0.0485, 0.0576, 0.0207, 0.0130, 0.0170, 0.0111, 0.0171, 0.0111, 0.0267,
         0.0209, 0.0208, 0.0064, 0.0194, 0.0075, 0.0483, 0.0052, 0.0392, 0.0103,
         0.0234, 0.0133, 0.0288, 0.0031, 0.0084, 0.0445, 0.0088, 0.0156, 0.0133,
         0.0678, 0.0100, 0.0556, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 7
images/443
(64, 64, 3)
tensor([[0.0097, 0.0108, 0.0114, 0.0132, 0.0211, 0.0159, 0.0306, 0.0921, 0.0184,
         0.0278, 0.1479, 0.0135, 0.0193, 0.0251, 0.0155, 0.0144, 0.0211, 0.0217,
         0.0180, 0.0110, 0.0102, 0.0083, 0.0084, 0.0067, 0.0048, 0.0546, 0.0023,
         0.0224, 0.0066, 0.0454, 0.0029, 0.0308, 0.0483, 0.0100, 0.0065, 0.0136,
         0.0613, 0.0149, 0.0545, 0.0290]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 8
images/437
(64, 64, 3)
tensor([[0.0214, 0.0138, 0.0188, 0.0077, 0.0227, 0.0346, 0.0091, 0.0247, 0.0029,
         0.0111, 0.0257, 0.0206, 0.0119, 0.0087, 0.0143, 0.0326, 0.0037, 0.0140,
         0.1130, 0.0287, 0.0113, 0.0280, 0.0052, 0.0134, 0.0060, 0.0402, 0.0025,
         0.0783, 0.0056, 0.0338, 0.0085, 0.0086, 0.0365, 0.0099, 0.0280, 0.0087,
         0.0233, 0.0099, 0.1742, 0.0283]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 9
images/497
(64, 64, 3)
tensor([[0.0252, 0.0130, 0.0153, 0.0154, 0.0503, 0.0093, 0.0872, 0.0396, 0.0143,
         0.0029, 0.0121, 0.0562, 0.0345, 0.0074, 0.0135, 0.0052, 0.0075, 0.0259,
         0.0474, 0.0040, 0.0449, 0.0154, 0.0074, 0.0166, 0.0054, 0.0192, 0.0145,
         0.0103, 0.0106, 0.1179, 0.0059, 0.0832, 0.0234, 0.0007, 0.0061, 0.0128,
         0.0215, 0.0052, 0.0322, 0.0608]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 10
images/26
(64, 64, 3)
tensor([[0.0145, 0.0385, 0.0053, 0.0127, 0.0354, 0.0157, 0.0852, 0.0223, 0.0352,
         0.0399, 0.0387, 0.0155, 0.0438, 0.0186, 0.0293, 0.0229, 0.0127, 0.0090,
         0.0167, 0.0067, 0.0312, 0.0160, 0.0316, 0.0093, 0.0213, 0.0254, 0.0036,
         0.0156, 0.0149, 0.0572, 0.0052, 0.0249, 0.0528, 0.0091, 0.0167, 0.0245,
         0.0264, 0.0255, 0.0594, 0.0108]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving Weights
**************************************************
Session Number: 11
images/106
(64, 64, 3)
tensor([[0.0203, 0.0036, 0.0039, 0.0156, 0.0293, 0.0202, 0.0590, 0.0202, 0.0045,
         0.0053, 0.0508, 0.0102, 0.0047, 0.0267, 0.0172, 0.0280, 0.0028, 0.0055,
         0.1333, 0.0160, 0.0032, 0.0304, 0.0010, 0.0264, 0.0079, 0.0737, 0.0010,
         0.0141, 0.0034, 0.0162, 0.0008, 0.0380, 0.0520, 0.0125, 0.0083, 0.0181,
         0.0504, 0.0205, 0.1219, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 12
images/259
(64, 64, 3)
tensor([[0.0305, 0.0347, 0.0203, 0.0217, 0.0344, 0.0262, 0.0265, 0.0225, 0.0179,
         0.0283, 0.0366, 0.0336, 0.0220, 0.0230, 0.0195, 0.0215, 0.0206, 0.0214,
         0.0225, 0.0322, 0.0213, 0.0323, 0.0186, 0.0174, 0.0278, 0.0228, 0.0172,
         0.0184, 0.0295, 0.0182, 0.0221, 0.0185, 0.0384, 0.0236, 0.0198, 0.0263,
         0.0311, 0.0272, 0.0279, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: -1
Breaking
Saved the weights
Saving Weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/319
(64, 64, 3)
2018-10-09 12:27:18.610 Python[75643:14909903] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0234, 0.0266, 0.0280, 0.0230, 0.0269, 0.0262, 0.0181, 0.0212, 0.0222,
         0.0280, 0.0353, 0.0259, 0.0241, 0.0238, 0.0252, 0.0280, 0.0179, 0.0254,
         0.0232, 0.0230, 0.0203, 0.0242, 0.0286, 0.0252, 0.0224, 0.0276, 0.0164,
         0.0235, 0.0255, 0.0210, 0.0209, 0.0223, 0.0358, 0.0284, 0.0215, 0.0225,
         0.0359, 0.0281, 0.0250, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/544
(64, 64, 3)
tensor([[0.0065, 0.0137, 0.0144, 0.0083, 0.0056, 0.0092, 0.2287, 0.0200, 0.0131,
         0.0129, 0.0865, 0.0079, 0.0107, 0.0092, 0.0107, 0.0105, 0.0085, 0.0213,
         0.0534, 0.0071, 0.0377, 0.0016, 0.0083, 0.0024, 0.0146, 0.0302, 0.0005,
         0.0036, 0.0072, 0.0074, 0.0025, 0.0058, 0.0329, 0.0267, 0.0091, 0.0152,
         0.0868, 0.0128, 0.1313, 0.0053]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Reinforce_torch.py
Loading the model if any
Session Number: 0
images/100
(64, 64, 3)
2018-10-09 12:27:56.091 Python[75693:14910324] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Reinforce_torch.py", line 212, in <module>
    main()
  File "Reinforce_torch.py", line 179, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Reinforce_torch.py", line 140, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py 
Loading the model if any
Session Number: 0
images/110
(64, 64, 3)
2018-10-09 12:30:14.342 Python[75779:14911589] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 212, in <module>
    main()
  File "Torch_reinforce01.py", line 179, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 137, in select_action
    probs = policy(state)
TypeError: 'dict' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/262
(64, 64, 3)
2018-10-09 12:31:06.227 Python[75832:14912332] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0252, 0.0258, 0.0270, 0.0248, 0.0250, 0.0257, 0.0211, 0.0214, 0.0229,
         0.0278, 0.0337, 0.0260, 0.0230, 0.0268, 0.0224, 0.0227, 0.0177, 0.0225,
         0.0270, 0.0261, 0.0221, 0.0256, 0.0309, 0.0246, 0.0205, 0.0234, 0.0165,
         0.0250, 0.0242, 0.0239, 0.0179, 0.0252, 0.0356, 0.0307, 0.0263, 0.0219,
         0.0323, 0.0287, 0.0240, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/31
(64, 64, 3)
2018-10-09 12:31:28.873 Python[75872:14912702] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 212, in <module>
    main()
  File "Torch_reinforce01.py", line 179, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 137, in select_action
    probs = policy(state)
TypeError: 'dict' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/198
(64, 64, 3)
2018-10-09 12:34:12.057 Python[75962:14914357] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0272, 0.0282, 0.0268, 0.0178, 0.0308, 0.0267, 0.0095, 0.0208, 0.0210,
         0.0307, 0.0565, 0.0231, 0.0191, 0.0274, 0.0202, 0.0297, 0.0101, 0.0153,
         0.0180, 0.0246, 0.0182, 0.0253, 0.0316, 0.0233, 0.0149, 0.0213, 0.0052,
         0.0190, 0.0278, 0.0145, 0.0093, 0.0253, 0.0678, 0.0327, 0.0163, 0.0184,
         0.0453, 0.0395, 0.0242, 0.0365]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Saving the weights
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 212, in <module>
    main()
  File "Torch_reinforce01.py", line 199, in main
    save_model()
  File "Torch_reinforce01.py", line 132, in save_model
    policy.save_state_dict('Weights1.pt')
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 518, in __getattr__
    type(self).__name__, name))
AttributeError: 'Policy' object has no attribute 'save_state_dict'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/234
(64, 64, 3)
2018-10-09 12:36:47.790 Python[76041:14915711] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0248, 0.0266, 0.0253, 0.0243, 0.0261, 0.0255, 0.0232, 0.0231, 0.0239,
         0.0249, 0.0259, 0.0253, 0.0249, 0.0248, 0.0248, 0.0256, 0.0237, 0.0252,
         0.0236, 0.0269, 0.0232, 0.0249, 0.0271, 0.0247, 0.0246, 0.0252, 0.0232,
         0.0258, 0.0255, 0.0230, 0.0239, 0.0234, 0.0278, 0.0261, 0.0241, 0.0237,
         0.0280, 0.0265, 0.0245, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/173
(64, 64, 3)
tensor([[0.0190, 0.0122, 0.0110, 0.0083, 0.0082, 0.0125, 0.1916, 0.0326, 0.0247,
         0.0122, 0.0659, 0.0218, 0.0124, 0.0078, 0.0147, 0.0224, 0.0067, 0.0314,
         0.0436, 0.0103, 0.0306, 0.0059, 0.0157, 0.0036, 0.0165, 0.0300, 0.0024,
         0.0030, 0.0102, 0.0129, 0.0056, 0.0123, 0.0659, 0.0255, 0.0102, 0.0164,
         0.0642, 0.0220, 0.0631, 0.0145]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/496
(64, 64, 3)
tensor([[0.0162, 0.0229, 0.0221, 0.0076, 0.0047, 0.0150, 0.1034, 0.0069, 0.0398,
         0.0075, 0.1693, 0.0205, 0.0183, 0.0125, 0.0025, 0.0067, 0.0098, 0.0085,
         0.0055, 0.0024, 0.0164, 0.0105, 0.0253, 0.0063, 0.0047, 0.0560, 0.0078,
         0.0077, 0.0037, 0.0228, 0.0082, 0.0078, 0.1034, 0.0194, 0.0215, 0.0118,
         0.0202, 0.0054, 0.0880, 0.0510]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/409
(64, 64, 3)
tensor([[0.0077, 0.0082, 0.0116, 0.0120, 0.0243, 0.0072, 0.0254, 0.0052, 0.0635,
         0.0339, 0.0355, 0.0051, 0.0327, 0.0227, 0.0016, 0.0011, 0.0041, 0.0124,
         0.0319, 0.0224, 0.0082, 0.0100, 0.0023, 0.0023, 0.0011, 0.0154, 0.0015,
         0.0020, 0.0020, 0.0537, 0.0005, 0.0053, 0.0754, 0.0061, 0.0365, 0.0790,
         0.2738, 0.0086, 0.0217, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 4
images/165
(64, 64, 3)
tensor([[0.0338, 0.0376, 0.0208, 0.0318, 0.0174, 0.0341, 0.0343, 0.0204, 0.0139,
         0.0088, 0.0283, 0.0191, 0.0313, 0.0368, 0.0140, 0.0153, 0.0226, 0.0145,
         0.0162, 0.0148, 0.0135, 0.0481, 0.0315, 0.0329, 0.0175, 0.0194, 0.0188,
         0.0228, 0.0237, 0.0306, 0.0080, 0.0239, 0.0264, 0.0137, 0.0488, 0.0111,
         0.0489, 0.0223, 0.0523, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 5
images/239
(64, 64, 3)
tensor([[0.0238, 0.0256, 0.0248, 0.0225, 0.0232, 0.0270, 0.0249, 0.0226, 0.0225,
         0.0190, 0.0304, 0.0242, 0.0282, 0.0228, 0.0229, 0.0253, 0.0250, 0.0282,
         0.0260, 0.0261, 0.0234, 0.0257, 0.0239, 0.0261, 0.0248, 0.0276, 0.0232,
         0.0251, 0.0228, 0.0291, 0.0222, 0.0222, 0.0269, 0.0247, 0.0252, 0.0255,
         0.0299, 0.0242, 0.0292, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/266
(64, 64, 3)
2018-10-09 12:37:30.326 Python[76087:14916162] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 214, in <module>
    main()
  File "Torch_reinforce01.py", line 181, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 142, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 123, in <module>
    policy.load_state_dict(states['state_dict'])
TypeError: 'Policy' object is not subscriptable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 124, in <module>
    policy.load_state_dict(states)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 692, in load_state_dict
    state_dict = state_dict.copy()
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 518, in __getattr__
    type(self).__name__, name))
AttributeError: 'Policy' object has no attribute 'copy'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 123, in <module>
    policy.load_state_dict(states['state_dict'])
TypeError: 'Policy' object is not subscriptable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/9
(64, 64, 3)
2018-10-09 12:50:57.964 Python[76478:14923765] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0168, 0.0170, 0.0239, 0.0171, 0.0298, 0.0291, 0.0058, 0.0092, 0.0138,
         0.0322, 0.0986, 0.0120, 0.0082, 0.0184, 0.0178, 0.0247, 0.0043, 0.0260,
         0.0190, 0.0262, 0.0082, 0.0185, 0.0258, 0.0298, 0.0082, 0.0184, 0.0041,
         0.0128, 0.0267, 0.0137, 0.0087, 0.0146, 0.0840, 0.0208, 0.0133, 0.0105,
         0.1031, 0.0646, 0.0260, 0.0380]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/144
(64, 64, 3)
tensor([[0.0106, 0.0179, 0.0145, 0.0123, 0.0121, 0.0177, 0.1624, 0.0412, 0.0266,
         0.0146, 0.0799, 0.0173, 0.0169, 0.0114, 0.0156, 0.0196, 0.0108, 0.0228,
         0.0418, 0.0143, 0.0304, 0.0061, 0.0155, 0.0049, 0.0204, 0.0256, 0.0029,
         0.0051, 0.0110, 0.0144, 0.0068, 0.0173, 0.0515, 0.0199, 0.0111, 0.0157,
         0.0613, 0.0174, 0.0669, 0.0154]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/387
(64, 64, 3)
tensor([[0.0249, 0.0274, 0.0265, 0.0239, 0.0225, 0.0240, 0.0332, 0.0204, 0.0305,
         0.0230, 0.0343, 0.0257, 0.0281, 0.0251, 0.0186, 0.0215, 0.0216, 0.0237,
         0.0193, 0.0193, 0.0211, 0.0221, 0.0235, 0.0208, 0.0215, 0.0312, 0.0215,
         0.0242, 0.0183, 0.0283, 0.0233, 0.0258, 0.0328, 0.0295, 0.0305, 0.0193,
         0.0242, 0.0213, 0.0356, 0.0315]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/306
(64, 64, 3)
tensor([[0.0259, 0.0247, 0.0253, 0.0259, 0.0286, 0.0234, 0.0286, 0.0243, 0.0304,
         0.0265, 0.0261, 0.0250, 0.0273, 0.0286, 0.0192, 0.0186, 0.0220, 0.0252,
         0.0257, 0.0278, 0.0230, 0.0247, 0.0202, 0.0222, 0.0202, 0.0256, 0.0195,
         0.0217, 0.0221, 0.0271, 0.0177, 0.0225, 0.0294, 0.0254, 0.0266, 0.0306,
         0.0332, 0.0237, 0.0278, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 0
Session Number: 4
images/495
(64, 64, 3)
tensor([[0.0301, 0.0262, 0.0295, 0.0189, 0.0137, 0.0342, 0.0323, 0.0088, 0.0130,
         0.0033, 0.0351, 0.0128, 0.0179, 0.0268, 0.0062, 0.0057, 0.0201, 0.0170,
         0.0066, 0.0141, 0.0103, 0.0436, 0.0214, 0.0358, 0.0064, 0.0235, 0.0059,
         0.0093, 0.0323, 0.0350, 0.0028, 0.0153, 0.0291, 0.0078, 0.0611, 0.0043,
         0.1178, 0.0209, 0.1238, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 5
images/102
(64, 64, 3)
tensor([[0.0235, 0.0254, 0.0228, 0.0116, 0.0179, 0.0378, 0.0173, 0.0154, 0.0081,
         0.0087, 0.0768, 0.0193, 0.0466, 0.0081, 0.0183, 0.0255, 0.0116, 0.0214,
         0.0275, 0.0252, 0.0156, 0.0371, 0.0089, 0.0281, 0.0138, 0.0230, 0.0049,
         0.0126, 0.0122, 0.0573, 0.0075, 0.0137, 0.0430, 0.0259, 0.0412, 0.0347,
         0.0588, 0.0138, 0.0625, 0.0167]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 6
images/232
(64, 64, 3)
tensor([[0.0195, 0.0288, 0.0254, 0.0212, 0.0331, 0.0303, 0.0279, 0.0219, 0.0179,
         0.0276, 0.0320, 0.0284, 0.0228, 0.0243, 0.0233, 0.0238, 0.0224, 0.0241,
         0.0261, 0.0268, 0.0195, 0.0231, 0.0228, 0.0312, 0.0201, 0.0302, 0.0196,
         0.0270, 0.0233, 0.0245, 0.0176, 0.0228, 0.0265, 0.0237, 0.0237, 0.0226,
         0.0356, 0.0221, 0.0333, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 7
images/496
(64, 64, 3)
tensor([[0.0111, 0.0049, 0.0065, 0.0133, 0.0245, 0.0144, 0.0275, 0.0976, 0.0201,
         0.0197, 0.1290, 0.0132, 0.0152, 0.0188, 0.0124, 0.0049, 0.0273, 0.0229,
         0.0342, 0.0063, 0.0145, 0.0130, 0.0120, 0.0123, 0.0038, 0.0552, 0.0063,
         0.0131, 0.0036, 0.0362, 0.0018, 0.0191, 0.0647, 0.0058, 0.0060, 0.0158,
         0.0506, 0.0684, 0.0275, 0.0464]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/395
(64, 64, 3)
2018-10-09 12:51:42.696 Python[76527:14924201] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 215, in <module>
    main()
  File "Torch_reinforce01.py", line 182, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 143, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 114, in <module>
    policy = Policy(*args,**kwargs)
NameError: name 'kwargs' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/421
(64, 64, 3)
2018-10-09 12:53:46.451 Python[76634:14925404] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0192, 0.0262, 0.0213, 0.0120, 0.0343, 0.0319, 0.0063, 0.0161, 0.0150,
         0.0230, 0.0569, 0.0161, 0.0162, 0.0147, 0.0238, 0.0345, 0.0098, 0.0197,
         0.0210, 0.0213, 0.0185, 0.0172, 0.0301, 0.0309, 0.0158, 0.0276, 0.0068,
         0.0204, 0.0205, 0.0150, 0.0077, 0.0155, 0.0670, 0.0417, 0.0107, 0.0170,
         0.0752, 0.0447, 0.0420, 0.0367]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/175
(64, 64, 3)
tensor([[0.0113, 0.0204, 0.0133, 0.0130, 0.0088, 0.0131, 0.1547, 0.0509, 0.0334,
         0.0117, 0.0859, 0.0201, 0.0128, 0.0116, 0.0172, 0.0277, 0.0105, 0.0319,
         0.0482, 0.0090, 0.0258, 0.0041, 0.0144, 0.0041, 0.0165, 0.0304, 0.0019,
         0.0041, 0.0079, 0.0126, 0.0060, 0.0106, 0.0544, 0.0210, 0.0090, 0.0256,
         0.0543, 0.0188, 0.0575, 0.0156]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/456
(64, 64, 3)
tensor([[0.0093, 0.0196, 0.0179, 0.0098, 0.0121, 0.0177, 0.0792, 0.0127, 0.0481,
         0.0205, 0.1024, 0.0138, 0.0204, 0.0239, 0.0037, 0.0133, 0.0057, 0.0122,
         0.0045, 0.0025, 0.0083, 0.0122, 0.0118, 0.0062, 0.0074, 0.0219, 0.0038,
         0.0117, 0.0037, 0.0457, 0.0123, 0.0170, 0.1130, 0.0301, 0.0388, 0.0048,
         0.0224, 0.0025, 0.1356, 0.0414]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 3
images/430
(64, 64, 3)
tensor([[0.0132, 0.0081, 0.0135, 0.0258, 0.0317, 0.0094, 0.0344, 0.0114, 0.0640,
         0.0218, 0.0394, 0.0150, 0.0279, 0.0287, 0.0030, 0.0010, 0.0041, 0.0114,
         0.0322, 0.0305, 0.0115, 0.0085, 0.0024, 0.0039, 0.0015, 0.0132, 0.0023,
         0.0031, 0.0057, 0.0502, 0.0006, 0.0114, 0.0808, 0.0128, 0.0373, 0.0595,
         0.1976, 0.0097, 0.0312, 0.0304]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 4
images/306
(64, 64, 3)
tensor([[0.0274, 0.0281, 0.0258, 0.0249, 0.0248, 0.0257, 0.0260, 0.0226, 0.0227,
         0.0200, 0.0260, 0.0250, 0.0278, 0.0267, 0.0221, 0.0220, 0.0251, 0.0269,
         0.0200, 0.0243, 0.0232, 0.0286, 0.0252, 0.0261, 0.0228, 0.0252, 0.0225,
         0.0257, 0.0247, 0.0256, 0.0212, 0.0229, 0.0252, 0.0256, 0.0278, 0.0220,
         0.0303, 0.0258, 0.0312, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 5
images/52
(64, 64, 3)
tensor([[0.0122, 0.0257, 0.0240, 0.0075, 0.0147, 0.0543, 0.0167, 0.0144, 0.0062,
         0.0054, 0.0994, 0.0222, 0.0447, 0.0086, 0.0137, 0.0270, 0.0118, 0.0262,
         0.0303, 0.0291, 0.0076, 0.0272, 0.0060, 0.0314, 0.0141, 0.0270, 0.0051,
         0.0130, 0.0104, 0.0593, 0.0060, 0.0114, 0.0398, 0.0224, 0.0314, 0.0395,
         0.0623, 0.0123, 0.0648, 0.0149]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 6
images/383
(64, 64, 3)
tensor([[0.0193, 0.0265, 0.0255, 0.0224, 0.0378, 0.0296, 0.0288, 0.0203, 0.0153,
         0.0312, 0.0321, 0.0257, 0.0198, 0.0240, 0.0230, 0.0235, 0.0215, 0.0209,
         0.0258, 0.0253, 0.0180, 0.0243, 0.0240, 0.0307, 0.0216, 0.0301, 0.0162,
         0.0302, 0.0206, 0.0216, 0.0186, 0.0278, 0.0273, 0.0236, 0.0261, 0.0229,
         0.0371, 0.0207, 0.0364, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 7
images/354
(64, 64, 3)
tensor([[0.0248, 0.0212, 0.0221, 0.0236, 0.0285, 0.0250, 0.0263, 0.0323, 0.0245,
         0.0246, 0.0302, 0.0243, 0.0264, 0.0259, 0.0254, 0.0228, 0.0248, 0.0247,
         0.0252, 0.0211, 0.0238, 0.0230, 0.0241, 0.0229, 0.0209, 0.0291, 0.0208,
         0.0241, 0.0202, 0.0277, 0.0186, 0.0254, 0.0293, 0.0261, 0.0211, 0.0244,
         0.0291, 0.0294, 0.0303, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/77
(64, 64, 3)
2018-10-09 12:54:17.928 Python[76677:14925768] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 215, in <module>
    main()
  File "Torch_reinforce01.py", line 182, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 143, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/370
(64, 64, 3)
2018-10-09 18:28:58.408 Python[77970:14964992] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0242, 0.0256, 0.0258, 0.0245, 0.0260, 0.0246, 0.0220, 0.0225, 0.0240,
         0.0262, 0.0271, 0.0256, 0.0247, 0.0259, 0.0227, 0.0248, 0.0227, 0.0256,
         0.0243, 0.0264, 0.0230, 0.0256, 0.0268, 0.0249, 0.0241, 0.0235, 0.0217,
         0.0273, 0.0246, 0.0235, 0.0218, 0.0246, 0.0295, 0.0264, 0.0245, 0.0234,
         0.0306, 0.0285, 0.0241, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/142
(64, 64, 3)
tensor([[0.0122, 0.0204, 0.0184, 0.0140, 0.0129, 0.0178, 0.1443, 0.0256, 0.0148,
         0.0197, 0.0811, 0.0153, 0.0212, 0.0142, 0.0141, 0.0192, 0.0118, 0.0261,
         0.0383, 0.0139, 0.0302, 0.0052, 0.0162, 0.0064, 0.0218, 0.0323, 0.0023,
         0.0109, 0.0149, 0.0133, 0.0064, 0.0097, 0.0310, 0.0245, 0.0160, 0.0200,
         0.0654, 0.0172, 0.0915, 0.0099]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/447
(64, 64, 3)
2018-10-09 18:29:19.851 Python[78010:14965328] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 215, in <module>
    main()
  File "Torch_reinforce01.py", line 182, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 143, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/405
(64, 64, 3)
2018-10-09 18:39:27.081 Python[78176:14970069] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0095, 0.0172, 0.0172, 0.0112, 0.0284, 0.0235, 0.0058, 0.0151, 0.0182,
         0.0323, 0.0667, 0.0110, 0.0100, 0.0123, 0.0134, 0.0551, 0.0068, 0.0109,
         0.0204, 0.0214, 0.0121, 0.0151, 0.0234, 0.0187, 0.0082, 0.0189, 0.0042,
         0.0140, 0.0132, 0.0062, 0.0041, 0.0102, 0.1445, 0.0222, 0.0103, 0.0140,
         0.1369, 0.0589, 0.0182, 0.0401]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/597
(64, 64, 3)
tensor([[0.0070, 0.0181, 0.0110, 0.0055, 0.0066, 0.0078, 0.2312, 0.0315, 0.0158,
         0.0115, 0.0727, 0.0147, 0.0148, 0.0107, 0.0114, 0.0123, 0.0074, 0.0257,
         0.0617, 0.0061, 0.0282, 0.0027, 0.0132, 0.0033, 0.0150, 0.0278, 0.0005,
         0.0034, 0.0065, 0.0081, 0.0033, 0.0053, 0.0355, 0.0216, 0.0087, 0.0239,
         0.0919, 0.0203, 0.0911, 0.0060]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/392
(64, 64, 3)
tensor([[0.0252, 0.0250, 0.0273, 0.0230, 0.0243, 0.0220, 0.0305, 0.0232, 0.0309,
         0.0254, 0.0307, 0.0271, 0.0264, 0.0272, 0.0206, 0.0233, 0.0204, 0.0241,
         0.0199, 0.0213, 0.0210, 0.0244, 0.0259, 0.0206, 0.0225, 0.0241, 0.0220,
         0.0239, 0.0224, 0.0286, 0.0244, 0.0253, 0.0311, 0.0283, 0.0296, 0.0207,
         0.0244, 0.0240, 0.0312, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/107
(64, 64, 3)
tensor([[0.0182, 0.0152, 0.0177, 0.0197, 0.0288, 0.0159, 0.0282, 0.0156, 0.0758,
         0.0207, 0.0277, 0.0148, 0.0272, 0.0291, 0.0039, 0.0027, 0.0135, 0.0203,
         0.0362, 0.0272, 0.0161, 0.0174, 0.0049, 0.0096, 0.0068, 0.0168, 0.0071,
         0.0053, 0.0079, 0.0309, 0.0023, 0.0089, 0.0511, 0.0145, 0.0228, 0.0508,
         0.1682, 0.0155, 0.0338, 0.0510]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 4
images/109
(64, 64, 3)
tensor([[0.0331, 0.0290, 0.0297, 0.0279, 0.0140, 0.0218, 0.0363, 0.0129, 0.0143,
         0.0054, 0.0226, 0.0143, 0.0423, 0.0301, 0.0097, 0.0146, 0.0165, 0.0176,
         0.0094, 0.0132, 0.0151, 0.0371, 0.0180, 0.0370, 0.0104, 0.0206, 0.0126,
         0.0159, 0.0260, 0.0346, 0.0039, 0.0109, 0.0342, 0.0134, 0.0742, 0.0072,
         0.0681, 0.0288, 0.0906, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/87
(64, 64, 3)
2018-10-09 18:39:50.301 Python[78218:14970515] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 212, in <module>
    main()
  File "Torch_reinforce01.py", line 179, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 140, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/166
(64, 64, 3)
2018-10-09 18:53:58.518 Python[78513:14976553] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0184, 0.0176, 0.0177, 0.0179, 0.0296, 0.0274, 0.0130, 0.0181, 0.0146,
         0.0213, 0.0634, 0.0165, 0.0120, 0.0137, 0.0180, 0.0344, 0.0096, 0.0328,
         0.0218, 0.0201, 0.0163, 0.0243, 0.0290, 0.0253, 0.0188, 0.0313, 0.0132,
         0.0191, 0.0206, 0.0172, 0.0099, 0.0172, 0.0579, 0.0270, 0.0132, 0.0198,
         0.0633, 0.0483, 0.0304, 0.0598]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 1
images/10
(64, 64, 3)
tensor([[0.0207, 0.0203, 0.0171, 0.0147, 0.0104, 0.0219, 0.0877, 0.0378, 0.0318,
         0.0168, 0.0502, 0.0196, 0.0156, 0.0153, 0.0162, 0.0296, 0.0134, 0.0283,
         0.0340, 0.0169, 0.0203, 0.0114, 0.0252, 0.0084, 0.0227, 0.0360, 0.0077,
         0.0066, 0.0161, 0.0138, 0.0096, 0.0191, 0.0694, 0.0272, 0.0148, 0.0262,
         0.0507, 0.0241, 0.0528, 0.0196]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/171
(64, 64, 3)
tensor([[0.0185, 0.0293, 0.0247, 0.0153, 0.0116, 0.0284, 0.0630, 0.0101, 0.0319,
         0.0163, 0.0791, 0.0215, 0.0281, 0.0198, 0.0061, 0.0124, 0.0165, 0.0191,
         0.0103, 0.0086, 0.0185, 0.0109, 0.0222, 0.0172, 0.0168, 0.0727, 0.0186,
         0.0176, 0.0079, 0.0348, 0.0165, 0.0174, 0.0513, 0.0243, 0.0281, 0.0190,
         0.0224, 0.0099, 0.0640, 0.0392]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/168
(64, 64, 3)
2018-10-09 18:54:34.147 Python[78556:14977021] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 212, in <module>
    main()
  File "Torch_reinforce01.py", line 179, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 140, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/80
(64, 64, 3)
2018-10-09 18:56:07.948 Python[78618:14977801] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0107, 0.0280, 0.0235, 0.0098, 0.0500, 0.0260, 0.0044, 0.0125, 0.0167,
         0.0560, 0.0730, 0.0160, 0.0133, 0.0239, 0.0234, 0.0269, 0.0059, 0.0149,
         0.0187, 0.0214, 0.0107, 0.0183, 0.0308, 0.0214, 0.0092, 0.0171, 0.0032,
         0.0161, 0.0165, 0.0137, 0.0087, 0.0168, 0.1264, 0.0251, 0.0171, 0.0084,
         0.0412, 0.0392, 0.0241, 0.0606]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/379
(64, 64, 3)
tensor([[0.0237, 0.0271, 0.0257, 0.0250, 0.0223, 0.0237, 0.0365, 0.0265, 0.0262,
         0.0246, 0.0299, 0.0240, 0.0262, 0.0226, 0.0227, 0.0268, 0.0221, 0.0266,
         0.0289, 0.0239, 0.0258, 0.0197, 0.0242, 0.0186, 0.0260, 0.0273, 0.0177,
         0.0224, 0.0235, 0.0222, 0.0206, 0.0221, 0.0291, 0.0278, 0.0244, 0.0239,
         0.0320, 0.0251, 0.0311, 0.0216]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/164
(64, 64, 3)
tensor([[0.0225, 0.0250, 0.0269, 0.0136, 0.0168, 0.0176, 0.0541, 0.0181, 0.0363,
         0.0142, 0.0838, 0.0262, 0.0230, 0.0317, 0.0096, 0.0169, 0.0147, 0.0151,
         0.0129, 0.0125, 0.0165, 0.0197, 0.0235, 0.0137, 0.0094, 0.0240, 0.0080,
         0.0194, 0.0090, 0.0281, 0.0196, 0.0271, 0.0487, 0.0451, 0.0394, 0.0107,
         0.0253, 0.0127, 0.0727, 0.0360]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/207
(64, 64, 3)
tensor([[0.0251, 0.0248, 0.0266, 0.0258, 0.0273, 0.0240, 0.0253, 0.0237, 0.0290,
         0.0254, 0.0253, 0.0252, 0.0273, 0.0286, 0.0205, 0.0188, 0.0233, 0.0266,
         0.0255, 0.0264, 0.0238, 0.0250, 0.0228, 0.0225, 0.0230, 0.0251, 0.0224,
         0.0225, 0.0223, 0.0240, 0.0196, 0.0217, 0.0291, 0.0263, 0.0262, 0.0287,
         0.0326, 0.0243, 0.0265, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 4
images/34
(64, 64, 3)
tensor([[0.0305, 0.0367, 0.0255, 0.0331, 0.0128, 0.0304, 0.0261, 0.0124, 0.0138,
         0.0057, 0.0270, 0.0254, 0.0374, 0.0515, 0.0135, 0.0122, 0.0221, 0.0193,
         0.0118, 0.0179, 0.0118, 0.0558, 0.0244, 0.0342, 0.0139, 0.0201, 0.0140,
         0.0224, 0.0237, 0.0333, 0.0071, 0.0156, 0.0278, 0.0150, 0.0494, 0.0088,
         0.0556, 0.0226, 0.0650, 0.0143]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 5
images/127
(64, 64, 3)
tensor([[0.0104, 0.0147, 0.0138, 0.0069, 0.0123, 0.0333, 0.0240, 0.0186, 0.0093,
         0.0036, 0.0993, 0.0129, 0.0338, 0.0072, 0.0136, 0.0308, 0.0148, 0.0267,
         0.0442, 0.0191, 0.0182, 0.0184, 0.0109, 0.0360, 0.0200, 0.0394, 0.0117,
         0.0124, 0.0064, 0.0904, 0.0102, 0.0175, 0.0354, 0.0117, 0.0250, 0.0361,
         0.0578, 0.0204, 0.0593, 0.0136]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 6
images/382
(64, 64, 3)
tensor([[0.0227, 0.0265, 0.0257, 0.0236, 0.0289, 0.0265, 0.0263, 0.0232, 0.0210,
         0.0254, 0.0273, 0.0277, 0.0243, 0.0249, 0.0235, 0.0236, 0.0239, 0.0256,
         0.0246, 0.0269, 0.0218, 0.0250, 0.0246, 0.0279, 0.0231, 0.0277, 0.0227,
         0.0265, 0.0241, 0.0243, 0.0225, 0.0242, 0.0262, 0.0241, 0.0246, 0.0229,
         0.0301, 0.0243, 0.0280, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 7
images/429
(64, 64, 3)
tensor([[0.0135, 0.0044, 0.0067, 0.0165, 0.0209, 0.0212, 0.0355, 0.0858, 0.0151,
         0.0210, 0.1768, 0.0148, 0.0203, 0.0130, 0.0137, 0.0108, 0.0165, 0.0179,
         0.0315, 0.0085, 0.0154, 0.0090, 0.0055, 0.0115, 0.0057, 0.0593, 0.0083,
         0.0090, 0.0039, 0.0251, 0.0032, 0.0375, 0.0509, 0.0119, 0.0108, 0.0090,
         0.0464, 0.0395, 0.0426, 0.0308]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 8
images/284
(64, 64, 3)
tensor([[0.0278, 0.0259, 0.0263, 0.0233, 0.0262, 0.0288, 0.0232, 0.0263, 0.0204,
         0.0224, 0.0243, 0.0302, 0.0243, 0.0229, 0.0237, 0.0281, 0.0201, 0.0241,
         0.0321, 0.0281, 0.0196, 0.0280, 0.0217, 0.0231, 0.0203, 0.0275, 0.0175,
         0.0292, 0.0260, 0.0234, 0.0222, 0.0232, 0.0276, 0.0255, 0.0282, 0.0212,
         0.0230, 0.0251, 0.0335, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 9
images/473
(64, 64, 3)
tensor([[0.0299, 0.0255, 0.0348, 0.0161, 0.0375, 0.0115, 0.0414, 0.0357, 0.0123,
         0.0045, 0.0120, 0.0489, 0.0541, 0.0166, 0.0148, 0.0084, 0.0071, 0.0271,
         0.0285, 0.0053, 0.0498, 0.0142, 0.0195, 0.0209, 0.0097, 0.0515, 0.0190,
         0.0165, 0.0076, 0.0675, 0.0071, 0.0428, 0.0291, 0.0038, 0.0049, 0.0247,
         0.0301, 0.0088, 0.0673, 0.0332]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 10
images/127
(64, 64, 3)
tensor([[0.0145, 0.0253, 0.0052, 0.0114, 0.0282, 0.0200, 0.0916, 0.0241, 0.0354,
         0.0296, 0.0450, 0.0258, 0.0456, 0.0152, 0.0257, 0.0251, 0.0193, 0.0148,
         0.0190, 0.0060, 0.0393, 0.0181, 0.0330, 0.0089, 0.0190, 0.0347, 0.0061,
         0.0183, 0.0141, 0.0409, 0.0049, 0.0244, 0.0539, 0.0097, 0.0107, 0.0295,
         0.0211, 0.0246, 0.0504, 0.0117]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/219
(64, 64, 3)
tensor([[0.0257, 0.0217, 0.0231, 0.0264, 0.0275, 0.0270, 0.0286, 0.0253, 0.0200,
         0.0203, 0.0298, 0.0252, 0.0235, 0.0285, 0.0239, 0.0263, 0.0206, 0.0219,
         0.0313, 0.0271, 0.0182, 0.0279, 0.0179, 0.0263, 0.0241, 0.0288, 0.0161,
         0.0265, 0.0211, 0.0226, 0.0188, 0.0272, 0.0280, 0.0270, 0.0208, 0.0239,
         0.0327, 0.0265, 0.0348, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 12
images/315
(64, 64, 3)
tensor([[0.0262, 0.0355, 0.0205, 0.0220, 0.0351, 0.0233, 0.0294, 0.0241, 0.0180,
         0.0261, 0.0372, 0.0302, 0.0216, 0.0265, 0.0206, 0.0231, 0.0205, 0.0198,
         0.0211, 0.0288, 0.0224, 0.0311, 0.0219, 0.0195, 0.0281, 0.0260, 0.0184,
         0.0235, 0.0303, 0.0201, 0.0179, 0.0198, 0.0314, 0.0267, 0.0183, 0.0275,
         0.0274, 0.0237, 0.0315, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 13
images/373
(64, 64, 3)
tensor([[0.0214, 0.0258, 0.0204, 0.0260, 0.0236, 0.0293, 0.0241, 0.0255, 0.0222,
         0.0281, 0.0283, 0.0273, 0.0263, 0.0231, 0.0209, 0.0247, 0.0213, 0.0216,
         0.0262, 0.0282, 0.0225, 0.0223, 0.0268, 0.0246, 0.0260, 0.0251, 0.0156,
         0.0223, 0.0206, 0.0206, 0.0206, 0.0237, 0.0333, 0.0265, 0.0327, 0.0261,
         0.0279, 0.0262, 0.0371, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 14
images/529
(64, 64, 3)
tensor([[0.0031, 0.0172, 0.0037, 0.0136, 0.0204, 0.0318, 0.0107, 0.0329, 0.0203,
         0.0053, 0.0962, 0.0658, 0.0115, 0.0182, 0.0121, 0.0146, 0.0025, 0.0105,
         0.0505, 0.0257, 0.0027, 0.0103, 0.0185, 0.0180, 0.0069, 0.0348, 0.0059,
         0.0061, 0.0098, 0.0206, 0.0083, 0.0060, 0.0281, 0.0105, 0.0301, 0.0104,
         0.1008, 0.0091, 0.1763, 0.0200]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 15
images/311
(64, 64, 3)
tensor([[0.0276, 0.0323, 0.0235, 0.0177, 0.0255, 0.0309, 0.0234, 0.0202, 0.0224,
         0.0171, 0.0394, 0.0284, 0.0201, 0.0291, 0.0267, 0.0286, 0.0235, 0.0251,
         0.0283, 0.0245, 0.0186, 0.0225, 0.0209, 0.0252, 0.0198, 0.0290, 0.0166,
         0.0293, 0.0277, 0.0182, 0.0182, 0.0222, 0.0336, 0.0233, 0.0198, 0.0204,
         0.0314, 0.0269, 0.0274, 0.0348]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 16
images/158
(64, 64, 3)
tensor([[0.0329, 0.0161, 0.0279, 0.0256, 0.0143, 0.0136, 0.0280, 0.0078, 0.0208,
         0.0159, 0.0562, 0.0358, 0.0244, 0.0308, 0.0192, 0.0071, 0.0281, 0.0175,
         0.0197, 0.0423, 0.0148, 0.0343, 0.0122, 0.0114, 0.0096, 0.0343, 0.0061,
         0.0378, 0.0181, 0.0365, 0.0133, 0.0227, 0.0628, 0.0190, 0.0397, 0.0196,
         0.0481, 0.0076, 0.0444, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 17
images/539
(64, 64, 3)
tensor([[0.0091, 0.0210, 0.0021, 0.0081, 0.0178, 0.0236, 0.0181, 0.0242, 0.0285,
         0.0035, 0.0619, 0.0405, 0.0429, 0.0130, 0.0046, 0.1115, 0.0041, 0.0028,
         0.0245, 0.0041, 0.0065, 0.0030, 0.0076, 0.0122, 0.0170, 0.0636, 0.0037,
         0.0020, 0.0102, 0.0057, 0.0036, 0.0050, 0.1738, 0.0124, 0.0083, 0.0230,
         0.0384, 0.0159, 0.0988, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 18
images/428
(64, 64, 3)
tensor([[0.0099, 0.0361, 0.0434, 0.0264, 0.0099, 0.0417, 0.0296, 0.0460, 0.0149,
         0.0140, 0.0526, 0.0317, 0.0120, 0.0440, 0.0129, 0.0067, 0.0221, 0.0056,
         0.0967, 0.0270, 0.0019, 0.0124, 0.0064, 0.0187, 0.0048, 0.0202, 0.0006,
         0.0084, 0.0090, 0.0325, 0.0020, 0.0184, 0.0317, 0.0054, 0.0108, 0.0014,
         0.1468, 0.0017, 0.0278, 0.0561]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 19
images/118
(64, 64, 3)
tensor([[0.0073, 0.0339, 0.0194, 0.0174, 0.0262, 0.0339, 0.0140, 0.0349, 0.0200,
         0.0171, 0.0812, 0.0241, 0.0310, 0.0110, 0.0113, 0.0140, 0.0137, 0.0156,
         0.0419, 0.0596, 0.0123, 0.0152, 0.0165, 0.0162, 0.0141, 0.0137, 0.0054,
         0.0255, 0.0381, 0.0095, 0.0099, 0.0194, 0.0370, 0.0171, 0.0124, 0.0181,
         0.0827, 0.0120, 0.0553, 0.0422]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 20
images/230
(64, 64, 3)
tensor([[0.0252, 0.0256, 0.0198, 0.0249, 0.0259, 0.0332, 0.0223, 0.0235, 0.0204,
         0.0207, 0.0279, 0.0280, 0.0301, 0.0244, 0.0250, 0.0229, 0.0210, 0.0213,
         0.0248, 0.0230, 0.0237, 0.0226, 0.0236, 0.0264, 0.0217, 0.0322, 0.0251,
         0.0261, 0.0226, 0.0233, 0.0205, 0.0282, 0.0267, 0.0288, 0.0277, 0.0225,
         0.0306, 0.0223, 0.0276, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 21
images/556
(64, 64, 3)
tensor([[0.0020, 0.0223, 0.0022, 0.0190, 0.0210, 0.0106, 0.1984, 0.0105, 0.0007,
         0.0017, 0.2485, 0.0020, 0.0032, 0.0031, 0.0213, 0.0142, 0.0014, 0.0013,
         0.1083, 0.0040, 0.0078, 0.0023, 0.0045, 0.0151, 0.0123, 0.0068, 0.0034,
         0.0029, 0.0040, 0.0507, 0.0029, 0.0292, 0.0185, 0.0044, 0.0063, 0.0026,
         0.0076, 0.0024, 0.1104, 0.0100]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 22
images/155
(64, 64, 3)
tensor([[0.0034, 0.0390, 0.0124, 0.0125, 0.0098, 0.0474, 0.0735, 0.0217, 0.0260,
         0.0180, 0.1199, 0.0235, 0.0300, 0.0046, 0.0113, 0.0085, 0.0260, 0.0226,
         0.0203, 0.0110, 0.0216, 0.0278, 0.0145, 0.0118, 0.0175, 0.0134, 0.0089,
         0.0297, 0.0076, 0.0511, 0.0043, 0.0211, 0.0235, 0.0088, 0.0232, 0.0343,
         0.0316, 0.0381, 0.0360, 0.0335]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 23
images/364
(64, 64, 3)
tensor([[0.0270, 0.0301, 0.0272, 0.0244, 0.0309, 0.0272, 0.0244, 0.0244, 0.0208,
         0.0215, 0.0258, 0.0180, 0.0220, 0.0283, 0.0279, 0.0219, 0.0268, 0.0187,
         0.0199, 0.0210, 0.0202, 0.0244, 0.0299, 0.0188, 0.0195, 0.0289, 0.0188,
         0.0228, 0.0235, 0.0276, 0.0157, 0.0276, 0.0312, 0.0354, 0.0337, 0.0216,
         0.0358, 0.0169, 0.0325, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 24
images/287
(64, 64, 3)
tensor([[0.0235, 0.0265, 0.0225, 0.0228, 0.0251, 0.0258, 0.0236, 0.0233, 0.0237,
         0.0231, 0.0268, 0.0278, 0.0267, 0.0239, 0.0222, 0.0255, 0.0246, 0.0288,
         0.0266, 0.0233, 0.0223, 0.0247, 0.0259, 0.0257, 0.0253, 0.0274, 0.0252,
         0.0278, 0.0234, 0.0243, 0.0240, 0.0238, 0.0284, 0.0258, 0.0251, 0.0216,
         0.0276, 0.0233, 0.0284, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 0
Session Number: 25
images/276
(64, 64, 3)
tensor([[0.0225, 0.0265, 0.0231, 0.0263, 0.0284, 0.0304, 0.0248, 0.0277, 0.0229,
         0.0243, 0.0287, 0.0268, 0.0236, 0.0241, 0.0229, 0.0239, 0.0229, 0.0276,
         0.0258, 0.0285, 0.0246, 0.0244, 0.0210, 0.0247, 0.0257, 0.0261, 0.0216,
         0.0281, 0.0222, 0.0240, 0.0223, 0.0230, 0.0275, 0.0246, 0.0239, 0.0221,
         0.0231, 0.0220, 0.0277, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 0.75
0
Enter Reward: Session Number: 26
images/312
(64, 64, 3)
tensor([[0.0278, 0.0298, 0.0198, 0.0271, 0.0267, 0.0294, 0.0288, 0.0234, 0.0219,
         0.0239, 0.0348, 0.0311, 0.0255, 0.0247, 0.0213, 0.0304, 0.0242, 0.0208,
         0.0218, 0.0200, 0.0273, 0.0211, 0.0229, 0.0292, 0.0229, 0.0275, 0.0243,
         0.0261, 0.0230, 0.0275, 0.0210, 0.0218, 0.0306, 0.0267, 0.0213, 0.0238,
         0.0211, 0.0212, 0.0252, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 27
images/45
(64, 64, 3)
tensor([[0.0396, 0.0441, 0.0229, 0.0064, 0.0193, 0.0262, 0.0349, 0.0222, 0.0177,
         0.0125, 0.0725, 0.0185, 0.0163, 0.0353, 0.0304, 0.0110, 0.0151, 0.0221,
         0.0345, 0.0242, 0.0190, 0.0344, 0.0286, 0.0289, 0.0240, 0.0412, 0.0108,
         0.0176, 0.0215, 0.0227, 0.0152, 0.0203, 0.0332, 0.0151, 0.0141, 0.0360,
         0.0178, 0.0204, 0.0413, 0.0122]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 28
images/533
(64, 64, 3)
tensor([[0.0130, 0.0138, 0.0215, 0.0021, 0.0063, 0.0083, 0.0200, 0.0087, 0.0152,
         0.0230, 0.0975, 0.1156, 0.0159, 0.0056, 0.0092, 0.0175, 0.0122, 0.0175,
         0.0384, 0.0122, 0.0301, 0.0081, 0.0112, 0.0966, 0.0063, 0.0851, 0.0046,
         0.0160, 0.0051, 0.0443, 0.0044, 0.0234, 0.0223, 0.0547, 0.0062, 0.0088,
         0.0520, 0.0085, 0.0300, 0.0086]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 29
images/499
(64, 64, 3)
tensor([[0.0091, 0.0070, 0.0035, 0.0116, 0.0199, 0.0345, 0.0143, 0.0115, 0.0193,
         0.0143, 0.0848, 0.0572, 0.0176, 0.0054, 0.0058, 0.1061, 0.0220, 0.0126,
         0.0295, 0.0021, 0.0168, 0.0287, 0.0258, 0.0049, 0.0048, 0.0120, 0.0046,
         0.0228, 0.0651, 0.0116, 0.0021, 0.0133, 0.0320, 0.0059, 0.0282, 0.0135,
         0.0435, 0.0083, 0.0430, 0.1251]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 1
Session Number: 30
images/61
(64, 64, 3)
tensor([[0.0062, 0.0068, 0.0202, 0.0392, 0.0174, 0.0078, 0.0416, 0.0125, 0.0124,
         0.0440, 0.0552, 0.0193, 0.0423, 0.0116, 0.0056, 0.0190, 0.0102, 0.0131,
         0.0227, 0.0138, 0.0215, 0.0160, 0.0140, 0.0097, 0.0100, 0.0156, 0.0168,
         0.0536, 0.0044, 0.0438, 0.0081, 0.1682, 0.0245, 0.0144, 0.0072, 0.0076,
         0.0412, 0.0124, 0.0349, 0.0548]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 31
images/22
(64, 64, 3)
tensor([[0.0035, 0.0087, 0.0130, 0.0134, 0.0074, 0.0024, 0.0039, 0.0021, 0.0019,
         0.0181, 0.2008, 0.0181, 0.0101, 0.0083, 0.0117, 0.0601, 0.0092, 0.0074,
         0.0296, 0.0110, 0.0019, 0.0196, 0.0065, 0.0156, 0.0013, 0.0285, 0.0023,
         0.0007, 0.0050, 0.0692, 0.0011, 0.1569, 0.0328, 0.0310, 0.0213, 0.0022,
         0.0969, 0.0085, 0.0458, 0.0123]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 32
images/515
(64, 64, 3)
tensor([[0.0366, 0.0179, 0.0210, 0.0253, 0.0158, 0.0511, 0.0214, 0.0151, 0.0136,
         0.0563, 0.0942, 0.0112, 0.0294, 0.0183, 0.0045, 0.0106, 0.0168, 0.0142,
         0.0591, 0.0146, 0.0080, 0.0362, 0.0248, 0.0254, 0.0092, 0.0466, 0.0059,
         0.0354, 0.0083, 0.0205, 0.0127, 0.0164, 0.0378, 0.0191, 0.0195, 0.0044,
         0.0323, 0.0262, 0.0149, 0.0493]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 33
images/467
(64, 64, 3)
tensor([[0.0197, 0.0337, 0.0233, 0.0064, 0.1445, 0.1112, 0.0499, 0.0118, 0.0166,
         0.0080, 0.0440, 0.0380, 0.0097, 0.0260, 0.0207, 0.0072, 0.0144, 0.0043,
         0.0399, 0.0056, 0.0051, 0.0057, 0.0161, 0.0144, 0.0063, 0.0125, 0.0068,
         0.0051, 0.0123, 0.0085, 0.0037, 0.0048, 0.0404, 0.0100, 0.0116, 0.0048,
         0.0216, 0.0148, 0.0539, 0.1067]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 34
images/60
(64, 64, 3)
tensor([[0.0125, 0.0286, 0.0155, 0.0116, 0.0177, 0.0227, 0.0138, 0.0301, 0.0142,
         0.0202, 0.0577, 0.0227, 0.0427, 0.0158, 0.0073, 0.0280, 0.0201, 0.0121,
         0.0282, 0.0299, 0.0195, 0.0230, 0.0155, 0.0273, 0.0138, 0.1267, 0.0042,
         0.0091, 0.0086, 0.0121, 0.0077, 0.0160, 0.0704, 0.0156, 0.0298, 0.0088,
         0.0423, 0.0113, 0.0408, 0.0463]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 35
images/69
(64, 64, 3)
tensor([[0.0209, 0.0094, 0.0184, 0.0152, 0.0201, 0.0302, 0.0343, 0.0360, 0.0067,
         0.0109, 0.0954, 0.0506, 0.0126, 0.0425, 0.0112, 0.0520, 0.0117, 0.0259,
         0.0151, 0.0281, 0.0104, 0.0051, 0.0365, 0.0215, 0.0088, 0.0209, 0.0052,
         0.0135, 0.0152, 0.0182, 0.0117, 0.0252, 0.0300, 0.0223, 0.0216, 0.0480,
         0.0585, 0.0145, 0.0360, 0.0297]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 36
images/481
(64, 64, 3)
tensor([[0.0043, 0.0059, 0.0014, 0.0111, 0.0072, 0.0148, 0.0468, 0.0118, 0.0890,
         0.0068, 0.0235, 0.0066, 0.0225, 0.0114, 0.0045, 0.0101, 0.0097, 0.0100,
         0.1804, 0.0211, 0.0102, 0.0108, 0.0138, 0.0060, 0.0075, 0.0092, 0.0004,
         0.0063, 0.0044, 0.0107, 0.0021, 0.0200, 0.1101, 0.0023, 0.0503, 0.0098,
         0.1129, 0.0053, 0.1019, 0.0073]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 37
images/519
(64, 64, 3)
tensor([[0.0061, 0.0170, 0.0247, 0.0117, 0.0249, 0.0107, 0.0808, 0.0522, 0.0144,
         0.0115, 0.0435, 0.0421, 0.0324, 0.0095, 0.0099, 0.0045, 0.0115, 0.0168,
         0.0147, 0.0101, 0.0100, 0.0102, 0.0515, 0.0047, 0.0109, 0.0669, 0.0084,
         0.0229, 0.0123, 0.0456, 0.0067, 0.0249, 0.0375, 0.0229, 0.0177, 0.0375,
         0.0653, 0.0502, 0.0221, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 38
images/513
(64, 64, 3)
tensor([[0.0024, 0.0132, 0.0060, 0.0456, 0.0279, 0.0340, 0.0149, 0.0189, 0.0133,
         0.0130, 0.1393, 0.0163, 0.0108, 0.0344, 0.0095, 0.0175, 0.0060, 0.0030,
         0.0242, 0.0372, 0.0077, 0.0073, 0.0135, 0.0135, 0.0025, 0.1463, 0.0009,
         0.0119, 0.0019, 0.0124, 0.0028, 0.0052, 0.0311, 0.0042, 0.0019, 0.0073,
         0.0999, 0.0462, 0.0714, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 39
images/470
(64, 64, 3)
tensor([[0.0305, 0.0300, 0.0136, 0.0462, 0.0091, 0.0207, 0.0164, 0.0785, 0.0105,
         0.0039, 0.0816, 0.1184, 0.0093, 0.0323, 0.0112, 0.0037, 0.0071, 0.0096,
         0.0449, 0.0038, 0.0260, 0.0113, 0.0272, 0.0099, 0.0088, 0.0358, 0.0058,
         0.0221, 0.0040, 0.0375, 0.0064, 0.1004, 0.0121, 0.0233, 0.0230, 0.0074,
         0.0040, 0.0093, 0.0360, 0.0086]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 40
images/69
(64, 64, 3)
tensor([[0.0123, 0.0130, 0.0120, 0.0079, 0.0325, 0.0371, 0.0115, 0.0210, 0.0074,
         0.0114, 0.1425, 0.0476, 0.0271, 0.0167, 0.0195, 0.0362, 0.0128, 0.0111,
         0.0148, 0.0502, 0.0038, 0.0156, 0.0111, 0.0254, 0.0137, 0.0251, 0.0084,
         0.0110, 0.0269, 0.0087, 0.0065, 0.0104, 0.0199, 0.0224, 0.0270, 0.0218,
         0.0227, 0.0113, 0.1406, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 41
images/357
(64, 64, 3)
tensor([[0.0223, 0.0279, 0.0235, 0.0242, 0.0261, 0.0209, 0.0221, 0.0239, 0.0255,
         0.0275, 0.0309, 0.0280, 0.0240, 0.0269, 0.0244, 0.0246, 0.0238, 0.0208,
         0.0253, 0.0240, 0.0262, 0.0229, 0.0221, 0.0240, 0.0238, 0.0250, 0.0175,
         0.0245, 0.0247, 0.0287, 0.0226, 0.0313, 0.0307, 0.0186, 0.0283, 0.0210,
         0.0274, 0.0279, 0.0297, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 42
images/450
(64, 64, 3)
tensor([[0.0079, 0.0227, 0.0139, 0.0165, 0.0162, 0.0716, 0.0341, 0.0131, 0.0099,
         0.0068, 0.1134, 0.0373, 0.0182, 0.0048, 0.0292, 0.0303, 0.0091, 0.0078,
         0.0275, 0.0200, 0.0426, 0.0122, 0.0204, 0.0067, 0.0067, 0.0283, 0.0081,
         0.0100, 0.0216, 0.0206, 0.0036, 0.0220, 0.0378, 0.0230, 0.0117, 0.0255,
         0.0445, 0.0384, 0.0874, 0.0187]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/101
(64, 64, 3)
tensor([[0.0148, 0.0059, 0.0185, 0.0257, 0.0342, 0.0338, 0.0236, 0.0088, 0.0146,
         0.0075, 0.0566, 0.0406, 0.0279, 0.0161, 0.0066, 0.0188, 0.0158, 0.0371,
         0.0328, 0.0230, 0.0280, 0.0088, 0.0069, 0.0394, 0.0123, 0.0291, 0.0141,
         0.0088, 0.0078, 0.0205, 0.0057, 0.0447, 0.0488, 0.0342, 0.0119, 0.0355,
         0.1041, 0.0168, 0.0359, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 44
images/553
(64, 64, 3)
tensor([[0.0230, 0.0156, 0.0113, 0.0068, 0.0144, 0.0328, 0.0084, 0.0079, 0.0144,
         0.0039, 0.3247, 0.0307, 0.0137, 0.0041, 0.0076, 0.0193, 0.0041, 0.0079,
         0.0090, 0.0377, 0.0104, 0.0052, 0.0174, 0.0188, 0.0043, 0.0262, 0.0027,
         0.0284, 0.0592, 0.0054, 0.0111, 0.0079, 0.0091, 0.0158, 0.0070, 0.0080,
         0.0963, 0.0105, 0.0415, 0.0175]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 45
images/223
(64, 64, 3)
tensor([[0.0260, 0.0281, 0.0222, 0.0236, 0.0244, 0.0297, 0.0239, 0.0260, 0.0274,
         0.0185, 0.0336, 0.0291, 0.0269, 0.0237, 0.0271, 0.0255, 0.0203, 0.0260,
         0.0227, 0.0298, 0.0195, 0.0206, 0.0265, 0.0249, 0.0253, 0.0283, 0.0203,
         0.0276, 0.0233, 0.0237, 0.0236, 0.0228, 0.0244, 0.0278, 0.0225, 0.0266,
         0.0254, 0.0187, 0.0301, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 46
images/477
(64, 64, 3)
tensor([[0.0285, 0.0139, 0.0082, 0.0079, 0.0172, 0.0638, 0.0243, 0.0053, 0.0185,
         0.0109, 0.1756, 0.0217, 0.0121, 0.0052, 0.0168, 0.0053, 0.0064, 0.0171,
         0.0134, 0.0061, 0.0109, 0.0153, 0.0045, 0.0079, 0.0040, 0.0299, 0.0022,
         0.0069, 0.0352, 0.0206, 0.0038, 0.0125, 0.1267, 0.0246, 0.0480, 0.0311,
         0.0784, 0.0043, 0.0460, 0.0093]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 47
images/383
(64, 64, 3)
tensor([[0.0274, 0.0250, 0.0269, 0.0153, 0.0262, 0.0230, 0.0230, 0.0274, 0.0152,
         0.0233, 0.0354, 0.0322, 0.0271, 0.0243, 0.0202, 0.0259, 0.0308, 0.0242,
         0.0263, 0.0349, 0.0268, 0.0271, 0.0250, 0.0276, 0.0196, 0.0262, 0.0142,
         0.0229, 0.0227, 0.0263, 0.0170, 0.0246, 0.0277, 0.0244, 0.0320, 0.0252,
         0.0198, 0.0216, 0.0283, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 48
images/322
(64, 64, 3)
tensor([[0.0263, 0.0263, 0.0241, 0.0228, 0.0319, 0.0292, 0.0287, 0.0220, 0.0246,
         0.0270, 0.0316, 0.0293, 0.0256, 0.0243, 0.0222, 0.0204, 0.0217, 0.0211,
         0.0214, 0.0223, 0.0251, 0.0198, 0.0286, 0.0204, 0.0236, 0.0204, 0.0178,
         0.0171, 0.0291, 0.0234, 0.0194, 0.0271, 0.0414, 0.0239, 0.0255, 0.0263,
         0.0349, 0.0244, 0.0237, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 49
images/575
(64, 64, 3)
tensor([[0.0035, 0.0286, 0.0106, 0.0044, 0.0477, 0.0361, 0.0130, 0.0228, 0.0136,
         0.0084, 0.0295, 0.0274, 0.0203, 0.0048, 0.0204, 0.0078, 0.0145, 0.0328,
         0.0652, 0.0041, 0.0217, 0.0298, 0.0158, 0.0131, 0.0083, 0.2060, 0.0026,
         0.0152, 0.0068, 0.0556, 0.0018, 0.0095, 0.0317, 0.0111, 0.0173, 0.0270,
         0.0256, 0.0223, 0.0421, 0.0216]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 50
images/18
(64, 64, 3)
tensor([[0.0086, 0.0121, 0.0148, 0.0180, 0.0176, 0.0236, 0.0148, 0.0121, 0.0062,
         0.0099, 0.2657, 0.0262, 0.0172, 0.0152, 0.0103, 0.0224, 0.0072, 0.0162,
         0.0195, 0.0049, 0.0074, 0.0103, 0.0143, 0.0316, 0.0115, 0.0474, 0.0034,
         0.0170, 0.0191, 0.0421, 0.0054, 0.0110, 0.0445, 0.0143, 0.0305, 0.0266,
         0.0351, 0.0141, 0.0377, 0.0342]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 51
images/302
(64, 64, 3)
tensor([[0.0238, 0.0234, 0.0331, 0.0286, 0.0303, 0.0254, 0.0224, 0.0233, 0.0204,
         0.0221, 0.0303, 0.0286, 0.0206, 0.0228, 0.0244, 0.0265, 0.0210, 0.0221,
         0.0207, 0.0214, 0.0180, 0.0219, 0.0270, 0.0265, 0.0191, 0.0309, 0.0176,
         0.0265, 0.0261, 0.0227, 0.0207, 0.0269, 0.0271, 0.0258, 0.0279, 0.0243,
         0.0344, 0.0211, 0.0348, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py
Loading the model if any
Session Number: 0
images/454
(64, 64, 3)
2018-10-09 18:59:25.514 Python[78714:14979455] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 212, in <module>
    main()
  File "Torch_reinforce01.py", line 179, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 140, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model=False
Loading the model if any
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 132, in <module>
    policy.load_state_dict(torch.load('Weight.pt'))
  File "/usr/local/lib/python3.6/site-packages/torch/serialization.py", line 356, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: 'Weight.pt'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model=False
Loading the model if any
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 132, in <module>
    policy.load_state_dict(torch.load('Weight.pt'))
  File "/usr/local/lib/python3.6/site-packages/torch/serialization.py", line 356, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: 'Weight.pt'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model=False
Loading the model if any
True
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 133, in <module>
    policy.load_state_dict(torch.load('Weight.pt'))
  File "/usr/local/lib/python3.6/site-packages/torch/serialization.py", line 356, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: 'Weight.pt'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model False
Loading the model if any
True
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 133, in <module>
    policy.load_state_dict(torch.load('Weight.pt'))
  File "/usr/local/lib/python3.6/site-packages/torch/serialization.py", line 356, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: 'Weight.pt'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py -load_model False 
usage: Torch_reinforce01.py [-h] [--gamma G] [--seed N] [--render]
                            [--log-interval N] [--load_model LOAD_MODEL]
Torch_reinforce01.py: error: unrecognized arguments: -load_model False
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model False
Loading the model if any
True
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 133, in <module>
    policy.load_state_dict(torch.load('Weight.pt'))
  File "/usr/local/lib/python3.6/site-packages/torch/serialization.py", line 356, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: 'Weight.pt'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model False
Loading the model if any
True
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 133, in <module>
    policy.load_state_dict(torch.load('Weight.pt'))
  File "/usr/local/lib/python3.6/site-packages/torch/serialization.py", line 356, in load
    f = open(f, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: 'Weight.pt'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0    
Loading the model if any
0
Session Number: 0
images/499
(64, 64, 3)
2018-10-09 23:38:55.254 Python[85426:15127346] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0091, 0.0155, 0.0197, 0.0141, 0.0348, 0.0284, 0.0026, 0.0105, 0.0133,
         0.0296, 0.0853, 0.0131, 0.0061, 0.0181, 0.0176, 0.0160, 0.0055, 0.0139,
         0.0185, 0.0153, 0.0107, 0.0155, 0.0271, 0.0230, 0.0057, 0.0213, 0.0031,
         0.0264, 0.0193, 0.0120, 0.0074, 0.0103, 0.1305, 0.0305, 0.0087, 0.0142,
         0.1201, 0.0492, 0.0271, 0.0509]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/538
(64, 64, 3)
tensor([[0.0086, 0.0156, 0.0133, 0.0091, 0.0055, 0.0107, 0.2454, 0.0233, 0.0118,
         0.0160, 0.0656, 0.0118, 0.0138, 0.0059, 0.0093, 0.0133, 0.0075, 0.0142,
         0.0354, 0.0080, 0.0303, 0.0025, 0.0143, 0.0041, 0.0164, 0.0299, 0.0010,
         0.0035, 0.0085, 0.0088, 0.0043, 0.0093, 0.0391, 0.0278, 0.0135, 0.0157,
         0.0921, 0.0150, 0.1095, 0.0105]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/396
(64, 64, 3)
tensor([[0.0256, 0.0258, 0.0251, 0.0236, 0.0228, 0.0248, 0.0293, 0.0245, 0.0291,
         0.0238, 0.0315, 0.0249, 0.0261, 0.0268, 0.0205, 0.0235, 0.0240, 0.0222,
         0.0213, 0.0207, 0.0230, 0.0239, 0.0265, 0.0216, 0.0216, 0.0261, 0.0216,
         0.0257, 0.0220, 0.0258, 0.0235, 0.0257, 0.0299, 0.0307, 0.0269, 0.0200,
         0.0250, 0.0245, 0.0323, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/101
(64, 64, 3)
tensor([[0.0154, 0.0169, 0.0196, 0.0149, 0.0360, 0.0162, 0.0410, 0.0136, 0.0712,
         0.0179, 0.0237, 0.0121, 0.0341, 0.0390, 0.0037, 0.0022, 0.0097, 0.0142,
         0.0327, 0.0243, 0.0188, 0.0170, 0.0045, 0.0087, 0.0055, 0.0252, 0.0052,
         0.0059, 0.0091, 0.0392, 0.0016, 0.0063, 0.0480, 0.0155, 0.0206, 0.0816,
         0.1312, 0.0144, 0.0349, 0.0483]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 4
images/338
(64, 64, 3)
tensor([[0.0273, 0.0262, 0.0270, 0.0263, 0.0239, 0.0255, 0.0259, 0.0229, 0.0234,
         0.0191, 0.0252, 0.0236, 0.0280, 0.0265, 0.0225, 0.0222, 0.0243, 0.0252,
         0.0217, 0.0249, 0.0230, 0.0281, 0.0258, 0.0266, 0.0229, 0.0254, 0.0231,
         0.0240, 0.0261, 0.0266, 0.0194, 0.0221, 0.0260, 0.0242, 0.0289, 0.0201,
         0.0313, 0.0274, 0.0325, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 5
images/226
(64, 64, 3)
tensor([[0.0231, 0.0256, 0.0254, 0.0232, 0.0239, 0.0264, 0.0262, 0.0246, 0.0220,
         0.0206, 0.0300, 0.0245, 0.0265, 0.0232, 0.0233, 0.0257, 0.0228, 0.0260,
         0.0262, 0.0263, 0.0218, 0.0259, 0.0240, 0.0259, 0.0255, 0.0267, 0.0219,
         0.0240, 0.0224, 0.0288, 0.0224, 0.0242, 0.0283, 0.0234, 0.0255, 0.0258,
         0.0290, 0.0259, 0.0280, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/96
(64, 64, 3)
2018-10-09 23:39:23.614 Python[85473:15127718] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 221, in <module>
    main()
  File "Torch_reinforce01.py", line 188, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 149, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model False
usage: Torch_reinforce01.py [-h] [--gamma G] [--seed N] [--render]
                            [--log-interval N] [--load_model N]
Torch_reinforce01.py: error: argument --load_model: invalid int value: 'False'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0    
Loading the model if any
0
Session Number: 0
images/546
(64, 64, 3)
2018-10-09 23:40:03.349 Python[85554:15128439] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0152, 0.0182, 0.0218, 0.0172, 0.0327, 0.0148, 0.0025, 0.0104, 0.0147,
         0.0347, 0.0982, 0.0078, 0.0173, 0.0200, 0.0129, 0.0155, 0.0025, 0.0167,
         0.0146, 0.0220, 0.0087, 0.0262, 0.0260, 0.0174, 0.0054, 0.0162, 0.0016,
         0.0119, 0.0341, 0.0095, 0.0041, 0.0138, 0.0906, 0.0468, 0.0199, 0.0069,
         0.1720, 0.0327, 0.0230, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/365
(64, 64, 3)
2018-10-09 23:40:18.810 Python[85594:15128696] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 221, in <module>
    main()
  File "Torch_reinforce01.py", line 188, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 149, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/598
(64, 64, 3)
2018-10-09 23:59:06.459 Python[85902:15136224] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0165, 0.0208, 0.0165, 0.0107, 0.0370, 0.0244, 0.0045, 0.0147, 0.0113,
         0.0255, 0.0730, 0.0133, 0.0120, 0.0111, 0.0221, 0.0358, 0.0068, 0.0127,
         0.0147, 0.0196, 0.0154, 0.0165, 0.0300, 0.0224, 0.0112, 0.0278, 0.0039,
         0.0122, 0.0229, 0.0136, 0.0048, 0.0164, 0.1211, 0.0364, 0.0084, 0.0145,
         0.0736, 0.0507, 0.0366, 0.0584]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Saving the weights
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 209, in main
    save_model()
  File "Torch_reinforce01.py", line 142, in save_model
    torch.save(optimizer.state_dict(),'Optimizer.pt')
NameError: name 'optimizer' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/567
(64, 64, 3)
2018-10-09 23:59:47.876 Python[85951:15136645] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0151, 0.0187, 0.0174, 0.0142, 0.0334, 0.0261, 0.0038, 0.0132, 0.0122,
         0.0246, 0.0643, 0.0135, 0.0114, 0.0134, 0.0173, 0.0322, 0.0063, 0.0158,
         0.0139, 0.0226, 0.0171, 0.0156, 0.0333, 0.0231, 0.0134, 0.0214, 0.0049,
         0.0174, 0.0222, 0.0103, 0.0052, 0.0141, 0.0734, 0.0370, 0.0088, 0.0177,
         0.1242, 0.0691, 0.0425, 0.0400]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/370
(64, 64, 3)
tensor([[0.0252, 0.0263, 0.0247, 0.0252, 0.0235, 0.0243, 0.0324, 0.0256, 0.0264,
         0.0255, 0.0289, 0.0257, 0.0262, 0.0254, 0.0239, 0.0243, 0.0234, 0.0268,
         0.0272, 0.0262, 0.0264, 0.0218, 0.0235, 0.0196, 0.0254, 0.0247, 0.0187,
         0.0244, 0.0233, 0.0232, 0.0216, 0.0233, 0.0283, 0.0259, 0.0243, 0.0241,
         0.0295, 0.0255, 0.0264, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/419
(64, 64, 3)
tensor([[0.0093, 0.0207, 0.0194, 0.0065, 0.0103, 0.0128, 0.0947, 0.0086, 0.0532,
         0.0095, 0.0685, 0.0197, 0.0220, 0.0172, 0.0030, 0.0084, 0.0093, 0.0058,
         0.0063, 0.0023, 0.0095, 0.0101, 0.0168, 0.0054, 0.0067, 0.0418, 0.0043,
         0.0112, 0.0032, 0.0458, 0.0074, 0.0124, 0.0840, 0.0337, 0.0417, 0.0061,
         0.0191, 0.0049, 0.1907, 0.0376]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 3
images/367
(64, 64, 3)
tensor([[0.0253, 0.0234, 0.0258, 0.0257, 0.0259, 0.0245, 0.0251, 0.0242, 0.0279,
         0.0270, 0.0277, 0.0245, 0.0288, 0.0270, 0.0200, 0.0202, 0.0225, 0.0253,
         0.0269, 0.0281, 0.0228, 0.0246, 0.0219, 0.0222, 0.0206, 0.0249, 0.0196,
         0.0214, 0.0219, 0.0285, 0.0187, 0.0245, 0.0306, 0.0250, 0.0277, 0.0279,
         0.0332, 0.0257, 0.0265, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/236
(64, 64, 3)
2018-10-10 00:12:05.732 Python[86034:15138607] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 189, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 150, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/179
(64, 64, 3)
2018-10-10 00:12:18.331 Python[86075:15139133] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 189, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 150, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/339
(64, 64, 3)
2018-10-10 00:12:31.244 Python[86116:15139506] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0237, 0.0260, 0.0254, 0.0247, 0.0267, 0.0256, 0.0229, 0.0233, 0.0235,
         0.0241, 0.0272, 0.0260, 0.0232, 0.0232, 0.0241, 0.0259, 0.0225, 0.0257,
         0.0238, 0.0250, 0.0228, 0.0240, 0.0265, 0.0257, 0.0250, 0.0267, 0.0227,
         0.0247, 0.0251, 0.0236, 0.0232, 0.0251, 0.0293, 0.0264, 0.0239, 0.0229,
         0.0291, 0.0276, 0.0248, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Saving the weights
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 209, in main
    save_model()
  File "Torch_reinforce01.py", line 142, in save_model
    torch.save(optimizer.state_dict(),'Optimizer.pt')
NameError: name 'optimizer' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/30
(64, 64, 3)
2018-10-10 00:12:46.771 Python[86158:15140037] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0080, 0.0133, 0.0156, 0.0138, 0.0205, 0.0198, 0.0097, 0.0166, 0.0125,
         0.0159, 0.0719, 0.0144, 0.0059, 0.0153, 0.0101, 0.0238, 0.0050, 0.0088,
         0.0262, 0.0183, 0.0108, 0.0114, 0.0374, 0.0188, 0.0097, 0.0355, 0.0062,
         0.0077, 0.0140, 0.0098, 0.0070, 0.0223, 0.1359, 0.0194, 0.0141, 0.0110,
         0.1180, 0.0433, 0.0202, 0.1021]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 1
images/2
(64, 64, 3)
tensor([[0.0155, 0.0196, 0.0096, 0.0128, 0.0064, 0.0143, 0.1420, 0.0209, 0.0274,
         0.0172, 0.1098, 0.0178, 0.0137, 0.0133, 0.0155, 0.0250, 0.0097, 0.0477,
         0.0593, 0.0122, 0.0202, 0.0038, 0.0170, 0.0068, 0.0106, 0.0246, 0.0035,
         0.0086, 0.0156, 0.0094, 0.0117, 0.0061, 0.0441, 0.0318, 0.0123, 0.0187,
         0.0671, 0.0163, 0.0506, 0.0115]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/487
(64, 64, 3)
tensor([[0.0120, 0.0239, 0.0231, 0.0073, 0.0056, 0.0115, 0.0701, 0.0098, 0.0385,
         0.0118, 0.0983, 0.0126, 0.0301, 0.0169, 0.0026, 0.0105, 0.0101, 0.0095,
         0.0029, 0.0029, 0.0151, 0.0120, 0.0207, 0.0059, 0.0027, 0.0208, 0.0045,
         0.0136, 0.0050, 0.0507, 0.0096, 0.0120, 0.1236, 0.0502, 0.0585, 0.0067,
         0.0341, 0.0082, 0.1016, 0.0345]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/55
(64, 64, 3)
tensor([[0.0204, 0.0165, 0.0226, 0.0349, 0.0288, 0.0158, 0.0257, 0.0191, 0.0552,
         0.0264, 0.0417, 0.0204, 0.0310, 0.0290, 0.0107, 0.0074, 0.0123, 0.0181,
         0.0377, 0.0224, 0.0173, 0.0169, 0.0088, 0.0115, 0.0117, 0.0209, 0.0074,
         0.0087, 0.0126, 0.0346, 0.0071, 0.0185, 0.0386, 0.0210, 0.0324, 0.0487,
         0.1117, 0.0137, 0.0387, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 4
images/95
(64, 64, 3)
tensor([[0.0391, 0.0303, 0.0250, 0.0159, 0.0121, 0.0284, 0.0424, 0.0141, 0.0147,
         0.0049, 0.0203, 0.0137, 0.0317, 0.0185, 0.0059, 0.0085, 0.0221, 0.0291,
         0.0124, 0.0186, 0.0207, 0.0376, 0.0229, 0.0222, 0.0135, 0.0237, 0.0126,
         0.0145, 0.0147, 0.0424, 0.0060, 0.0150, 0.0285, 0.0203, 0.0241, 0.0083,
         0.1148, 0.0298, 0.0846, 0.0361]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/547
(64, 64, 3)
2018-10-10 02:19:56.084 Python[86227:15142557] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 189, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 150, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/588
(64, 64, 3)
2018-10-10 02:20:09.879 Python[86274:15143251] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0268, 0.0269, 0.0220, 0.0205, 0.0113, 0.0309, 0.0046, 0.0140, 0.0191,
         0.0166, 0.0689, 0.0207, 0.0101, 0.0103, 0.0155, 0.0114, 0.0034, 0.0307,
         0.0140, 0.0159, 0.0062, 0.0158, 0.0298, 0.0334, 0.0161, 0.0262, 0.0050,
         0.0123, 0.0255, 0.0114, 0.0042, 0.0163, 0.1004, 0.0490, 0.0107, 0.0094,
         0.1248, 0.0238, 0.0282, 0.0578]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Saving the weights
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 209, in main
    save_model()
  File "Torch_reinforce01.py", line 142, in save_model
    torch.save(optimizer.state_dict(),'Optimizer.pt')
NameError: name 'optimizer' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/178
(64, 64, 3)
2018-10-10 02:20:22.120 Python[86316:15143632] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0281, 0.0277, 0.0265, 0.0150, 0.0297, 0.0307, 0.0102, 0.0219, 0.0168,
         0.0186, 0.0466, 0.0243, 0.0234, 0.0197, 0.0227, 0.0285, 0.0103, 0.0203,
         0.0205, 0.0186, 0.0170, 0.0226, 0.0384, 0.0299, 0.0137, 0.0305, 0.0094,
         0.0220, 0.0308, 0.0132, 0.0118, 0.0187, 0.0733, 0.0300, 0.0129, 0.0161,
         0.0469, 0.0353, 0.0255, 0.0419]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: -1
Breaking
Saving the weights
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 204, in main
    save_model()
  File "Torch_reinforce01.py", line 142, in save_model
    torch.save(optimizer.state_dict(),'Optimizer.pt')
NameError: name 'optimizer' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/581
(64, 64, 3)
2018-10-10 02:20:34.510 Python[86355:15143881] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0133, 0.0151, 0.0138, 0.0142, 0.0267, 0.0202, 0.0122, 0.0150, 0.0162,
         0.0200, 0.0886, 0.0191, 0.0084, 0.0120, 0.0172, 0.0412, 0.0075, 0.0330,
         0.0160, 0.0215, 0.0100, 0.0186, 0.0189, 0.0213, 0.0106, 0.0415, 0.0084,
         0.0130, 0.0097, 0.0153, 0.0079, 0.0239, 0.1137, 0.0192, 0.0122, 0.0090,
         0.0672, 0.0494, 0.0301, 0.0688]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/280
(64, 64, 3)
tensor([[0.0243, 0.0268, 0.0256, 0.0227, 0.0233, 0.0241, 0.0347, 0.0250, 0.0247,
         0.0232, 0.0325, 0.0256, 0.0246, 0.0234, 0.0253, 0.0255, 0.0235, 0.0270,
         0.0278, 0.0242, 0.0263, 0.0197, 0.0252, 0.0213, 0.0252, 0.0269, 0.0169,
         0.0220, 0.0252, 0.0224, 0.0210, 0.0219, 0.0270, 0.0278, 0.0239, 0.0235,
         0.0312, 0.0253, 0.0309, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/79
(64, 64, 3)
tensor([[0.0250, 0.0190, 0.0171, 0.0138, 0.0132, 0.0176, 0.0776, 0.0172, 0.0393,
         0.0154, 0.0904, 0.0257, 0.0240, 0.0265, 0.0078, 0.0101, 0.0137, 0.0135,
         0.0123, 0.0102, 0.0128, 0.0114, 0.0180, 0.0118, 0.0095, 0.0383, 0.0091,
         0.0151, 0.0065, 0.0249, 0.0181, 0.0228, 0.0608, 0.0546, 0.0356, 0.0096,
         0.0156, 0.0057, 0.0987, 0.0317]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/65
(64, 64, 3)
tensor([[0.0116, 0.0181, 0.0270, 0.0231, 0.0297, 0.0110, 0.0398, 0.0198, 0.0673,
         0.0190, 0.0345, 0.0164, 0.0244, 0.0337, 0.0044, 0.0027, 0.0087, 0.0238,
         0.0229, 0.0252, 0.0111, 0.0136, 0.0062, 0.0109, 0.0056, 0.0233, 0.0070,
         0.0090, 0.0078, 0.0285, 0.0030, 0.0108, 0.0611, 0.0201, 0.0242, 0.0507,
         0.1601, 0.0112, 0.0337, 0.0390]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 4
images/31
(64, 64, 3)
tensor([[0.0341, 0.0293, 0.0277, 0.0199, 0.0169, 0.0351, 0.0262, 0.0147, 0.0171,
         0.0095, 0.0241, 0.0161, 0.0420, 0.0321, 0.0098, 0.0154, 0.0220, 0.0263,
         0.0108, 0.0224, 0.0214, 0.0365, 0.0185, 0.0287, 0.0153, 0.0204, 0.0122,
         0.0230, 0.0236, 0.0343, 0.0084, 0.0138, 0.0242, 0.0214, 0.0467, 0.0117,
         0.0646, 0.0268, 0.0754, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 5
images/184
(64, 64, 3)
tensor([[0.0199, 0.0197, 0.0339, 0.0103, 0.0185, 0.0399, 0.0118, 0.0142, 0.0094,
         0.0069, 0.0772, 0.0266, 0.0517, 0.0094, 0.0220, 0.0331, 0.0135, 0.0225,
         0.0249, 0.0247, 0.0207, 0.0377, 0.0157, 0.0328, 0.0171, 0.0293, 0.0086,
         0.0083, 0.0114, 0.0541, 0.0093, 0.0092, 0.0244, 0.0210, 0.0364, 0.0271,
         0.0538, 0.0141, 0.0668, 0.0119]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 1
Session Number: 6
images/219
(64, 64, 3)
tensor([[0.0215, 0.0274, 0.0239, 0.0223, 0.0327, 0.0312, 0.0291, 0.0228, 0.0192,
         0.0283, 0.0297, 0.0275, 0.0230, 0.0236, 0.0218, 0.0226, 0.0219, 0.0240,
         0.0250, 0.0280, 0.0197, 0.0240, 0.0220, 0.0319, 0.0218, 0.0300, 0.0200,
         0.0246, 0.0246, 0.0241, 0.0187, 0.0220, 0.0270, 0.0232, 0.0235, 0.0221,
         0.0334, 0.0237, 0.0339, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 7
images/273
(64, 64, 3)
tensor([[0.0245, 0.0232, 0.0244, 0.0247, 0.0261, 0.0244, 0.0257, 0.0287, 0.0243,
         0.0251, 0.0290, 0.0250, 0.0261, 0.0260, 0.0253, 0.0247, 0.0246, 0.0250,
         0.0249, 0.0241, 0.0222, 0.0233, 0.0252, 0.0224, 0.0229, 0.0276, 0.0210,
         0.0257, 0.0230, 0.0265, 0.0210, 0.0257, 0.0274, 0.0247, 0.0229, 0.0236,
         0.0281, 0.0273, 0.0282, 0.0258]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 8
images/118
(64, 64, 3)
tensor([[0.0208, 0.0196, 0.0239, 0.0121, 0.0210, 0.0436, 0.0187, 0.0344, 0.0087,
         0.0165, 0.0315, 0.0263, 0.0113, 0.0131, 0.0220, 0.0326, 0.0071, 0.0154,
         0.0714, 0.0355, 0.0175, 0.0356, 0.0105, 0.0195, 0.0104, 0.0359, 0.0073,
         0.0471, 0.0109, 0.0352, 0.0147, 0.0127, 0.0314, 0.0159, 0.0237, 0.0145,
         0.0235, 0.0234, 0.0955, 0.0290]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 9
images/135
(64, 64, 3)
tensor([[0.0353, 0.0278, 0.0210, 0.0233, 0.0314, 0.0144, 0.0453, 0.0406, 0.0199,
         0.0154, 0.0227, 0.0547, 0.0303, 0.0207, 0.0203, 0.0229, 0.0153, 0.0195,
         0.0252, 0.0118, 0.0208, 0.0205, 0.0140, 0.0261, 0.0160, 0.0384, 0.0204,
         0.0238, 0.0184, 0.0292, 0.0156, 0.0447, 0.0291, 0.0239, 0.0204, 0.0209,
         0.0289, 0.0122, 0.0338, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 10
images/286
(64, 64, 3)
tensor([[0.0267, 0.0270, 0.0221, 0.0219, 0.0252, 0.0254, 0.0297, 0.0228, 0.0271,
         0.0283, 0.0291, 0.0262, 0.0325, 0.0290, 0.0249, 0.0265, 0.0207, 0.0211,
         0.0232, 0.0200, 0.0237, 0.0250, 0.0259, 0.0217, 0.0230, 0.0249, 0.0170,
         0.0265, 0.0242, 0.0282, 0.0171, 0.0267, 0.0320, 0.0239, 0.0222, 0.0251,
         0.0263, 0.0260, 0.0311, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/571
(64, 64, 3)
tensor([[0.0098, 0.0061, 0.0079, 0.0168, 0.0388, 0.0256, 0.0398, 0.0294, 0.0036,
         0.0084, 0.0234, 0.0187, 0.0105, 0.0387, 0.0142, 0.0182, 0.0053, 0.0061,
         0.0707, 0.0158, 0.0037, 0.0260, 0.0015, 0.0164, 0.0075, 0.0516, 0.0014,
         0.0297, 0.0045, 0.0198, 0.0016, 0.0226, 0.0362, 0.0195, 0.0039, 0.0221,
         0.0784, 0.0194, 0.1961, 0.0302]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 12
images/258
(64, 64, 3)
tensor([[0.0269, 0.0265, 0.0230, 0.0242, 0.0270, 0.0244, 0.0266, 0.0226, 0.0228,
         0.0256, 0.0277, 0.0285, 0.0242, 0.0243, 0.0208, 0.0236, 0.0232, 0.0263,
         0.0231, 0.0277, 0.0242, 0.0266, 0.0235, 0.0220, 0.0271, 0.0270, 0.0244,
         0.0248, 0.0271, 0.0230, 0.0231, 0.0225, 0.0281, 0.0267, 0.0222, 0.0257,
         0.0262, 0.0257, 0.0268, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 13
images/46
(64, 64, 3)
tensor([[0.0081, 0.0207, 0.0055, 0.0208, 0.0082, 0.0289, 0.0221, 0.0180, 0.0223,
         0.0774, 0.0519, 0.0304, 0.0351, 0.0072, 0.0084, 0.0173, 0.0085, 0.0073,
         0.0423, 0.0266, 0.0197, 0.0127, 0.0204, 0.0164, 0.0207, 0.0212, 0.0023,
         0.0089, 0.0092, 0.0085, 0.0094, 0.0227, 0.1075, 0.0121, 0.0732, 0.0329,
         0.0392, 0.0202, 0.0466, 0.0294]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 14
images/509
(64, 64, 3)
tensor([[0.0026, 0.0167, 0.0021, 0.0122, 0.0153, 0.0150, 0.0095, 0.0471, 0.0394,
         0.0035, 0.1021, 0.0550, 0.0079, 0.0098, 0.0098, 0.0160, 0.0018, 0.0096,
         0.0438, 0.0158, 0.0025, 0.0118, 0.0306, 0.0113, 0.0040, 0.0307, 0.0079,
         0.0033, 0.0041, 0.0138, 0.0061, 0.0066, 0.0194, 0.0123, 0.0162, 0.0060,
         0.1107, 0.0099, 0.2157, 0.0424]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 15
images/250
(64, 64, 3)
tensor([[0.0273, 0.0291, 0.0274, 0.0232, 0.0231, 0.0273, 0.0251, 0.0232, 0.0239,
         0.0217, 0.0337, 0.0258, 0.0237, 0.0260, 0.0282, 0.0291, 0.0233, 0.0195,
         0.0236, 0.0231, 0.0206, 0.0240, 0.0243, 0.0233, 0.0245, 0.0228, 0.0198,
         0.0273, 0.0272, 0.0199, 0.0210, 0.0258, 0.0347, 0.0250, 0.0208, 0.0184,
         0.0287, 0.0283, 0.0279, 0.0282]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 16
images/220
(64, 64, 3)
tensor([[0.0238, 0.0241, 0.0264, 0.0217, 0.0245, 0.0238, 0.0247, 0.0206, 0.0240,
         0.0222, 0.0274, 0.0268, 0.0272, 0.0260, 0.0224, 0.0208, 0.0256, 0.0261,
         0.0236, 0.0294, 0.0241, 0.0290, 0.0228, 0.0223, 0.0224, 0.0281, 0.0230,
         0.0267, 0.0248, 0.0257, 0.0220, 0.0239, 0.0306, 0.0253, 0.0254, 0.0230,
         0.0278, 0.0242, 0.0296, 0.0281]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 17
images/550
(64, 64, 3)
tensor([[0.0051, 0.0222, 0.0023, 0.0107, 0.0145, 0.0214, 0.0163, 0.0160, 0.0382,
         0.0049, 0.0693, 0.0464, 0.0431, 0.0168, 0.0041, 0.0702, 0.0045, 0.0034,
         0.0228, 0.0048, 0.0057, 0.0023, 0.0059, 0.0101, 0.0281, 0.0623, 0.0037,
         0.0019, 0.0100, 0.0074, 0.0070, 0.0045, 0.1869, 0.0122, 0.0060, 0.0150,
         0.0504, 0.0157, 0.1104, 0.0175]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 18
images/436
(64, 64, 3)
tensor([[0.0100, 0.0120, 0.0293, 0.0192, 0.0099, 0.0427, 0.0173, 0.0615, 0.0113,
         0.0082, 0.0206, 0.0078, 0.0120, 0.0374, 0.0064, 0.0084, 0.0126, 0.0182,
         0.1541, 0.0179, 0.0031, 0.0123, 0.0028, 0.0132, 0.0035, 0.0170, 0.0004,
         0.0047, 0.0033, 0.0265, 0.0016, 0.0133, 0.0163, 0.0068, 0.0093, 0.0019,
         0.2558, 0.0009, 0.0396, 0.0512]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 19
images/543
(64, 64, 3)
tensor([[0.0086, 0.0505, 0.0360, 0.0160, 0.0342, 0.0328, 0.0088, 0.0441, 0.0159,
         0.0132, 0.1072, 0.0276, 0.0411, 0.0095, 0.0125, 0.0130, 0.0072, 0.0190,
         0.0303, 0.0370, 0.0080, 0.0154, 0.0158, 0.0223, 0.0071, 0.0128, 0.0018,
         0.0194, 0.0236, 0.0077, 0.0089, 0.0329, 0.0406, 0.0250, 0.0165, 0.0115,
         0.0551, 0.0082, 0.0745, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 20
images/15
(64, 64, 3)
tensor([[0.0214, 0.0148, 0.0042, 0.0235, 0.0162, 0.1477, 0.0119, 0.0219, 0.0132,
         0.0162, 0.0319, 0.0282, 0.0344, 0.0123, 0.0198, 0.0185, 0.0161, 0.0197,
         0.0174, 0.0132, 0.0097, 0.0088, 0.0190, 0.0321, 0.0122, 0.0899, 0.0350,
         0.0167, 0.0083, 0.0192, 0.0100, 0.0249, 0.0271, 0.0115, 0.0218, 0.0126,
         0.0523, 0.0113, 0.0376, 0.0375]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 21
images/91
(64, 64, 3)
tensor([[0.0080, 0.0296, 0.0098, 0.0234, 0.0177, 0.0210, 0.1396, 0.0144, 0.0038,
         0.0050, 0.1019, 0.0121, 0.0113, 0.0116, 0.0282, 0.0175, 0.0062, 0.0093,
         0.0934, 0.0115, 0.0198, 0.0105, 0.0121, 0.0189, 0.0261, 0.0217, 0.0182,
         0.0121, 0.0122, 0.0550, 0.0081, 0.0366, 0.0308, 0.0131, 0.0101, 0.0081,
         0.0338, 0.0112, 0.0479, 0.0188]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/560
(64, 64, 3)
2018-10-10 02:22:07.907 Python[86430:15144674] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 189, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 150, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/377
(64, 64, 3)
2018-10-10 02:22:30.727 Python[86472:15144991] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0240, 0.0257, 0.0249, 0.0238, 0.0269, 0.0279, 0.0210, 0.0230, 0.0239,
         0.0237, 0.0280, 0.0232, 0.0228, 0.0230, 0.0239, 0.0262, 0.0218, 0.0263,
         0.0223, 0.0263, 0.0243, 0.0244, 0.0282, 0.0247, 0.0240, 0.0275, 0.0217,
         0.0254, 0.0241, 0.0225, 0.0208, 0.0229, 0.0315, 0.0275, 0.0214, 0.0237,
         0.0314, 0.0290, 0.0268, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Saving the weights
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 222, in <module>
    main()
  File "Torch_reinforce01.py", line 209, in main
    save_model()
  File "Torch_reinforce01.py", line 142, in save_model
    torch.save(optimizer.state_dict(),'Optimizer.pt')
NameError: name 'optimizer' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/151
(64, 64, 3)
2018-10-10 02:23:31.973 Python[86526:15145567] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0150, 0.0217, 0.0270, 0.0190, 0.0261, 0.0201, 0.0089, 0.0174, 0.0205,
         0.0366, 0.0577, 0.0195, 0.0128, 0.0182, 0.0201, 0.0325, 0.0109, 0.0146,
         0.0206, 0.0251, 0.0159, 0.0261, 0.0386, 0.0202, 0.0117, 0.0270, 0.0089,
         0.0152, 0.0267, 0.0139, 0.0100, 0.0194, 0.0721, 0.0317, 0.0180, 0.0153,
         0.0698, 0.0490, 0.0284, 0.0380]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 1
images/182
(64, 64, 3)
tensor([[0.0137, 0.0194, 0.0134, 0.0188, 0.0090, 0.0167, 0.1186, 0.0286, 0.0238,
         0.0148, 0.0622, 0.0170, 0.0153, 0.0217, 0.0145, 0.0135, 0.0118, 0.0467,
         0.0443, 0.0178, 0.0293, 0.0041, 0.0165, 0.0066, 0.0179, 0.0307, 0.0026,
         0.0141, 0.0138, 0.0133, 0.0088, 0.0096, 0.0359, 0.0425, 0.0160, 0.0229,
         0.0749, 0.0170, 0.0710, 0.0109]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/290
(64, 64, 3)
tensor([[0.0236, 0.0271, 0.0255, 0.0212, 0.0226, 0.0249, 0.0385, 0.0217, 0.0289,
         0.0218, 0.0352, 0.0265, 0.0282, 0.0251, 0.0171, 0.0219, 0.0206, 0.0228,
         0.0190, 0.0168, 0.0214, 0.0223, 0.0269, 0.0199, 0.0222, 0.0311, 0.0205,
         0.0244, 0.0178, 0.0274, 0.0225, 0.0256, 0.0378, 0.0279, 0.0313, 0.0192,
         0.0249, 0.0181, 0.0375, 0.0320]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/46
(64, 64, 3)
2018-10-10 02:23:45.502 Python[86568:15145828] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 223, in <module>
    main()
  File "Torch_reinforce01.py", line 190, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 151, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/30
(64, 64, 3)
2018-10-10 02:23:57.767 Python[86606:15146028] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0080, 0.0133, 0.0156, 0.0138, 0.0205, 0.0198, 0.0097, 0.0166, 0.0125,
         0.0159, 0.0719, 0.0144, 0.0059, 0.0153, 0.0101, 0.0238, 0.0050, 0.0088,
         0.0262, 0.0183, 0.0108, 0.0114, 0.0374, 0.0188, 0.0097, 0.0355, 0.0062,
         0.0077, 0.0140, 0.0098, 0.0070, 0.0223, 0.1359, 0.0194, 0.0141, 0.0110,
         0.1180, 0.0433, 0.0202, 0.1021]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0 
Saving the weights
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 223, in <module>
    main()
  File "Torch_reinforce01.py", line 210, in main
    save_model()
  File "Torch_reinforce01.py", line 143, in save_model
    torch.save(optimizer.state_dict(),'Optimizer.pt')
NameError: name 'optimizer' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/62
(64, 64, 3)
2018-10-10 02:24:37.380 Python[86654:15146460] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0202, 0.0298, 0.0262, 0.0141, 0.0356, 0.0233, 0.0072, 0.0149, 0.0156,
         0.0229, 0.0588, 0.0131, 0.0094, 0.0199, 0.0255, 0.0315, 0.0095, 0.0212,
         0.0216, 0.0239, 0.0146, 0.0241, 0.0333, 0.0261, 0.0143, 0.0253, 0.0085,
         0.0185, 0.0228, 0.0165, 0.0142, 0.0132, 0.0777, 0.0336, 0.0127, 0.0134,
         0.0746, 0.0477, 0.0310, 0.0335]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 1
images/318
(64, 64, 3)
tensor([[0.0198, 0.0257, 0.0247, 0.0217, 0.0222, 0.0221, 0.0393, 0.0273, 0.0243,
         0.0240, 0.0329, 0.0253, 0.0249, 0.0219, 0.0241, 0.0249, 0.0226, 0.0283,
         0.0319, 0.0232, 0.0283, 0.0182, 0.0255, 0.0176, 0.0261, 0.0288, 0.0140,
         0.0197, 0.0213, 0.0232, 0.0182, 0.0215, 0.0314, 0.0282, 0.0234, 0.0246,
         0.0361, 0.0252, 0.0363, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/33
(64, 64, 3)
tensor([[0.0158, 0.0196, 0.0280, 0.0110, 0.0173, 0.0220, 0.0825, 0.0089, 0.0477,
         0.0190, 0.0922, 0.0353, 0.0292, 0.0321, 0.0050, 0.0116, 0.0083, 0.0096,
         0.0049, 0.0070, 0.0177, 0.0132, 0.0263, 0.0158, 0.0082, 0.0148, 0.0081,
         0.0130, 0.0089, 0.0443, 0.0167, 0.0321, 0.0574, 0.0355, 0.0319, 0.0072,
         0.0277, 0.0115, 0.0680, 0.0346]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/388
(64, 64, 3)
tensor([[0.0243, 0.0250, 0.0256, 0.0255, 0.0277, 0.0230, 0.0256, 0.0234, 0.0283,
         0.0245, 0.0252, 0.0256, 0.0276, 0.0269, 0.0217, 0.0201, 0.0236, 0.0251,
         0.0264, 0.0271, 0.0247, 0.0244, 0.0232, 0.0227, 0.0223, 0.0246, 0.0223,
         0.0230, 0.0228, 0.0267, 0.0205, 0.0233, 0.0282, 0.0258, 0.0255, 0.0267,
         0.0319, 0.0259, 0.0266, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: -1
Breaking
Saving the weights
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 223, in <module>
    main()
  File "Torch_reinforce01.py", line 205, in main
    save_model()
  File "Torch_reinforce01.py", line 143, in save_model
    torch.save(optimizer.state_dict(),'Optimizer.pt')
NameError: name 'optimizer' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/326
(64, 64, 3)
2018-10-10 02:26:31.980 Python[86725:15147396] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0264, 0.0270, 0.0269, 0.0253, 0.0259, 0.0255, 0.0225, 0.0219, 0.0240,
         0.0242, 0.0274, 0.0242, 0.0261, 0.0263, 0.0236, 0.0239, 0.0213, 0.0267,
         0.0239, 0.0260, 0.0225, 0.0252, 0.0270, 0.0255, 0.0236, 0.0250, 0.0210,
         0.0256, 0.0257, 0.0234, 0.0227, 0.0247, 0.0299, 0.0272, 0.0232, 0.0224,
         0.0288, 0.0270, 0.0244, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0 
Session Number: 1
images/313
(64, 64, 3)
tensor([[0.0266, 0.0257, 0.0241, 0.0230, 0.0232, 0.0224, 0.0325, 0.0245, 0.0263,
         0.0227, 0.0294, 0.0269, 0.0269, 0.0251, 0.0226, 0.0235, 0.0248, 0.0295,
         0.0254, 0.0264, 0.0258, 0.0217, 0.0251, 0.0206, 0.0237, 0.0266, 0.0204,
         0.0245, 0.0261, 0.0222, 0.0227, 0.0211, 0.0276, 0.0299, 0.0231, 0.0238,
         0.0299, 0.0240, 0.0275, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/542
(64, 64, 3)
tensor([[0.0118, 0.0198, 0.0123, 0.0062, 0.0123, 0.0170, 0.0903, 0.0100, 0.0409,
         0.0179, 0.0711, 0.0212, 0.0275, 0.0158, 0.0026, 0.0069, 0.0090, 0.0065,
         0.0077, 0.0029, 0.0122, 0.0084, 0.0173, 0.0054, 0.0062, 0.0355, 0.0052,
         0.0122, 0.0034, 0.0540, 0.0084, 0.0162, 0.1180, 0.0290, 0.0407, 0.0082,
         0.0151, 0.0039, 0.1514, 0.0394]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/204
(64, 64, 3)
tensor([[0.0250, 0.0249, 0.0249, 0.0243, 0.0273, 0.0232, 0.0262, 0.0237, 0.0276,
         0.0263, 0.0264, 0.0244, 0.0282, 0.0273, 0.0209, 0.0205, 0.0230, 0.0259,
         0.0263, 0.0280, 0.0233, 0.0242, 0.0226, 0.0220, 0.0218, 0.0252, 0.0214,
         0.0217, 0.0223, 0.0280, 0.0192, 0.0244, 0.0303, 0.0256, 0.0263, 0.0287,
         0.0324, 0.0242, 0.0253, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 4
images/54
(64, 64, 3)
tensor([[0.0279, 0.0310, 0.0252, 0.0200, 0.0109, 0.0279, 0.0421, 0.0154, 0.0148,
         0.0065, 0.0229, 0.0127, 0.0392, 0.0232, 0.0085, 0.0130, 0.0247, 0.0195,
         0.0103, 0.0162, 0.0165, 0.0315, 0.0238, 0.0299, 0.0134, 0.0200, 0.0122,
         0.0166, 0.0238, 0.0356, 0.0056, 0.0116, 0.0232, 0.0191, 0.0511, 0.0096,
         0.0872, 0.0319, 0.0994, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 5
images/9
(64, 64, 3)
tensor([[0.0061, 0.0145, 0.0181, 0.0068, 0.0119, 0.0401, 0.0167, 0.0125, 0.0060,
         0.0057, 0.1500, 0.0090, 0.0259, 0.0045, 0.0088, 0.0279, 0.0052, 0.0126,
         0.0442, 0.0189, 0.0061, 0.0335, 0.0058, 0.0195, 0.0141, 0.0218, 0.0023,
         0.0048, 0.0060, 0.0805, 0.0041, 0.0116, 0.0396, 0.0076, 0.0428, 0.0329,
         0.1036, 0.0132, 0.0873, 0.0172]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 6
images/575
(64, 64, 3)
tensor([[0.0041, 0.0323, 0.0129, 0.0068, 0.0695, 0.0778, 0.0496, 0.0086, 0.0037,
         0.0318, 0.0720, 0.0315, 0.0116, 0.0112, 0.0059, 0.0095, 0.0132, 0.0177,
         0.0194, 0.0167, 0.0056, 0.0130, 0.0058, 0.0675, 0.0026, 0.0422, 0.0075,
         0.0205, 0.0087, 0.0249, 0.0013, 0.0052, 0.0354, 0.0056, 0.0095, 0.0119,
         0.0941, 0.0085, 0.1065, 0.0183]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 7
images/14
(64, 64, 3)
tensor([[0.0181, 0.0046, 0.0137, 0.0286, 0.0081, 0.0136, 0.0234, 0.0564, 0.0171,
         0.0328, 0.2262, 0.0176, 0.0155, 0.0183, 0.0181, 0.0268, 0.0334, 0.0243,
         0.0228, 0.0251, 0.0049, 0.0078, 0.0135, 0.0036, 0.0114, 0.0259, 0.0053,
         0.0156, 0.0065, 0.0222, 0.0085, 0.0428, 0.0359, 0.0130, 0.0226, 0.0114,
         0.0404, 0.0192, 0.0174, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/34
(64, 64, 3)
2018-10-10 02:27:01.597 Python[86771:15147747] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 224, in <module>
    main()
  File "Torch_reinforce01.py", line 191, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 152, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/381
(64, 64, 3)
2018-10-10 23:07:14.527 Python[93450:15331464] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 224, in <module>
    main()
  File "Torch_reinforce01.py", line 191, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 152, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/481
(64, 64, 3)
2018-10-10 23:07:28.017 Python[93489:15331707] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0079, 0.0108, 0.0133, 0.0183, 0.0340, 0.0175, 0.0045, 0.0156, 0.0139,
         0.0294, 0.0523, 0.0097, 0.0069, 0.0144, 0.0164, 0.0432, 0.0047, 0.0175,
         0.0286, 0.0201, 0.0083, 0.0198, 0.0309, 0.0095, 0.0117, 0.0263, 0.0042,
         0.0134, 0.0117, 0.0104, 0.0045, 0.0208, 0.1655, 0.0179, 0.0151, 0.0114,
         0.1139, 0.0468, 0.0244, 0.0549]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 1
images/340
(64, 64, 3)
tensor([[0.0230, 0.0256, 0.0221, 0.0219, 0.0205, 0.0230, 0.0437, 0.0287, 0.0289,
         0.0239, 0.0317, 0.0245, 0.0260, 0.0255, 0.0224, 0.0261, 0.0213, 0.0278,
         0.0332, 0.0238, 0.0264, 0.0196, 0.0236, 0.0166, 0.0235, 0.0264, 0.0139,
         0.0213, 0.0230, 0.0236, 0.0210, 0.0228, 0.0324, 0.0271, 0.0241, 0.0239,
         0.0308, 0.0238, 0.0308, 0.0218]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/419
(64, 64, 3)
tensor([[0.0093, 0.0207, 0.0194, 0.0065, 0.0103, 0.0128, 0.0947, 0.0086, 0.0532,
         0.0095, 0.0685, 0.0197, 0.0220, 0.0172, 0.0030, 0.0084, 0.0093, 0.0058,
         0.0063, 0.0023, 0.0095, 0.0101, 0.0168, 0.0054, 0.0067, 0.0418, 0.0043,
         0.0112, 0.0032, 0.0458, 0.0074, 0.0124, 0.0840, 0.0337, 0.0417, 0.0061,
         0.0191, 0.0049, 0.1907, 0.0376]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 3
images/516
(64, 64, 3)
tensor([[0.0208, 0.0104, 0.0238, 0.0359, 0.0228, 0.0107, 0.0396, 0.0177, 0.0536,
         0.0248, 0.0440, 0.0224, 0.0412, 0.0351, 0.0046, 0.0028, 0.0093, 0.0123,
         0.0219, 0.0212, 0.0110, 0.0177, 0.0041, 0.0103, 0.0109, 0.0129, 0.0040,
         0.0045, 0.0089, 0.0444, 0.0027, 0.0194, 0.0458, 0.0194, 0.0346, 0.0490,
         0.1660, 0.0104, 0.0293, 0.0198]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 4
images/88
(64, 64, 3)
tensor([[0.0296, 0.0249, 0.0210, 0.0366, 0.0173, 0.0280, 0.0252, 0.0132, 0.0108,
         0.0054, 0.0286, 0.0247, 0.0354, 0.0402, 0.0107, 0.0190, 0.0189, 0.0153,
         0.0102, 0.0121, 0.0122, 0.0570, 0.0304, 0.0342, 0.0142, 0.0194, 0.0109,
         0.0236, 0.0239, 0.0262, 0.0061, 0.0219, 0.0278, 0.0139, 0.0739, 0.0085,
         0.0568, 0.0235, 0.0738, 0.0150]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 5
images/241
(64, 64, 3)
tensor([[0.0214, 0.0253, 0.0243, 0.0193, 0.0245, 0.0297, 0.0268, 0.0230, 0.0192,
         0.0173, 0.0367, 0.0226, 0.0300, 0.0178, 0.0232, 0.0273, 0.0203, 0.0262,
         0.0281, 0.0271, 0.0230, 0.0269, 0.0208, 0.0272, 0.0258, 0.0288, 0.0180,
         0.0204, 0.0190, 0.0360, 0.0189, 0.0240, 0.0298, 0.0224, 0.0289, 0.0265,
         0.0319, 0.0246, 0.0337, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 0
Session Number: 6
images/340
(64, 64, 3)
tensor([[0.0189, 0.0267, 0.0261, 0.0203, 0.0352, 0.0307, 0.0290, 0.0225, 0.0193,
         0.0282, 0.0336, 0.0279, 0.0225, 0.0249, 0.0209, 0.0225, 0.0211, 0.0249,
         0.0278, 0.0257, 0.0192, 0.0233, 0.0233, 0.0284, 0.0193, 0.0291, 0.0189,
         0.0266, 0.0222, 0.0259, 0.0185, 0.0222, 0.0296, 0.0226, 0.0258, 0.0220,
         0.0350, 0.0192, 0.0357, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 7
images/145
(64, 64, 3)
tensor([[0.0150, 0.0079, 0.0084, 0.0163, 0.0296, 0.0183, 0.0301, 0.0827, 0.0221,
         0.0238, 0.0679, 0.0195, 0.0237, 0.0191, 0.0217, 0.0123, 0.0208, 0.0197,
         0.0283, 0.0111, 0.0147, 0.0106, 0.0148, 0.0166, 0.0098, 0.0458, 0.0072,
         0.0195, 0.0073, 0.0565, 0.0049, 0.0289, 0.0330, 0.0149, 0.0087, 0.0269,
         0.0438, 0.0501, 0.0559, 0.0319]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 8
images/350
(64, 64, 3)
tensor([[0.0274, 0.0247, 0.0267, 0.0222, 0.0263, 0.0284, 0.0215, 0.0274, 0.0187,
         0.0238, 0.0257, 0.0286, 0.0239, 0.0236, 0.0244, 0.0280, 0.0192, 0.0231,
         0.0327, 0.0280, 0.0207, 0.0271, 0.0215, 0.0227, 0.0205, 0.0286, 0.0169,
         0.0319, 0.0230, 0.0268, 0.0217, 0.0211, 0.0277, 0.0223, 0.0281, 0.0207,
         0.0276, 0.0233, 0.0369, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 9
images/320
(64, 64, 3)
tensor([[0.0285, 0.0244, 0.0253, 0.0256, 0.0310, 0.0205, 0.0319, 0.0294, 0.0204,
         0.0183, 0.0220, 0.0386, 0.0305, 0.0235, 0.0216, 0.0217, 0.0193, 0.0285,
         0.0301, 0.0165, 0.0297, 0.0250, 0.0245, 0.0248, 0.0207, 0.0267, 0.0236,
         0.0218, 0.0197, 0.0300, 0.0187, 0.0344, 0.0276, 0.0133, 0.0188, 0.0234,
         0.0263, 0.0193, 0.0292, 0.0346]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 10
images/555
(64, 64, 3)
tensor([[0.0104, 0.0295, 0.0040, 0.0059, 0.0293, 0.0138, 0.0668, 0.0208, 0.0364,
         0.0593, 0.0430, 0.0204, 0.0646, 0.0227, 0.0217, 0.0279, 0.0117, 0.0065,
         0.0130, 0.0044, 0.0386, 0.0187, 0.0360, 0.0046, 0.0144, 0.0196, 0.0018,
         0.0250, 0.0102, 0.0617, 0.0023, 0.0207, 0.0699, 0.0089, 0.0095, 0.0270,
         0.0218, 0.0230, 0.0682, 0.0059]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 11
images/582
(64, 64, 3)
tensor([[0.0440, 0.0143, 0.0102, 0.0216, 0.0592, 0.0267, 0.0337, 0.0201, 0.0029,
         0.0072, 0.0568, 0.0474, 0.0089, 0.0408, 0.0190, 0.0146, 0.0047, 0.0082,
         0.0663, 0.0250, 0.0043, 0.0421, 0.0021, 0.0109, 0.0085, 0.0259, 0.0015,
         0.0277, 0.0096, 0.0354, 0.0035, 0.0303, 0.0501, 0.0188, 0.0114, 0.0244,
         0.0371, 0.0177, 0.0841, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 12
images/303
(64, 64, 3)
tensor([[0.0245, 0.0290, 0.0214, 0.0227, 0.0337, 0.0200, 0.0334, 0.0238, 0.0208,
         0.0272, 0.0387, 0.0312, 0.0228, 0.0235, 0.0175, 0.0243, 0.0207, 0.0248,
         0.0232, 0.0302, 0.0232, 0.0281, 0.0221, 0.0196, 0.0276, 0.0279, 0.0209,
         0.0235, 0.0255, 0.0214, 0.0182, 0.0197, 0.0323, 0.0279, 0.0158, 0.0280,
         0.0289, 0.0230, 0.0321, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 13
images/364
(64, 64, 3)
tensor([[0.0214, 0.0266, 0.0193, 0.0275, 0.0216, 0.0324, 0.0232, 0.0233, 0.0200,
         0.0300, 0.0322, 0.0314, 0.0261, 0.0238, 0.0194, 0.0214, 0.0184, 0.0213,
         0.0258, 0.0297, 0.0223, 0.0225, 0.0247, 0.0265, 0.0238, 0.0257, 0.0117,
         0.0219, 0.0203, 0.0190, 0.0180, 0.0225, 0.0406, 0.0236, 0.0354, 0.0271,
         0.0313, 0.0227, 0.0389, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 14
images/539
(64, 64, 3)
tensor([[0.0025, 0.0237, 0.0019, 0.0155, 0.0188, 0.0168, 0.0084, 0.0408, 0.0254,
         0.0049, 0.1307, 0.0807, 0.0145, 0.0128, 0.0084, 0.0205, 0.0024, 0.0069,
         0.0427, 0.0186, 0.0039, 0.0095, 0.0236, 0.0128, 0.0058, 0.0402, 0.0058,
         0.0038, 0.0065, 0.0151, 0.0071, 0.0078, 0.0285, 0.0110, 0.0168, 0.0065,
         0.0876, 0.0070, 0.1735, 0.0304]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 15
images/213
(64, 64, 3)
tensor([[0.0299, 0.0321, 0.0261, 0.0195, 0.0228, 0.0270, 0.0253, 0.0184, 0.0225,
         0.0217, 0.0418, 0.0232, 0.0236, 0.0250, 0.0281, 0.0406, 0.0208, 0.0184,
         0.0240, 0.0203, 0.0180, 0.0248, 0.0260, 0.0221, 0.0216, 0.0218, 0.0162,
         0.0257, 0.0302, 0.0178, 0.0151, 0.0249, 0.0376, 0.0202, 0.0245, 0.0156,
         0.0337, 0.0322, 0.0311, 0.0300]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 16
images/223
(64, 64, 3)
tensor([[0.0262, 0.0254, 0.0262, 0.0222, 0.0234, 0.0239, 0.0275, 0.0198, 0.0231,
         0.0206, 0.0286, 0.0303, 0.0272, 0.0257, 0.0220, 0.0196, 0.0253, 0.0268,
         0.0232, 0.0328, 0.0241, 0.0259, 0.0213, 0.0241, 0.0221, 0.0260, 0.0227,
         0.0276, 0.0229, 0.0239, 0.0228, 0.0205, 0.0360, 0.0272, 0.0231, 0.0209,
         0.0310, 0.0227, 0.0284, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 17
images/63
(64, 64, 3)
tensor([[0.0160, 0.0204, 0.0068, 0.0108, 0.0152, 0.0249, 0.0233, 0.0190, 0.0333,
         0.0042, 0.0716, 0.0584, 0.0442, 0.0220, 0.0106, 0.0608, 0.0141, 0.0102,
         0.0288, 0.0091, 0.0100, 0.0055, 0.0122, 0.0270, 0.0164, 0.0871, 0.0068,
         0.0056, 0.0124, 0.0080, 0.0117, 0.0078, 0.0790, 0.0271, 0.0115, 0.0219,
         0.0523, 0.0161, 0.0616, 0.0159]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 18
images/589
(64, 64, 3)
tensor([[0.0256, 0.0207, 0.0246, 0.0361, 0.0070, 0.1008, 0.0206, 0.1018, 0.0065,
         0.0029, 0.0165, 0.0282, 0.0144, 0.0307, 0.0108, 0.0031, 0.0130, 0.0096,
         0.0679, 0.0127, 0.0049, 0.0076, 0.0034, 0.0237, 0.0061, 0.0330, 0.0005,
         0.0080, 0.0025, 0.0106, 0.0030, 0.0172, 0.0674, 0.0206, 0.0083, 0.0024,
         0.1525, 0.0017, 0.0130, 0.0597]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 19
images/151
(64, 64, 3)
tensor([[0.0081, 0.0353, 0.0287, 0.0191, 0.0344, 0.0248, 0.0136, 0.0361, 0.0175,
         0.0282, 0.0948, 0.0267, 0.0323, 0.0155, 0.0109, 0.0154, 0.0126, 0.0180,
         0.0471, 0.0443, 0.0105, 0.0165, 0.0202, 0.0124, 0.0116, 0.0102, 0.0042,
         0.0231, 0.0287, 0.0099, 0.0085, 0.0175, 0.0437, 0.0195, 0.0165, 0.0129,
         0.0727, 0.0107, 0.0520, 0.0352]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 20
images/254
(64, 64, 3)
tensor([[0.0243, 0.0240, 0.0179, 0.0255, 0.0246, 0.0349, 0.0215, 0.0258, 0.0221,
         0.0241, 0.0306, 0.0278, 0.0313, 0.0198, 0.0230, 0.0245, 0.0232, 0.0236,
         0.0257, 0.0219, 0.0193, 0.0184, 0.0274, 0.0256, 0.0213, 0.0385, 0.0289,
         0.0258, 0.0200, 0.0255, 0.0215, 0.0267, 0.0275, 0.0198, 0.0230, 0.0222,
         0.0320, 0.0224, 0.0278, 0.0301]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 21
images/578
(64, 64, 3)
tensor([[0.0040, 0.0291, 0.0051, 0.0093, 0.0144, 0.0131, 0.2876, 0.0083, 0.0010,
         0.0011, 0.1486, 0.0057, 0.0031, 0.0041, 0.0242, 0.0080, 0.0024, 0.0027,
         0.1560, 0.0034, 0.0093, 0.0026, 0.0047, 0.0168, 0.0146, 0.0069, 0.0055,
         0.0044, 0.0044, 0.0396, 0.0024, 0.0230, 0.0289, 0.0057, 0.0059, 0.0029,
         0.0201, 0.0031, 0.0600, 0.0080]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 22
images/387
(64, 64, 3)
tensor([[0.0161, 0.0275, 0.0242, 0.0238, 0.0239, 0.0301, 0.0306, 0.0253, 0.0263,
         0.0240, 0.0375, 0.0241, 0.0275, 0.0186, 0.0206, 0.0205, 0.0250, 0.0276,
         0.0246, 0.0235, 0.0232, 0.0274, 0.0241, 0.0221, 0.0238, 0.0223, 0.0197,
         0.0279, 0.0207, 0.0256, 0.0183, 0.0284, 0.0278, 0.0212, 0.0275, 0.0228,
         0.0303, 0.0278, 0.0303, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 23
images/153
(64, 64, 3)
tensor([[0.0218, 0.0272, 0.0140, 0.0112, 0.0294, 0.0223, 0.0328, 0.0375, 0.0141,
         0.0127, 0.0319, 0.0069, 0.0098, 0.0283, 0.0225, 0.0134, 0.0259, 0.0121,
         0.0175, 0.0089, 0.0123, 0.0124, 0.0332, 0.0156, 0.0154, 0.0462, 0.0122,
         0.0124, 0.0053, 0.0325, 0.0045, 0.0349, 0.0564, 0.0592, 0.0273, 0.0207,
         0.0845, 0.0054, 0.0684, 0.0410]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 24
images/5
(64, 64, 3)
tensor([[0.0103, 0.0200, 0.0046, 0.0061, 0.0173, 0.0375, 0.0296, 0.0146, 0.0229,
         0.0114, 0.0796, 0.0362, 0.0430, 0.0180, 0.0070, 0.0178, 0.0137, 0.0883,
         0.0459, 0.0093, 0.0087, 0.0129, 0.0184, 0.0198, 0.0106, 0.0387, 0.0188,
         0.0264, 0.0098, 0.0174, 0.0153, 0.0110, 0.0887, 0.0183, 0.0196, 0.0084,
         0.0338, 0.0085, 0.0624, 0.0194]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 25
images/488
(64, 64, 3)
tensor([[0.0045, 0.0271, 0.0086, 0.0218, 0.0396, 0.0253, 0.0168, 0.0405, 0.0093,
         0.0079, 0.0591, 0.0261, 0.0063, 0.0091, 0.0093, 0.0188, 0.0092, 0.0587,
         0.0311, 0.0310, 0.0153, 0.0189, 0.0051, 0.0123, 0.0116, 0.0704, 0.0083,
         0.0160, 0.0066, 0.0286, 0.0043, 0.0100, 0.0650, 0.0133, 0.0060, 0.0218,
         0.0133, 0.0052, 0.0746, 0.1335]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 26
images/258
(64, 64, 3)
tensor([[0.0276, 0.0287, 0.0215, 0.0272, 0.0262, 0.0271, 0.0250, 0.0231, 0.0227,
         0.0248, 0.0288, 0.0274, 0.0260, 0.0262, 0.0233, 0.0284, 0.0238, 0.0238,
         0.0217, 0.0223, 0.0244, 0.0222, 0.0242, 0.0259, 0.0236, 0.0276, 0.0249,
         0.0263, 0.0234, 0.0266, 0.0244, 0.0230, 0.0262, 0.0274, 0.0242, 0.0237,
         0.0230, 0.0239, 0.0256, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 27
images/376
(64, 64, 3)
tensor([[0.0290, 0.0312, 0.0247, 0.0165, 0.0260, 0.0258, 0.0294, 0.0248, 0.0226,
         0.0210, 0.0361, 0.0225, 0.0251, 0.0270, 0.0258, 0.0209, 0.0218, 0.0252,
         0.0297, 0.0230, 0.0245, 0.0300, 0.0234, 0.0264, 0.0264, 0.0317, 0.0182,
         0.0242, 0.0231, 0.0233, 0.0236, 0.0242, 0.0294, 0.0213, 0.0208, 0.0266,
         0.0231, 0.0248, 0.0256, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 28
images/24
(64, 64, 3)
tensor([[0.0152, 0.0180, 0.0239, 0.0053, 0.0140, 0.0122, 0.0270, 0.0153, 0.0228,
         0.0242, 0.0611, 0.1080, 0.0244, 0.0126, 0.0182, 0.0226, 0.0159, 0.0166,
         0.0315, 0.0207, 0.0215, 0.0116, 0.0194, 0.0677, 0.0128, 0.0413, 0.0084,
         0.0200, 0.0127, 0.0395, 0.0087, 0.0201, 0.0246, 0.0257, 0.0149, 0.0178,
         0.0547, 0.0206, 0.0305, 0.0181]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 29
images/366
(64, 64, 3)
tensor([[0.0229, 0.0238, 0.0170, 0.0230, 0.0243, 0.0274, 0.0241, 0.0228, 0.0247,
         0.0235, 0.0364, 0.0342, 0.0271, 0.0210, 0.0199, 0.0364, 0.0249, 0.0239,
         0.0272, 0.0192, 0.0231, 0.0252, 0.0284, 0.0195, 0.0243, 0.0247, 0.0211,
         0.0259, 0.0321, 0.0207, 0.0172, 0.0245, 0.0295, 0.0222, 0.0239, 0.0246,
         0.0287, 0.0222, 0.0252, 0.0334]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 30
images/397
(64, 64, 3)
tensor([[0.0199, 0.0189, 0.0261, 0.0326, 0.0255, 0.0228, 0.0325, 0.0190, 0.0243,
         0.0273, 0.0303, 0.0258, 0.0366, 0.0218, 0.0196, 0.0213, 0.0215, 0.0208,
         0.0281, 0.0250, 0.0263, 0.0321, 0.0232, 0.0213, 0.0215, 0.0243, 0.0222,
         0.0323, 0.0183, 0.0275, 0.0170, 0.0330, 0.0292, 0.0221, 0.0234, 0.0177,
         0.0311, 0.0245, 0.0261, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 31
images/219
(64, 64, 3)
tensor([[0.0218, 0.0239, 0.0209, 0.0227, 0.0244, 0.0199, 0.0246, 0.0213, 0.0206,
         0.0250, 0.0344, 0.0265, 0.0262, 0.0228, 0.0234, 0.0311, 0.0238, 0.0262,
         0.0258, 0.0271, 0.0219, 0.0296, 0.0249, 0.0263, 0.0194, 0.0293, 0.0198,
         0.0180, 0.0240, 0.0285, 0.0194, 0.0331, 0.0263, 0.0293, 0.0238, 0.0223,
         0.0286, 0.0249, 0.0329, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 32
images/228
(64, 64, 3)
tensor([[0.0278, 0.0269, 0.0271, 0.0230, 0.0224, 0.0295, 0.0228, 0.0204, 0.0233,
         0.0288, 0.0305, 0.0242, 0.0272, 0.0257, 0.0194, 0.0207, 0.0263, 0.0255,
         0.0300, 0.0240, 0.0194, 0.0286, 0.0272, 0.0267, 0.0211, 0.0303, 0.0181,
         0.0296, 0.0201, 0.0253, 0.0241, 0.0230, 0.0305, 0.0268, 0.0227, 0.0179,
         0.0267, 0.0247, 0.0213, 0.0303]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 33
images/54
(64, 64, 3)
tensor([[0.0179, 0.0262, 0.0195, 0.0097, 0.0642, 0.0602, 0.0526, 0.0242, 0.0256,
         0.0099, 0.0431, 0.0466, 0.0195, 0.0177, 0.0150, 0.0179, 0.0236, 0.0075,
         0.0730, 0.0059, 0.0069, 0.0063, 0.0163, 0.0159, 0.0173, 0.0288, 0.0104,
         0.0065, 0.0113, 0.0153, 0.0055, 0.0084, 0.0390, 0.0122, 0.0173, 0.0076,
         0.0245, 0.0182, 0.0439, 0.1087]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Session Number: 34
images/196
(64, 64, 3)
tensor([[0.0147, 0.0331, 0.0188, 0.0138, 0.0213, 0.0282, 0.0148, 0.0250, 0.0099,
         0.0291, 0.0286, 0.0334, 0.0927, 0.0166, 0.0140, 0.0157, 0.0280, 0.0168,
         0.0377, 0.0314, 0.0181, 0.0302, 0.0182, 0.0240, 0.0126, 0.0682, 0.0047,
         0.0214, 0.0165, 0.0129, 0.0092, 0.0171, 0.0351, 0.0243, 0.0203, 0.0127,
         0.0376, 0.0066, 0.0565, 0.0303]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 35
images/442
(64, 64, 3)
tensor([[0.0103, 0.0114, 0.0110, 0.0122, 0.0241, 0.0173, 0.0439, 0.0754, 0.0073,
         0.0046, 0.1214, 0.0544, 0.0123, 0.0483, 0.0089, 0.0454, 0.0079, 0.0117,
         0.0182, 0.0237, 0.0091, 0.0057, 0.0368, 0.0144, 0.0051, 0.0152, 0.0023,
         0.0064, 0.0100, 0.0440, 0.0050, 0.0132, 0.0377, 0.0096, 0.0290, 0.0512,
         0.0431, 0.0129, 0.0307, 0.0491]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 36
images/501
(64, 64, 3)
tensor([[0.0075, 0.0110, 0.0015, 0.0063, 0.0094, 0.0153, 0.0537, 0.0134, 0.0720,
         0.0090, 0.0796, 0.0131, 0.0091, 0.0143, 0.0035, 0.0091, 0.0084, 0.0095,
         0.0498, 0.0199, 0.0102, 0.0173, 0.0092, 0.0103, 0.0113, 0.0270, 0.0004,
         0.0077, 0.0074, 0.0136, 0.0036, 0.0294, 0.0848, 0.0032, 0.0712, 0.0057,
         0.1352, 0.0076, 0.1155, 0.0141]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 37
images/357
(64, 64, 3)
tensor([[0.0236, 0.0260, 0.0270, 0.0239, 0.0239, 0.0214, 0.0258, 0.0294, 0.0256,
         0.0252, 0.0251, 0.0268, 0.0260, 0.0236, 0.0250, 0.0231, 0.0228, 0.0257,
         0.0244, 0.0215, 0.0209, 0.0238, 0.0304, 0.0194, 0.0225, 0.0273, 0.0204,
         0.0252, 0.0251, 0.0274, 0.0213, 0.0276, 0.0277, 0.0289, 0.0264, 0.0240,
         0.0292, 0.0280, 0.0249, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 38
images/272
(64, 64, 3)
tensor([[0.0211, 0.0278, 0.0232, 0.0272, 0.0274, 0.0263, 0.0251, 0.0254, 0.0242,
         0.0247, 0.0296, 0.0272, 0.0256, 0.0263, 0.0232, 0.0255, 0.0248, 0.0217,
         0.0232, 0.0274, 0.0225, 0.0238, 0.0253, 0.0236, 0.0224, 0.0325, 0.0210,
         0.0243, 0.0210, 0.0243, 0.0221, 0.0224, 0.0265, 0.0231, 0.0202, 0.0224,
         0.0298, 0.0296, 0.0295, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 39
images/338
(64, 64, 3)
tensor([[0.0267, 0.0268, 0.0253, 0.0273, 0.0250, 0.0262, 0.0244, 0.0282, 0.0234,
         0.0210, 0.0289, 0.0315, 0.0239, 0.0262, 0.0233, 0.0222, 0.0218, 0.0235,
         0.0271, 0.0217, 0.0261, 0.0238, 0.0275, 0.0229, 0.0245, 0.0286, 0.0204,
         0.0257, 0.0232, 0.0251, 0.0221, 0.0264, 0.0269, 0.0267, 0.0267, 0.0210,
         0.0217, 0.0263, 0.0263, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 40
images/300
(64, 64, 3)
tensor([[0.0226, 0.0239, 0.0231, 0.0229, 0.0279, 0.0275, 0.0217, 0.0239, 0.0204,
         0.0215, 0.0333, 0.0303, 0.0277, 0.0249, 0.0271, 0.0264, 0.0237, 0.0218,
         0.0224, 0.0285, 0.0216, 0.0250, 0.0222, 0.0265, 0.0243, 0.0256, 0.0225,
         0.0275, 0.0255, 0.0222, 0.0209, 0.0219, 0.0243, 0.0278, 0.0263, 0.0263,
         0.0264, 0.0240, 0.0339, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 41
images/416
(64, 64, 3)
tensor([[0.0043, 0.0400, 0.0092, 0.0082, 0.0458, 0.0083, 0.0085, 0.0134, 0.0136,
         0.0257, 0.1044, 0.0345, 0.0160, 0.0268, 0.0114, 0.0155, 0.0126, 0.0059,
         0.0223, 0.0108, 0.0577, 0.0122, 0.0080, 0.0115, 0.0116, 0.0126, 0.0009,
         0.0236, 0.0085, 0.0503, 0.0062, 0.0662, 0.0916, 0.0019, 0.0348, 0.0068,
         0.0414, 0.0222, 0.0628, 0.0320]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 42
images/447
(64, 64, 3)
tensor([[0.0075, 0.0138, 0.0132, 0.0210, 0.0144, 0.1392, 0.0503, 0.0072, 0.0063,
         0.0071, 0.0619, 0.0294, 0.0222, 0.0053, 0.0263, 0.0279, 0.0050, 0.0053,
         0.0352, 0.0102, 0.0285, 0.0097, 0.0132, 0.0058, 0.0112, 0.0159, 0.0099,
         0.0051, 0.0202, 0.0108, 0.0032, 0.0344, 0.0430, 0.0069, 0.0096, 0.0131,
         0.0478, 0.1079, 0.0819, 0.0127]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/478
(64, 64, 3)
tensor([[0.0181, 0.0038, 0.0147, 0.0335, 0.0332, 0.0206, 0.0157, 0.0072, 0.0103,
         0.0089, 0.0781, 0.0794, 0.0127, 0.0108, 0.0066, 0.0109, 0.0126, 0.0244,
         0.0600, 0.0298, 0.0206, 0.0042, 0.0051, 0.0227, 0.0070, 0.0296, 0.0118,
         0.0048, 0.0045, 0.0244, 0.0043, 0.0394, 0.0667, 0.0294, 0.0114, 0.0225,
         0.1400, 0.0129, 0.0239, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 44
images/126
(64, 64, 3)
tensor([[0.0171, 0.0107, 0.0057, 0.0035, 0.0062, 0.0219, 0.0067, 0.0055, 0.0231,
         0.0023, 0.4172, 0.0189, 0.0063, 0.0024, 0.0052, 0.0174, 0.0015, 0.0031,
         0.0091, 0.0239, 0.0065, 0.0026, 0.0126, 0.0120, 0.0028, 0.0180, 0.0017,
         0.0103, 0.0649, 0.0038, 0.0074, 0.0054, 0.0062, 0.0059, 0.0047, 0.0061,
         0.1347, 0.0115, 0.0383, 0.0372]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 45
images/80
(64, 64, 3)
tensor([[0.0094, 0.0167, 0.0098, 0.0108, 0.0172, 0.0361, 0.0110, 0.0252, 0.0196,
         0.0035, 0.2046, 0.0102, 0.0256, 0.0101, 0.0287, 0.0184, 0.0026, 0.0182,
         0.0073, 0.0193, 0.0058, 0.0052, 0.0076, 0.0154, 0.0075, 0.0678, 0.0012,
         0.0118, 0.0073, 0.0849, 0.0068, 0.0175, 0.0049, 0.0177, 0.0234, 0.0248,
         0.0184, 0.0075, 0.1317, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 46
images/413
(64, 64, 3)
tensor([[0.0106, 0.0221, 0.0091, 0.0063, 0.0398, 0.0401, 0.0403, 0.0047, 0.0221,
         0.0082, 0.1078, 0.0216, 0.0153, 0.0104, 0.0161, 0.0057, 0.0067, 0.0131,
         0.0236, 0.0114, 0.0062, 0.0177, 0.0120, 0.0116, 0.0047, 0.0237, 0.0036,
         0.0087, 0.0311, 0.0262, 0.0059, 0.0064, 0.1533, 0.0190, 0.0451, 0.0246,
         0.0875, 0.0056, 0.0636, 0.0086]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 47
images/195
(64, 64, 3)
tensor([[0.0272, 0.0254, 0.0166, 0.0028, 0.0178, 0.0258, 0.0090, 0.0276, 0.0052,
         0.0093, 0.1032, 0.0495, 0.0204, 0.0136, 0.0097, 0.0213, 0.0477, 0.0275,
         0.0311, 0.0398, 0.0376, 0.0205, 0.0144, 0.0725, 0.0067, 0.0232, 0.0034,
         0.0119, 0.0194, 0.0234, 0.0052, 0.0120, 0.0390, 0.0136, 0.0383, 0.0318,
         0.0083, 0.0136, 0.0449, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 48
images/226
(64, 64, 3)
tensor([[0.0250, 0.0270, 0.0221, 0.0234, 0.0285, 0.0256, 0.0277, 0.0225, 0.0236,
         0.0241, 0.0297, 0.0275, 0.0283, 0.0242, 0.0223, 0.0224, 0.0241, 0.0240,
         0.0230, 0.0245, 0.0258, 0.0218, 0.0294, 0.0243, 0.0243, 0.0246, 0.0221,
         0.0210, 0.0258, 0.0245, 0.0234, 0.0255, 0.0320, 0.0242, 0.0235, 0.0232,
         0.0297, 0.0241, 0.0251, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 49
images/215
(64, 64, 3)
tensor([[0.0207, 0.0283, 0.0241, 0.0193, 0.0278, 0.0248, 0.0233, 0.0275, 0.0231,
         0.0218, 0.0259, 0.0275, 0.0275, 0.0206, 0.0254, 0.0242, 0.0228, 0.0262,
         0.0290, 0.0236, 0.0231, 0.0279, 0.0253, 0.0241, 0.0235, 0.0334, 0.0198,
         0.0239, 0.0228, 0.0292, 0.0182, 0.0226, 0.0287, 0.0252, 0.0263, 0.0242,
         0.0272, 0.0280, 0.0259, 0.0271]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 50
images/323
(64, 64, 3)
tensor([[0.0232, 0.0247, 0.0244, 0.0249, 0.0263, 0.0264, 0.0261, 0.0224, 0.0226,
         0.0239, 0.0319, 0.0280, 0.0268, 0.0247, 0.0225, 0.0245, 0.0246, 0.0264,
         0.0243, 0.0232, 0.0216, 0.0240, 0.0251, 0.0255, 0.0247, 0.0267, 0.0223,
         0.0255, 0.0250, 0.0262, 0.0233, 0.0225, 0.0281, 0.0255, 0.0256, 0.0240,
         0.0273, 0.0246, 0.0248, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 51
images/324
(64, 64, 3)
tensor([[0.0224, 0.0226, 0.0289, 0.0276, 0.0302, 0.0249, 0.0247, 0.0252, 0.0237,
         0.0221, 0.0281, 0.0291, 0.0220, 0.0234, 0.0249, 0.0233, 0.0220, 0.0264,
         0.0224, 0.0210, 0.0209, 0.0224, 0.0255, 0.0249, 0.0225, 0.0311, 0.0215,
         0.0254, 0.0265, 0.0236, 0.0215, 0.0247, 0.0266, 0.0268, 0.0242, 0.0243,
         0.0304, 0.0234, 0.0302, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 52
images/454
(64, 64, 3)
tensor([[0.0080, 0.0083, 0.0152, 0.0082, 0.0071, 0.0193, 0.0304, 0.0066, 0.0127,
         0.0700, 0.0691, 0.0348, 0.0172, 0.0481, 0.0083, 0.0252, 0.0135, 0.0262,
         0.0373, 0.0131, 0.0043, 0.0230, 0.0375, 0.0056, 0.0070, 0.0359, 0.0061,
         0.0139, 0.0268, 0.0225, 0.0024, 0.0318, 0.0865, 0.0066, 0.0451, 0.0148,
         0.0641, 0.0109, 0.0524, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 53
images/65
(64, 64, 3)
tensor([[0.0281, 0.0320, 0.0203, 0.0181, 0.0167, 0.0139, 0.0203, 0.0182, 0.0383,
         0.0081, 0.0830, 0.0347, 0.0220, 0.0186, 0.0084, 0.0250, 0.0134, 0.0130,
         0.0221, 0.0101, 0.0052, 0.0105, 0.0124, 0.0712, 0.0042, 0.0354, 0.0142,
         0.0240, 0.0129, 0.0378, 0.0398, 0.0195, 0.0360, 0.0251, 0.0146, 0.0109,
         0.0801, 0.0068, 0.0364, 0.0386]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/349
(64, 64, 3)
2018-10-10 23:13:26.445 Python[93655:15334866] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 224, in <module>
    main()
  File "Torch_reinforce01.py", line 191, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 152, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images_for_training/236
(64, 64, 3)
2018-10-10 23:14:08.829 Python[93702:15335372] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 224, in <module>
    main()
  File "Torch_reinforce01.py", line 191, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 152, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/336
(64, 64, 3)
2018-10-10 23:18:18.297 Python[93822:15338022] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[36., 36., 34.,  ..., 40., 39., 42.],
          [40., 40., 42.,  ..., 37., 39., 38.],
          [37., 39., 38.,  ..., 35., 35., 33.],
          ...,
          [43., 38., 44.,  ..., 38., 44., 42.],
          [38., 44., 42.,  ..., 46., 42., 41.],
          [42., 40., 38.,  ..., 42., 38., 43.]],

         [[42., 38., 43.,  ..., 38., 45., 43.],
          [38., 44., 43.,  ..., 46., 43., 42.],
          [42., 40., 38.,  ..., 42., 37., 43.],
          ...,
          [29., 43., 39.,  ..., 48., 42., 39.],
          [46., 41., 40.,  ...,  8.,  9.,  6.],
          [ 7.,  9.,  6.,  ..., 13., 30., 27.]],

         [[26., 41., 37.,  ..., 47., 41., 38.],
          [45., 41., 39.,  ...,  9., 11.,  7.],
          [ 8., 10.,  7.,  ..., 12., 28., 25.],
          ...,
          [41., 37., 36.,  ..., 41., 40., 41.],
          [39., 38., 38.,  ..., 40., 45., 39.],
          [37., 44., 38.,  ..., 43., 38., 37.]]]])



tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 227, in <module>
    main()
  File "Torch_reinforce01.py", line 194, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 155, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/402
(64, 64, 3)
2018-10-10 23:19:38.961 Python[93882:15338805] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[255., 255., 255.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 255., 255., 255.],
          ...,
          [255., 255., 255.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 255., 255., 255.]],

         [[255., 255., 255.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 253., 253., 253.],
          [255., 255., 255.,  ..., 255., 255., 255.],
          ...,
          [ 38.,  34.,  34.,  ..., 238., 238., 238.],
          [255., 255., 255.,  ...,   9.,   9.,  16.],
          [ 16.,  16.,  16.,  ...,  14.,  23.,  23.]],

         [[ 23.,  23.,  23.,  ..., 212., 212., 212.],
          [255., 255., 255.,  ...,  25.,  25.,  12.],
          [ 12.,  12.,  11.,  ...,   9.,  16.,  16.],
          ...,
          [255., 255., 255.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 207., 183., 183.],
          [183., 154., 154.,  ...,  66.,  66.,  66.]]]])



Traceback (most recent call last):
  File "Torch_reinforce01.py", line 228, in <module>
    main()
  File "Torch_reinforce01.py", line 195, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 153, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 83, in forward
    raise NotImplementedError
NotImplementedError
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/430
(64, 64, 3)
2018-10-10 23:20:29.409 Python[93931:15339385] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[  0.,   9.,   5.,  ..., 206., 241., 108.],
          [210., 243., 136.,  ..., 255., 140., 255.],
          [255., 127., 255.,  ...,  97., 197., 255.],
          ...,
          [243., 234., 239.,  ..., 255., 255., 255.],
          [255., 210., 239.,  ..., 149., 210., 175.],
          [ 57., 121., 125.,  ..., 171., 167., 191.]],

         [[206., 199., 217.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 165., 226., 191.],
          [ 81., 167., 173.,  ..., 149., 147., 165.],
          ...,
          [210., 226., 226.,  ..., 210., 186., 160.],
          [ 86., 215., 239.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 206., 239., 237.]],

         [[197., 206., 206.,  ..., 212., 189., 164.],
          [ 88., 215., 241.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 189., 221., 221.],
          ...,
          [ 62., 191., 202.,  ..., 255., 255., 164.],
          [255., 255., 165.,  ..., 171.,  88., 189.],
          [177.,  90., 189.,  ...,  95., 191., 177.]]]])



Traceback (most recent call last):
  File "Torch_reinforce01.py", line 228, in <module>
    main()
  File "Torch_reinforce01.py", line 195, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 153, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 83, in forward
    raise NotImplementedError
NotImplementedError
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/280
(64, 64, 3)
2018-10-10 23:21:37.648 Python[93987:15340071] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[25., 23., 11.,  ..., 21., 11., 24.],
          [21., 11., 23.,  ...,  9., 22., 21.],
          [10., 23., 22.,  ..., 23., 22., 11.],
          ...,
          [35., 35., 38.,  ..., 13., 25., 22.],
          [12., 24., 22.,  ..., 23., 23., 10.],
          [26., 25., 13.,  ..., 28., 28., 36.]],

         [[29., 29., 37.,  ..., 18., 26., 25.],
          [16., 25., 24.,  ..., 23., 23., 10.],
          [27., 25., 13.,  ..., 20., 21., 36.],
          ...,
          [10., 20., 19.,  ..., 22., 21.,  8.],
          [26., 24., 11.,  ..., 38., 38., 37.],
          [37., 35., 34.,  ...,  9., 22., 21.]],

         [[ 9., 21., 21.,  ..., 21., 21.,  8.],
          [26., 24., 11.,  ..., 38., 38., 36.],
          [36., 34., 32.,  ...,  9., 22., 21.],
          ...,
          [25., 23., 11.,  ..., 23., 11., 25.],
          [23., 10., 24.,  ...,  8., 22., 21.],
          [ 9., 22., 21.,  ..., 20., 20.,  8.]]]])



Traceback (most recent call last):
  File "Torch_reinforce01.py", line 230, in <module>
    main()
  File "Torch_reinforce01.py", line 197, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 155, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 83, in forward
    raise NotImplementedError
NotImplementedError
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 125, in <module>
    policy = Policy()
TypeError: 'module' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/203
(64, 64, 3)
2018-10-10 23:22:20.577 Python[94075:15340723] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[35., 35., 35.,  ..., 35., 35., 35.],
          [35., 35., 35.,  ..., 35., 35., 35.],
          [35., 35., 35.,  ..., 35., 35., 35.],
          ...,
          [ 5.,  6.,  6.,  ...,  9.,  8., 13.],
          [ 9.,  8., 13.,  ..., 34., 34., 34.],
          [29., 29., 29.,  ...,  5.,  6.,  4.]],

         [[ 3.,  4.,  5.,  ..., 10.,  9., 13.],
          [10.,  8., 13.,  ..., 34., 34., 34.],
          [29., 28., 28.,  ...,  4.,  5.,  3.],
          ...,
          [ 0.,  0.,  0.,  ..., 32., 32., 31.],
          [35., 35., 35.,  ...,  3.,  2.,  2.],
          [ 2.,  1.,  3.,  ...,  0.,  0.,  0.]],

         [[ 0.,  0.,  0.,  ..., 35., 35., 34.],
          [35., 35., 35.,  ...,  3.,  3.,  3.],
          [ 2.,  2.,  3.,  ...,  1.,  1.,  0.],
          ...,
          [35., 35., 35.,  ..., 35., 35., 35.],
          [35., 35., 35.,  ..., 35., 35., 35.],
          [35., 35., 35.,  ..., 35., 35., 35.]]]])



Traceback (most recent call last):
  File "Torch_reinforce01.py", line 230, in <module>
    main()
  File "Torch_reinforce01.py", line 197, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 155, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 83, in forward
    raise NotImplementedError
NotImplementedError
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 7, in <module>
    from Policy import Policy,forward
ImportError: cannot import name 'forward'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/223
(64, 64, 3)
2018-10-10 23:23:37.634 Python[94175:15341820] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[13., 16., 26.,  ..., 17., 26., 11.],
          [17., 26., 11.,  ..., 24., 11., 16.],
          [24., 11., 16.,  ..., 10., 16., 24.],
          ...,
          [24., 26., 24.,  ..., 36., 34., 35.],
          [35., 33., 34.,  ..., 28., 29., 34.],
          [ 7., 13., 19.,  ..., 21., 23., 22.]],

         [[23., 24., 25.,  ..., 41., 41., 42.],
          [42., 41., 42.,  ..., 28., 29., 34.],
          [ 7., 12., 18.,  ..., 21., 21., 21.],
          ...,
          [42., 42., 42.,  ..., 28., 28., 30.],
          [ 3.,  6., 11.,  ..., 25., 22., 28.],
          [27., 24., 30.,  ..., 40., 41., 40.]],

         [[40., 42., 41.,  ..., 28., 28., 30.],
          [ 3.,  7., 11.,  ..., 22., 19., 25.],
          [24., 21., 27.,  ..., 37., 40., 38.],
          ...,
          [ 2.,  6.,  8.,  ...,  5.,  5.,  3.],
          [ 5.,  4.,  3.,  ..., 11., 11., 11.],
          [10., 11., 11.,  ...,  3.,  5.,  8.]]]])



Traceback (most recent call last):
  File "Torch_reinforce01.py", line 230, in <module>
    main()
  File "Torch_reinforce01.py", line 197, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 155, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 83, in forward
    raise NotImplementedError
NotImplementedError
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/42
(64, 64, 3)
2018-10-10 23:29:22.905 Python[94333:15345532] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[145., 125.,  83.,  ..., 169., 124., 200.],
          [172., 127., 206.,  ..., 166., 237., 214.],
          [169., 238., 215.,  ..., 225., 201., 160.],
          ...,
          [198., 161., 224.,  ..., 176., 238., 214.],
          [177., 238., 214.,  ..., 227., 202., 162.],
          [212., 180., 142.,  ..., 204., 168., 227.]],

         [[198., 161., 222.,  ..., 178., 238., 215.],
          [180., 238., 214.,  ..., 229., 204., 164.],
          [214., 185., 144.,  ..., 203., 165., 227.],
          ...,
          [169., 233., 207.,  ..., 217., 192., 154.],
          [231., 207., 170.,  ..., 198., 161., 225.],
          [197., 160., 225.,  ..., 170., 231., 204.]],

         [[165., 231., 203.,  ..., 221., 196., 158.],
          [237., 211., 177.,  ..., 200., 163., 227.],
          [199., 162., 227.,  ..., 172., 232., 205.],
          ...,
          [ 98.,  98.,  80.,  ..., 189., 155., 216.],
          [187., 151., 217.,  ..., 182., 241., 215.],
          [181., 241., 215.,  ..., 231., 206., 171.]]]])



tensor([[0.0180, 0.0164, 0.0181, 0.0139, 0.0324, 0.0318, 0.0042, 0.0158, 0.0178,
         0.0413, 0.0564, 0.0109, 0.0174, 0.0167, 0.0183, 0.0262, 0.0062, 0.0125,
         0.0129, 0.0170, 0.0198, 0.0201, 0.0269, 0.0182, 0.0090, 0.0230, 0.0031,
         0.0233, 0.0404, 0.0121, 0.0045, 0.0112, 0.1375, 0.0293, 0.0129, 0.0130,
         0.0948, 0.0383, 0.0233, 0.0354]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: ^C^CTraceback (most recent call last):
  File "Torch_reinforce01.py", line 230, in <module>
    main()
  File "Torch_reinforce01.py", line 206, in main
    reward = int(input("Enter Reward: "))
KeyboardInterrupt

 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/119
(64, 64, 3)
2018-10-10 23:29:37.647 Python[94380:15345800] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[183., 182., 222.,  ..., 235., 247., 250.],
          [247., 251., 245.,  ..., 203., 203., 191.],
          [192., 219., 211.,  ..., 245., 250., 252.],
          ...,
          [229., 243., 223.,  ..., 193., 174., 177.],
          [179., 187., 191.,  ..., 213., 222., 239.],
          [222., 217., 219.,  ..., 224., 232., 227.]],

         [[221., 230., 227.,  ..., 176., 171., 169.],
          [168., 186., 184.,  ..., 224., 229., 244.],
          [217., 206., 202.,  ..., 210., 210., 218.],
          ...,
          [128., 157., 143.,  ..., 124., 115., 125.],
          [161., 149., 118.,  ..., 145., 132., 169.],
          [145., 130., 149.,  ..., 115., 148., 128.]],

         [[130., 140., 126.,  ..., 127., 118., 126.],
          [166., 152., 117.,  ..., 136., 121., 166.],
          [136., 118., 151.,  ..., 110., 138., 118.],
          ...,
          [251., 251., 242.,  ..., 113.,  97., 144.],
          [130., 112., 177.,  ..., 234., 253., 252.],
          [234., 252., 251.,  ..., 250., 248., 220.]]]])



tensor([[0.0119, 0.0200, 0.0188, 0.0167, 0.0307, 0.0220, 0.0067, 0.0185, 0.0163,
         0.0236, 0.0648, 0.0129, 0.0098, 0.0173, 0.0165, 0.0383, 0.0074, 0.0159,
         0.0205, 0.0210, 0.0160, 0.0289, 0.0342, 0.0165, 0.0132, 0.0296, 0.0061,
         0.0126, 0.0152, 0.0123, 0.0079, 0.0167, 0.0911, 0.0222, 0.0106, 0.0123,
         0.0863, 0.0670, 0.0263, 0.0652]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 1
images/131
(64, 64, 3)
^C^CTraceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/matplotlib/backend_bases.py", line 1953, in motion_notify_event
    def motion_notify_event(self, x, y, guiEvent=None):
KeyboardInterrupt
States 


tensor([[[[130., 146., 120.,  ..., 126.,  68., 100.],
          [128.,  72., 106.,  ...,  98., 122., 130.],
          [ 93., 118., 126.,  ..., 118., 127.,  91.],
          ...,
          [143., 110., 126.,  ..., 102., 129., 139.],
          [ 98., 126., 137.,  ..., 150., 140., 114.],
          [108., 119.,  89.,  ..., 146., 118., 129.]],

         [[132.,  93., 121.,  ..., 104., 135., 140.],
          [103., 135., 141.,  ..., 151., 143., 115.],
          [112., 122.,  93.,  ..., 137., 105., 127.],
          ...,
          [101., 158., 130.,  ..., 159., 151., 123.],
          [139., 144., 102.,  ..., 161., 148., 175.],
          [163., 149., 168.,  ..., 103., 155., 130.]],

         [[ 98., 153., 127.,  ..., 157., 149., 119.],
          [139., 142., 102.,  ..., 152., 135., 172.],
          [160., 143., 172.,  ..., 103., 157., 133.],
          ...,
          [145., 143., 109.,  ..., 151., 122., 152.],
          [147., 118., 147.,  ..., 113., 148., 143.],
          [113., 145., 140.,  ..., 146., 142., 112.]]]])



tensor([[0.0131, 0.0236, 0.0217, 0.0151, 0.0144, 0.0198, 0.1087, 0.0288, 0.0211,
         0.0241, 0.0577, 0.0187, 0.0192, 0.0174, 0.0199, 0.0197, 0.0167, 0.0288,
         0.0452, 0.0141, 0.0335, 0.0083, 0.0189, 0.0093, 0.0228, 0.0286, 0.0039,
         0.0132, 0.0151, 0.0149, 0.0087, 0.0127, 0.0418, 0.0227, 0.0183, 0.0221,
         0.0613, 0.0197, 0.0634, 0.0131]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: ^C^CTraceback (most recent call last):
  File "Torch_reinforce01.py", line 230, in <module>
    main()
  File "Torch_reinforce01.py", line 206, in main
    reward = int(input("Enter Reward: "))
KeyboardInterrupt

                                                                                                                       
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       

 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
                                                                                                                       


 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/234
(64, 64, 3)
2018-10-10 23:36:41.631 Python[94854:15350344] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[13., 15., 15.,  ..., 16., 16., 14.],
          [16., 16., 14.,  ..., 16., 14., 15.],
          [16., 14., 15.,  ..., 13., 15., 15.],
          ...,
          [ 5.,  4.,  5.,  ...,  6.,  8.,  9.],
          [ 9.,  8., 10.,  ..., 10., 12., 11.],
          [ 2.,  3.,  1.,  ...,  4.,  3.,  3.]],

         [[ 4.,  3.,  3.,  ...,  3.,  5.,  7.],
          [ 6.,  5.,  7.,  ...,  9., 10., 10.],
          [ 2.,  3.,  1.,  ...,  4.,  3.,  3.],
          ...,
          [ 6.,  8.,  9.,  ..., 10., 10.,  9.],
          [11., 11.,  9.,  ...,  8.,  6.,  7.],
          [ 8.,  6.,  7.,  ...,  4.,  6.,  6.]],

         [[ 5.,  7.,  8.,  ...,  9., 10.,  8.],
          [12., 12., 10.,  ..., 10.,  8.,  9.],
          [10.,  8.,  9.,  ...,  5.,  7.,  7.],
          ...,
          [12., 12.,  8.,  ..., 13., 10., 12.],
          [13., 10., 12.,  ..., 10., 13., 13.],
          [10., 13., 13.,  ..., 10., 11.,  8.]]]])



tensor([[0.0248, 0.0266, 0.0253, 0.0243, 0.0261, 0.0255, 0.0232, 0.0231, 0.0239,
         0.0249, 0.0259, 0.0253, 0.0249, 0.0248, 0.0248, 0.0256, 0.0237, 0.0252,
         0.0236, 0.0269, 0.0232, 0.0249, 0.0271, 0.0247, 0.0246, 0.0252, 0.0232,
         0.0258, 0.0255, 0.0230, 0.0239, 0.0234, 0.0278, 0.0261, 0.0241, 0.0237,
         0.0280, 0.0265, 0.0245, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 1
images/418
(64, 64, 3)
States 


tensor([[[[ 30.,  69., 205.,  ...,  88., 220.,  28.],
          [ 88., 220.,  28.,  ..., 246.,  41., 105.],
          [245.,  43., 107.,  ...,  37., 103., 243.],
          ...,
          [186., 255., 101.,  ..., 255., 141., 224.],
          [255., 148., 229.,  ..., 148., 226., 255.],
          [ 86., 171., 255.,  ..., 192., 255., 113.]],

         [[197., 255., 111.,  ..., 255., 148., 228.],
          [255., 156., 233.,  ..., 152., 229., 255.],
          [ 92., 179., 255.,  ..., 199., 255., 122.],
          ...,
          [255., 255., 255.,  ..., 255., 255., 255.],
          [246., 255., 255.,  ..., 255., 255., 252.],
          [255., 255., 255.,  ..., 255., 255., 255.]],

         [[255., 255., 255.,  ..., 255., 255., 255.],
          [254., 255., 255.,  ..., 255., 255., 255.],
          [255., 255., 255.,  ..., 255., 255., 255.],
          ...,
          [214., 162., 139.,  ..., 255., 222., 255.],
          [250., 207., 255.,  ..., 239., 255., 255.],
          [229., 255., 255.,  ..., 255., 222., 171.]]]])



tensor([[0.0071, 0.0089, 0.0077, 0.0073, 0.0071, 0.0184, 0.3011, 0.0201, 0.0084,
         0.0236, 0.1002, 0.0070, 0.0162, 0.0079, 0.0088, 0.0221, 0.0036, 0.0122,
         0.0505, 0.0046, 0.0109, 0.0025, 0.0068, 0.0023, 0.0154, 0.0146, 0.0003,
         0.0031, 0.0099, 0.0085, 0.0014, 0.0121, 0.0418, 0.0123, 0.0189, 0.0104,
         0.0740, 0.0078, 0.0991, 0.0050]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 2
images/120
(64, 64, 3)
States 


tensor([[[[240., 240., 240.,  ..., 207., 208., 207.],
          [208., 210., 210.,  ..., 234., 236., 236.],
          [234., 236., 236.,  ..., 214., 215., 219.],
          ...,
          [121., 121.,  91.,  ..., 222., 226., 226.],
          [226., 234., 234.,  ..., 212., 212., 212.],
          [249., 249., 249.,  ..., 117., 115.,  84.]],

         [[ 95.,  94.,  56.,  ..., 191., 205., 206.],
          [205., 223., 223.,  ..., 228., 228., 228.],
          [251., 251., 251.,  ..., 124., 122.,  88.],
          ...,
          [ 42.,  36.,  38.,  ..., 182., 183., 187.],
          [255., 255., 255.,  ..., 129., 128., 148.],
          [152., 151., 173.,  ...,  41.,  49.,  51.]],

         [[ 49.,  47.,  48.,  ..., 180., 181., 186.],
          [251., 252., 253.,  ..., 128., 127., 139.],
          [143., 142., 168.,  ...,  54.,  60.,  62.],
          ...,
          [155., 158., 164.,  ..., 144., 153., 141.],
          [144., 153., 141.,  ..., 142., 129., 135.],
          [143., 129., 134.,  ..., 122., 125., 134.]]]])



tensor([[0.0112, 0.0211, 0.0282, 0.0079, 0.0085, 0.0208, 0.0901, 0.0072, 0.0476,
         0.0108, 0.0871, 0.0189, 0.0340, 0.0194, 0.0047, 0.0067, 0.0136, 0.0148,
         0.0093, 0.0052, 0.0196, 0.0098, 0.0109, 0.0069, 0.0074, 0.0491, 0.0090,
         0.0156, 0.0041, 0.0433, 0.0085, 0.0123, 0.0869, 0.0285, 0.0437, 0.0099,
         0.0201, 0.0054, 0.1065, 0.0352]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: ^C0
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 187, in <module>
    main()
  File "Torch_reinforce01.py", line 163, in main
    reward = int(input("Enter Reward: "))
KeyboardInterrupt
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Session Number: 0
images/215
(64, 64, 3)
2018-10-10 23:39:00.867 Python[94934:15351480] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
States 


tensor([[[[ 8.,  4., 29.,  ...,  4., 25.,  7.],
          [ 4., 25.,  8.,  ..., 27.,  9.,  4.],
          [27.,  9.,  4.,  ...,  8.,  4., 27.],
          ...,
          [35., 34., 33.,  ..., 34., 16., 24.],
          [32., 20., 25.,  ..., 27., 25., 25.],
          [30., 28., 38.,  ..., 27., 26., 28.]],

         [[27., 27., 24.,  ..., 33., 17., 26.],
          [32., 22., 28.,  ..., 25., 23., 22.],
          [29., 28., 37.,  ..., 18., 18., 16.],
          ...,
          [ 7., 15., 13.,  ..., 23., 22., 14.],
          [21., 22., 20.,  ...,  1.,  1.,  6.],
          [ 3.,  2., 11.,  ...,  8., 10.,  8.]],

         [[ 5.,  9.,  7.,  ..., 23., 23., 14.],
          [18., 19., 19.,  ...,  1.,  1.,  6.],
          [ 4.,  3., 12.,  ...,  6.,  7.,  5.],
          ...,
          [13.,  9., 28.,  ...,  5., 20., 10.],
          [ 6., 21., 12.,  ..., 28., 18., 13.],
          [28., 17., 13.,  ..., 17., 13., 28.]]]])



tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 166, in <module>
    main()
  File "Torch_reinforce01.py", line 133, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 94, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights 





Session Number: 0
images/291
(64, 64, 3)
2018-10-10 23:42:00.122 Python[95028:15353328] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 170, in <module>
    main()
  File "Torch_reinforce01.py", line 137, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 98, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights 


Traceback (most recent call last):
  File "Torch_reinforce01.py", line 81, in <module>
    for name, param in model.named_parameters():
NameError: name 'model' is not defined
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights 


layer1.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer2.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.1.bias tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
        -0.0233,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan])
layer3.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.weight tensor([[[[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         ...,

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]]],


        [[[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         ...,

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]]],


        [[[-0.0218,  0.0195, -0.0075, -0.0117,  0.0203],
          [ 0.0219,  0.0053,  0.0186, -0.0216, -0.0069],
          [-0.0158, -0.0012, -0.0047,  0.0016, -0.0094],
          [-0.0024, -0.0040,  0.0222, -0.0137, -0.0112],
          [-0.0128, -0.0030, -0.0024, -0.0030,  0.0035]],

         [[-0.0150,  0.0108, -0.0243,  0.0180, -0.0064],
          [-0.0157,  0.0037,  0.0017, -0.0247,  0.0034],
          [-0.0228,  0.0128, -0.0013,  0.0035, -0.0136],
          [ 0.0020, -0.0211,  0.0025,  0.0024, -0.0072],
          [ 0.0218,  0.0141, -0.0144, -0.0046, -0.0103]],

         [[ 0.0043, -0.0157, -0.0198, -0.0113,  0.0203],
          [ 0.0010, -0.0210, -0.0162, -0.0176, -0.0018],
          [-0.0055, -0.0031,  0.0079,  0.0065, -0.0210],
          [ 0.0157,  0.0042,  0.0114, -0.0075,  0.0196],
          [ 0.0017,  0.0189, -0.0152, -0.0249, -0.0166]],

         ...,

         [[-0.0151, -0.0072, -0.0088,  0.0236, -0.0201],
          [ 0.0086,  0.0086,  0.0062, -0.0146,  0.0074],
          [-0.0034,  0.0026,  0.0062, -0.0190,  0.0245],
          [-0.0124,  0.0092,  0.0165, -0.0146, -0.0162],
          [ 0.0007,  0.0144, -0.0006, -0.0075, -0.0069]],

         [[-0.0234,  0.0106,  0.0212,  0.0189,  0.0142],
          [ 0.0084, -0.0237, -0.0164,  0.0231, -0.0109],
          [-0.0051,  0.0214, -0.0220, -0.0100,  0.0169],
          [-0.0104,  0.0064,  0.0082, -0.0189, -0.0108],
          [ 0.0222, -0.0058,  0.0175, -0.0216,  0.0150]],

         [[ 0.0249, -0.0001,  0.0074,  0.0092, -0.0095],
          [ 0.0072,  0.0246, -0.0186,  0.0028, -0.0228],
          [ 0.0240, -0.0119, -0.0018,  0.0040,  0.0068],
          [-0.0176, -0.0206,  0.0180,  0.0027,  0.0014],
          [-0.0154, -0.0063,  0.0138,  0.0107,  0.0099]]],


        ...,


        [[[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         ...,

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]]],


        [[[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         ...,

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]]],


        [[[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         ...,

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]],

         [[    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan],
          [    nan,     nan,     nan,     nan,     nan]]]])
layer3.1.bias tensor([   nan,    nan, 0.0010,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan])
fc1.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc2.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc2.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])



Session Number: 0
images/374
(64, 64, 3)
2018-10-10 23:43:50.042 Python[95134:15354670] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 172, in <module>
    main()
  File "Torch_reinforce01.py", line 139, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 100, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/532
(64, 64, 3)
2018-10-10 23:45:36.107 Python[95203:15355676] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0148, 0.0281, 0.0255, 0.0097, 0.0337, 0.0214, 0.0033, 0.0129, 0.0147,
         0.0423, 0.0663, 0.0134, 0.0143, 0.0162, 0.0183, 0.0380, 0.0024, 0.0100,
         0.0141, 0.0153, 0.0073, 0.0231, 0.0348, 0.0141, 0.0076, 0.0213, 0.0015,
         0.0078, 0.0330, 0.0061, 0.0046, 0.0255, 0.1601, 0.0458, 0.0143, 0.0082,
         0.0834, 0.0297, 0.0185, 0.0386]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 1
images/214
(64, 64, 3)
tensor([[0.0227, 0.0255, 0.0258, 0.0233, 0.0219, 0.0246, 0.0367, 0.0269, 0.0239,
         0.0262, 0.0309, 0.0238, 0.0249, 0.0241, 0.0254, 0.0273, 0.0229, 0.0275,
         0.0310, 0.0247, 0.0248, 0.0211, 0.0236, 0.0187, 0.0251, 0.0261, 0.0148,
         0.0220, 0.0232, 0.0239, 0.0201, 0.0234, 0.0303, 0.0253, 0.0259, 0.0227,
         0.0315, 0.0250, 0.0316, 0.0210]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/461
(64, 64, 3)
tensor([[0.0218, 0.0203, 0.0148, 0.0063, 0.0158, 0.0157, 0.1079, 0.0126, 0.0286,
         0.0122, 0.0778, 0.0228, 0.0292, 0.0230, 0.0025, 0.0084, 0.0047, 0.0031,
         0.0043, 0.0027, 0.0112, 0.0094, 0.0109, 0.0039, 0.0058, 0.0183, 0.0040,
         0.0083, 0.0052, 0.0324, 0.0052, 0.0219, 0.0825, 0.0708, 0.0664, 0.0052,
         0.0085, 0.0105, 0.1543, 0.0308]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/13
(64, 64, 3)
tensor([[0.0194, 0.0094, 0.0140, 0.0158, 0.0243, 0.0239, 0.0316, 0.0118, 0.0628,
         0.0267, 0.0259, 0.0111, 0.0330, 0.0304, 0.0031, 0.0028, 0.0083, 0.0192,
         0.0322, 0.0349, 0.0188, 0.0233, 0.0068, 0.0091, 0.0071, 0.0223, 0.0058,
         0.0031, 0.0055, 0.0186, 0.0023, 0.0066, 0.0662, 0.0124, 0.0366, 0.0711,
         0.1322, 0.0169, 0.0308, 0.0642]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 4
images/523
(64, 64, 3)
tensor([[0.0405, 0.0264, 0.0232, 0.0443, 0.0090, 0.0362, 0.0297, 0.0116, 0.0101,
         0.0036, 0.0306, 0.0102, 0.0437, 0.0431, 0.0068, 0.0085, 0.0131, 0.0163,
         0.0077, 0.0181, 0.0078, 0.0556, 0.0156, 0.0320, 0.0093, 0.0257, 0.0067,
         0.0130, 0.0208, 0.0340, 0.0024, 0.0089, 0.0220, 0.0052, 0.0576, 0.0044,
         0.0626, 0.0247, 0.1365, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
Weights 


layer1.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer2.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.1.bias tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
        -0.0233,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan])
layer3.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.1.bias tensor([   nan,    nan,    nan,    nan, 0.0159,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
           nan])
fc1.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc2.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc2.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])



 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/142
(64, 64, 3)
2018-10-11 00:15:27.432 Python[95289:15357838] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0219, 0.0287, 0.0211, 0.0157, 0.0308, 0.0322, 0.0067, 0.0197, 0.0136,
         0.0308, 0.0711, 0.0169, 0.0204, 0.0197, 0.0232, 0.0252, 0.0071, 0.0172,
         0.0198, 0.0196, 0.0164, 0.0214, 0.0297, 0.0270, 0.0120, 0.0245, 0.0049,
         0.0183, 0.0313, 0.0171, 0.0073, 0.0146, 0.0687, 0.0366, 0.0142, 0.0125,
         0.0606, 0.0447, 0.0380, 0.0385]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 1
images/192
(64, 64, 3)
tensor([[0.0079, 0.0165, 0.0144, 0.0068, 0.0063, 0.0102, 0.1852, 0.0221, 0.0127,
         0.0136, 0.0743, 0.0176, 0.0154, 0.0090, 0.0162, 0.0177, 0.0079, 0.0217,
         0.0594, 0.0108, 0.0250, 0.0048, 0.0116, 0.0051, 0.0151, 0.0322, 0.0015,
         0.0053, 0.0108, 0.0124, 0.0041, 0.0104, 0.0334, 0.0253, 0.0151, 0.0154,
         0.0879, 0.0196, 0.1109, 0.0085]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/232
(64, 64, 3)
tensor([[0.0239, 0.0276, 0.0267, 0.0220, 0.0238, 0.0245, 0.0326, 0.0233, 0.0301,
         0.0239, 0.0320, 0.0266, 0.0272, 0.0263, 0.0202, 0.0229, 0.0221, 0.0216,
         0.0209, 0.0181, 0.0210, 0.0238, 0.0243, 0.0213, 0.0222, 0.0295, 0.0196,
         0.0244, 0.0207, 0.0284, 0.0225, 0.0247, 0.0327, 0.0299, 0.0295, 0.0197,
         0.0245, 0.0215, 0.0343, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/343
(64, 64, 3)
tensor([[0.0251, 0.0238, 0.0269, 0.0267, 0.0293, 0.0237, 0.0284, 0.0239, 0.0318,
         0.0242, 0.0297, 0.0265, 0.0281, 0.0276, 0.0195, 0.0166, 0.0243, 0.0239,
         0.0257, 0.0267, 0.0225, 0.0236, 0.0189, 0.0220, 0.0216, 0.0241, 0.0179,
         0.0185, 0.0206, 0.0291, 0.0171, 0.0244, 0.0304, 0.0252, 0.0294, 0.0299,
         0.0367, 0.0233, 0.0258, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
Weights 


layer1.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer2.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.1.bias tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
        -0.0233,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan])
layer3.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.1.bias tensor([    nan,     nan,     nan,     nan,  0.0159,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan, -0.0148,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan])
fc1.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc2.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc2.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])



 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/436
(64, 64, 3)
2018-10-11 00:16:18.163 Python[95352:15358885] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0169, 0.0219, 0.0157, 0.0129, 0.0277, 0.0178, 0.0023, 0.0094, 0.0145,
         0.0431, 0.0803, 0.0089, 0.0098, 0.0134, 0.0248, 0.0460, 0.0028, 0.0103,
         0.0151, 0.0237, 0.0062, 0.0161, 0.0243, 0.0167, 0.0066, 0.0211, 0.0028,
         0.0101, 0.0386, 0.0101, 0.0036, 0.0088, 0.1084, 0.0337, 0.0132, 0.0091,
         0.1474, 0.0512, 0.0301, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 1
images/338
(64, 64, 3)
tensor([[0.0235, 0.0250, 0.0253, 0.0234, 0.0230, 0.0232, 0.0343, 0.0259, 0.0253,
         0.0245, 0.0301, 0.0242, 0.0253, 0.0234, 0.0256, 0.0255, 0.0229, 0.0258,
         0.0284, 0.0240, 0.0262, 0.0207, 0.0255, 0.0199, 0.0256, 0.0267, 0.0170,
         0.0211, 0.0227, 0.0233, 0.0208, 0.0228, 0.0297, 0.0281, 0.0237, 0.0244,
         0.0319, 0.0262, 0.0326, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/584
(64, 64, 3)
tensor([[0.0145, 0.0163, 0.0234, 0.0129, 0.0145, 0.0229, 0.1058, 0.0107, 0.0370,
         0.0204, 0.0911, 0.0208, 0.0218, 0.0226, 0.0058, 0.0127, 0.0060, 0.0105,
         0.0053, 0.0037, 0.0103, 0.0131, 0.0155, 0.0087, 0.0052, 0.0316, 0.0056,
         0.0154, 0.0066, 0.0429, 0.0137, 0.0196, 0.0620, 0.0250, 0.0412, 0.0062,
         0.0164, 0.0071, 0.1282, 0.0470]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 3
images/403
(64, 64, 3)
tensor([[0.0126, 0.0118, 0.0179, 0.0120, 0.0331, 0.0102, 0.0354, 0.0132, 0.0549,
         0.0189, 0.0235, 0.0086, 0.0380, 0.0322, 0.0023, 0.0015, 0.0069, 0.0109,
         0.0400, 0.0228, 0.0103, 0.0120, 0.0022, 0.0062, 0.0027, 0.0208, 0.0019,
         0.0030, 0.0044, 0.0414, 0.0006, 0.0057, 0.0420, 0.0125, 0.0172, 0.1134,
         0.2164, 0.0114, 0.0309, 0.0383]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 0
Session Number: 4
images/404
(64, 64, 3)
tensor([[0.0245, 0.0256, 0.0282, 0.0211, 0.0085, 0.0239, 0.0206, 0.0092, 0.0100,
         0.0034, 0.0303, 0.0120, 0.0432, 0.0374, 0.0075, 0.0110, 0.0180, 0.0212,
         0.0078, 0.0140, 0.0114, 0.0487, 0.0196, 0.0390, 0.0073, 0.0166, 0.0079,
         0.0238, 0.0264, 0.0351, 0.0032, 0.0087, 0.0202, 0.0107, 0.0632, 0.0055,
         0.1131, 0.0228, 0.1217, 0.0177]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 5
images/208
(64, 64, 3)
tensor([[0.0202, 0.0240, 0.0283, 0.0201, 0.0235, 0.0276, 0.0246, 0.0218, 0.0208,
         0.0194, 0.0352, 0.0237, 0.0283, 0.0223, 0.0217, 0.0277, 0.0187, 0.0238,
         0.0292, 0.0263, 0.0199, 0.0276, 0.0225, 0.0270, 0.0235, 0.0271, 0.0188,
         0.0220, 0.0196, 0.0323, 0.0198, 0.0230, 0.0338, 0.0233, 0.0303, 0.0278,
         0.0349, 0.0243, 0.0327, 0.0228]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 6
images/114
(64, 64, 3)
tensor([[0.0059, 0.0252, 0.0145, 0.0135, 0.0607, 0.0800, 0.0435, 0.0137, 0.0040,
         0.0565, 0.0637, 0.0239, 0.0132, 0.0178, 0.0113, 0.0136, 0.0108, 0.0201,
         0.0250, 0.0159, 0.0071, 0.0193, 0.0075, 0.0347, 0.0100, 0.0445, 0.0105,
         0.0241, 0.0150, 0.0271, 0.0031, 0.0150, 0.0610, 0.0084, 0.0172, 0.0123,
         0.0720, 0.0074, 0.0513, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 7
images/46
(64, 64, 3)
tensor([[0.0155, 0.0050, 0.0129, 0.0156, 0.0142, 0.0173, 0.0459, 0.0735, 0.0272,
         0.0266, 0.1649, 0.0217, 0.0193, 0.0136, 0.0131, 0.0193, 0.0148, 0.0144,
         0.0296, 0.0132, 0.0078, 0.0107, 0.0133, 0.0108, 0.0103, 0.0314, 0.0048,
         0.0137, 0.0077, 0.0289, 0.0060, 0.0602, 0.0371, 0.0146, 0.0125, 0.0112,
         0.0479, 0.0331, 0.0326, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
Weights 


layer1.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer2.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.1.bias tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
        -0.0233,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan])
layer3.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.1.bias tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan, -0.0148,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan])
fc1.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc2.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc2.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])



 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 7, in <module>
    from Policy import *
  File "/Users/siddharthnayak/Downloads/RL Project/Code/Policy.py", line 23
    nn.ReLU(),
     ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/431
(64, 64, 3)
2018-10-11 00:37:22.275 Python[95875:15372615] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 182, in <module>
    main()
  File "Torch_reinforce01.py", line 139, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 97, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/siddharthnayak/Downloads/RL Project/Code/Policy.py", line 56, in forward
    out = self.layer1(x)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 66, in forward
    exponential_average_factor, self.eps)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py", line 1254, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: running_mean should contain 32 elements not 64
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/47
(64, 64, 3)
2018-10-11 00:37:41.177 Python[95917:15372936] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 182, in <module>
    main()
  File "Torch_reinforce01.py", line 139, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 97, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/siddharthnayak/Downloads/RL Project/Code/Policy.py", line 61, in forward
    out = self.BatchNorm1(out)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 66, in forward
    exponential_average_factor, self.eps)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py", line 1251, in batch_norm
    raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))
ValueError: Expected more than 1 value per channel when training, got input size [1, 4096]
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/381
(64, 64, 3)
2018-10-11 00:38:39.665 Python[95975:15373784] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 182, in <module>
    main()
  File "Torch_reinforce01.py", line 139, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 97, in select_action
    probs = policy(state)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/siddharthnayak/Downloads/RL Project/Code/Policy.py", line 62, in forward
    out = self.BatchNorm2(out)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 66, in forward
    exponential_average_factor, self.eps)
  File "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py", line 1251, in batch_norm
    raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))
ValueError: Expected more than 1 value per channel when training, got input size [1, 512]
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/428
(64, 64, 3)
2018-10-11 00:38:58.755 Python[96017:15374097] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0308, 0.0201, 0.0220, 0.0284, 0.0349, 0.0220, 0.0241, 0.0164, 0.0164,
         0.0147, 0.0146, 0.0234, 0.0260, 0.0301, 0.0495, 0.0219, 0.0165, 0.0233,
         0.0125, 0.0178, 0.0174, 0.0213, 0.0328, 0.0259, 0.0365, 0.0232, 0.0245,
         0.0281, 0.0274, 0.0163, 0.0184, 0.0436, 0.0177, 0.0264, 0.0285, 0.0339,
         0.0322, 0.0305, 0.0284, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 1
images/220
(64, 64, 3)
tensor([[0.0268, 0.0292, 0.0235, 0.0135, 0.0285, 0.0170, 0.0369, 0.0128, 0.0188,
         0.0162, 0.0216, 0.0261, 0.0257, 0.0319, 0.0263, 0.0225, 0.0219, 0.0394,
         0.0156, 0.0247, 0.0163, 0.0274, 0.0220, 0.0289, 0.0249, 0.0280, 0.0175,
         0.0316, 0.0230, 0.0229, 0.0151, 0.0451, 0.0235, 0.0271, 0.0180, 0.0325,
         0.0388, 0.0233, 0.0213, 0.0338]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/319
(64, 64, 3)
tensor([[0.0379, 0.0300, 0.0166, 0.0156, 0.0284, 0.0256, 0.0282, 0.0127, 0.0148,
         0.0158, 0.0244, 0.0315, 0.0370, 0.0470, 0.0182, 0.0188, 0.0293, 0.0358,
         0.0177, 0.0140, 0.0114, 0.0240, 0.0321, 0.0281, 0.0179, 0.0193, 0.0339,
         0.0227, 0.0330, 0.0235, 0.0232, 0.0281, 0.0331, 0.0312, 0.0289, 0.0374,
         0.0224, 0.0184, 0.0144, 0.0178]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 3
images/325
(64, 64, 3)
tensor([[0.0308, 0.0184, 0.0130, 0.0173, 0.0422, 0.0191, 0.0311, 0.0197, 0.0229,
         0.0122, 0.0217, 0.0244, 0.0388, 0.0328, 0.0277, 0.0180, 0.0195, 0.0364,
         0.0175, 0.0229, 0.0150, 0.0402, 0.0153, 0.0145, 0.0212, 0.0100, 0.0231,
         0.0501, 0.0339, 0.0215, 0.0193, 0.0225, 0.0420, 0.0387, 0.0317, 0.0224,
         0.0276, 0.0234, 0.0229, 0.0186]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 4
images/369
(64, 64, 3)
tensor([[0.0260, 0.0281, 0.0232, 0.0176, 0.0449, 0.0219, 0.0247, 0.0179, 0.0171,
         0.0184, 0.0144, 0.0384, 0.0340, 0.0438, 0.0247, 0.0229, 0.0205, 0.0318,
         0.0168, 0.0146, 0.0162, 0.0178, 0.0279, 0.0175, 0.0239, 0.0177, 0.0435,
         0.0338, 0.0406, 0.0213, 0.0194, 0.0323, 0.0176, 0.0202, 0.0374, 0.0227,
         0.0182, 0.0169, 0.0159, 0.0375]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 5
images/58
(64, 64, 3)
tensor([[0.0159, 0.0275, 0.0166, 0.0145, 0.0332, 0.0191, 0.0380, 0.0227, 0.0171,
         0.0202, 0.0198, 0.0324, 0.0386, 0.0279, 0.0301, 0.0322, 0.0176, 0.0434,
         0.0208, 0.0258, 0.0163, 0.0264, 0.0245, 0.0223, 0.0219, 0.0139, 0.0281,
         0.0312, 0.0282, 0.0224, 0.0247, 0.0261, 0.0276, 0.0285, 0.0235, 0.0312,
         0.0213, 0.0165, 0.0202, 0.0321]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 0
Session Number: 6
images/56
(64, 64, 3)
tensor([[0.0450, 0.0287, 0.0217, 0.0162, 0.0263, 0.0267, 0.0263, 0.0216, 0.0165,
         0.0298, 0.0177, 0.0285, 0.0380, 0.0240, 0.0244, 0.0185, 0.0183, 0.0447,
         0.0213, 0.0245, 0.0163, 0.0319, 0.0248, 0.0295, 0.0201, 0.0141, 0.0180,
         0.0300, 0.0313, 0.0204, 0.0242, 0.0296, 0.0193, 0.0198, 0.0154, 0.0283,
         0.0264, 0.0226, 0.0332, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 7
images/488
(64, 64, 3)
tensor([[0.0429, 0.0230, 0.0265, 0.0156, 0.0169, 0.0157, 0.0227, 0.0120, 0.0132,
         0.0158, 0.0165, 0.0426, 0.0320, 0.0377, 0.0226, 0.0238, 0.0238, 0.0266,
         0.0167, 0.0273, 0.0149, 0.0263, 0.0215, 0.0274, 0.0154, 0.0232, 0.0400,
         0.0461, 0.0377, 0.0185, 0.0252, 0.0290, 0.0212, 0.0304, 0.0201, 0.0333,
         0.0335, 0.0228, 0.0154, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/523
(64, 64, 3)
tensor([[0.0250, 0.0228, 0.0142, 0.0181, 0.0340, 0.0311, 0.0311, 0.0209, 0.0155,
         0.0238, 0.0135, 0.0294, 0.0441, 0.0229, 0.0200, 0.0206, 0.0207, 0.0398,
         0.0190, 0.0154, 0.0111, 0.0224, 0.0317, 0.0246, 0.0192, 0.0359, 0.0284,
         0.0355, 0.0335, 0.0297, 0.0081, 0.0291, 0.0309, 0.0227, 0.0262, 0.0280,
         0.0262, 0.0208, 0.0197, 0.0341]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 9
images/481
(64, 64, 3)
tensor([[0.0340, 0.0260, 0.0113, 0.0101, 0.0295, 0.0198, 0.0572, 0.0230, 0.0130,
         0.0232, 0.0195, 0.0169, 0.0343, 0.0423, 0.0346, 0.0181, 0.0237, 0.0322,
         0.0160, 0.0151, 0.0161, 0.0276, 0.0161, 0.0215, 0.0218, 0.0166, 0.0311,
         0.0220, 0.0391, 0.0239, 0.0282, 0.0301, 0.0297, 0.0234, 0.0184, 0.0399,
         0.0212, 0.0143, 0.0306, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 10
images/20
(64, 64, 3)
tensor([[0.0221, 0.0207, 0.0184, 0.0145, 0.0484, 0.0186, 0.0252, 0.0221, 0.0235,
         0.0209, 0.0196, 0.0336, 0.0413, 0.0235, 0.0296, 0.0093, 0.0172, 0.0292,
         0.0242, 0.0251, 0.0139, 0.0190, 0.0223, 0.0258, 0.0200, 0.0181, 0.0413,
         0.0237, 0.0206, 0.0223, 0.0265, 0.0321, 0.0329, 0.0262, 0.0376, 0.0256,
         0.0211, 0.0266, 0.0260, 0.0315]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 11
images/574
(64, 64, 3)
tensor([[0.0232, 0.0287, 0.0360, 0.0102, 0.0349, 0.0287, 0.0236, 0.0214, 0.0251,
         0.0257, 0.0124, 0.0320, 0.0225, 0.0285, 0.0226, 0.0203, 0.0121, 0.0500,
         0.0157, 0.0150, 0.0194, 0.0294, 0.0186, 0.0416, 0.0236, 0.0200, 0.0187,
         0.0268, 0.0351, 0.0463, 0.0204, 0.0286, 0.0364, 0.0183, 0.0191, 0.0172,
         0.0272, 0.0215, 0.0189, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/44
(64, 64, 3)
tensor([[0.0388, 0.0210, 0.0140, 0.0177, 0.0285, 0.0176, 0.0303, 0.0170, 0.0188,
         0.0123, 0.0236, 0.0256, 0.0358, 0.0609, 0.0130, 0.0273, 0.0265, 0.0430,
         0.0130, 0.0165, 0.0161, 0.0277, 0.0287, 0.0221, 0.0222, 0.0232, 0.0206,
         0.0324, 0.0525, 0.0179, 0.0138, 0.0342, 0.0234, 0.0121, 0.0189, 0.0261,
         0.0288, 0.0250, 0.0250, 0.0282]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 13
images/247
(64, 64, 3)
tensor([[0.0232, 0.0213, 0.0198, 0.0122, 0.0230, 0.0358, 0.0333, 0.0145, 0.0156,
         0.0196, 0.0308, 0.0256, 0.0471, 0.0403, 0.0156, 0.0153, 0.0156, 0.0255,
         0.0152, 0.0209, 0.0255, 0.0297, 0.0155, 0.0199, 0.0238, 0.0162, 0.0241,
         0.0438, 0.0450, 0.0149, 0.0217, 0.0422, 0.0295, 0.0132, 0.0286, 0.0249,
         0.0357, 0.0182, 0.0264, 0.0310]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
Weights 


layer1.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer2.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc1.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc2.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc2.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])



 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



Loading the model if any
0
Session Number: 0
images/367
(64, 64, 3)
2018-10-11 01:01:18.863 Python[96486:15387375] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0226, 0.0205, 0.0159, 0.0310, 0.0281, 0.0177, 0.0261, 0.0129, 0.0183,
         0.0149, 0.0181, 0.0171, 0.0368, 0.0289, 0.0488, 0.0224, 0.0175, 0.0339,
         0.0152, 0.0241, 0.0146, 0.0251, 0.0323, 0.0216, 0.0278, 0.0318, 0.0192,
         0.0384, 0.0253, 0.0149, 0.0181, 0.0487, 0.0301, 0.0202, 0.0226, 0.0329,
         0.0320, 0.0271, 0.0222, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 1
images/466
(64, 64, 3)
tensor([[0.0352, 0.0254, 0.0209, 0.0164, 0.0367, 0.0136, 0.0279, 0.0205, 0.0186,
         0.0171, 0.0196, 0.0363, 0.0202, 0.0321, 0.0244, 0.0205, 0.0210, 0.0304,
         0.0207, 0.0260, 0.0184, 0.0241, 0.0179, 0.0230, 0.0248, 0.0188, 0.0249,
         0.0333, 0.0223, 0.0282, 0.0177, 0.0351, 0.0240, 0.0380, 0.0183, 0.0350,
         0.0427, 0.0203, 0.0154, 0.0341]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
Weights 


layer1.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer2.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc1.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc2.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc2.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])



 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/331
(64, 64, 3)
2018-10-11 01:02:13.399 Python[96540:15387994] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0303, 0.0238, 0.0201, 0.0205, 0.0338, 0.0217, 0.0339, 0.0161, 0.0190,
         0.0188, 0.0137, 0.0247, 0.0255, 0.0282, 0.0446, 0.0226, 0.0204, 0.0239,
         0.0206, 0.0195, 0.0171, 0.0238, 0.0284, 0.0220, 0.0277, 0.0276, 0.0185,
         0.0299, 0.0256, 0.0161, 0.0197, 0.0326, 0.0228, 0.0246, 0.0278, 0.0328,
         0.0370, 0.0339, 0.0251, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 1
images/318
(64, 64, 3)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0360, 0.0242, 0.0189, 0.0149, 0.0381, 0.0172, 0.0255, 0.0199, 0.0143,
         0.0141, 0.0196, 0.0389, 0.0238, 0.0336, 0.0377, 0.0133, 0.0219, 0.0429,
         0.0141, 0.0241, 0.0136, 0.0265, 0.0173, 0.0341, 0.0224, 0.0157, 0.0201,
         0.0327, 0.0351, 0.0187, 0.0215, 0.0409, 0.0264, 0.0299, 0.0148, 0.0332,
         0.0367, 0.0266, 0.0167, 0.0240]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/250
(64, 64, 3)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0390, 0.0289, 0.0140, 0.0206, 0.0336, 0.0223, 0.0347, 0.0203, 0.0125,
         0.0155, 0.0286, 0.0251, 0.0445, 0.0448, 0.0200, 0.0185, 0.0340, 0.0422,
         0.0093, 0.0107, 0.0170, 0.0255, 0.0282, 0.0295, 0.0185, 0.0136, 0.0286,
         0.0202, 0.0424, 0.0202, 0.0179, 0.0246, 0.0281, 0.0346, 0.0189, 0.0392,
         0.0253, 0.0178, 0.0162, 0.0144]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 3
images/436
(64, 64, 3)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0296, 0.0252, 0.0138, 0.0279, 0.0227, 0.0203, 0.0314, 0.0238, 0.0242,
         0.0142, 0.0216, 0.0323, 0.0337, 0.0460, 0.0296, 0.0207, 0.0187, 0.0488,
         0.0155, 0.0302, 0.0160, 0.0172, 0.0203, 0.0233, 0.0217, 0.0156, 0.0220,
         0.0425, 0.0351, 0.0197, 0.0198, 0.0215, 0.0255, 0.0290, 0.0245, 0.0201,
         0.0218, 0.0317, 0.0217, 0.0207]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 4
images/114
(64, 64, 3)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0291, 0.0274, 0.0254, 0.0214, 0.0442, 0.0223, 0.0262, 0.0180, 0.0150,
         0.0309, 0.0153, 0.0334, 0.0286, 0.0330, 0.0287, 0.0149, 0.0257, 0.0274,
         0.0233, 0.0172, 0.0162, 0.0227, 0.0244, 0.0244, 0.0199, 0.0261, 0.0324,
         0.0320, 0.0290, 0.0223, 0.0171, 0.0373, 0.0207, 0.0211, 0.0360, 0.0200,
         0.0218, 0.0236, 0.0225, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 5
images/346
(64, 64, 3)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0142, 0.0294, 0.0152, 0.0137, 0.0312, 0.0247, 0.0327, 0.0202, 0.0131,
         0.0227, 0.0192, 0.0433, 0.0314, 0.0255, 0.0308, 0.0248, 0.0202, 0.0372,
         0.0144, 0.0278, 0.0247, 0.0190, 0.0263, 0.0285, 0.0182, 0.0150, 0.0276,
         0.0222, 0.0385, 0.0225, 0.0174, 0.0390, 0.0268, 0.0241, 0.0309, 0.0421,
         0.0239, 0.0171, 0.0189, 0.0257]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 6
images/498
(64, 64, 3)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0324, 0.0325, 0.0205, 0.0147, 0.0317, 0.0194, 0.0320, 0.0239, 0.0174,
         0.0236, 0.0180, 0.0258, 0.0281, 0.0267, 0.0239, 0.0155, 0.0187, 0.0363,
         0.0131, 0.0287, 0.0187, 0.0251, 0.0213, 0.0256, 0.0172, 0.0182, 0.0205,
         0.0275, 0.0487, 0.0178, 0.0257, 0.0305, 0.0261, 0.0223, 0.0172, 0.0351,
         0.0328, 0.0225, 0.0294, 0.0349]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 7
images/383
(64, 64, 3)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0446, 0.0316, 0.0205, 0.0113, 0.0291, 0.0197, 0.0286, 0.0138, 0.0167,
         0.0112, 0.0158, 0.0410, 0.0418, 0.0228, 0.0187, 0.0378, 0.0261, 0.0269,
         0.0130, 0.0254, 0.0195, 0.0259, 0.0150, 0.0271, 0.0228, 0.0252, 0.0364,
         0.0409, 0.0381, 0.0267, 0.0326, 0.0266, 0.0265, 0.0258, 0.0146, 0.0210,
         0.0227, 0.0154, 0.0108, 0.0302]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0   
Session Number: 8
images/593
(64, 64, 3)
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



tensor([[0.0296, 0.0213, 0.0118, 0.0116, 0.0315, 0.0220, 0.0239, 0.0238, 0.0205,
         0.0254, 0.0172, 0.0364, 0.0465, 0.0236, 0.0253, 0.0147, 0.0334, 0.0351,
         0.0222, 0.0176, 0.0100, 0.0208, 0.0268, 0.0336, 0.0208, 0.0163, 0.0317,
         0.0376, 0.0263, 0.0176, 0.0124, 0.0430, 0.0295, 0.0222, 0.0260, 0.0291,
         0.0254, 0.0229, 0.0200, 0.0344]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
Weights 


layer1.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer1.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer1.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan])
layer2.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer2.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer2.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.0.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.0.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.3.weight tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        ...,


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],


        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         ...,

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],

         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
layer3.3.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.4.weight tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
layer3.4.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc1.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc1.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan])
fc2.weight tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]])
fc2.bias tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])



 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/131
(64, 64, 3)
2018-10-11 01:11:46.497 Python[96758:15393327] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0268, 0.0258, 0.0121, 0.0237, 0.0403, 0.0192, 0.0269, 0.0118, 0.0236,
         0.0176, 0.0157, 0.0256, 0.0338, 0.0286, 0.0490, 0.0226, 0.0167, 0.0271,
         0.0163, 0.0206, 0.0140, 0.0272, 0.0428, 0.0219, 0.0272, 0.0269, 0.0234,
         0.0231, 0.0238, 0.0179, 0.0177, 0.0374, 0.0213, 0.0301, 0.0275, 0.0298,
         0.0313, 0.0291, 0.0184, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



Enter Reward: 1
Session Number: 1
images/103
(64, 64, 3)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 189, in <module>
    main()
  File "Torch_reinforce01.py", line 140, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 101, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/55
(64, 64, 3)
2018-10-11 01:17:43.671 Python[96932:15396745] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0283, 0.0212, 0.0198, 0.0226, 0.0310, 0.0261, 0.0303, 0.0181, 0.0176,
         0.0118, 0.0180, 0.0181, 0.0294, 0.0283, 0.0496, 0.0253, 0.0189, 0.0304,
         0.0145, 0.0198, 0.0150, 0.0211, 0.0367, 0.0230, 0.0318, 0.0242, 0.0243,
         0.0280, 0.0284, 0.0190, 0.0222, 0.0361, 0.0214, 0.0268, 0.0195, 0.0292,
         0.0332, 0.0344, 0.0216, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



Enter Reward: 1
Policy reward
None
Session Number: 1
images/525
(64, 64, 3)
tensor([[0.0297, 0.0229, 0.0171, 0.0113, 0.0319, 0.0187, 0.0297, 0.0228, 0.0119,
         0.0186, 0.0225, 0.0252, 0.0297, 0.0405, 0.0300, 0.0176, 0.0214, 0.0409,
         0.0207, 0.0296, 0.0119, 0.0213, 0.0189, 0.0267, 0.0310, 0.0211, 0.0152,
         0.0413, 0.0284, 0.0287, 0.0163, 0.0419, 0.0248, 0.0221, 0.0160, 0.0359,
         0.0399, 0.0224, 0.0202, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([-1.0000e-30,  1.0000e-30,  1.0000e-30,  1.0000e-30,  1.0000e-30,
         9.9999e-31, -1.0000e-30,  9.9999e-31, -1.0000e-30, -1.0000e-30,
         1.0000e-30, -1.0000e-30, -1.0000e-30, -1.0000e-30,  9.9999e-31,
        -9.9999e-31, -9.9999e-31, -1.0000e-30,  1.0000e-30,  1.0000e-30,
        -1.0000e-30,  1.0000e-30,  1.0000e-30, -9.9999e-31, -1.0000e-30,
         1.0000e-30, -1.0000e-30, -9.9990e-31,  1.0000e-30, -9.9999e-31,
        -1.0000e-30,  1.0000e-30])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([ 1.0000e-30,  9.9998e-31,  9.9999e-31,  9.9999e-31,  9.9999e-31,
        -9.9967e-31, -9.9998e-31, -1.0000e-30,  9.9999e-31, -9.9972e-31,
         9.9996e-31,  1.0000e-30, -9.9999e-31, -9.9999e-31,  1.0000e-30,
         9.9999e-31,  9.9999e-31,  9.9997e-31,  9.9999e-31, -9.9999e-31,
        -9.9999e-31,  9.9999e-31, -9.9999e-31, -1.0000e-30,  9.9997e-31,
        -1.0000e-30, -9.9999e-31, -9.9999e-31,  9.9999e-31, -9.9999e-31,
        -9.9999e-31,  9.9999e-31])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([ 9.9999e-31, -9.9997e-31,  9.9999e-31, -9.9991e-31, -9.9999e-31,
         9.9998e-31, -9.9998e-31, -9.9998e-31, -1.0000e-30, -9.9989e-31,
         9.9999e-31,  9.9993e-31, -9.9998e-31, -9.9999e-31, -1.0000e-30,
         9.9996e-31,  9.9999e-31, -9.9999e-31, -9.9999e-31, -1.0000e-30,
        -9.9996e-31, -9.9998e-31, -9.9998e-31, -9.9999e-31, -1.0000e-30,
        -9.9999e-31, -9.9999e-31,  9.9988e-31, -9.9999e-31, -9.9997e-31,
         9.9992e-31,  9.9999e-31, -9.9999e-31,  9.9999e-31, -9.9999e-31,
        -9.9998e-31,  9.9999e-31,  9.9999e-31,  9.9998e-31,  9.9998e-31,
         9.9999e-31, -9.9999e-31,  9.9998e-31,  9.9999e-31, -9.9998e-31,
         9.9997e-31, -1.0000e-30,  9.9999e-31, -9.9998e-31, -9.9999e-31,
        -1.0000e-30,  1.0000e-30,  9.9995e-31, -9.9999e-31,  9.9999e-31,
         9.9999e-31, -9.9999e-31,  9.9998e-31, -9.8768e-31,  9.9998e-31,
        -9.9999e-31,  9.9999e-31,  9.9998e-31,  9.9999e-31])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([ 9.9997e-31, -9.9999e-31, -9.9999e-31, -9.9997e-31, -9.9999e-31,
        -9.9950e-31, -9.9998e-31, -9.9998e-31,  9.9998e-31, -9.9998e-31,
         9.9993e-31,  9.9999e-31, -9.9996e-31, -9.9998e-31,  9.9996e-31,
         9.9998e-31, -9.9997e-31, -9.9998e-31,  9.9997e-31, -9.9999e-31,
         9.9999e-31, -9.9999e-31,  9.9995e-31,  9.9999e-31,  9.9998e-31,
        -9.9975e-31,  9.9998e-31,  9.9999e-31, -9.9998e-31, -9.9997e-31,
         9.9987e-31,  9.9998e-31, -9.9972e-31,  9.9998e-31,  9.9997e-31,
         9.9997e-31, -9.9996e-31, -9.9995e-31,  9.9998e-31, -9.9999e-31,
        -9.9999e-31,  9.9994e-31,  9.9999e-31,  9.9999e-31, -9.9998e-31,
         9.9999e-31, -9.9999e-31,  9.9998e-31,  9.9997e-31, -9.9986e-31,
        -9.9998e-31,  9.9999e-31,  9.9998e-31, -9.9999e-31,  9.9998e-31,
        -9.9997e-31, -9.9995e-31,  9.9999e-31,  9.9998e-31, -9.9999e-31,
        -9.9995e-31,  9.9999e-31, -9.9999e-31, -9.9996e-31])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([-9.9996e-31,  9.9999e-31,  9.9999e-31, -9.9999e-31,  9.9987e-31,
        -9.9998e-31, -9.9999e-31,  9.9999e-31,  9.9997e-31,  9.9864e-31,
        -9.9999e-31, -9.9994e-31,  9.9996e-31, -1.0000e-30,  9.9999e-31,
        -9.9997e-31,  9.9999e-31,  9.9999e-31, -9.9998e-31, -9.9997e-31,
        -9.9997e-31, -9.9999e-31,  9.9999e-31, -9.9996e-31,  9.9999e-31,
         1.0000e-30, -9.9997e-31,  9.9999e-31,  9.9999e-31, -9.9999e-31,
        -9.9997e-31,  9.9999e-31,  9.9999e-31, -9.9999e-31,  9.9999e-31,
         9.9998e-31, -9.9998e-31,  9.9998e-31, -9.9996e-31,  9.9998e-31,
        -9.9995e-31, -9.9998e-31, -9.9999e-31, -9.9978e-31, -9.9999e-31,
        -9.9909e-31,  9.9997e-31,  9.9998e-31,  1.0000e-30, -9.9999e-31,
         9.9999e-31, -9.9997e-31, -9.9999e-31,  9.9999e-31, -9.9999e-31,
         9.9999e-31,  9.9999e-31,  9.9999e-31, -9.9997e-31,  9.9998e-31,
        -9.9997e-31,  9.9991e-31,  9.9995e-31,  9.9996e-31])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([ 9.9998e-31, -1.0000e-30,  9.9998e-31,  1.0000e-30,  1.0000e-30,
         9.9999e-31, -9.9997e-31,  9.9992e-31, -9.9997e-31,  1.0000e-30,
        -9.9998e-31, -9.9999e-31,  9.9995e-31,  9.9997e-31,  9.9997e-31,
        -9.9999e-31,  9.9999e-31,  9.9999e-31, -9.9998e-31, -9.9890e-31,
        -1.0000e-30, -1.0000e-30, -9.9999e-31,  9.9998e-31, -9.9995e-31,
        -9.9998e-31, -9.9998e-31,  9.9999e-31,  9.9989e-31,  9.9999e-31,
         9.9997e-31,  9.9999e-31, -1.0000e-30,  9.9997e-31, -1.0000e-30,
         9.9999e-31, -9.9999e-31,  9.9999e-31,  1.0000e-30,  1.0000e-30,
         9.9999e-31,  9.9999e-31,  9.9998e-31,  9.9998e-31, -9.9999e-31,
         9.9999e-31,  9.9998e-31,  9.9996e-31,  9.9998e-31,  9.9997e-31,
         9.9971e-31, -9.9999e-31,  9.9997e-31, -9.9999e-31,  9.9999e-31,
        -1.0000e-30, -9.9996e-31,  9.9928e-31,  9.9999e-31, -9.9998e-31,
         9.9999e-31,  9.9999e-31, -9.9999e-31, -9.9998e-31])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



Enter Reward: 1
Policy reward
None
Session Number: 2
images/435
(64, 64, 3)
tensor([[0.0362, 0.0316, 0.0129, 0.0136, 0.0265, 0.0292, 0.0337, 0.0131, 0.0155,
         0.0251, 0.0282, 0.0397, 0.0325, 0.0327, 0.0183, 0.0227, 0.0269, 0.0368,
         0.0169, 0.0179, 0.0192, 0.0209, 0.0236, 0.0348, 0.0156, 0.0160, 0.0373,
         0.0238, 0.0454, 0.0162, 0.0240, 0.0220, 0.0307, 0.0295, 0.0238, 0.0295,
         0.0283, 0.0174, 0.0167, 0.0155]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([-1.8788e-30,  1.9835e-30,  1.7992e-30,  1.8087e-30,  1.9540e-30,
         1.8007e-30, -1.9785e-30,  1.9494e-30, -1.1066e-30, -1.9606e-30,
         1.1691e-30, -9.5571e-31, -1.6645e-30, -8.6232e-31,  1.9986e-30,
        -8.3570e-31, -1.9761e-30, -1.8813e-30,  6.0830e-31,  1.6413e-30,
        -1.5020e-30,  1.7720e-30,  1.4387e-30, -4.0322e-31, -1.0790e-30,
         1.9292e-30, -1.1010e-30, -2.7269e-31,  1.9126e-30, -1.5330e-30,
        -1.9702e-30,  9.6588e-31])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([ 1.7323e-30,  1.4571e-30,  1.9976e-30,  9.7363e-31,  1.0589e-30,
        -4.4088e-31, -1.9776e-30, -1.2818e-30,  6.1851e-31, -1.7675e-30,
         1.8664e-30,  1.9644e-30, -1.9982e-30, -1.9980e-30,  1.1840e-30,
         1.8701e-30,  1.9384e-30,  9.4658e-31,  1.1705e-30, -1.9906e-30,
        -1.8783e-30,  1.7383e-30, -1.7417e-30, -1.3520e-30,  1.6166e-30,
        -1.5289e-30, -1.6843e-30, -1.3472e-30,  1.4848e-30, -1.5630e-30,
        -1.6846e-30,  8.9554e-31])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([ 1.7324e-30, -1.9902e-30,  1.3694e-30, -1.8515e-30, -6.0307e-31,
         1.7529e-30, -1.8907e-30, -1.9033e-30, -1.5624e-30, -2.9182e-31,
         5.7371e-31,  1.8873e-30, -7.0157e-31, -1.7238e-30, -1.9398e-30,
         1.9195e-30,  1.5579e-30, -1.5473e-30, -7.7380e-31, -1.2963e-30,
        -3.3709e-31, -1.9291e-30, -1.1691e-30, -1.4210e-30, -9.7074e-31,
        -1.6415e-30, -7.9204e-31,  3.2032e-31, -1.9913e-30, -3.7452e-31,
         1.9105e-30,  1.8250e-30, -1.6914e-30,  1.9694e-30, -1.2260e-30,
        -1.8429e-30,  6.4446e-31,  7.5713e-31,  1.9787e-30,  1.9266e-30,
         1.6952e-30, -1.9961e-30,  1.9738e-30,  1.7374e-30, -1.9947e-30,
         2.0005e-30, -7.8980e-31,  6.6025e-31, -8.5635e-31, -1.5972e-30,
        -1.3744e-30,  1.6757e-30,  7.0107e-31, -2.0013e-30,  1.9851e-30,
         9.8850e-31, -1.7908e-30,  1.9137e-30, -2.4400e-31,  4.8869e-31,
        -1.9833e-30,  8.6237e-31,  1.9856e-30,  1.4972e-30])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([ 1.9344e-30, -1.6137e-30, -1.9851e-30, -5.3376e-31, -1.7995e-30,
        -2.8341e-31, -1.9978e-30, -9.5274e-31,  2.0012e-30, -1.9024e-30,
         2.0012e-30,  1.9678e-30, -1.7058e-30, -1.5234e-30,  5.5611e-31,
         1.2762e-30, -8.8018e-31, -6.2578e-31,  1.9960e-30, -1.8154e-30,
         1.2077e-30, -9.3978e-31,  1.9034e-30,  1.7709e-30,  1.9994e-30,
        -3.3082e-31,  5.7539e-31,  1.9965e-30, -1.9906e-30, -6.0107e-31,
         3.5017e-31,  1.0280e-30, -1.7826e-30,  6.9880e-31,  1.7836e-30,
         1.5617e-30, -1.9774e-30, -6.1323e-31,  1.7108e-30, -1.3473e-30,
        -1.8331e-30,  1.9738e-30,  1.7323e-30,  1.7981e-30, -1.9674e-30,
         8.0077e-31, -1.2216e-30,  1.9404e-30,  9.6180e-31, -1.8558e-30,
        -6.0987e-31,  1.4407e-30,  8.6594e-31, -1.9612e-30,  1.7911e-30,
        -7.7268e-31, -7.9199e-31,  1.5667e-30,  9.4884e-31, -1.2954e-30,
        -5.9895e-31,  8.0639e-31, -1.2938e-30, -1.4097e-30])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([-1.4014e-30,  1.0830e-30,  1.7154e-30, -1.9426e-30,  4.2507e-31,
        -1.7648e-30, -6.1162e-31,  1.9926e-30,  4.2119e-31,  1.7475e-30,
        -1.3958e-30, -1.4073e-30,  5.5396e-31, -1.5336e-30,  1.0039e-30,
        -1.9831e-30,  1.9562e-30,  1.9275e-30, -1.9191e-30, -3.9660e-31,
        -6.1868e-31, -1.9074e-30,  1.9343e-30, -6.7957e-31,  1.6151e-30,
         1.8236e-30, -1.9892e-30,  1.8401e-30,  1.2138e-30, -9.9022e-31,
        -1.0775e-30,  1.7723e-30,  1.9828e-30, -1.8778e-30,  1.8634e-30,
         1.9169e-30, -9.1485e-31,  1.9293e-30, -1.5052e-30,  1.1854e-30,
        -4.3266e-31, -1.7870e-30, -5.7360e-31, -5.4735e-31, -9.4629e-31,
        -2.6968e-31,  6.6341e-31,  4.7977e-31,  1.7621e-30, -1.2917e-30,
         1.9539e-30, -1.9150e-30, -1.2313e-30,  9.5212e-31, -1.9974e-30,
         6.1608e-31,  1.9107e-30,  5.0848e-31, -1.9990e-30,  1.9265e-30,
        -5.7690e-31,  1.0557e-30,  1.3157e-30,  1.9109e-30])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([ 1.9969e-30, -1.5659e-30,  1.9225e-30,  1.7818e-30,  1.7600e-30,
         1.9408e-30, -1.7170e-30,  4.1691e-31, -1.9654e-30,  1.7949e-30,
        -7.5904e-31, -1.5118e-30,  1.6045e-30,  4.5980e-31,  3.8385e-31,
        -8.0425e-31,  1.3568e-30,  1.2428e-30, -1.9968e-30, -2.7083e-31,
        -1.7106e-30, -1.9749e-30, -1.9985e-30,  1.8132e-30, -5.4713e-31,
        -1.8566e-30, -5.9124e-31,  1.4739e-30,  2.7813e-31,  1.9386e-30,
         1.9549e-30,  1.3329e-30, -1.6411e-30,  4.7620e-31, -1.8471e-30,
         1.9699e-30, -1.9873e-30,  1.9328e-30,  1.6342e-30,  1.4734e-30,
         9.7099e-31,  1.4871e-30,  1.7267e-30,  1.3260e-30, -6.8525e-31,
         1.8357e-30,  1.9923e-30,  2.0012e-30,  1.9124e-30,  3.5498e-31,
         1.7759e-30, -1.9926e-30,  3.3815e-31, -1.7388e-30,  1.9762e-30,
        -1.8104e-30, -1.9625e-30,  1.7554e-30,  1.1576e-30, -3.8337e-31,
         2.0011e-30,  1.3157e-30, -2.0003e-30, -2.0011e-30])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



Enter Reward: 0
Policy reward
None
Session Number: 3
images/458
(64, 64, 3)
tensor([[0.0203, 0.0232, 0.0152, 0.0256, 0.0308, 0.0204, 0.0270, 0.0159, 0.0300,
         0.0095, 0.0354, 0.0276, 0.0456, 0.0387, 0.0248, 0.0184, 0.0190, 0.0395,
         0.0180, 0.0277, 0.0153, 0.0217, 0.0168, 0.0139, 0.0193, 0.0146, 0.0236,
         0.0503, 0.0286, 0.0231, 0.0183, 0.0145, 0.0298, 0.0389, 0.0313, 0.0277,
         0.0293, 0.0287, 0.0190, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Weights 


layer1.0.weight tensor([[[[-0.0456, -0.1133,  0.0550,  0.0423, -0.0632],
          [ 0.0644,  0.0885,  0.0204,  0.1113,  0.0174],
          [-0.0014, -0.1110, -0.0450,  0.1113, -0.0890],
          [ 0.0609, -0.0475,  0.1152,  0.0048, -0.0325],
          [-0.0263,  0.0712, -0.0490,  0.0129, -0.0703]],

         [[ 0.0935, -0.0633,  0.0159, -0.0320,  0.0050],
          [-0.0845,  0.0340,  0.0174, -0.0934,  0.0762],
          [ 0.0808,  0.0613, -0.0972,  0.0826, -0.1120],
          [-0.0567,  0.0963, -0.0455, -0.0740, -0.0824],
          [-0.0462,  0.0170, -0.0163, -0.0038, -0.0370]],

         [[-0.0705, -0.0845, -0.0711, -0.0028, -0.0829],
          [ 0.1107,  0.0418,  0.0826, -0.0785,  0.1083],
          [ 0.0597,  0.0571,  0.0515, -0.0129, -0.0351],
          [-0.0589,  0.0979, -0.0397, -0.1065, -0.1023],
          [ 0.1142, -0.0192,  0.0441, -0.0939,  0.0759]]],


        [[[ 0.0160, -0.0309,  0.0778,  0.0202, -0.0672],
          [ 0.0737,  0.0164, -0.0457,  0.0408, -0.0978],
          [ 0.0599, -0.0611,  0.0809, -0.0205,  0.0740],
          [ 0.0950,  0.0035,  0.0691,  0.0345, -0.1119],
          [-0.1050,  0.0504, -0.0286, -0.0730, -0.0359]],

         [[-0.0652, -0.0380,  0.1042, -0.0397,  0.0704],
          [-0.0355, -0.0362,  0.0787, -0.0567, -0.1081],
          [-0.1134, -0.0369,  0.0533,  0.0044, -0.1067],
          [-0.0607, -0.0155, -0.0854, -0.0645, -0.0517],
          [ 0.0468,  0.0397,  0.0674, -0.1101, -0.0196]],

         [[-0.0801,  0.0317,  0.0330, -0.1118, -0.0212],
          [-0.1023, -0.0123, -0.0014,  0.0093, -0.0377],
          [ 0.0788,  0.1112,  0.0208,  0.0597,  0.0215],
          [ 0.0516, -0.0124,  0.0171, -0.0043, -0.0142],
          [-0.0335,  0.0977, -0.0129, -0.0395,  0.0858]]],


        [[[ 0.1113,  0.0742,  0.0276,  0.0125,  0.0402],
          [-0.0024, -0.0456,  0.1107,  0.0360, -0.0560],
          [ 0.0288, -0.0539,  0.0781, -0.1001,  0.0302],
          [ 0.0144, -0.0984, -0.0354,  0.0546, -0.0830],
          [-0.0693,  0.0924, -0.0970,  0.0221, -0.0657]],

         [[ 0.0026, -0.0856, -0.0951, -0.0566, -0.0660],
          [-0.0029,  0.0043,  0.0485,  0.0330,  0.1032],
          [ 0.0128, -0.0230, -0.0671, -0.1006, -0.1133],
          [-0.0442, -0.0711,  0.0409,  0.0951, -0.0663],
          [ 0.0002,  0.0449, -0.1099,  0.0274,  0.0217]],

         [[-0.0199,  0.0789,  0.0860,  0.0288,  0.0630],
          [ 0.0411, -0.0228,  0.0759,  0.0091,  0.0133],
          [ 0.0383, -0.0306, -0.0499, -0.0137, -0.0808],
          [ 0.0108,  0.0271, -0.0496,  0.0151, -0.0451],
          [-0.1019,  0.0738, -0.0711, -0.1145,  0.0075]]],


        ...,


        [[[-0.0789, -0.0860,  0.0481, -0.1090,  0.0813],
          [-0.0337,  0.0079,  0.0280, -0.0586,  0.0423],
          [ 0.0032,  0.0739,  0.0603, -0.1105, -0.0387],
          [ 0.0519, -0.0681,  0.0461,  0.1048, -0.1038],
          [-0.0001, -0.0609,  0.0387,  0.0415,  0.0752]],

         [[ 0.0103, -0.0365, -0.0618,  0.0544, -0.0846],
          [-0.0430,  0.0050, -0.0538, -0.0708,  0.0696],
          [ 0.0325,  0.0964, -0.1073,  0.0450, -0.0104],
          [-0.0737,  0.0262,  0.0996,  0.0746, -0.0582],
          [ 0.0175,  0.0336, -0.0540, -0.0008, -0.0428]],

         [[ 0.0224,  0.1045, -0.0336, -0.0939, -0.0440],
          [ 0.0036, -0.0210, -0.0545, -0.0503, -0.0993],
          [ 0.0229,  0.0371,  0.1027, -0.0541,  0.0266],
          [ 0.0101, -0.0393, -0.0525, -0.0336,  0.1058],
          [ 0.0592,  0.0505, -0.1079, -0.0636, -0.0992]]],


        [[[-0.0450,  0.1079,  0.0211, -0.1006, -0.0705],
          [ 0.0623,  0.0284, -0.0419,  0.0299, -0.0216],
          [ 0.0430, -0.0722,  0.0513, -0.1028, -0.0942],
          [ 0.0315,  0.0206, -0.1155, -0.0419,  0.0168],
          [-0.0728, -0.0716, -0.0948, -0.0661,  0.0904]],

         [[ 0.1099, -0.0034, -0.0661, -0.0521,  0.0285],
          [ 0.1037,  0.1048,  0.0340, -0.0215, -0.0203],
          [-0.1055, -0.1066, -0.0997,  0.1057,  0.0318],
          [ 0.0784, -0.0944, -0.0081,  0.0013,  0.0670],
          [-0.1035, -0.0856,  0.0551, -0.1075,  0.0177]],

         [[ 0.1046, -0.1147, -0.0595,  0.1083, -0.0095],
          [ 0.0155, -0.1120,  0.0309, -0.0903,  0.0681],
          [ 0.0594,  0.0213, -0.0000, -0.0496,  0.0533],
          [-0.0221,  0.0038,  0.0422, -0.0226, -0.1146],
          [ 0.0069,  0.0367,  0.0777,  0.0338,  0.0909]]],


        [[[-0.0778, -0.0505,  0.0068,  0.0961,  0.0676],
          [-0.0840,  0.0765,  0.0891,  0.0597, -0.0346],
          [-0.0488,  0.1045, -0.0738,  0.0396, -0.0004],
          [ 0.0996,  0.0074, -0.0960, -0.0481, -0.0195],
          [ 0.0839, -0.0616, -0.0312, -0.0922, -0.0051]],

         [[-0.0126, -0.0677,  0.0487,  0.1052,  0.0104],
          [ 0.0137,  0.0697,  0.0212,  0.0735,  0.0734],
          [ 0.0874,  0.0420,  0.0715, -0.0700,  0.0490],
          [ 0.0397, -0.0414, -0.1006, -0.0157, -0.0944],
          [ 0.0598,  0.0315, -0.0746, -0.1067,  0.0556]],

         [[ 0.0745, -0.1121, -0.0992,  0.0988,  0.0222],
          [ 0.0836,  0.0265,  0.1039, -0.1047, -0.0521],
          [ 0.1083, -0.0115,  0.0848,  0.0677, -0.0966],
          [ 0.1110,  0.0927, -0.0052, -0.0932, -0.0547],
          [-0.0763, -0.0199,  0.0217,  0.0288, -0.0101]]]])
layer1.0.bias tensor([-0.0724,  0.0123, -0.0237,  0.0210,  0.0294,  0.0892, -0.0819, -0.0652,
         0.1030,  0.0744,  0.0907,  0.0424,  0.0145, -0.0604,  0.0165, -0.0167,
         0.0847, -0.0057, -0.0488, -0.0863,  0.0880, -0.0476,  0.0925, -0.0741,
        -0.0964, -0.0846, -0.0612, -0.0718,  0.0614,  0.0037,  0.0680,  0.0777])
layer1.1.weight tensor([0.2535, 0.7801, 0.8525, 0.2406, 0.1452, 0.8986, 0.7948, 0.5587, 0.9167,
        0.3437, 0.8150, 0.4594, 0.1066, 0.2704, 0.8498, 0.0309, 0.4777, 0.3139,
        0.7061, 0.3526, 0.7230, 0.2288, 0.6266, 0.4926, 0.6451, 0.8385, 0.4773,
        0.7575, 0.8093, 0.3932, 0.8076, 0.3142])
layer1.1.bias tensor([-2.5581e-30,  2.7438e-30,  2.4170e-30,  2.4338e-30,  2.6914e-30,
         2.4196e-30, -2.7350e-30,  2.6833e-30, -1.1890e-30, -2.7032e-30,
         1.2999e-30, -9.2147e-31, -2.1781e-30, -7.5589e-31,  2.7706e-30,
        -7.0870e-31, -2.7307e-30, -2.5626e-30,  3.0552e-31,  2.1370e-30,
        -1.8901e-30,  2.3688e-30,  1.7778e-30,  5.8094e-32, -1.1400e-30,
         2.6475e-30, -1.1791e-30,  2.8944e-31,  2.6180e-30, -1.9450e-30,
        -2.7201e-30,  9.3950e-31])
layer1.3.weight tensor([[[[-0.0144, -0.0187, -0.0172,  0.0008, -0.0262],
          [-0.0005,  0.0088,  0.0253,  0.0219, -0.0325],
          [ 0.0249,  0.0087, -0.0027, -0.0070,  0.0160],
          [-0.0293, -0.0095, -0.0325, -0.0025,  0.0216],
          [-0.0049,  0.0002,  0.0307,  0.0330,  0.0041]],

         [[ 0.0241, -0.0275,  0.0216,  0.0134, -0.0140],
          [-0.0141,  0.0162, -0.0352,  0.0230, -0.0015],
          [ 0.0207,  0.0312, -0.0224,  0.0250, -0.0307],
          [-0.0290,  0.0333, -0.0277, -0.0282,  0.0214],
          [ 0.0036, -0.0200, -0.0266,  0.0233,  0.0246]],

         [[-0.0129,  0.0152,  0.0112,  0.0217,  0.0168],
          [ 0.0227,  0.0236,  0.0197, -0.0056, -0.0208],
          [-0.0280, -0.0170,  0.0207,  0.0247,  0.0289],
          [ 0.0182,  0.0130,  0.0147, -0.0024,  0.0340],
          [-0.0255,  0.0146, -0.0225, -0.0024,  0.0147]],

         ...,

         [[ 0.0351,  0.0118, -0.0026,  0.0327, -0.0159],
          [ 0.0284, -0.0146,  0.0268,  0.0171,  0.0020],
          [ 0.0187, -0.0317, -0.0243, -0.0138,  0.0082],
          [ 0.0078,  0.0279,  0.0009, -0.0088, -0.0240],
          [ 0.0256,  0.0086,  0.0051, -0.0338,  0.0303]],

         [[-0.0095, -0.0269,  0.0204,  0.0231, -0.0163],
          [ 0.0052, -0.0130, -0.0269, -0.0078,  0.0167],
          [-0.0129,  0.0046, -0.0260, -0.0236, -0.0227],
          [ 0.0117, -0.0098,  0.0146, -0.0243,  0.0345],
          [ 0.0240,  0.0217, -0.0159, -0.0073, -0.0322]],

         [[-0.0104,  0.0107,  0.0215, -0.0109,  0.0312],
          [-0.0242,  0.0235, -0.0018, -0.0110,  0.0230],
          [ 0.0330,  0.0065,  0.0225,  0.0258,  0.0204],
          [-0.0089,  0.0036,  0.0292, -0.0144,  0.0342],
          [ 0.0272,  0.0295, -0.0217,  0.0266, -0.0167]]],


        [[[ 0.0219, -0.0036, -0.0349, -0.0071, -0.0244],
          [ 0.0134, -0.0291,  0.0026,  0.0138, -0.0014],
          [-0.0278, -0.0203,  0.0133,  0.0317,  0.0195],
          [-0.0207,  0.0074,  0.0077, -0.0044, -0.0275],
          [ 0.0289,  0.0292,  0.0072,  0.0289, -0.0025]],

         [[ 0.0076, -0.0204,  0.0036,  0.0096, -0.0231],
          [ 0.0118, -0.0212, -0.0044, -0.0137,  0.0144],
          [ 0.0165, -0.0214,  0.0264,  0.0182,  0.0053],
          [-0.0331,  0.0167,  0.0353,  0.0050, -0.0260],
          [ 0.0315,  0.0243, -0.0288, -0.0225, -0.0256]],

         [[ 0.0010,  0.0072, -0.0025, -0.0022,  0.0346],
          [ 0.0289, -0.0234,  0.0107, -0.0145,  0.0262],
          [-0.0053,  0.0082,  0.0037, -0.0213,  0.0298],
          [-0.0052,  0.0177, -0.0101, -0.0148,  0.0162],
          [ 0.0281, -0.0008,  0.0105, -0.0268, -0.0242]],

         ...,

         [[ 0.0293, -0.0250, -0.0269,  0.0044,  0.0071],
          [-0.0150,  0.0190,  0.0240,  0.0234,  0.0060],
          [-0.0326, -0.0125,  0.0129, -0.0281,  0.0093],
          [-0.0152, -0.0307, -0.0213,  0.0253,  0.0216],
          [ 0.0154, -0.0314,  0.0337, -0.0226, -0.0008]],

         [[-0.0049, -0.0247, -0.0133, -0.0239, -0.0149],
          [-0.0289,  0.0270,  0.0156,  0.0244, -0.0226],
          [-0.0019,  0.0235,  0.0057, -0.0313, -0.0128],
          [-0.0351,  0.0146, -0.0319, -0.0091, -0.0074],
          [-0.0029,  0.0145,  0.0169, -0.0008, -0.0186]],

         [[-0.0279,  0.0206,  0.0219, -0.0110,  0.0019],
          [ 0.0031,  0.0318,  0.0171,  0.0234,  0.0277],
          [-0.0027,  0.0232, -0.0011, -0.0144,  0.0253],
          [ 0.0229,  0.0255,  0.0290, -0.0187,  0.0087],
          [ 0.0056,  0.0267, -0.0092, -0.0140, -0.0297]]],


        [[[ 0.0153,  0.0220, -0.0130, -0.0211, -0.0146],
          [-0.0164,  0.0091, -0.0219, -0.0079,  0.0236],
          [-0.0002,  0.0273,  0.0304,  0.0310,  0.0287],
          [-0.0059, -0.0230,  0.0161,  0.0140,  0.0056],
          [-0.0151, -0.0225, -0.0244,  0.0008, -0.0143]],

         [[ 0.0163, -0.0346, -0.0040,  0.0195, -0.0271],
          [-0.0256,  0.0253,  0.0189,  0.0200, -0.0106],
          [-0.0181, -0.0199, -0.0057, -0.0265,  0.0007],
          [-0.0240,  0.0164, -0.0273,  0.0257, -0.0133],
          [-0.0319, -0.0281, -0.0067,  0.0246, -0.0057]],

         [[-0.0285,  0.0037,  0.0110,  0.0249,  0.0195],
          [ 0.0004,  0.0180, -0.0071, -0.0306,  0.0194],
          [ 0.0242,  0.0134,  0.0205,  0.0091, -0.0137],
          [ 0.0043, -0.0237, -0.0307, -0.0109,  0.0012],
          [ 0.0111, -0.0202,  0.0128,  0.0088, -0.0282]],

         ...,

         [[ 0.0346,  0.0337,  0.0018, -0.0045, -0.0105],
          [ 0.0155,  0.0337, -0.0098, -0.0353,  0.0255],
          [ 0.0337, -0.0137, -0.0068,  0.0208, -0.0001],
          [ 0.0200, -0.0061,  0.0036,  0.0122,  0.0128],
          [ 0.0275,  0.0068, -0.0314, -0.0214,  0.0099]],

         [[ 0.0311, -0.0042,  0.0230,  0.0112, -0.0139],
          [-0.0335, -0.0088, -0.0081, -0.0302, -0.0342],
          [ 0.0251, -0.0044,  0.0217, -0.0116,  0.0227],
          [ 0.0020, -0.0086, -0.0237, -0.0001, -0.0221],
          [-0.0338, -0.0105,  0.0082, -0.0109,  0.0330]],

         [[-0.0136,  0.0255,  0.0246, -0.0207,  0.0249],
          [ 0.0332, -0.0301, -0.0033, -0.0092, -0.0099],
          [ 0.0228, -0.0277, -0.0119,  0.0279,  0.0108],
          [ 0.0352, -0.0333,  0.0007,  0.0159,  0.0039],
          [ 0.0029, -0.0119, -0.0338,  0.0033, -0.0117]]],


        ...,


        [[[-0.0158,  0.0246, -0.0123, -0.0284,  0.0078],
          [-0.0199,  0.0223, -0.0097, -0.0197,  0.0140],
          [-0.0221,  0.0106,  0.0218,  0.0228,  0.0205],
          [ 0.0255,  0.0120, -0.0315, -0.0187, -0.0236],
          [-0.0345,  0.0039, -0.0243,  0.0294, -0.0236]],

         [[ 0.0114,  0.0176,  0.0078, -0.0128,  0.0312],
          [ 0.0349,  0.0353,  0.0181, -0.0018,  0.0185],
          [ 0.0153, -0.0030,  0.0278, -0.0313, -0.0345],
          [-0.0284,  0.0197,  0.0323,  0.0283,  0.0225],
          [-0.0083,  0.0091,  0.0129,  0.0215, -0.0114]],

         [[ 0.0210,  0.0052,  0.0275, -0.0121, -0.0003],
          [ 0.0109, -0.0165,  0.0186,  0.0024,  0.0180],
          [-0.0214, -0.0049,  0.0298, -0.0048,  0.0150],
          [ 0.0242, -0.0284, -0.0149, -0.0271, -0.0352],
          [-0.0001,  0.0296, -0.0035, -0.0057, -0.0006]],

         ...,

         [[-0.0266,  0.0284, -0.0065, -0.0115,  0.0312],
          [ 0.0022,  0.0208, -0.0117,  0.0154, -0.0069],
          [-0.0207,  0.0214, -0.0028,  0.0213,  0.0198],
          [-0.0226, -0.0251,  0.0098,  0.0148, -0.0015],
          [ 0.0296,  0.0303,  0.0157,  0.0338, -0.0216]],

         [[ 0.0229, -0.0147, -0.0021, -0.0104,  0.0249],
          [-0.0136, -0.0034, -0.0089,  0.0259,  0.0030],
          [-0.0099,  0.0255,  0.0299, -0.0194, -0.0080],
          [-0.0091, -0.0228,  0.0144,  0.0013,  0.0139],
          [-0.0075, -0.0231, -0.0154,  0.0228, -0.0292]],

         [[-0.0342, -0.0265,  0.0188,  0.0337,  0.0312],
          [-0.0283,  0.0118, -0.0351, -0.0162, -0.0183],
          [ 0.0240, -0.0011, -0.0202, -0.0208,  0.0019],
          [ 0.0210,  0.0100,  0.0245, -0.0064, -0.0112],
          [ 0.0123, -0.0047,  0.0247,  0.0077, -0.0294]]],


        [[[ 0.0035, -0.0243, -0.0282,  0.0041,  0.0207],
          [ 0.0083,  0.0269,  0.0252,  0.0270, -0.0050],
          [-0.0060,  0.0136,  0.0016, -0.0041, -0.0297],
          [-0.0154,  0.0114, -0.0347, -0.0244,  0.0062],
          [-0.0310,  0.0215, -0.0057, -0.0198, -0.0034]],

         [[-0.0201,  0.0103,  0.0271, -0.0198, -0.0277],
          [ 0.0144, -0.0228,  0.0224,  0.0188,  0.0038],
          [-0.0316,  0.0344,  0.0150,  0.0005, -0.0154],
          [-0.0117, -0.0246, -0.0229, -0.0284,  0.0266],
          [ 0.0217,  0.0096,  0.0079, -0.0325,  0.0142]],

         [[ 0.0147,  0.0128, -0.0232, -0.0100,  0.0053],
          [-0.0336, -0.0040, -0.0170,  0.0068, -0.0128],
          [-0.0189, -0.0241,  0.0090, -0.0152,  0.0175],
          [-0.0012,  0.0072,  0.0213, -0.0221,  0.0146],
          [-0.0078, -0.0353,  0.0160,  0.0235, -0.0122]],

         ...,

         [[-0.0178, -0.0008, -0.0150,  0.0087,  0.0298],
          [ 0.0178, -0.0159, -0.0240,  0.0160, -0.0014],
          [-0.0194,  0.0298,  0.0114, -0.0226, -0.0130],
          [-0.0216, -0.0301,  0.0067, -0.0297, -0.0205],
          [ 0.0239,  0.0221, -0.0334,  0.0102,  0.0148]],

         [[ 0.0319,  0.0346, -0.0064,  0.0128,  0.0142],
          [ 0.0274, -0.0153,  0.0209, -0.0059,  0.0245],
          [-0.0223,  0.0209, -0.0100,  0.0000,  0.0231],
          [ 0.0335, -0.0046,  0.0213,  0.0084,  0.0190],
          [ 0.0230,  0.0194, -0.0315, -0.0323, -0.0137]],

         [[-0.0350,  0.0025,  0.0157, -0.0016,  0.0215],
          [ 0.0051,  0.0034,  0.0091,  0.0021,  0.0227],
          [-0.0102,  0.0300,  0.0155,  0.0186, -0.0167],
          [ 0.0080, -0.0201, -0.0145, -0.0203, -0.0300],
          [-0.0009, -0.0053, -0.0131, -0.0070,  0.0029]]],


        [[[ 0.0005,  0.0089, -0.0335, -0.0061, -0.0296],
          [ 0.0313,  0.0201, -0.0080, -0.0000,  0.0199],
          [ 0.0273,  0.0173,  0.0217,  0.0277, -0.0077],
          [-0.0149,  0.0038,  0.0335, -0.0009, -0.0063],
          [-0.0176, -0.0050,  0.0140, -0.0009,  0.0177]],

         [[-0.0018,  0.0091,  0.0057,  0.0184,  0.0133],
          [ 0.0056, -0.0014, -0.0217,  0.0177, -0.0342],
          [ 0.0218, -0.0108, -0.0122,  0.0188, -0.0176],
          [-0.0089,  0.0093, -0.0083,  0.0317,  0.0159],
          [-0.0196, -0.0132, -0.0312, -0.0265, -0.0245]],

         [[-0.0130,  0.0322,  0.0232,  0.0347, -0.0258],
          [ 0.0220,  0.0246, -0.0150,  0.0320, -0.0253],
          [-0.0055,  0.0070,  0.0061,  0.0161, -0.0241],
          [ 0.0060,  0.0127, -0.0093,  0.0045,  0.0217],
          [ 0.0087,  0.0272, -0.0314, -0.0043,  0.0349]],

         ...,

         [[-0.0115,  0.0270, -0.0349,  0.0298, -0.0322],
          [-0.0099,  0.0098, -0.0076,  0.0142, -0.0128],
          [ 0.0235, -0.0178,  0.0325, -0.0208, -0.0011],
          [-0.0141,  0.0153,  0.0298, -0.0249,  0.0150],
          [-0.0270, -0.0058, -0.0307, -0.0060,  0.0024]],

         [[-0.0223, -0.0009,  0.0104, -0.0021, -0.0293],
          [ 0.0099, -0.0084, -0.0195, -0.0250,  0.0006],
          [-0.0181,  0.0021, -0.0351,  0.0235, -0.0063],
          [ 0.0115,  0.0200, -0.0027, -0.0295, -0.0248],
          [ 0.0278, -0.0120, -0.0273,  0.0260, -0.0179]],

         [[ 0.0128,  0.0346,  0.0147, -0.0066,  0.0200],
          [-0.0130, -0.0290, -0.0220, -0.0235,  0.0343],
          [ 0.0262, -0.0040, -0.0181, -0.0030, -0.0200],
          [-0.0062,  0.0305,  0.0204,  0.0177, -0.0288],
          [ 0.0021,  0.0293, -0.0027, -0.0149,  0.0004]]]])
layer1.3.bias tensor([-0.0079, -0.0326,  0.0082, -0.0178,  0.0262,  0.0148,  0.0316, -0.0312,
         0.0274,  0.0219, -0.0300, -0.0052,  0.0241,  0.0347,  0.0128, -0.0006,
         0.0215, -0.0178,  0.0237,  0.0189, -0.0333, -0.0293,  0.0349, -0.0260,
        -0.0165, -0.0167, -0.0249,  0.0172,  0.0005,  0.0337, -0.0040, -0.0267])
layer1.4.weight tensor([0.3738, 0.8346, 0.8213, 0.3043, 0.2221, 0.9739, 0.4659, 0.8179, 0.4287,
        0.7754, 0.7725, 0.4807, 0.3301, 0.2868, 0.7218, 0.9722, 0.7245, 0.6921,
        0.0101, 0.8549, 0.3666, 0.6831, 0.9997, 0.4221, 0.3251, 0.1580, 0.1443,
        0.9227, 0.1744, 0.1481, 0.5509, 0.8323])
layer1.4.bias tensor([ 2.2984e-30,  1.8105e-30,  2.7688e-30,  9.5325e-31,  1.1045e-30,
        -8.9268e-33, -2.7333e-30, -1.4997e-30,  3.2362e-31, -2.3611e-30,
         2.5361e-30,  2.7098e-30, -2.7699e-30, -2.7694e-30,  1.3263e-30,
         2.5428e-30,  2.6637e-30,  9.0531e-31,  1.3022e-30, -2.7563e-30,
        -2.5572e-30,  2.3090e-30, -2.3150e-30, -1.6241e-30,  2.0933e-30,
        -1.9378e-30, -2.2133e-30, -1.6155e-30,  1.8596e-30, -1.9982e-30,
        -2.2139e-30,  8.1480e-31])
layer2.0.weight tensor([[[[ 0.0307, -0.0222,  0.0128, -0.0269,  0.0110],
          [-0.0192, -0.0040, -0.0049, -0.0023,  0.0150],
          [ 0.0262, -0.0310,  0.0010,  0.0302, -0.0132],
          [ 0.0212,  0.0300,  0.0216,  0.0070,  0.0232],
          [ 0.0023,  0.0132,  0.0161, -0.0037, -0.0010]],

         [[ 0.0298, -0.0185, -0.0156, -0.0159, -0.0317],
          [-0.0011,  0.0113,  0.0283,  0.0207,  0.0299],
          [-0.0209, -0.0129, -0.0225,  0.0052,  0.0095],
          [-0.0336,  0.0235,  0.0324, -0.0100, -0.0075],
          [-0.0162,  0.0023,  0.0271, -0.0162, -0.0032]],

         [[-0.0351, -0.0242,  0.0319,  0.0285,  0.0170],
          [ 0.0224,  0.0222,  0.0146,  0.0306, -0.0004],
          [ 0.0247,  0.0260,  0.0343,  0.0258,  0.0352],
          [-0.0239,  0.0086, -0.0087, -0.0266,  0.0307],
          [ 0.0139, -0.0087, -0.0037, -0.0260, -0.0102]],

         ...,

         [[-0.0049,  0.0252, -0.0027, -0.0137,  0.0230],
          [-0.0123,  0.0255,  0.0256, -0.0077, -0.0078],
          [-0.0307,  0.0277,  0.0152,  0.0314,  0.0287],
          [ 0.0189,  0.0229,  0.0291,  0.0158, -0.0015],
          [ 0.0258, -0.0302,  0.0038, -0.0074, -0.0088]],

         [[-0.0051, -0.0111,  0.0325,  0.0193,  0.0015],
          [-0.0121, -0.0216, -0.0265, -0.0156,  0.0265],
          [ 0.0125,  0.0028, -0.0054,  0.0078,  0.0051],
          [ 0.0203,  0.0314,  0.0010, -0.0323,  0.0258],
          [-0.0134, -0.0281,  0.0323,  0.0015, -0.0150]],

         [[ 0.0303,  0.0043, -0.0125,  0.0217, -0.0353],
          [ 0.0215,  0.0031,  0.0072,  0.0178,  0.0166],
          [-0.0320, -0.0158, -0.0291,  0.0245,  0.0020],
          [ 0.0253, -0.0246,  0.0198,  0.0339, -0.0093],
          [-0.0301,  0.0200,  0.0190,  0.0253,  0.0059]]],


        [[[ 0.0015,  0.0036, -0.0192,  0.0330,  0.0182],
          [-0.0084,  0.0307,  0.0146, -0.0259, -0.0067],
          [ 0.0158,  0.0111,  0.0004, -0.0269, -0.0094],
          [-0.0058,  0.0306, -0.0206,  0.0266, -0.0172],
          [-0.0062, -0.0014,  0.0008,  0.0213,  0.0187]],

         [[ 0.0183,  0.0079, -0.0123, -0.0054, -0.0180],
          [ 0.0065, -0.0094,  0.0120, -0.0337,  0.0110],
          [-0.0136,  0.0087,  0.0184, -0.0247, -0.0211],
          [ 0.0147, -0.0104, -0.0026,  0.0083,  0.0191],
          [-0.0150, -0.0099, -0.0166, -0.0271,  0.0295]],

         [[ 0.0157, -0.0265,  0.0228,  0.0091,  0.0259],
          [ 0.0182,  0.0147,  0.0037, -0.0139,  0.0249],
          [ 0.0133,  0.0103,  0.0030,  0.0237, -0.0214],
          [-0.0118,  0.0324,  0.0204, -0.0330,  0.0069],
          [ 0.0013, -0.0129, -0.0351,  0.0186, -0.0302]],

         ...,

         [[ 0.0244, -0.0267, -0.0032, -0.0248,  0.0296],
          [ 0.0347,  0.0030, -0.0054, -0.0083,  0.0029],
          [ 0.0226,  0.0010, -0.0289, -0.0164, -0.0159],
          [-0.0340, -0.0155,  0.0257, -0.0349,  0.0053],
          [-0.0040, -0.0245, -0.0291,  0.0338, -0.0266]],

         [[-0.0293,  0.0346, -0.0148,  0.0092,  0.0063],
          [-0.0068, -0.0273,  0.0321,  0.0071, -0.0330],
          [-0.0254,  0.0069, -0.0343, -0.0079,  0.0210],
          [-0.0157,  0.0010,  0.0048, -0.0314, -0.0159],
          [ 0.0230, -0.0240, -0.0191, -0.0301, -0.0062]],

         [[-0.0102, -0.0068,  0.0222,  0.0106, -0.0094],
          [-0.0298,  0.0007, -0.0086, -0.0005,  0.0236],
          [ 0.0101, -0.0274, -0.0317,  0.0079, -0.0087],
          [-0.0046,  0.0129,  0.0048,  0.0078,  0.0197],
          [-0.0055, -0.0220,  0.0092,  0.0178, -0.0093]]],


        [[[-0.0210,  0.0074,  0.0050, -0.0028,  0.0158],
          [ 0.0014, -0.0054,  0.0204, -0.0328,  0.0153],
          [-0.0005,  0.0030,  0.0252,  0.0064, -0.0240],
          [ 0.0129,  0.0279, -0.0332, -0.0126, -0.0208],
          [ 0.0047, -0.0199,  0.0139,  0.0159,  0.0082]],

         [[-0.0220,  0.0002, -0.0321, -0.0288, -0.0138],
          [-0.0046,  0.0272,  0.0030,  0.0250, -0.0184],
          [ 0.0153, -0.0265,  0.0211,  0.0167, -0.0144],
          [-0.0245, -0.0205,  0.0204,  0.0329, -0.0051],
          [ 0.0265,  0.0210,  0.0314,  0.0089,  0.0183]],

         [[ 0.0167, -0.0335, -0.0045, -0.0213,  0.0215],
          [-0.0351,  0.0236, -0.0219,  0.0197, -0.0166],
          [-0.0063,  0.0187, -0.0298,  0.0050, -0.0287],
          [ 0.0142, -0.0177, -0.0186,  0.0204, -0.0336],
          [ 0.0351,  0.0136,  0.0262,  0.0024,  0.0056]],

         ...,

         [[-0.0018, -0.0002,  0.0089, -0.0108, -0.0044],
          [-0.0078,  0.0272,  0.0299, -0.0112, -0.0074],
          [-0.0301,  0.0199, -0.0060,  0.0121, -0.0350],
          [ 0.0068,  0.0041,  0.0307,  0.0088, -0.0310],
          [ 0.0198, -0.0283,  0.0133, -0.0086,  0.0282]],

         [[-0.0223,  0.0179,  0.0340, -0.0312,  0.0275],
          [ 0.0213, -0.0256, -0.0008,  0.0042,  0.0116],
          [ 0.0216,  0.0007,  0.0234,  0.0022,  0.0115],
          [-0.0047,  0.0122,  0.0050,  0.0268,  0.0165],
          [-0.0005,  0.0109, -0.0124, -0.0056,  0.0341]],

         [[ 0.0041,  0.0277,  0.0035, -0.0346, -0.0105],
          [-0.0267,  0.0207, -0.0033,  0.0102, -0.0104],
          [-0.0072,  0.0252, -0.0116, -0.0072, -0.0095],
          [-0.0039,  0.0154,  0.0171, -0.0228, -0.0272],
          [-0.0239,  0.0161,  0.0000, -0.0262, -0.0250]]],


        ...,


        [[[-0.0093, -0.0190, -0.0252,  0.0278,  0.0218],
          [-0.0270, -0.0082, -0.0197, -0.0341,  0.0314],
          [-0.0077,  0.0180, -0.0022,  0.0078, -0.0025],
          [-0.0002,  0.0144, -0.0274,  0.0205,  0.0109],
          [ 0.0236,  0.0239, -0.0300,  0.0007, -0.0257]],

         [[ 0.0046, -0.0313, -0.0262, -0.0138, -0.0048],
          [-0.0272, -0.0350,  0.0068,  0.0330,  0.0232],
          [ 0.0309,  0.0255,  0.0330,  0.0096, -0.0101],
          [-0.0140, -0.0347,  0.0113, -0.0235,  0.0352],
          [-0.0011,  0.0238, -0.0337, -0.0008,  0.0146]],

         [[ 0.0136, -0.0138, -0.0197, -0.0342,  0.0166],
          [ 0.0229, -0.0166,  0.0352,  0.0273, -0.0305],
          [ 0.0239,  0.0052, -0.0343,  0.0327, -0.0171],
          [-0.0087,  0.0174, -0.0021,  0.0288, -0.0321],
          [ 0.0225, -0.0307, -0.0116,  0.0283,  0.0195]],

         ...,

         [[ 0.0334,  0.0207, -0.0231,  0.0159, -0.0289],
          [ 0.0001,  0.0145,  0.0264, -0.0246, -0.0095],
          [-0.0006, -0.0129, -0.0250, -0.0302, -0.0241],
          [-0.0106, -0.0312,  0.0067,  0.0137,  0.0262],
          [ 0.0021,  0.0002, -0.0262, -0.0018,  0.0205]],

         [[ 0.0080,  0.0193, -0.0312, -0.0201,  0.0303],
          [ 0.0111,  0.0049, -0.0112,  0.0232, -0.0056],
          [-0.0001,  0.0271,  0.0247, -0.0057,  0.0248],
          [-0.0248, -0.0251,  0.0280,  0.0189, -0.0240],
          [ 0.0163, -0.0147,  0.0060, -0.0273,  0.0041]],

         [[-0.0089,  0.0217, -0.0347,  0.0215,  0.0288],
          [-0.0132,  0.0016,  0.0004, -0.0254,  0.0261],
          [ 0.0183,  0.0202, -0.0171, -0.0306, -0.0079],
          [ 0.0207, -0.0298, -0.0143,  0.0248,  0.0144],
          [-0.0195, -0.0043,  0.0193, -0.0156,  0.0036]]],


        [[[ 0.0294, -0.0181, -0.0060, -0.0313,  0.0044],
          [ 0.0261, -0.0286, -0.0035, -0.0008,  0.0203],
          [ 0.0238,  0.0158,  0.0131,  0.0199, -0.0123],
          [ 0.0152,  0.0261,  0.0087, -0.0268, -0.0222],
          [-0.0017, -0.0142, -0.0003,  0.0116, -0.0290]],

         [[-0.0228,  0.0146, -0.0340,  0.0086, -0.0261],
          [ 0.0147, -0.0170,  0.0019, -0.0213, -0.0191],
          [-0.0004, -0.0189,  0.0195, -0.0037, -0.0129],
          [-0.0298,  0.0282, -0.0346,  0.0149, -0.0082],
          [ 0.0294,  0.0269,  0.0292, -0.0275, -0.0288]],

         [[ 0.0325,  0.0145,  0.0247, -0.0117,  0.0179],
          [-0.0137, -0.0135, -0.0112, -0.0290, -0.0308],
          [ 0.0269, -0.0244,  0.0021, -0.0152,  0.0327],
          [-0.0099, -0.0069,  0.0034,  0.0124, -0.0021],
          [ 0.0042,  0.0251,  0.0216,  0.0112,  0.0265]],

         ...,

         [[-0.0150,  0.0211,  0.0213, -0.0291, -0.0022],
          [ 0.0068, -0.0040, -0.0112,  0.0300,  0.0048],
          [-0.0211, -0.0317,  0.0271, -0.0036, -0.0235],
          [-0.0260,  0.0323, -0.0090,  0.0222,  0.0051],
          [ 0.0279, -0.0311,  0.0114, -0.0147,  0.0036]],

         [[-0.0233, -0.0217, -0.0120, -0.0208,  0.0180],
          [ 0.0091, -0.0239,  0.0107,  0.0092,  0.0207],
          [-0.0248,  0.0284,  0.0034,  0.0116, -0.0148],
          [-0.0324,  0.0268,  0.0336, -0.0098, -0.0117],
          [ 0.0249, -0.0119, -0.0135,  0.0139, -0.0246]],

         [[-0.0075,  0.0315,  0.0307,  0.0226, -0.0337],
          [ 0.0196, -0.0048, -0.0219,  0.0332, -0.0002],
          [-0.0235,  0.0262,  0.0321,  0.0079,  0.0317],
          [ 0.0190,  0.0287, -0.0006,  0.0199,  0.0197],
          [-0.0078,  0.0260,  0.0340, -0.0191, -0.0232]]],


        [[[ 0.0330,  0.0045,  0.0006, -0.0164,  0.0052],
          [-0.0238,  0.0021, -0.0127, -0.0344, -0.0240],
          [ 0.0184, -0.0147,  0.0331, -0.0073, -0.0165],
          [-0.0151, -0.0195,  0.0005, -0.0160, -0.0194],
          [-0.0138, -0.0249,  0.0097, -0.0075, -0.0057]],

         [[-0.0346,  0.0109,  0.0127,  0.0219, -0.0032],
          [-0.0087,  0.0192,  0.0000,  0.0176, -0.0082],
          [ 0.0033,  0.0151,  0.0291,  0.0331,  0.0278],
          [ 0.0130, -0.0000,  0.0245,  0.0201, -0.0196],
          [-0.0167,  0.0333,  0.0050,  0.0300,  0.0323]],

         [[ 0.0240, -0.0303,  0.0328, -0.0125, -0.0017],
          [ 0.0301,  0.0234, -0.0254,  0.0193,  0.0120],
          [-0.0147,  0.0215,  0.0090,  0.0193, -0.0203],
          [ 0.0267, -0.0153, -0.0090,  0.0051, -0.0143],
          [-0.0147,  0.0072,  0.0002,  0.0133, -0.0238]],

         ...,

         [[-0.0295,  0.0008,  0.0137, -0.0311,  0.0133],
          [ 0.0137,  0.0168, -0.0257, -0.0319, -0.0068],
          [ 0.0168,  0.0210, -0.0311,  0.0145, -0.0162],
          [-0.0328,  0.0328,  0.0020,  0.0197, -0.0101],
          [ 0.0204,  0.0293, -0.0349,  0.0201,  0.0259]],

         [[-0.0327, -0.0047, -0.0026,  0.0210, -0.0226],
          [-0.0079, -0.0271, -0.0004, -0.0189,  0.0175],
          [ 0.0068,  0.0206,  0.0132,  0.0257, -0.0152],
          [-0.0176,  0.0009, -0.0278,  0.0056,  0.0110],
          [ 0.0058,  0.0161, -0.0322, -0.0222,  0.0110]],

         [[-0.0223, -0.0261,  0.0259,  0.0061, -0.0334],
          [ 0.0077,  0.0021,  0.0262, -0.0001,  0.0330],
          [ 0.0150, -0.0340,  0.0064,  0.0095,  0.0250],
          [ 0.0148,  0.0276,  0.0071, -0.0225, -0.0336],
          [ 0.0078,  0.0346,  0.0072,  0.0080,  0.0323]]]])
layer2.0.bias tensor([ 0.0167, -0.0184, -0.0322,  0.0017,  0.0236, -0.0178,  0.0208, -0.0087,
        -0.0280,  0.0030, -0.0066, -0.0031,  0.0073,  0.0086, -0.0099, -0.0147,
        -0.0316, -0.0195, -0.0204, -0.0054,  0.0196,  0.0252,  0.0093,  0.0083,
        -0.0074,  0.0316,  0.0278, -0.0241,  0.0323,  0.0035, -0.0014, -0.0027,
        -0.0103,  0.0075, -0.0301,  0.0162,  0.0228,  0.0289,  0.0253, -0.0095,
         0.0279, -0.0329,  0.0261, -0.0305,  0.0003, -0.0185, -0.0058, -0.0253,
        -0.0162, -0.0312,  0.0084,  0.0096, -0.0229,  0.0146,  0.0239, -0.0142,
        -0.0149, -0.0267, -0.0166,  0.0334,  0.0304, -0.0025,  0.0118, -0.0341])
layer2.1.weight tensor([0.7634, 0.6903, 0.9783, 0.7645, 0.1639, 0.5906, 0.4563, 0.7787, 0.9635,
        0.6630, 0.4893, 0.8946, 0.7858, 0.8982, 0.1628, 0.4599, 0.5718, 0.0979,
        0.7927, 0.8259, 0.2506, 0.1767, 0.3473, 0.7037, 0.5928, 0.8491, 0.9814,
        0.5961, 0.9656, 0.8445, 0.4547, 0.8426, 0.3454, 0.3746, 0.0256, 0.7460,
        0.6300, 0.9143, 0.3080, 0.6978, 0.4003, 0.6970, 0.8045, 0.7076, 0.3737,
        0.1629, 0.9879, 0.7409, 0.5202, 0.6984, 0.7130, 0.7153, 0.6532, 0.1171,
        0.1794, 0.7608, 0.6452, 0.4770, 0.5995, 0.1197, 0.0483, 0.7192, 0.6191,
        0.1163])
layer2.1.bias tensor([ 2.2985e-30, -2.7556e-30,  1.6550e-30, -2.5098e-30, -2.9625e-31,
         2.3350e-30, -2.5792e-30, -2.6016e-30, -1.9972e-30,  2.5552e-31,
         2.4419e-31,  2.5733e-30, -4.7090e-31, -2.2833e-30, -2.6663e-30,
         2.6303e-30,  1.9892e-30, -1.9704e-30, -5.9895e-31, -1.5253e-30,
         1.7532e-31, -2.6473e-30, -1.2998e-30, -1.7464e-30, -9.4812e-31,
        -2.1374e-30, -6.3129e-31, -2.0498e-31, -2.7576e-30,  1.0896e-31,
         2.6145e-30,  2.4627e-30, -2.2259e-30,  2.7187e-30, -1.4007e-30,
        -2.4944e-30,  3.6964e-31,  5.6940e-31,  2.7352e-30,  2.6430e-30,
         2.2327e-30, -2.7661e-30,  2.7265e-30,  2.3074e-30, -2.7636e-30,
         2.7740e-30, -6.2732e-31,  3.9763e-31, -7.4532e-31, -2.0588e-30,
        -1.6638e-30,  2.1980e-30,  4.7003e-31, -2.7753e-30,  2.7466e-30,
         9.7961e-31, -2.4020e-30,  2.6200e-30,  3.3087e-31,  9.3466e-32,
        -2.7434e-30,  7.5598e-31,  2.7475e-30,  1.8815e-30])
layer2.3.weight tensor([[[[ 0.0063, -0.0048,  0.0036,  0.0114,  0.0116],
          [-0.0190, -0.0079, -0.0007, -0.0189, -0.0184],
          [-0.0175,  0.0233,  0.0244,  0.0063, -0.0096],
          [ 0.0009,  0.0250,  0.0053,  0.0248, -0.0084],
          [-0.0248,  0.0193,  0.0249,  0.0076,  0.0101]],

         [[-0.0215,  0.0112, -0.0097,  0.0214,  0.0219],
          [-0.0047,  0.0230, -0.0040,  0.0060, -0.0111],
          [ 0.0167, -0.0135, -0.0194,  0.0114,  0.0243],
          [ 0.0091,  0.0112,  0.0095,  0.0115, -0.0235],
          [-0.0147, -0.0201, -0.0140, -0.0032,  0.0114]],

         [[ 0.0062,  0.0031,  0.0186,  0.0048, -0.0101],
          [-0.0113,  0.0154,  0.0160, -0.0043,  0.0200],
          [ 0.0039, -0.0077, -0.0038,  0.0157, -0.0102],
          [-0.0143, -0.0150, -0.0237,  0.0056,  0.0177],
          [ 0.0050, -0.0014, -0.0162,  0.0070,  0.0010]],

         ...,

         [[-0.0027,  0.0229, -0.0080,  0.0007, -0.0134],
          [ 0.0113,  0.0171,  0.0056,  0.0178,  0.0247],
          [-0.0102, -0.0220, -0.0095,  0.0166, -0.0202],
          [-0.0105,  0.0056, -0.0120, -0.0084,  0.0066],
          [-0.0237,  0.0022, -0.0072,  0.0117,  0.0021]],

         [[-0.0088,  0.0183,  0.0024, -0.0016,  0.0049],
          [ 0.0053, -0.0055, -0.0173, -0.0010, -0.0169],
          [-0.0160,  0.0019, -0.0133, -0.0030, -0.0217],
          [-0.0085, -0.0112,  0.0224, -0.0063,  0.0028],
          [ 0.0091,  0.0093,  0.0120,  0.0064, -0.0064]],

         [[-0.0207,  0.0191, -0.0092, -0.0201,  0.0031],
          [ 0.0196,  0.0069, -0.0099,  0.0228, -0.0051],
          [-0.0237, -0.0201, -0.0162, -0.0001, -0.0083],
          [ 0.0175,  0.0124, -0.0055, -0.0098,  0.0164],
          [ 0.0051, -0.0192, -0.0211, -0.0216,  0.0042]]],


        [[[-0.0131,  0.0235, -0.0073, -0.0037,  0.0029],
          [-0.0095, -0.0190, -0.0210, -0.0086, -0.0079],
          [ 0.0103, -0.0171,  0.0127, -0.0126, -0.0011],
          [-0.0015, -0.0221,  0.0007,  0.0028, -0.0019],
          [-0.0239, -0.0011, -0.0218,  0.0013,  0.0142]],

         [[-0.0005,  0.0043,  0.0121,  0.0176,  0.0093],
          [-0.0229,  0.0121, -0.0192,  0.0146,  0.0091],
          [ 0.0027, -0.0067,  0.0062, -0.0161, -0.0134],
          [ 0.0207,  0.0243, -0.0024,  0.0003,  0.0081],
          [-0.0045, -0.0144, -0.0012, -0.0226,  0.0242]],

         [[-0.0014,  0.0085, -0.0009,  0.0079,  0.0045],
          [ 0.0223, -0.0245, -0.0141, -0.0008,  0.0069],
          [ 0.0088,  0.0109,  0.0140,  0.0145, -0.0057],
          [ 0.0062,  0.0229, -0.0146,  0.0040,  0.0191],
          [-0.0146, -0.0091, -0.0117, -0.0116,  0.0176]],

         ...,

         [[ 0.0179,  0.0137, -0.0178, -0.0059, -0.0234],
          [ 0.0248, -0.0209, -0.0190, -0.0061,  0.0173],
          [ 0.0089,  0.0078, -0.0055, -0.0049, -0.0242],
          [ 0.0004,  0.0134, -0.0117, -0.0025,  0.0034],
          [ 0.0056,  0.0224, -0.0152,  0.0033,  0.0101]],

         [[ 0.0150,  0.0237,  0.0213, -0.0203,  0.0218],
          [-0.0094, -0.0118, -0.0204, -0.0088,  0.0176],
          [ 0.0035,  0.0033, -0.0179, -0.0203,  0.0098],
          [-0.0120, -0.0120,  0.0122,  0.0085, -0.0173],
          [-0.0016,  0.0082, -0.0039,  0.0118,  0.0072]],

         [[ 0.0188, -0.0121, -0.0182, -0.0203,  0.0209],
          [-0.0232, -0.0088,  0.0005,  0.0054, -0.0138],
          [-0.0220,  0.0189, -0.0244,  0.0079, -0.0096],
          [-0.0180, -0.0013, -0.0024,  0.0136,  0.0097],
          [-0.0144,  0.0128,  0.0244,  0.0183, -0.0115]]],


        [[[ 0.0215, -0.0012,  0.0074, -0.0179,  0.0098],
          [ 0.0060,  0.0233, -0.0057, -0.0020, -0.0113],
          [ 0.0153, -0.0188, -0.0090,  0.0192, -0.0046],
          [ 0.0188,  0.0104, -0.0092, -0.0021, -0.0006],
          [ 0.0201,  0.0012, -0.0088, -0.0182, -0.0090]],

         [[ 0.0117,  0.0009,  0.0002,  0.0187, -0.0098],
          [-0.0040, -0.0160, -0.0044, -0.0127, -0.0013],
          [-0.0050,  0.0219, -0.0049, -0.0026,  0.0154],
          [-0.0083,  0.0089, -0.0071,  0.0183, -0.0164],
          [-0.0176,  0.0102,  0.0058,  0.0125,  0.0185]],

         [[ 0.0083,  0.0173,  0.0015,  0.0126, -0.0162],
          [-0.0091, -0.0166,  0.0104,  0.0028, -0.0041],
          [ 0.0060,  0.0112,  0.0177,  0.0064,  0.0230],
          [ 0.0010,  0.0223, -0.0065,  0.0163,  0.0198],
          [ 0.0156, -0.0244, -0.0233, -0.0216,  0.0190]],

         ...,

         [[-0.0141,  0.0094,  0.0194, -0.0189,  0.0239],
          [ 0.0087,  0.0085,  0.0103,  0.0006,  0.0231],
          [-0.0105,  0.0076, -0.0026,  0.0228, -0.0186],
          [ 0.0217, -0.0192, -0.0073, -0.0189, -0.0155],
          [-0.0204,  0.0111,  0.0229, -0.0215,  0.0247]],

         [[-0.0177,  0.0075, -0.0079,  0.0112,  0.0168],
          [ 0.0055, -0.0169,  0.0195, -0.0025,  0.0129],
          [ 0.0071, -0.0086,  0.0128,  0.0024,  0.0072],
          [-0.0057, -0.0134,  0.0009,  0.0087, -0.0196],
          [ 0.0005,  0.0193, -0.0109, -0.0211,  0.0224]],

         [[-0.0139, -0.0121, -0.0017,  0.0190,  0.0196],
          [-0.0193, -0.0199,  0.0242,  0.0235, -0.0135],
          [ 0.0040, -0.0085,  0.0233,  0.0108,  0.0166],
          [ 0.0229, -0.0065,  0.0007, -0.0168,  0.0247],
          [ 0.0122, -0.0181, -0.0099, -0.0145,  0.0202]]],


        ...,


        [[[ 0.0241,  0.0010,  0.0164, -0.0048, -0.0191],
          [ 0.0198,  0.0242,  0.0023, -0.0147,  0.0064],
          [ 0.0017, -0.0087,  0.0101, -0.0034,  0.0199],
          [-0.0128, -0.0188,  0.0120, -0.0162, -0.0184],
          [ 0.0217, -0.0245,  0.0097, -0.0237, -0.0057]],

         [[ 0.0121,  0.0240, -0.0078, -0.0075, -0.0176],
          [-0.0231, -0.0249,  0.0219,  0.0082,  0.0037],
          [-0.0113, -0.0032, -0.0223, -0.0241,  0.0249],
          [ 0.0118,  0.0179, -0.0234,  0.0049, -0.0135],
          [ 0.0011,  0.0019, -0.0129,  0.0114, -0.0043]],

         [[ 0.0115,  0.0213, -0.0090,  0.0026, -0.0157],
          [ 0.0217,  0.0104,  0.0011,  0.0190,  0.0122],
          [ 0.0119, -0.0242,  0.0117, -0.0163,  0.0223],
          [ 0.0188, -0.0146,  0.0042,  0.0145,  0.0234],
          [-0.0131,  0.0094, -0.0002,  0.0181,  0.0159]],

         ...,

         [[-0.0084,  0.0134, -0.0071,  0.0222,  0.0063],
          [-0.0222, -0.0004, -0.0074,  0.0019, -0.0118],
          [ 0.0178,  0.0219, -0.0164,  0.0135,  0.0167],
          [-0.0111,  0.0033,  0.0112, -0.0143,  0.0035],
          [-0.0224, -0.0094,  0.0229,  0.0062,  0.0243]],

         [[-0.0113,  0.0237, -0.0076,  0.0235,  0.0055],
          [-0.0240, -0.0031, -0.0187,  0.0105, -0.0168],
          [ 0.0225, -0.0043, -0.0029, -0.0052, -0.0112],
          [-0.0121, -0.0241,  0.0226, -0.0180,  0.0189],
          [-0.0212,  0.0118,  0.0125, -0.0212, -0.0151]],

         [[ 0.0203, -0.0198, -0.0029,  0.0073,  0.0224],
          [ 0.0020, -0.0003,  0.0221,  0.0019, -0.0040],
          [-0.0111,  0.0118, -0.0132,  0.0210, -0.0096],
          [-0.0170, -0.0046,  0.0185, -0.0004,  0.0161],
          [ 0.0062, -0.0169,  0.0065,  0.0227,  0.0066]]],


        [[[-0.0007, -0.0020,  0.0006,  0.0130,  0.0012],
          [ 0.0072,  0.0146,  0.0150,  0.0159, -0.0208],
          [ 0.0177, -0.0143,  0.0056,  0.0121, -0.0039],
          [-0.0054,  0.0200,  0.0165, -0.0194,  0.0059],
          [ 0.0230,  0.0014, -0.0058, -0.0014, -0.0175]],

         [[ 0.0082,  0.0225, -0.0247,  0.0007,  0.0058],
          [-0.0145, -0.0190, -0.0167, -0.0148,  0.0013],
          [-0.0195, -0.0101,  0.0106,  0.0030, -0.0220],
          [ 0.0105,  0.0127, -0.0056, -0.0041, -0.0087],
          [ 0.0103,  0.0122,  0.0236,  0.0071,  0.0219]],

         [[-0.0002,  0.0088, -0.0145,  0.0129,  0.0237],
          [-0.0017,  0.0070, -0.0074,  0.0105,  0.0168],
          [-0.0170, -0.0244,  0.0101, -0.0225,  0.0171],
          [ 0.0093, -0.0011,  0.0184, -0.0200,  0.0162],
          [ 0.0097,  0.0229, -0.0002,  0.0021, -0.0224]],

         ...,

         [[ 0.0217,  0.0200, -0.0061,  0.0152, -0.0027],
          [ 0.0014,  0.0194,  0.0191, -0.0107,  0.0006],
          [-0.0064, -0.0146,  0.0241,  0.0002,  0.0101],
          [ 0.0058, -0.0096,  0.0096,  0.0119,  0.0048],
          [ 0.0053, -0.0039, -0.0022, -0.0207,  0.0043]],

         [[ 0.0091,  0.0164, -0.0063,  0.0029,  0.0145],
          [-0.0113, -0.0166, -0.0179, -0.0190,  0.0227],
          [ 0.0096,  0.0104,  0.0148,  0.0102, -0.0223],
          [ 0.0027,  0.0207,  0.0159,  0.0087,  0.0110],
          [ 0.0204,  0.0078,  0.0139,  0.0250,  0.0091]],

         [[ 0.0206, -0.0085,  0.0177, -0.0176,  0.0150],
          [ 0.0004,  0.0065,  0.0136, -0.0107,  0.0125],
          [-0.0175, -0.0128, -0.0184,  0.0014, -0.0012],
          [-0.0081,  0.0144, -0.0158,  0.0111, -0.0233],
          [ 0.0225, -0.0009, -0.0188,  0.0090,  0.0011]]],


        [[[-0.0050,  0.0128, -0.0133, -0.0129,  0.0129],
          [ 0.0241,  0.0131,  0.0206,  0.0202,  0.0027],
          [ 0.0160, -0.0161,  0.0151,  0.0144,  0.0201],
          [ 0.0110,  0.0083, -0.0172,  0.0036,  0.0060],
          [-0.0047, -0.0183,  0.0097,  0.0175,  0.0037]],

         [[ 0.0067,  0.0024, -0.0124,  0.0236, -0.0149],
          [-0.0068, -0.0124,  0.0156,  0.0006,  0.0017],
          [-0.0191,  0.0068,  0.0080, -0.0070,  0.0035],
          [ 0.0055, -0.0156,  0.0158,  0.0151, -0.0073],
          [-0.0233, -0.0189, -0.0110, -0.0104, -0.0158]],

         [[ 0.0162, -0.0211, -0.0045,  0.0037, -0.0064],
          [-0.0009,  0.0028,  0.0006,  0.0239, -0.0078],
          [ 0.0231,  0.0052, -0.0090, -0.0112,  0.0048],
          [ 0.0112,  0.0176, -0.0039,  0.0134, -0.0013],
          [ 0.0047, -0.0232,  0.0145, -0.0122,  0.0146]],

         ...,

         [[ 0.0207,  0.0206, -0.0086,  0.0095,  0.0037],
          [-0.0134,  0.0223, -0.0209,  0.0159,  0.0123],
          [ 0.0082,  0.0176,  0.0167,  0.0222,  0.0216],
          [ 0.0176, -0.0073,  0.0045, -0.0160,  0.0205],
          [-0.0157, -0.0021,  0.0205, -0.0011, -0.0060]],

         [[-0.0141, -0.0046, -0.0134,  0.0081, -0.0027],
          [ 0.0204,  0.0096,  0.0213, -0.0192, -0.0104],
          [-0.0175,  0.0132,  0.0215, -0.0223, -0.0079],
          [ 0.0124, -0.0160,  0.0016,  0.0074, -0.0133],
          [-0.0007,  0.0171,  0.0015, -0.0149,  0.0212]],

         [[ 0.0033,  0.0194, -0.0060,  0.0114,  0.0082],
          [ 0.0008, -0.0105, -0.0147,  0.0214, -0.0152],
          [ 0.0056, -0.0224,  0.0121, -0.0039, -0.0162],
          [ 0.0114, -0.0206, -0.0127,  0.0029, -0.0109],
          [ 0.0142, -0.0146,  0.0110,  0.0073,  0.0203]]]])
layer2.3.bias tensor([ 0.0220, -0.0244, -0.0113,  0.0026,  0.0011,  0.0234,  0.0143, -0.0227,
        -0.0174,  0.0145,  0.0018,  0.0225, -0.0174,  0.0059, -0.0241, -0.0201,
         0.0239, -0.0034,  0.0101,  0.0186,  0.0016,  0.0163, -0.0075, -0.0175,
        -0.0055, -0.0187,  0.0138, -0.0125, -0.0070, -0.0116, -0.0021,  0.0175,
         0.0027, -0.0038,  0.0240,  0.0131,  0.0074, -0.0106,  0.0122,  0.0042,
         0.0190, -0.0125, -0.0247, -0.0177,  0.0116,  0.0242,  0.0111,  0.0195,
         0.0177, -0.0169, -0.0211, -0.0198,  0.0137, -0.0213, -0.0184, -0.0221,
        -0.0037,  0.0125,  0.0034, -0.0011,  0.0179, -0.0132,  0.0168,  0.0235])
layer2.4.weight tensor([0.3639, 0.5607, 0.9805, 0.2644, 0.0294, 0.7686, 0.9758, 0.8297, 0.1661,
        0.9382, 0.7482, 0.6052, 0.7889, 0.7560, 0.5961, 0.6796, 0.4835, 0.0632,
        0.9915, 0.5126, 0.5796, 0.9025, 0.9310, 0.3972, 0.0782, 0.5696, 0.6226,
        0.1323, 0.4730, 0.6794, 0.2912, 0.3499, 0.9676, 0.3523, 0.7693, 0.6787,
        0.1178, 0.8372, 0.9520, 0.4811, 0.1189, 0.9658, 0.7224, 0.8378, 0.5837,
        0.7821, 0.5465, 0.3532, 0.8683, 0.7186, 0.6378, 0.7550, 0.3985, 0.1954,
        0.0691, 0.0995, 0.5686, 0.1875, 0.2955, 0.0788, 0.3876, 0.7974, 0.8413,
        0.3371])
layer2.4.bias tensor([ 2.6567e-30, -2.0881e-30, -2.7466e-30, -1.7338e-31, -2.4176e-30,
         2.7013e-31, -2.7691e-30, -9.1622e-31,  2.7751e-30, -2.5999e-30,
         2.7752e-30,  2.7160e-30, -2.2514e-30, -1.9280e-30,  2.1300e-31,
         1.4896e-30, -7.8758e-31, -3.3653e-31,  2.7660e-30, -2.4457e-30,
         1.3683e-30, -8.9324e-31,  2.6018e-30,  2.3668e-30,  2.7719e-30,
         1.8627e-31,  2.4719e-31,  2.7668e-30, -2.7563e-30, -2.9272e-31,
        -1.5205e-31,  1.0497e-30, -2.3877e-30,  4.6598e-31,  2.3893e-30,
         1.9959e-30, -2.7330e-30, -3.1429e-31,  2.2603e-30, -1.6157e-30,
        -2.4771e-30,  2.7265e-30,  2.2984e-30,  2.4150e-30, -2.7151e-30,
         6.4678e-31, -1.3930e-30,  2.6674e-30,  9.3230e-31, -2.5175e-30,
        -3.0832e-31,  1.7814e-30,  7.6234e-31, -2.7042e-30,  2.4026e-30,
        -5.9699e-31, -6.3124e-31,  2.0048e-30,  9.0931e-31, -1.5238e-30,
        -2.8898e-31,  6.5673e-31, -1.5209e-30, -1.7265e-30])
layer3.0.weight tensor([[[[ 0.0145, -0.0075, -0.0024, -0.0029,  0.0187],
          [ 0.0113,  0.0105, -0.0148,  0.0020, -0.0205],
          [-0.0207,  0.0129, -0.0058, -0.0051, -0.0072],
          [-0.0041,  0.0055, -0.0094,  0.0159, -0.0168],
          [-0.0192, -0.0181,  0.0216,  0.0147,  0.0005]],

         [[ 0.0088,  0.0050,  0.0108, -0.0045,  0.0179],
          [-0.0208,  0.0130, -0.0006,  0.0104,  0.0224],
          [ 0.0047, -0.0089,  0.0110, -0.0146,  0.0001],
          [ 0.0184,  0.0124,  0.0149,  0.0036,  0.0204],
          [ 0.0176, -0.0031,  0.0154,  0.0064, -0.0025]],

         [[ 0.0026,  0.0218,  0.0118, -0.0134,  0.0082],
          [ 0.0036,  0.0055,  0.0048, -0.0092, -0.0012],
          [-0.0166, -0.0079,  0.0011, -0.0091, -0.0046],
          [ 0.0015,  0.0077, -0.0046, -0.0086, -0.0204],
          [-0.0245,  0.0093,  0.0207, -0.0061,  0.0014]],

         ...,

         [[-0.0166,  0.0207, -0.0008, -0.0098, -0.0208],
          [-0.0092, -0.0103,  0.0173,  0.0178,  0.0076],
          [ 0.0131, -0.0242, -0.0245, -0.0141,  0.0136],
          [-0.0171, -0.0063,  0.0204,  0.0080, -0.0193],
          [ 0.0142, -0.0036,  0.0194, -0.0078,  0.0102]],

         [[ 0.0245,  0.0229, -0.0021, -0.0169, -0.0067],
          [-0.0052, -0.0205, -0.0229,  0.0014,  0.0105],
          [ 0.0217,  0.0124, -0.0242,  0.0169,  0.0105],
          [-0.0048,  0.0203,  0.0104,  0.0216, -0.0226],
          [-0.0060, -0.0199, -0.0062, -0.0039, -0.0073]],

         [[-0.0246, -0.0159, -0.0005,  0.0163, -0.0227],
          [ 0.0128, -0.0199, -0.0046,  0.0073, -0.0115],
          [ 0.0241,  0.0191,  0.0108,  0.0043,  0.0046],
          [ 0.0140, -0.0194, -0.0095,  0.0046,  0.0109],
          [-0.0049, -0.0212, -0.0190,  0.0062, -0.0227]]],


        [[[-0.0094, -0.0226,  0.0066, -0.0013,  0.0165],
          [ 0.0173,  0.0189,  0.0197, -0.0220, -0.0106],
          [ 0.0154, -0.0117, -0.0080,  0.0021, -0.0043],
          [-0.0077, -0.0056,  0.0068, -0.0195,  0.0130],
          [-0.0046, -0.0218, -0.0210, -0.0040, -0.0010]],

         [[-0.0147, -0.0110, -0.0223,  0.0015,  0.0119],
          [ 0.0185, -0.0195,  0.0227, -0.0128,  0.0163],
          [ 0.0142,  0.0036,  0.0073, -0.0152, -0.0202],
          [-0.0208, -0.0124, -0.0185, -0.0137,  0.0079],
          [-0.0130,  0.0130,  0.0009,  0.0040,  0.0111]],

         [[ 0.0175, -0.0055, -0.0129,  0.0022, -0.0111],
          [ 0.0180,  0.0154, -0.0006,  0.0074,  0.0081],
          [ 0.0139, -0.0174,  0.0194,  0.0090,  0.0144],
          [ 0.0192, -0.0122,  0.0098, -0.0033, -0.0148],
          [ 0.0237,  0.0129,  0.0166,  0.0102,  0.0204]],

         ...,

         [[-0.0143,  0.0172, -0.0210,  0.0214, -0.0162],
          [-0.0160,  0.0156, -0.0247, -0.0229,  0.0162],
          [-0.0039,  0.0087,  0.0234,  0.0003,  0.0069],
          [-0.0073,  0.0040,  0.0091,  0.0227, -0.0111],
          [-0.0133,  0.0151, -0.0037,  0.0078,  0.0226]],

         [[-0.0243,  0.0080,  0.0180,  0.0140,  0.0206],
          [ 0.0154,  0.0136,  0.0213, -0.0135, -0.0061],
          [ 0.0133,  0.0212, -0.0115, -0.0039,  0.0078],
          [ 0.0038, -0.0154, -0.0039, -0.0197,  0.0242],
          [ 0.0237, -0.0111, -0.0116,  0.0192,  0.0157]],

         [[-0.0207,  0.0063,  0.0190,  0.0118, -0.0090],
          [-0.0062,  0.0153,  0.0123, -0.0099,  0.0167],
          [-0.0023, -0.0238,  0.0035, -0.0147,  0.0223],
          [-0.0141,  0.0043,  0.0064, -0.0024,  0.0238],
          [ 0.0029, -0.0197, -0.0031, -0.0169,  0.0008]]],


        [[[-0.0025, -0.0054, -0.0002,  0.0151, -0.0226],
          [ 0.0176,  0.0082, -0.0203, -0.0231,  0.0167],
          [ 0.0223, -0.0107, -0.0083,  0.0235, -0.0215],
          [ 0.0103, -0.0233, -0.0081,  0.0153,  0.0192],
          [-0.0235, -0.0236, -0.0142,  0.0224,  0.0028]],

         [[-0.0035, -0.0018, -0.0019, -0.0106, -0.0026],
          [-0.0153,  0.0170, -0.0105,  0.0049,  0.0204],
          [ 0.0151,  0.0020,  0.0034, -0.0217, -0.0200],
          [-0.0125,  0.0243, -0.0118,  0.0077, -0.0203],
          [-0.0028,  0.0039,  0.0219, -0.0173,  0.0014]],

         [[-0.0162, -0.0172,  0.0106,  0.0221,  0.0173],
          [ 0.0170, -0.0125, -0.0135,  0.0043,  0.0038],
          [-0.0154, -0.0195, -0.0088, -0.0012,  0.0149],
          [ 0.0048,  0.0113,  0.0240,  0.0039, -0.0029],
          [-0.0146,  0.0088, -0.0213,  0.0101,  0.0184]],

         ...,

         [[-0.0042,  0.0077,  0.0117,  0.0125,  0.0216],
          [ 0.0247,  0.0091,  0.0080,  0.0115, -0.0087],
          [-0.0149, -0.0203,  0.0072,  0.0221, -0.0016],
          [ 0.0075,  0.0055, -0.0036,  0.0211,  0.0182],
          [ 0.0040, -0.0210, -0.0188, -0.0178, -0.0071]],

         [[ 0.0018,  0.0044,  0.0111, -0.0186, -0.0187],
          [ 0.0044, -0.0222, -0.0115,  0.0088,  0.0143],
          [ 0.0195, -0.0179,  0.0019,  0.0138,  0.0101],
          [-0.0194,  0.0121,  0.0245, -0.0055, -0.0109],
          [ 0.0233, -0.0001, -0.0222, -0.0113, -0.0246]],

         [[-0.0136, -0.0051,  0.0074, -0.0114, -0.0248],
          [ 0.0061,  0.0239,  0.0183, -0.0083, -0.0245],
          [ 0.0088,  0.0120, -0.0157,  0.0010,  0.0109],
          [-0.0073, -0.0212,  0.0041, -0.0200, -0.0159],
          [ 0.0226,  0.0114, -0.0136,  0.0145,  0.0142]]],


        ...,


        [[[-0.0238,  0.0233,  0.0108,  0.0060,  0.0096],
          [ 0.0043,  0.0051, -0.0173,  0.0051, -0.0076],
          [-0.0120, -0.0073, -0.0016, -0.0006,  0.0152],
          [ 0.0114, -0.0178, -0.0018, -0.0062, -0.0093],
          [ 0.0187,  0.0135,  0.0002,  0.0150,  0.0064]],

         [[-0.0023, -0.0089, -0.0215,  0.0082, -0.0105],
          [ 0.0177, -0.0131,  0.0141, -0.0104, -0.0156],
          [ 0.0092, -0.0016,  0.0045, -0.0081,  0.0043],
          [ 0.0108, -0.0004,  0.0239, -0.0087, -0.0116],
          [-0.0114,  0.0084,  0.0052,  0.0106,  0.0234]],

         [[-0.0007,  0.0195,  0.0083,  0.0001,  0.0044],
          [-0.0030,  0.0004, -0.0074, -0.0119, -0.0154],
          [-0.0148, -0.0097, -0.0194,  0.0173, -0.0174],
          [-0.0229,  0.0230, -0.0001, -0.0038,  0.0086],
          [ 0.0202, -0.0213, -0.0120,  0.0145,  0.0188]],

         ...,

         [[-0.0109, -0.0022,  0.0192, -0.0006, -0.0027],
          [-0.0082,  0.0246,  0.0045,  0.0129, -0.0215],
          [-0.0183, -0.0091, -0.0134,  0.0172,  0.0168],
          [-0.0104,  0.0162, -0.0075, -0.0044,  0.0026],
          [ 0.0018, -0.0144, -0.0127, -0.0124,  0.0226]],

         [[-0.0056,  0.0243, -0.0210,  0.0217,  0.0019],
          [ 0.0205, -0.0083,  0.0039, -0.0138,  0.0205],
          [-0.0176, -0.0103,  0.0035,  0.0103, -0.0071],
          [-0.0073,  0.0198,  0.0151, -0.0225, -0.0200],
          [-0.0034, -0.0074,  0.0153, -0.0088, -0.0248]],

         [[-0.0232,  0.0048, -0.0105, -0.0018,  0.0181],
          [-0.0146,  0.0083, -0.0030,  0.0136,  0.0009],
          [ 0.0045, -0.0006, -0.0182, -0.0140, -0.0098],
          [ 0.0186,  0.0184, -0.0064, -0.0109,  0.0035],
          [-0.0169,  0.0033,  0.0171,  0.0141, -0.0210]]],


        [[[ 0.0039, -0.0176, -0.0153,  0.0219, -0.0114],
          [ 0.0118, -0.0019,  0.0233,  0.0091,  0.0035],
          [-0.0171, -0.0237,  0.0186,  0.0126,  0.0245],
          [-0.0169, -0.0164, -0.0164, -0.0162, -0.0160],
          [-0.0126,  0.0132, -0.0058,  0.0230,  0.0039]],

         [[-0.0066,  0.0153,  0.0013, -0.0038,  0.0113],
          [ 0.0104, -0.0235,  0.0115,  0.0034, -0.0062],
          [-0.0218,  0.0179, -0.0046,  0.0017,  0.0012],
          [-0.0177,  0.0156,  0.0007, -0.0092, -0.0145],
          [ 0.0049,  0.0093,  0.0193, -0.0217, -0.0051]],

         [[-0.0018,  0.0187, -0.0187, -0.0064, -0.0180],
          [-0.0140,  0.0117, -0.0212, -0.0095, -0.0237],
          [-0.0120,  0.0210, -0.0192,  0.0002,  0.0014],
          [-0.0055, -0.0004,  0.0025, -0.0059, -0.0138],
          [ 0.0118,  0.0069,  0.0105, -0.0154, -0.0071]],

         ...,

         [[-0.0146,  0.0063, -0.0190, -0.0148,  0.0191],
          [ 0.0100,  0.0146, -0.0176,  0.0210, -0.0038],
          [-0.0225,  0.0235, -0.0064,  0.0121, -0.0110],
          [ 0.0126, -0.0018, -0.0093,  0.0201,  0.0027],
          [-0.0211, -0.0186,  0.0140, -0.0207, -0.0066]],

         [[-0.0061, -0.0230,  0.0076, -0.0066, -0.0144],
          [ 0.0057, -0.0157, -0.0233,  0.0028, -0.0217],
          [-0.0159, -0.0064,  0.0178,  0.0233, -0.0103],
          [ 0.0081,  0.0088,  0.0185,  0.0066, -0.0189],
          [-0.0209,  0.0177, -0.0056,  0.0115, -0.0135]],

         [[-0.0015, -0.0001,  0.0048,  0.0064, -0.0243],
          [-0.0174,  0.0071,  0.0048,  0.0205,  0.0095],
          [-0.0107,  0.0106,  0.0066, -0.0189,  0.0248],
          [ 0.0196,  0.0096, -0.0150, -0.0091,  0.0074],
          [ 0.0142, -0.0049, -0.0233, -0.0226,  0.0132]]],


        [[[ 0.0008, -0.0173,  0.0145, -0.0126,  0.0248],
          [-0.0184, -0.0006, -0.0133,  0.0092,  0.0196],
          [-0.0061,  0.0138, -0.0210, -0.0128,  0.0195],
          [-0.0205, -0.0081,  0.0114,  0.0184,  0.0050],
          [-0.0086,  0.0068,  0.0210, -0.0223, -0.0128]],

         [[-0.0109,  0.0065,  0.0030,  0.0230,  0.0045],
          [-0.0155, -0.0200, -0.0044,  0.0229, -0.0067],
          [ 0.0165,  0.0055,  0.0222,  0.0209,  0.0178],
          [ 0.0152, -0.0175, -0.0204,  0.0215, -0.0080],
          [ 0.0118, -0.0094, -0.0130, -0.0147,  0.0109]],

         [[ 0.0119,  0.0064, -0.0236, -0.0174, -0.0237],
          [-0.0006, -0.0090, -0.0165,  0.0163,  0.0142],
          [-0.0101, -0.0091, -0.0247,  0.0028, -0.0235],
          [-0.0220,  0.0053, -0.0068,  0.0172, -0.0043],
          [-0.0052,  0.0137, -0.0101, -0.0244,  0.0195]],

         ...,

         [[ 0.0045, -0.0033,  0.0153, -0.0195, -0.0189],
          [ 0.0015, -0.0231,  0.0206, -0.0020,  0.0209],
          [-0.0234, -0.0188,  0.0228,  0.0164, -0.0038],
          [-0.0024, -0.0235,  0.0046, -0.0080,  0.0241],
          [ 0.0235,  0.0021, -0.0191, -0.0193,  0.0018]],

         [[ 0.0204, -0.0234, -0.0131,  0.0094,  0.0171],
          [-0.0158,  0.0204,  0.0045,  0.0135,  0.0121],
          [-0.0046,  0.0116,  0.0075, -0.0014,  0.0105],
          [ 0.0193, -0.0061,  0.0053, -0.0224, -0.0030],
          [-0.0091,  0.0220, -0.0081, -0.0106, -0.0101]],

         [[-0.0170,  0.0001, -0.0052,  0.0111, -0.0237],
          [-0.0010, -0.0232, -0.0098, -0.0132, -0.0126],
          [ 0.0088, -0.0181,  0.0085, -0.0219, -0.0219],
          [ 0.0239, -0.0180,  0.0107, -0.0002, -0.0136],
          [-0.0081, -0.0196, -0.0213, -0.0184,  0.0003]]]])
layer3.0.bias tensor([ 0.0175,  0.0237, -0.0009,  0.0094, -0.0165,  0.0127,  0.0197, -0.0166,
        -0.0199,  0.0039, -0.0080,  0.0061, -0.0240, -0.0039, -0.0022, -0.0045,
        -0.0012,  0.0240,  0.0137, -0.0094, -0.0080,  0.0143,  0.0003, -0.0062,
         0.0017,  0.0075,  0.0084, -0.0161, -0.0080, -0.0125, -0.0232,  0.0181,
        -0.0213, -0.0055, -0.0080,  0.0014, -0.0000,  0.0018,  0.0160, -0.0201,
        -0.0218, -0.0182, -0.0052, -0.0169,  0.0117, -0.0123,  0.0223, -0.0134,
         0.0093,  0.0230,  0.0055,  0.0124, -0.0027, -0.0101,  0.0144,  0.0013,
        -0.0120,  0.0027,  0.0248,  0.0154,  0.0073,  0.0183, -0.0141,  0.0055])
layer3.1.weight tensor([0.1732, 0.9217, 0.4902, 0.4370, 0.1910, 0.9498, 0.9244, 0.4403, 0.1488,
        0.6642, 0.2786, 0.1472, 0.2232, 0.3068, 0.1910, 0.5279, 0.6570, 0.1222,
        0.9944, 0.1148, 0.8259, 0.7283, 0.3583, 0.6708, 0.9963, 0.6806, 0.3034,
        0.9520, 0.9198, 0.8097, 0.5726, 0.2780, 0.4037, 0.6373, 0.6546, 0.7860,
        0.2271, 0.9386, 0.3231, 0.2488, 0.7741, 0.6915, 0.2208, 0.1641, 0.6366,
        0.2399, 0.0583, 0.0098, 0.6219, 0.0356, 0.2191, 0.9833, 0.3176, 0.9678,
        0.5802, 0.5692, 0.7840, 0.8292, 0.6808, 0.4308, 0.1925, 0.8836, 0.9339,
        0.8949])
layer3.1.bias tensor([-1.7117e-30,  1.1471e-30,  2.2685e-30, -2.6712e-30, -1.9249e-32,
        -2.3560e-30, -3.1141e-31,  2.7599e-30, -2.6207e-32,  2.3263e-30,
        -1.7018e-30, -1.7222e-30,  2.0919e-31, -1.9460e-30,  1.0070e-30,
        -2.7431e-30,  2.6954e-30,  2.6445e-30, -2.6296e-30,  6.9807e-32,
        -3.2394e-31, -2.6088e-30,  2.6566e-30, -4.3191e-31,  2.0907e-30,
         2.4602e-30, -2.7539e-30,  2.4895e-30,  1.3791e-30, -9.8267e-31,
        -1.1375e-30,  2.3692e-30,  2.7425e-30, -2.5563e-30,  2.5309e-30,
         2.6258e-30, -8.4903e-31,  2.6477e-30, -1.8958e-30,  1.3288e-30,
         5.8616e-33, -2.3953e-30, -2.4400e-31, -1.9762e-31, -9.0478e-31,
         2.9416e-31,  4.0324e-31,  7.7649e-32,  2.3513e-30, -1.5172e-30,
         2.6912e-30, -2.6223e-30, -1.4101e-30,  9.1512e-31, -2.7685e-30,
         3.1932e-31,  2.6148e-30,  1.2855e-31, -2.7712e-30,  2.6427e-30,
        -2.4987e-31,  1.0987e-30,  1.5598e-30,  2.6151e-30])
layer3.3.weight tensor([[[[-0.0230,  0.0072,  0.0231, -0.0248, -0.0033],
          [-0.0090, -0.0084,  0.0103,  0.0003, -0.0003],
          [ 0.0185, -0.0145,  0.0224,  0.0193, -0.0113],
          [ 0.0034,  0.0122, -0.0220, -0.0186,  0.0163],
          [-0.0186,  0.0187, -0.0072, -0.0100,  0.0129]],

         [[-0.0245, -0.0118,  0.0089, -0.0041,  0.0068],
          [-0.0070,  0.0216,  0.0211,  0.0143,  0.0225],
          [ 0.0065, -0.0179,  0.0174,  0.0144,  0.0102],
          [ 0.0114, -0.0060,  0.0034,  0.0087,  0.0130],
          [ 0.0211,  0.0116,  0.0158, -0.0135, -0.0210]],

         [[-0.0048,  0.0221, -0.0139,  0.0025,  0.0091],
          [ 0.0230, -0.0191,  0.0126,  0.0086, -0.0237],
          [ 0.0075,  0.0018, -0.0130,  0.0103, -0.0103],
          [-0.0115,  0.0228,  0.0014,  0.0134,  0.0077],
          [-0.0123,  0.0090,  0.0024,  0.0023,  0.0143]],

         ...,

         [[ 0.0227, -0.0015, -0.0075, -0.0144, -0.0205],
          [ 0.0112,  0.0004,  0.0152, -0.0057, -0.0105],
          [-0.0168,  0.0139, -0.0055,  0.0210,  0.0204],
          [ 0.0032,  0.0014, -0.0196,  0.0104, -0.0193],
          [-0.0091,  0.0217,  0.0227, -0.0031, -0.0212]],

         [[ 0.0225,  0.0073,  0.0035, -0.0099,  0.0007],
          [ 0.0147, -0.0189, -0.0110,  0.0142,  0.0038],
          [-0.0232,  0.0208, -0.0230, -0.0185, -0.0214],
          [-0.0221, -0.0026, -0.0094, -0.0008,  0.0135],
          [-0.0144, -0.0202,  0.0036, -0.0029,  0.0008]],

         [[-0.0085, -0.0202,  0.0018, -0.0187,  0.0122],
          [-0.0069, -0.0154,  0.0030, -0.0186, -0.0052],
          [-0.0052,  0.0234,  0.0197, -0.0097,  0.0132],
          [-0.0142,  0.0072,  0.0172, -0.0186,  0.0136],
          [ 0.0044,  0.0020, -0.0027, -0.0143, -0.0148]]],


        [[[-0.0172,  0.0207,  0.0023,  0.0189, -0.0248],
          [ 0.0118,  0.0053,  0.0172, -0.0148,  0.0220],
          [-0.0076, -0.0088, -0.0173,  0.0027,  0.0243],
          [-0.0003,  0.0202,  0.0030,  0.0024,  0.0154],
          [-0.0059,  0.0123,  0.0054,  0.0036, -0.0205]],

         [[-0.0113, -0.0109,  0.0212, -0.0088, -0.0180],
          [-0.0222, -0.0067,  0.0238, -0.0159, -0.0166],
          [-0.0118,  0.0026,  0.0071, -0.0111, -0.0197],
          [-0.0139,  0.0133, -0.0009,  0.0209, -0.0200],
          [-0.0172,  0.0235,  0.0071,  0.0216,  0.0081]],

         [[-0.0218,  0.0119, -0.0130,  0.0192, -0.0173],
          [-0.0051,  0.0234, -0.0094, -0.0014,  0.0112],
          [ 0.0126,  0.0002,  0.0155, -0.0011,  0.0193],
          [ 0.0066, -0.0051, -0.0004,  0.0047,  0.0195],
          [ 0.0088, -0.0101,  0.0010,  0.0018, -0.0184]],

         ...,

         [[ 0.0198, -0.0105,  0.0242,  0.0180,  0.0033],
          [ 0.0065,  0.0186, -0.0112, -0.0040, -0.0123],
          [ 0.0122,  0.0126, -0.0029,  0.0020,  0.0041],
          [-0.0239, -0.0148, -0.0102,  0.0039, -0.0040],
          [-0.0042, -0.0176,  0.0207,  0.0143,  0.0132]],

         [[-0.0006,  0.0203,  0.0207, -0.0010, -0.0050],
          [-0.0072,  0.0178, -0.0083, -0.0016,  0.0089],
          [-0.0198,  0.0033, -0.0087,  0.0198,  0.0196],
          [ 0.0163, -0.0096,  0.0060,  0.0200,  0.0234],
          [-0.0242,  0.0146,  0.0101, -0.0050, -0.0190]],

         [[ 0.0061,  0.0075,  0.0039,  0.0002,  0.0149],
          [ 0.0014, -0.0002,  0.0164,  0.0216,  0.0150],
          [ 0.0043, -0.0052, -0.0023, -0.0167,  0.0023],
          [ 0.0083,  0.0037, -0.0165,  0.0185,  0.0162],
          [ 0.0208, -0.0188,  0.0045, -0.0048,  0.0088]]],


        [[[-0.0003, -0.0159, -0.0089,  0.0178,  0.0175],
          [-0.0215, -0.0045,  0.0142, -0.0179,  0.0041],
          [ 0.0097,  0.0001,  0.0042,  0.0161, -0.0201],
          [-0.0088,  0.0032, -0.0072, -0.0082,  0.0235],
          [-0.0013, -0.0038,  0.0146,  0.0031,  0.0203]],

         [[-0.0085,  0.0069,  0.0221, -0.0016, -0.0175],
          [-0.0095, -0.0096, -0.0134,  0.0092, -0.0165],
          [-0.0002,  0.0033,  0.0203, -0.0170, -0.0153],
          [ 0.0220,  0.0148,  0.0023,  0.0113,  0.0040],
          [ 0.0004, -0.0145,  0.0122,  0.0039, -0.0107]],

         [[-0.0014,  0.0191,  0.0092, -0.0190,  0.0151],
          [ 0.0180,  0.0154,  0.0238,  0.0197, -0.0226],
          [-0.0118,  0.0113,  0.0144, -0.0122, -0.0226],
          [-0.0246, -0.0097,  0.0013,  0.0153,  0.0205],
          [-0.0203,  0.0163,  0.0064, -0.0009, -0.0091]],

         ...,

         [[-0.0036, -0.0008,  0.0229,  0.0008,  0.0197],
          [-0.0044,  0.0008, -0.0091, -0.0194, -0.0061],
          [-0.0168, -0.0125, -0.0101, -0.0115,  0.0247],
          [-0.0121, -0.0235, -0.0145, -0.0139, -0.0100],
          [ 0.0143, -0.0209, -0.0201, -0.0005,  0.0226]],

         [[-0.0071, -0.0112,  0.0027,  0.0011,  0.0150],
          [-0.0152, -0.0131, -0.0154,  0.0179,  0.0063],
          [ 0.0229,  0.0244, -0.0080,  0.0015,  0.0229],
          [ 0.0026,  0.0158, -0.0182,  0.0115,  0.0222],
          [ 0.0116, -0.0247, -0.0014,  0.0010,  0.0062]],

         [[-0.0071, -0.0014, -0.0034, -0.0026,  0.0232],
          [-0.0026,  0.0103, -0.0006, -0.0141, -0.0008],
          [ 0.0120,  0.0069,  0.0141,  0.0164, -0.0156],
          [ 0.0178, -0.0229, -0.0122,  0.0249,  0.0058],
          [-0.0109,  0.0085, -0.0071,  0.0166,  0.0045]]],


        ...,


        [[[ 0.0237, -0.0156,  0.0072, -0.0086, -0.0080],
          [-0.0093, -0.0240, -0.0206, -0.0122,  0.0222],
          [ 0.0126,  0.0153, -0.0061,  0.0084,  0.0201],
          [-0.0171, -0.0166, -0.0234,  0.0236, -0.0073],
          [ 0.0178,  0.0018,  0.0098,  0.0246,  0.0047]],

         [[ 0.0061, -0.0229, -0.0212, -0.0006, -0.0046],
          [ 0.0133, -0.0121,  0.0070,  0.0115, -0.0112],
          [-0.0051, -0.0185, -0.0213, -0.0057,  0.0241],
          [ 0.0073,  0.0241,  0.0058,  0.0032,  0.0140],
          [ 0.0117, -0.0079, -0.0176,  0.0121,  0.0036]],

         [[-0.0025, -0.0168,  0.0184,  0.0250, -0.0071],
          [ 0.0077,  0.0123, -0.0015, -0.0079, -0.0171],
          [-0.0190, -0.0157,  0.0148,  0.0206, -0.0014],
          [ 0.0147,  0.0226, -0.0121, -0.0091, -0.0143],
          [-0.0026,  0.0170,  0.0102, -0.0037, -0.0195]],

         ...,

         [[-0.0175, -0.0204,  0.0023,  0.0118,  0.0111],
          [-0.0047, -0.0180,  0.0110, -0.0059, -0.0163],
          [-0.0156,  0.0116, -0.0172, -0.0165,  0.0168],
          [ 0.0242,  0.0230,  0.0219,  0.0098, -0.0062],
          [ 0.0249,  0.0190,  0.0117,  0.0248, -0.0075]],

         [[-0.0175, -0.0209,  0.0238, -0.0127, -0.0164],
          [-0.0098, -0.0065,  0.0029, -0.0238, -0.0084],
          [ 0.0133, -0.0099, -0.0235,  0.0158,  0.0070],
          [ 0.0129,  0.0176,  0.0105,  0.0144,  0.0238],
          [-0.0185, -0.0153,  0.0027,  0.0130,  0.0155]],

         [[-0.0136,  0.0071, -0.0020, -0.0014, -0.0119],
          [-0.0012, -0.0222,  0.0171, -0.0165, -0.0114],
          [-0.0061,  0.0232, -0.0011, -0.0116, -0.0186],
          [-0.0140,  0.0170, -0.0044, -0.0205,  0.0149],
          [-0.0120, -0.0006, -0.0198, -0.0141,  0.0148]]],


        [[[-0.0024, -0.0093, -0.0132,  0.0027,  0.0018],
          [-0.0049, -0.0170, -0.0225,  0.0169, -0.0101],
          [ 0.0100, -0.0229,  0.0034,  0.0026, -0.0178],
          [-0.0209, -0.0048, -0.0075, -0.0020,  0.0162],
          [-0.0075, -0.0123, -0.0122,  0.0054, -0.0026]],

         [[ 0.0177, -0.0105,  0.0185,  0.0054,  0.0210],
          [ 0.0082, -0.0205, -0.0071,  0.0158, -0.0240],
          [-0.0190, -0.0091,  0.0062, -0.0151, -0.0232],
          [-0.0135, -0.0139, -0.0117,  0.0066,  0.0097],
          [ 0.0135,  0.0230,  0.0011, -0.0062,  0.0141]],

         [[-0.0041,  0.0229,  0.0141, -0.0012,  0.0198],
          [ 0.0216,  0.0140, -0.0226,  0.0212, -0.0030],
          [-0.0164, -0.0218,  0.0071, -0.0228, -0.0040],
          [-0.0085, -0.0203,  0.0173,  0.0186, -0.0194],
          [ 0.0104,  0.0026, -0.0236, -0.0182,  0.0083]],

         ...,

         [[ 0.0170, -0.0202,  0.0018,  0.0195, -0.0169],
          [-0.0227,  0.0010,  0.0129, -0.0237,  0.0229],
          [ 0.0043,  0.0184,  0.0247, -0.0226,  0.0015],
          [ 0.0187,  0.0041,  0.0040, -0.0162, -0.0208],
          [-0.0026,  0.0163,  0.0001, -0.0149,  0.0151]],

         [[-0.0086,  0.0028,  0.0200, -0.0065,  0.0076],
          [ 0.0126,  0.0107, -0.0215,  0.0071,  0.0103],
          [-0.0192, -0.0114, -0.0098,  0.0194,  0.0228],
          [-0.0106,  0.0040,  0.0172,  0.0242, -0.0207],
          [-0.0104, -0.0121, -0.0242, -0.0156,  0.0007]],

         [[ 0.0248,  0.0167,  0.0198,  0.0066,  0.0193],
          [ 0.0142, -0.0086,  0.0190,  0.0032,  0.0026],
          [ 0.0060, -0.0020, -0.0080, -0.0030,  0.0213],
          [ 0.0121, -0.0174,  0.0079, -0.0133, -0.0020],
          [ 0.0023, -0.0078, -0.0246,  0.0070,  0.0086]]],


        [[[ 0.0039,  0.0141, -0.0199,  0.0173,  0.0177],
          [-0.0162, -0.0098, -0.0011, -0.0106, -0.0069],
          [-0.0019, -0.0013,  0.0141, -0.0091,  0.0097],
          [-0.0030,  0.0102, -0.0180,  0.0068, -0.0127],
          [-0.0182, -0.0248,  0.0019,  0.0043, -0.0188]],

         [[ 0.0182, -0.0031, -0.0059,  0.0117, -0.0004],
          [ 0.0250, -0.0147,  0.0196, -0.0086, -0.0120],
          [-0.0200,  0.0063,  0.0213,  0.0203,  0.0181],
          [-0.0075, -0.0106,  0.0144,  0.0154,  0.0033],
          [-0.0183,  0.0149, -0.0091,  0.0160,  0.0206]],

         [[-0.0063,  0.0129, -0.0062, -0.0093, -0.0031],
          [ 0.0036, -0.0056, -0.0180, -0.0010,  0.0218],
          [-0.0132,  0.0155,  0.0200,  0.0211, -0.0094],
          [-0.0090,  0.0174, -0.0104, -0.0209,  0.0004],
          [ 0.0122,  0.0040, -0.0072,  0.0172, -0.0088]],

         ...,

         [[ 0.0079, -0.0026, -0.0160,  0.0085,  0.0091],
          [-0.0015, -0.0196, -0.0239, -0.0023,  0.0076],
          [-0.0220,  0.0215,  0.0245, -0.0141, -0.0066],
          [-0.0135,  0.0036, -0.0038, -0.0158, -0.0247],
          [-0.0103,  0.0028, -0.0139,  0.0076, -0.0197]],

         [[ 0.0008,  0.0190, -0.0102, -0.0187, -0.0233],
          [ 0.0167, -0.0235,  0.0201,  0.0208,  0.0043],
          [-0.0150, -0.0151,  0.0225,  0.0043,  0.0071],
          [ 0.0214,  0.0052,  0.0214,  0.0146, -0.0072],
          [-0.0207,  0.0031,  0.0107, -0.0239,  0.0037]],

         [[ 0.0164,  0.0071, -0.0184,  0.0202, -0.0080],
          [-0.0188, -0.0188,  0.0155, -0.0047, -0.0147],
          [-0.0027,  0.0059, -0.0070, -0.0091,  0.0161],
          [-0.0059,  0.0071, -0.0231,  0.0056, -0.0156],
          [-0.0069, -0.0123,  0.0124,  0.0137,  0.0178]]]])
layer3.3.bias tensor([-0.0036, -0.0056,  0.0197,  0.0178, -0.0133,  0.0150, -0.0179,  0.0216,
        -0.0127,  0.0204, -0.0230, -0.0128,  0.0124,  0.0075,  0.0211,  0.0023,
        -0.0016,  0.0236, -0.0118, -0.0142,  0.0091,  0.0004,  0.0087,  0.0223,
        -0.0054, -0.0033, -0.0228,  0.0110, -0.0142,  0.0065,  0.0108,  0.0048,
        -0.0182, -0.0227, -0.0242, -0.0042, -0.0042, -0.0057,  0.0121, -0.0250,
        -0.0211, -0.0103,  0.0217,  0.0068,  0.0028,  0.0248, -0.0090, -0.0164,
        -0.0234, -0.0071, -0.0025,  0.0117, -0.0214, -0.0012, -0.0166,  0.0224,
         0.0161,  0.0059, -0.0006, -0.0068, -0.0181, -0.0083,  0.0214, -0.0190])
layer3.4.weight tensor([0.0617, 0.8025, 0.3917, 0.3486, 0.6975, 0.8138, 0.9665, 0.4475, 0.7156,
        0.2489, 0.0722, 0.3300, 0.8094, 0.5892, 0.6064, 0.1419, 0.3121, 0.7043,
        0.3777, 0.7069, 0.8040, 0.2933, 0.3437, 0.6780, 0.7974, 0.0488, 0.9282,
        0.5040, 0.6309, 0.1220, 0.9179, 0.0334, 0.2202, 0.4244, 0.4294, 0.7070,
        0.6943, 0.4568, 0.4361, 0.0577, 0.7009, 0.0583, 0.6310, 0.9985, 0.0779,
        0.6794, 0.7429, 0.9303, 0.3466, 0.0821, 0.3147, 0.8194, 0.4241, 0.2554,
        0.6527, 0.9709, 0.3747, 0.5476, 0.0267, 0.8640, 0.2417, 0.0928, 0.2599,
        0.2183])
layer3.4.bias tensor([ 2.7676e-30, -2.0034e-30,  2.6356e-30,  2.3862e-30,  2.3475e-30,
         2.6681e-30, -2.2713e-30, -3.3754e-32, -2.7116e-30,  2.4094e-30,
        -5.7280e-31, -1.9075e-30,  2.0718e-30,  4.2254e-32, -9.2420e-32,
        -6.5295e-31,  1.6326e-30,  1.4305e-30, -2.7674e-30,  2.9198e-31,
        -2.2599e-30, -2.7285e-30, -2.7703e-30,  2.4418e-30, -1.9710e-31,
        -2.5188e-30, -2.7528e-31,  1.8402e-30, -2.7979e-31,  2.6641e-30,
         2.6931e-30,  1.5902e-30, -2.1366e-30,  7.1324e-32, -2.5018e-30,
         2.7197e-30, -2.7504e-30,  2.6539e-30,  2.1244e-30,  1.8393e-30,
         9.4857e-31,  1.8636e-30,  2.2884e-30,  1.5780e-30, -4.4195e-31,
         2.4817e-30,  2.7594e-30,  2.7751e-30,  2.6177e-30, -1.4360e-31,
         2.3759e-30, -2.7600e-30, -1.7344e-31, -2.3100e-30,  2.7309e-30,
        -2.4368e-30, -2.7065e-30,  2.3399e-30,  1.2795e-30,  9.3275e-32,
         2.7749e-30,  1.5598e-30, -2.7736e-30, -2.7750e-30])
fc1.weight tensor([[-0.0134, -0.0059,  0.0024,  ...,  0.0121,  0.0034,  0.0006],
        [ 0.0037, -0.0116,  0.0064,  ..., -0.0068,  0.0088,  0.0092],
        [-0.0041, -0.0057,  0.0154,  ..., -0.0020, -0.0082, -0.0108],
        ...,
        [-0.0099, -0.0131,  0.0029,  ..., -0.0127, -0.0083, -0.0044],
        [ 0.0023, -0.0069,  0.0018,  ..., -0.0126, -0.0149,  0.0044],
        [-0.0059,  0.0025, -0.0048,  ...,  0.0123, -0.0050,  0.0061]])
fc1.bias tensor([ 0.0035,  0.0035, -0.0081,  0.0060, -0.0037,  0.0114,  0.0061, -0.0032,
        -0.0001, -0.0086, -0.0044,  0.0139, -0.0036, -0.0132, -0.0010,  0.0075,
        -0.0095,  0.0068,  0.0050,  0.0131,  0.0067,  0.0139, -0.0021, -0.0119,
        -0.0020, -0.0090,  0.0029, -0.0018,  0.0057, -0.0006, -0.0119,  0.0037,
         0.0046,  0.0032, -0.0042,  0.0105,  0.0106,  0.0074,  0.0061,  0.0145,
        -0.0120,  0.0128, -0.0060, -0.0005, -0.0030,  0.0061, -0.0133,  0.0121,
        -0.0027, -0.0056, -0.0076, -0.0058,  0.0019, -0.0107, -0.0072,  0.0032,
        -0.0087, -0.0001,  0.0052,  0.0060,  0.0005, -0.0041, -0.0093, -0.0156,
         0.0074,  0.0101,  0.0047, -0.0053, -0.0088, -0.0101,  0.0015,  0.0039,
        -0.0048,  0.0040,  0.0125, -0.0086, -0.0004,  0.0007, -0.0035, -0.0015,
        -0.0119, -0.0044,  0.0059,  0.0061,  0.0037,  0.0112, -0.0077,  0.0053,
        -0.0091,  0.0123, -0.0099,  0.0103,  0.0102,  0.0137, -0.0071,  0.0014,
        -0.0021,  0.0023,  0.0038,  0.0084,  0.0086, -0.0052,  0.0055,  0.0095,
         0.0017,  0.0060, -0.0026,  0.0112, -0.0116, -0.0007, -0.0061, -0.0059,
        -0.0012, -0.0090,  0.0031, -0.0059,  0.0039,  0.0071, -0.0134,  0.0004,
         0.0021, -0.0092,  0.0069,  0.0101, -0.0093,  0.0098, -0.0001, -0.0118,
         0.0123, -0.0070, -0.0015, -0.0100,  0.0077,  0.0042, -0.0073,  0.0142,
        -0.0078,  0.0040,  0.0101,  0.0144, -0.0061, -0.0015, -0.0128, -0.0149,
        -0.0086,  0.0004, -0.0156, -0.0010,  0.0087,  0.0120, -0.0048, -0.0154,
        -0.0112, -0.0071, -0.0136, -0.0036, -0.0045,  0.0056,  0.0006, -0.0042,
        -0.0058, -0.0116,  0.0096, -0.0047,  0.0116,  0.0026,  0.0015,  0.0006,
         0.0003,  0.0016, -0.0096,  0.0143, -0.0040, -0.0117, -0.0040,  0.0138,
        -0.0112, -0.0096,  0.0140, -0.0024, -0.0106,  0.0106, -0.0153,  0.0102,
         0.0059,  0.0120,  0.0050,  0.0075, -0.0050,  0.0133, -0.0156, -0.0025,
        -0.0153,  0.0141, -0.0104,  0.0076,  0.0005, -0.0009,  0.0033, -0.0085,
        -0.0156,  0.0140, -0.0092, -0.0056,  0.0031,  0.0132,  0.0128, -0.0002,
        -0.0146,  0.0055, -0.0031, -0.0113, -0.0039,  0.0129, -0.0050,  0.0073,
        -0.0142, -0.0111, -0.0092, -0.0014, -0.0021,  0.0054,  0.0035,  0.0055,
         0.0120, -0.0039, -0.0084, -0.0115,  0.0065, -0.0145, -0.0148,  0.0047,
         0.0017, -0.0152,  0.0016, -0.0147,  0.0156,  0.0015, -0.0122, -0.0044,
         0.0050,  0.0146,  0.0134,  0.0136, -0.0006,  0.0033, -0.0023, -0.0118,
        -0.0097,  0.0042, -0.0155, -0.0073,  0.0055, -0.0101, -0.0072,  0.0110,
         0.0006, -0.0047, -0.0085,  0.0017,  0.0122, -0.0025, -0.0107, -0.0081,
        -0.0003,  0.0033, -0.0046,  0.0006,  0.0103, -0.0011,  0.0031, -0.0152,
        -0.0045,  0.0108, -0.0120,  0.0014, -0.0095,  0.0088,  0.0059, -0.0074,
         0.0034,  0.0115, -0.0080,  0.0067, -0.0064,  0.0101,  0.0147,  0.0119,
         0.0029,  0.0027,  0.0137, -0.0097, -0.0026,  0.0087,  0.0058, -0.0056,
        -0.0113,  0.0002, -0.0155,  0.0021, -0.0147, -0.0074,  0.0050,  0.0147,
         0.0135,  0.0150, -0.0036, -0.0013,  0.0061,  0.0019,  0.0051,  0.0059,
        -0.0092, -0.0148, -0.0065,  0.0151, -0.0003,  0.0088,  0.0058,  0.0054,
         0.0067,  0.0004, -0.0053,  0.0126,  0.0031,  0.0059,  0.0012, -0.0025,
        -0.0036, -0.0104, -0.0111, -0.0035, -0.0074, -0.0052,  0.0125, -0.0031,
        -0.0110, -0.0008, -0.0022,  0.0146,  0.0012, -0.0003, -0.0092, -0.0077,
        -0.0153, -0.0119, -0.0099, -0.0088,  0.0091,  0.0076,  0.0136,  0.0101,
        -0.0002,  0.0104, -0.0077,  0.0031, -0.0058, -0.0055,  0.0041,  0.0073,
         0.0045, -0.0098,  0.0004, -0.0148,  0.0002,  0.0073,  0.0084,  0.0002,
        -0.0152, -0.0136,  0.0100,  0.0106, -0.0042,  0.0147,  0.0013,  0.0053,
        -0.0102, -0.0058,  0.0060, -0.0021, -0.0020, -0.0112, -0.0090,  0.0123,
         0.0111,  0.0111,  0.0155,  0.0028, -0.0061,  0.0116,  0.0131, -0.0003,
        -0.0129, -0.0116, -0.0144, -0.0015, -0.0106, -0.0146, -0.0048, -0.0109,
         0.0066,  0.0047,  0.0065,  0.0003,  0.0030, -0.0110, -0.0140, -0.0138,
        -0.0134,  0.0086, -0.0038,  0.0054, -0.0062,  0.0094,  0.0058, -0.0049,
        -0.0075,  0.0079, -0.0152,  0.0037, -0.0101, -0.0099,  0.0013,  0.0008,
         0.0027,  0.0152,  0.0080,  0.0091,  0.0024,  0.0044,  0.0085, -0.0109,
        -0.0082, -0.0062,  0.0133, -0.0007,  0.0087, -0.0086,  0.0070, -0.0142,
        -0.0004,  0.0028, -0.0155,  0.0124,  0.0146,  0.0038, -0.0060,  0.0102,
         0.0019, -0.0025, -0.0130,  0.0135,  0.0140,  0.0050,  0.0023,  0.0008,
         0.0104,  0.0106,  0.0037,  0.0150, -0.0021,  0.0131,  0.0060, -0.0059,
         0.0013, -0.0140,  0.0015, -0.0120, -0.0053,  0.0120,  0.0041, -0.0003,
        -0.0053,  0.0080, -0.0092, -0.0056, -0.0002,  0.0053, -0.0025, -0.0130,
        -0.0039, -0.0006, -0.0065,  0.0101, -0.0094,  0.0059, -0.0044, -0.0060,
        -0.0095, -0.0128, -0.0125,  0.0045, -0.0105, -0.0001,  0.0089,  0.0078,
        -0.0149, -0.0066, -0.0150,  0.0104,  0.0152, -0.0075,  0.0046,  0.0088,
        -0.0053,  0.0133, -0.0014, -0.0029, -0.0117, -0.0152, -0.0022,  0.0047])
fc2.weight tensor([[-0.0110, -0.0158, -0.0343,  ..., -0.0090, -0.0103, -0.0059],
        [-0.0427,  0.0103,  0.0340,  ..., -0.0374, -0.0251,  0.0309],
        [ 0.0200,  0.0034, -0.0401,  ...,  0.0289, -0.0114, -0.0124],
        ...,
        [ 0.0251, -0.0281, -0.0225,  ..., -0.0370,  0.0314, -0.0194],
        [ 0.0283, -0.0407, -0.0369,  ...,  0.0198, -0.0190,  0.0089],
        [ 0.0192,  0.0342, -0.0035,  ...,  0.0244,  0.0074, -0.0209]])
fc2.bias tensor([ 0.0233,  0.0059, -0.0152, -0.0146, -0.0271, -0.0147, -0.0069,  0.0318,
         0.0111, -0.0335, -0.0184, -0.0218, -0.0223, -0.0220, -0.0325, -0.0362,
         0.0356,  0.0112, -0.0041, -0.0021,  0.0026, -0.0342, -0.0311,  0.0336,
         0.0084,  0.0377,  0.0412, -0.0311,  0.0223, -0.0097, -0.0322,  0.0154,
        -0.0023, -0.0060,  0.0262, -0.0002, -0.0213, -0.0190, -0.0418, -0.0297])



Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/381
(64, 64, 3)
2018-10-11 01:19:49.194 Python[97008:15398033] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0262, 0.0268, 0.0216, 0.0181, 0.0299, 0.0220, 0.0272, 0.0218, 0.0138,
         0.0225, 0.0170, 0.0167, 0.0359, 0.0286, 0.0360, 0.0283, 0.0310, 0.0257,
         0.0140, 0.0232, 0.0159, 0.0299, 0.0401, 0.0278, 0.0323, 0.0199, 0.0211,
         0.0192, 0.0260, 0.0139, 0.0175, 0.0334, 0.0326, 0.0257, 0.0230, 0.0293,
         0.0320, 0.0265, 0.0253, 0.0223]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0 

 Policy reward
None


Session Number: 1
images/23
(64, 64, 3)
tensor([[0.0260, 0.0281, 0.0205, 0.0141, 0.0412, 0.0187, 0.0343, 0.0189, 0.0163,
         0.0176, 0.0259, 0.0309, 0.0402, 0.0285, 0.0247, 0.0148, 0.0202, 0.0476,
         0.0197, 0.0244, 0.0165, 0.0230, 0.0158, 0.0258, 0.0252, 0.0227, 0.0254,
         0.0255, 0.0251, 0.0193, 0.0172, 0.0476, 0.0178, 0.0238, 0.0198, 0.0384,
         0.0337, 0.0183, 0.0228, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0

 Policy reward
None


Traceback (most recent call last):
  File "Torch_reinforce01.py", line 183, in <module>
    main()
  File "Torch_reinforce01.py", line 170, in main
    finish_episode()
  File "Torch_reinforce01.py", line 119, in finish_episode
    policy_loss.backward()
  File "/usr/local/lib/python3.6/site-packages/torch/tensor.py", line 93, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/usr/local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 90, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/476
(64, 64, 3)
2018-10-11 01:20:20.994 Python[97053:15398575] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0290, 0.0236, 0.0197, 0.0187, 0.0240, 0.0207, 0.0349, 0.0200, 0.0134,
         0.0149, 0.0206, 0.0257, 0.0290, 0.0306, 0.0349, 0.0258, 0.0227, 0.0226,
         0.0176, 0.0162, 0.0127, 0.0255, 0.0364, 0.0256, 0.0274, 0.0237, 0.0242,
         0.0349, 0.0262, 0.0192, 0.0271, 0.0329, 0.0206, 0.0225, 0.0265, 0.0332,
         0.0332, 0.0315, 0.0258, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1

 Policy reward
None


Session Number: 1
images/316
(64, 64, 3)
tensor([[0.0416, 0.0294, 0.0152, 0.0165, 0.0279, 0.0158, 0.0429, 0.0179, 0.0137,
         0.0156, 0.0241, 0.0290, 0.0301, 0.0332, 0.0250, 0.0179, 0.0182, 0.0392,
         0.0221, 0.0215, 0.0116, 0.0189, 0.0177, 0.0242, 0.0248, 0.0169, 0.0207,
         0.0309, 0.0349, 0.0248, 0.0159, 0.0312, 0.0230, 0.0290, 0.0219, 0.0470,
         0.0374, 0.0233, 0.0229, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0

 Policy reward
None


Session Number: 2
images/120
(64, 64, 3)
tensor([[0.0275, 0.0335, 0.0159, 0.0198, 0.0343, 0.0224, 0.0389, 0.0144, 0.0128,
         0.0181, 0.0228, 0.0473, 0.0340, 0.0272, 0.0243, 0.0254, 0.0350, 0.0446,
         0.0181, 0.0130, 0.0181, 0.0231, 0.0198, 0.0236, 0.0190, 0.0187, 0.0260,
         0.0216, 0.0391, 0.0199, 0.0225, 0.0245, 0.0209, 0.0257, 0.0304, 0.0338,
         0.0229, 0.0160, 0.0277, 0.0174]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0

 Policy reward
None


Session Number: 3
images/410
(64, 64, 3)
tensor([[0.0348, 0.0320, 0.0152, 0.0222, 0.0366, 0.0199, 0.0263, 0.0208, 0.0211,
         0.0146, 0.0302, 0.0270, 0.0286, 0.0288, 0.0327, 0.0199, 0.0170, 0.0349,
         0.0161, 0.0378, 0.0160, 0.0251, 0.0169, 0.0251, 0.0254, 0.0196, 0.0214,
         0.0442, 0.0316, 0.0222, 0.0167, 0.0226, 0.0246, 0.0276, 0.0219, 0.0259,
         0.0226, 0.0296, 0.0260, 0.0188]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0

 Policy reward
None


Session Number: 4
images/343
(64, 64, 3)
tensor([[0.0260, 0.0413, 0.0153, 0.0216, 0.0421, 0.0220, 0.0377, 0.0127, 0.0149,
         0.0289, 0.0182, 0.0336, 0.0329, 0.0343, 0.0273, 0.0192, 0.0181, 0.0403,
         0.0152, 0.0144, 0.0137, 0.0190, 0.0190, 0.0197, 0.0199, 0.0206, 0.0266,
         0.0262, 0.0314, 0.0269, 0.0172, 0.0341, 0.0271, 0.0287, 0.0287, 0.0217,
         0.0260, 0.0225, 0.0274, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/334
(64, 64, 3)
2018-10-11 01:33:28.728 Python[97382:15409060] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0321, 0.0232, 0.0183, 0.0196, 0.0343, 0.0247, 0.0292, 0.0203, 0.0189,
         0.0188, 0.0165, 0.0216, 0.0291, 0.0448, 0.0457, 0.0220, 0.0226, 0.0322,
         0.0215, 0.0169, 0.0155, 0.0248, 0.0270, 0.0241, 0.0344, 0.0232, 0.0174,
         0.0211, 0.0208, 0.0193, 0.0182, 0.0294, 0.0268, 0.0227, 0.0218, 0.0329,
         0.0332, 0.0266, 0.0277, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0

 Policy reward
None


Reward currently is 0
Reward currently is 0
Session Number: 1
images/70
(64, 64, 3)
tensor([[0.0232, 0.0181, 0.0258, 0.0184, 0.0328, 0.0211, 0.0334, 0.0218, 0.0174,
         0.0191, 0.0162, 0.0379, 0.0226, 0.0346, 0.0245, 0.0157, 0.0218, 0.0381,
         0.0169, 0.0301, 0.0167, 0.0226, 0.0240, 0.0271, 0.0220, 0.0153, 0.0274,
         0.0347, 0.0386, 0.0199, 0.0165, 0.0373, 0.0256, 0.0256, 0.0264, 0.0345,
         0.0306, 0.0269, 0.0139, 0.0247]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 184, in <module>
    if __name__ == '__main__':
  File "Torch_reinforce01.py", line 151, in main
    
ValueError: invalid literal for int() with base 10: '-'
1%                                                                                                                      ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/475
(64, 64, 3)
2018-10-11 01:34:17.919 Python[97430:15409642] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0296, 0.0154, 0.0124, 0.0287, 0.0374, 0.0282, 0.0295, 0.0166, 0.0214,
         0.0224, 0.0151, 0.0241, 0.0398, 0.0334, 0.0304, 0.0225, 0.0220, 0.0340,
         0.0190, 0.0169, 0.0157, 0.0233, 0.0328, 0.0233, 0.0408, 0.0254, 0.0209,
         0.0306, 0.0221, 0.0201, 0.0162, 0.0424, 0.0179, 0.0180, 0.0178, 0.0278,
         0.0341, 0.0308, 0.0227, 0.0184]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1

 Policy reward
None


Reward currently is 1
Reward currently is 1
[1.99, 1.0]
Session Number: 1
images/82
(64, 64, 3)
^CTraceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/matplotlib/backend_bases.py", line 1953, in motion_notify_event
    def motion_notify_event(self, x, y, guiEvent=None):
KeyboardInterrupt
tensor([[0.0319, 0.0350, 0.0208, 0.0184, 0.0273, 0.0164, 0.0300, 0.0162, 0.0140,
         0.0220, 0.0216, 0.0328, 0.0329, 0.0429, 0.0270, 0.0181, 0.0150, 0.0333,
         0.0193, 0.0285, 0.0170, 0.0269, 0.0209, 0.0210, 0.0264, 0.0185, 0.0156,
         0.0429, 0.0282, 0.0244, 0.0131, 0.0346, 0.0245, 0.0230, 0.0239, 0.0267,
         0.0478, 0.0225, 0.0124, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/588
(64, 64, 3)
2018-10-11 01:35:03.491 Python[97481:15410182] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0295, 0.0197, 0.0210, 0.0244, 0.0355, 0.0190, 0.0364, 0.0140, 0.0183,
         0.0147, 0.0217, 0.0235, 0.0328, 0.0179, 0.0303, 0.0214, 0.0159, 0.0264,
         0.0177, 0.0139, 0.0172, 0.0260, 0.0281, 0.0239, 0.0280, 0.0247, 0.0215,
         0.0313, 0.0337, 0.0212, 0.0160, 0.0356, 0.0205, 0.0277, 0.0173, 0.0328,
         0.0489, 0.0348, 0.0288, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1

 Policy reward
None


[1, 1]
Reward currently is 1
Reward currently is 1
[1.99, 1.0]
Session Number: 1
images/420
(64, 64, 3)
tensor([[0.0305, 0.0286, 0.0167, 0.0168, 0.0218, 0.0214, 0.0328, 0.0134, 0.0141,
         0.0222, 0.0242, 0.0424, 0.0226, 0.0369, 0.0236, 0.0159, 0.0170, 0.0353,
         0.0224, 0.0280, 0.0189, 0.0299, 0.0185, 0.0336, 0.0297, 0.0162, 0.0205,
         0.0280, 0.0296, 0.0207, 0.0121, 0.0337, 0.0247, 0.0274, 0.0177, 0.0283,
         0.0653, 0.0173, 0.0160, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/410
(64, 64, 3)
2018-10-11 01:36:18.045 Python[97541:15410918] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0395, 0.0292, 0.0146, 0.0226, 0.0283, 0.0196, 0.0243, 0.0191, 0.0146,
         0.0205, 0.0198, 0.0197, 0.0244, 0.0240, 0.0459, 0.0178, 0.0226, 0.0263,
         0.0131, 0.0290, 0.0151, 0.0250, 0.0272, 0.0280, 0.0344, 0.0246, 0.0211,
         0.0275, 0.0284, 0.0201, 0.0165, 0.0351, 0.0254, 0.0279, 0.0144, 0.0312,
         0.0437, 0.0329, 0.0229, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1

 Policy reward


[1]
Reward currently is 1
[1.0]
Session Number: 1
images/208
(64, 64, 3)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 186, in <module>
  File "Torch_reinforce01.py", line 143, in main
    print('Action:',action_table[action])
  File "Torch_reinforce01.py", line 101, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/108
(64, 64, 3)
2018-10-11 01:37:11.619 Python[97593:15411465] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0283, 0.0238, 0.0241, 0.0228, 0.0351, 0.0200, 0.0296, 0.0149, 0.0144,
         0.0281, 0.0175, 0.0183, 0.0267, 0.0326, 0.0371, 0.0218, 0.0235, 0.0231,
         0.0143, 0.0265, 0.0135, 0.0223, 0.0323, 0.0247, 0.0326, 0.0273, 0.0217,
         0.0323, 0.0270, 0.0177, 0.0207, 0.0398, 0.0236, 0.0295, 0.0270, 0.0240,
         0.0299, 0.0246, 0.0241, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0 

 Policy reward


[0.0]
Session Number: 1
images/198
(64, 64, 3)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 184, in <module>
    main()
  File "Torch_reinforce01.py", line 141, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 101, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0

Loading the model if any
0
Session Number: 0
images/261
(64, 64, 3)
2018-10-11 01:37:46.952 Python[97638:15411914] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0334, 0.0249, 0.0165, 0.0295, 0.0360, 0.0283, 0.0256, 0.0205, 0.0172,
         0.0184, 0.0140, 0.0213, 0.0359, 0.0313, 0.0328, 0.0183, 0.0251, 0.0311,
         0.0166, 0.0117, 0.0160, 0.0260, 0.0281, 0.0204, 0.0341, 0.0289, 0.0216,
         0.0318, 0.0277, 0.0183, 0.0181, 0.0306, 0.0238, 0.0237, 0.0172, 0.0321,
         0.0375, 0.0292, 0.0255, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: Traceback (most recent call last):
  File "Torch_reinforce01.py", line 184, in <module>
    main()
  File "Torch_reinforce01.py", line 151, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: ''
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/439
(64, 64, 3)
2018-10-11 01:38:12.998 Python[97680:15412388] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0300, 0.0203, 0.0201, 0.0224, 0.0312, 0.0244, 0.0298, 0.0173, 0.0164,
         0.0169, 0.0167, 0.0229, 0.0411, 0.0348, 0.0325, 0.0245, 0.0179, 0.0288,
         0.0138, 0.0229, 0.0145, 0.0198, 0.0256, 0.0277, 0.0373, 0.0221, 0.0145,
         0.0201, 0.0249, 0.0232, 0.0196, 0.0459, 0.0205, 0.0184, 0.0208, 0.0458,
         0.0426, 0.0239, 0.0293, 0.0186]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1

 Policy reward


tensor([nan])
Session Number: 1
images/158
(64, 64, 3)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 184, in <module>
    main()
  File "Torch_reinforce01.py", line 141, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 101, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/121
(64, 64, 3)
2018-10-11 01:39:01.521 Python[97730:15412933] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0311, 0.0258, 0.0161, 0.0229, 0.0318, 0.0204, 0.0298, 0.0172, 0.0159,
         0.0163, 0.0195, 0.0269, 0.0317, 0.0261, 0.0347, 0.0244, 0.0191, 0.0277,
         0.0246, 0.0153, 0.0119, 0.0231, 0.0325, 0.0279, 0.0234, 0.0292, 0.0219,
         0.0270, 0.0296, 0.0148, 0.0134, 0.0438, 0.0291, 0.0228, 0.0237, 0.0256,
         0.0444, 0.0362, 0.0224, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0

 Policy reward


tensor(nan)
Session Number: 1
images/298
(64, 64, 3)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 184, in <module>
    main()
  File "Torch_reinforce01.py", line 141, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 101, in select_action
    action = m.sample()
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 90, in sample
    sample_2d = torch.multinomial(probs_2d, 1, True)
RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorRandom.cpp:407
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/464
(64, 64, 3)
2018-10-11 01:40:44.012 Python[97795:15413853] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0342, 0.0265, 0.0198, 0.0196, 0.0302, 0.0186, 0.0257, 0.0167, 0.0181,
         0.0207, 0.0167, 0.0241, 0.0312, 0.0240, 0.0368, 0.0206, 0.0291, 0.0270,
         0.0122, 0.0174, 0.0128, 0.0248, 0.0330, 0.0244, 0.0265, 0.0310, 0.0267,
         0.0323, 0.0240, 0.0175, 0.0206, 0.0302, 0.0213, 0.0224, 0.0276, 0.0362,
         0.0452, 0.0276, 0.0261, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1

 Policy reward


tensor(nan)
Session Number: 1
images/512
(64, 64, 3)
tensor([[0.0305, 0.0222, 0.0164, 0.0165, 0.0267, 0.0122, 0.0292, 0.0162, 0.0191,
         0.0138, 0.0231, 0.0329, 0.0261, 0.0326, 0.0237, 0.0219, 0.0215, 0.0438,
         0.0179, 0.0239, 0.0215, 0.0328, 0.0235, 0.0256, 0.0239, 0.0185, 0.0214,
         0.0335, 0.0265, 0.0243, 0.0146, 0.0470, 0.0272, 0.0325, 0.0134, 0.0508,
         0.0348, 0.0176, 0.0156, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0

 Policy reward


tensor(nan)
Session Number: 2
images/504
(64, 64, 3)
tensor([[0.0304, 0.0289, 0.0191, 0.0259, 0.0389, 0.0196, 0.0277, 0.0127, 0.0207,
         0.0277, 0.0234, 0.0337, 0.0373, 0.0282, 0.0251, 0.0160, 0.0277, 0.0402,
         0.0232, 0.0167, 0.0154, 0.0251, 0.0207, 0.0239, 0.0162, 0.0178, 0.0334,
         0.0203, 0.0376, 0.0190, 0.0182, 0.0263, 0.0236, 0.0336, 0.0234, 0.0368,
         0.0302, 0.0197, 0.0182, 0.0174]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0

 Policy reward


tensor(nan)
Session Number: 3
images/418
(64, 64, 3)
tensor([[0.0302, 0.0271, 0.0210, 0.0273, 0.0261, 0.0228, 0.0266, 0.0139, 0.0291,
         0.0147, 0.0263, 0.0375, 0.0435, 0.0439, 0.0213, 0.0182, 0.0172, 0.0264,
         0.0177, 0.0305, 0.0175, 0.0212, 0.0167, 0.0188, 0.0246, 0.0168, 0.0210,
         0.0455, 0.0357, 0.0189, 0.0174, 0.0217, 0.0343, 0.0325, 0.0271, 0.0224,
         0.0281, 0.0210, 0.0176, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: -1
Breaking
Saving the weights
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
  File "Torch_reinforce01.py", line 27
    help='Path to the weights.')
       ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 0
Loading the model if any
0
Session Number: 0
images/14
(64, 64, 3)
2018-10-12 16:04:42.152 Python[5577:15626640] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0369, 0.0281, 0.0225, 0.0217, 0.0299, 0.0222, 0.0314, 0.0153, 0.0188,
         0.0153, 0.0235, 0.0283, 0.0415, 0.0300, 0.0424, 0.0248, 0.0185, 0.0190,
         0.0157, 0.0193, 0.0138, 0.0242, 0.0317, 0.0199, 0.0266, 0.0193, 0.0198,
         0.0291, 0.0250, 0.0194, 0.0192, 0.0298, 0.0219, 0.0348, 0.0244, 0.0317,
         0.0333, 0.0285, 0.0209, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1

 Policy reward


Session Number: 1
images/61
(64, 64, 3)
tensor([[0.0333, 0.0259, 0.0164, 0.0213, 0.0309, 0.0185, 0.0284, 0.0161, 0.0125,
         0.0242, 0.0173, 0.0262, 0.0297, 0.0384, 0.0213, 0.0176, 0.0188, 0.0363,
         0.0216, 0.0239, 0.0122, 0.0283, 0.0211, 0.0294, 0.0263, 0.0230, 0.0154,
         0.0390, 0.0400, 0.0323, 0.0127, 0.0310, 0.0200, 0.0235, 0.0219, 0.0376,
         0.0409, 0.0221, 0.0192, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0

 Policy reward


Session Number: 2
images/366
(64, 64, 3)
tensor([[0.0366, 0.0315, 0.0150, 0.0145, 0.0309, 0.0334, 0.0308, 0.0100, 0.0136,
         0.0194, 0.0258, 0.0253, 0.0422, 0.0449, 0.0232, 0.0191, 0.0362, 0.0378,
         0.0217, 0.0201, 0.0194, 0.0287, 0.0255, 0.0275, 0.0185, 0.0195, 0.0238,
         0.0250, 0.0294, 0.0157, 0.0266, 0.0254, 0.0297, 0.0244, 0.0176, 0.0248,
         0.0260, 0.0203, 0.0213, 0.0190]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0

 Policy reward


Session Number: 3
images/497
(64, 64, 3)
tensor([[0.0340, 0.0236, 0.0241, 0.0196, 0.0201, 0.0212, 0.0332, 0.0215, 0.0280,
         0.0164, 0.0238, 0.0280, 0.0258, 0.0363, 0.0271, 0.0241, 0.0196, 0.0318,
         0.0250, 0.0222, 0.0150, 0.0303, 0.0174, 0.0164, 0.0267, 0.0193, 0.0201,
         0.0399, 0.0387, 0.0254, 0.0330, 0.0159, 0.0259, 0.0299, 0.0208, 0.0277,
         0.0264, 0.0209, 0.0269, 0.0179]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0

 Policy reward


Session Number: 4
images/258
(64, 64, 3)
tensor([[0.0265, 0.0238, 0.0210, 0.0208, 0.0360, 0.0223, 0.0323, 0.0229, 0.0185,
         0.0207, 0.0132, 0.0276, 0.0388, 0.0417, 0.0274, 0.0184, 0.0259, 0.0324,
         0.0234, 0.0144, 0.0177, 0.0220, 0.0266, 0.0174, 0.0175, 0.0249, 0.0305,
         0.0270, 0.0288, 0.0245, 0.0219, 0.0263, 0.0220, 0.0261, 0.0351, 0.0252,
         0.0211, 0.0251, 0.0246, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0

 Policy reward


Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/588
(64, 64, 3)
2018-10-12 16:05:39.951 Python[5635:15627346] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0295, 0.0197, 0.0210, 0.0244, 0.0355, 0.0190, 0.0364, 0.0140, 0.0183,
         0.0147, 0.0217, 0.0235, 0.0328, 0.0179, 0.0303, 0.0214, 0.0159, 0.0264,
         0.0177, 0.0139, 0.0172, 0.0260, 0.0281, 0.0239, 0.0280, 0.0247, 0.0215,
         0.0313, 0.0337, 0.0212, 0.0160, 0.0356, 0.0205, 0.0277, 0.0173, 0.0328,
         0.0489, 0.0348, 0.0288, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 1
images/214
(64, 64, 3)
tensor([[0.0401, 0.0208, 0.0195, 0.0169, 0.0243, 0.0204, 0.0323, 0.0237, 0.0170,
         0.0119, 0.0160, 0.0280, 0.0222, 0.0330, 0.0353, 0.0287, 0.0270, 0.0429,
         0.0155, 0.0222, 0.0140, 0.0250, 0.0248, 0.0260, 0.0232, 0.0174, 0.0200,
         0.0368, 0.0332, 0.0197, 0.0250, 0.0414, 0.0188, 0.0251, 0.0245, 0.0329,
         0.0345, 0.0182, 0.0176, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/325
(64, 64, 3)
tensor([[0.0291, 0.0233, 0.0143, 0.0175, 0.0455, 0.0224, 0.0429, 0.0189, 0.0158,
         0.0145, 0.0261, 0.0270, 0.0376, 0.0326, 0.0285, 0.0176, 0.0236, 0.0298,
         0.0227, 0.0172, 0.0162, 0.0278, 0.0189, 0.0238, 0.0165, 0.0146, 0.0369,
         0.0247, 0.0285, 0.0201, 0.0245, 0.0287, 0.0389, 0.0367, 0.0218, 0.0245,
         0.0296, 0.0215, 0.0225, 0.0163]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 3
images/77
(64, 64, 3)
tensor([[0.0329, 0.0227, 0.0154, 0.0260, 0.0356, 0.0191, 0.0378, 0.0185, 0.0237,
         0.0168, 0.0314, 0.0302, 0.0299, 0.0435, 0.0242, 0.0203, 0.0211, 0.0479,
         0.0203, 0.0334, 0.0205, 0.0172, 0.0161, 0.0217, 0.0277, 0.0161, 0.0214,
         0.0345, 0.0266, 0.0255, 0.0151, 0.0203, 0.0263, 0.0317, 0.0228, 0.0209,
         0.0198, 0.0270, 0.0211, 0.0170]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 4
images/311
(64, 64, 3)
tensor([[0.0248, 0.0286, 0.0230, 0.0127, 0.0332, 0.0172, 0.0303, 0.0155, 0.0158,
         0.0183, 0.0133, 0.0406, 0.0254, 0.0355, 0.0335, 0.0188, 0.0198, 0.0453,
         0.0193, 0.0164, 0.0207, 0.0365, 0.0203, 0.0210, 0.0179, 0.0216, 0.0326,
         0.0271, 0.0381, 0.0299, 0.0147, 0.0358, 0.0233, 0.0338, 0.0344, 0.0219,
         0.0207, 0.0230, 0.0202, 0.0191]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 5
images/554
(64, 64, 3)
tensor([[0.0174, 0.0327, 0.0203, 0.0153, 0.0253, 0.0199, 0.0448, 0.0311, 0.0182,
         0.0175, 0.0239, 0.0317, 0.0349, 0.0391, 0.0405, 0.0277, 0.0192, 0.0387,
         0.0136, 0.0329, 0.0174, 0.0192, 0.0266, 0.0259, 0.0172, 0.0119, 0.0219,
         0.0269, 0.0268, 0.0276, 0.0223, 0.0299, 0.0316, 0.0217, 0.0211, 0.0235,
         0.0183, 0.0181, 0.0231, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 6
images/94
(64, 64, 3)
tensor([[0.0437, 0.0376, 0.0245, 0.0143, 0.0212, 0.0270, 0.0301, 0.0224, 0.0239,
         0.0302, 0.0289, 0.0239, 0.0424, 0.0236, 0.0264, 0.0153, 0.0185, 0.0432,
         0.0167, 0.0229, 0.0107, 0.0248, 0.0261, 0.0204, 0.0188, 0.0170, 0.0215,
         0.0296, 0.0298, 0.0214, 0.0258, 0.0267, 0.0226, 0.0217, 0.0194, 0.0316,
         0.0208, 0.0215, 0.0243, 0.0288]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 7
images/386
(64, 64, 3)
tensor([[0.0422, 0.0234, 0.0279, 0.0209, 0.0208, 0.0134, 0.0295, 0.0147, 0.0139,
         0.0102, 0.0201, 0.0446, 0.0436, 0.0376, 0.0185, 0.0238, 0.0190, 0.0281,
         0.0148, 0.0226, 0.0125, 0.0218, 0.0156, 0.0278, 0.0186, 0.0193, 0.0349,
         0.0444, 0.0329, 0.0201, 0.0247, 0.0314, 0.0240, 0.0318, 0.0169, 0.0249,
         0.0473, 0.0230, 0.0136, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/54
(64, 64, 3)
tensor([[0.0176, 0.0219, 0.0173, 0.0234, 0.0268, 0.0166, 0.0363, 0.0227, 0.0164,
         0.0215, 0.0193, 0.0336, 0.0418, 0.0277, 0.0251, 0.0179, 0.0200, 0.0384,
         0.0214, 0.0189, 0.0105, 0.0177, 0.0281, 0.0262, 0.0203, 0.0200, 0.0300,
         0.0265, 0.0398, 0.0164, 0.0118, 0.0450, 0.0265, 0.0227, 0.0235, 0.0362,
         0.0223, 0.0232, 0.0248, 0.0440]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 9
images/163
(64, 64, 3)
tensor([[0.0240, 0.0315, 0.0157, 0.0168, 0.0323, 0.0125, 0.0398, 0.0229, 0.0143,
         0.0210, 0.0266, 0.0266, 0.0253, 0.0383, 0.0266, 0.0165, 0.0211, 0.0359,
         0.0164, 0.0174, 0.0145, 0.0236, 0.0146, 0.0245, 0.0211, 0.0224, 0.0204,
         0.0253, 0.0716, 0.0245, 0.0199, 0.0271, 0.0273, 0.0246, 0.0207, 0.0462,
         0.0207, 0.0184, 0.0248, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 10
images/20
(64, 64, 3)
tensor([[0.0221, 0.0207, 0.0184, 0.0145, 0.0484, 0.0186, 0.0252, 0.0221, 0.0235,
         0.0209, 0.0196, 0.0336, 0.0413, 0.0235, 0.0296, 0.0093, 0.0172, 0.0292,
         0.0242, 0.0251, 0.0139, 0.0190, 0.0223, 0.0258, 0.0200, 0.0181, 0.0413,
         0.0237, 0.0206, 0.0223, 0.0265, 0.0321, 0.0329, 0.0262, 0.0376, 0.0256,
         0.0211, 0.0266, 0.0260, 0.0315]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 11
images/33
(64, 64, 3)
tensor([[0.0157, 0.0287, 0.0371, 0.0142, 0.0397, 0.0241, 0.0372, 0.0136, 0.0295,
         0.0254, 0.0124, 0.0285, 0.0360, 0.0333, 0.0248, 0.0172, 0.0148, 0.0422,
         0.0162, 0.0148, 0.0185, 0.0241, 0.0292, 0.0249, 0.0199, 0.0149, 0.0229,
         0.0412, 0.0353, 0.0335, 0.0171, 0.0253, 0.0256, 0.0213, 0.0371, 0.0217,
         0.0209, 0.0238, 0.0157, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/173
(64, 64, 3)
tensor([[0.0424, 0.0270, 0.0143, 0.0189, 0.0221, 0.0170, 0.0376, 0.0196, 0.0166,
         0.0166, 0.0175, 0.0230, 0.0504, 0.0372, 0.0183, 0.0214, 0.0195, 0.0377,
         0.0173, 0.0179, 0.0240, 0.0287, 0.0236, 0.0242, 0.0204, 0.0150, 0.0232,
         0.0298, 0.0500, 0.0192, 0.0142, 0.0363, 0.0255, 0.0161, 0.0253, 0.0249,
         0.0228, 0.0246, 0.0232, 0.0366]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 13
images/361
(64, 64, 3)
tensor([[0.0259, 0.0244, 0.0220, 0.0131, 0.0186, 0.0412, 0.0396, 0.0224, 0.0134,
         0.0195, 0.0259, 0.0251, 0.0406, 0.0336, 0.0191, 0.0419, 0.0138, 0.0258,
         0.0202, 0.0186, 0.0189, 0.0279, 0.0120, 0.0199, 0.0308, 0.0132, 0.0219,
         0.0430, 0.0273, 0.0164, 0.0191, 0.0341, 0.0331, 0.0119, 0.0260, 0.0270,
         0.0375, 0.0172, 0.0256, 0.0323]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 14
images/199
(64, 64, 3)
tensor([[0.0362, 0.0171, 0.0164, 0.0151, 0.0216, 0.0276, 0.0390, 0.0231, 0.0201,
         0.0153, 0.0231, 0.0334, 0.0346, 0.0237, 0.0366, 0.0169, 0.0236, 0.0288,
         0.0152, 0.0202, 0.0240, 0.0184, 0.0204, 0.0201, 0.0184, 0.0274, 0.0269,
         0.0374, 0.0287, 0.0175, 0.0198, 0.0475, 0.0344, 0.0159, 0.0161, 0.0194,
         0.0260, 0.0171, 0.0444, 0.0324]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 15
images/77
(64, 64, 3)
tensor([[0.0276, 0.0180, 0.0199, 0.0229, 0.0384, 0.0150, 0.0271, 0.0226, 0.0181,
         0.0208, 0.0199, 0.0301, 0.0209, 0.0278, 0.0258, 0.0204, 0.0154, 0.0340,
         0.0168, 0.0260, 0.0190, 0.0240, 0.0264, 0.0299, 0.0275, 0.0234, 0.0176,
         0.0353, 0.0250, 0.0314, 0.0237, 0.0438, 0.0254, 0.0154, 0.0201, 0.0308,
         0.0392, 0.0144, 0.0366, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/102
(64, 64, 3)
tensor([[0.0232, 0.0273, 0.0127, 0.0189, 0.0256, 0.0250, 0.0299, 0.0230, 0.0168,
         0.0294, 0.0206, 0.0229, 0.0433, 0.0301, 0.0340, 0.0198, 0.0184, 0.0587,
         0.0281, 0.0231, 0.0191, 0.0202, 0.0172, 0.0202, 0.0205, 0.0295, 0.0149,
         0.0533, 0.0314, 0.0257, 0.0186, 0.0336, 0.0227, 0.0168, 0.0271, 0.0244,
         0.0142, 0.0235, 0.0190, 0.0173]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 17
images/379
(64, 64, 3)
tensor([[0.0208, 0.0399, 0.0270, 0.0228, 0.0328, 0.0155, 0.0310, 0.0264, 0.0253,
         0.0224, 0.0145, 0.0288, 0.0531, 0.0341, 0.0240, 0.0143, 0.0206, 0.0527,
         0.0198, 0.0128, 0.0160, 0.0162, 0.0229, 0.0175, 0.0219, 0.0145, 0.0326,
         0.0279, 0.0250, 0.0296, 0.0191, 0.0328, 0.0242, 0.0220, 0.0271, 0.0283,
         0.0283, 0.0171, 0.0172, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 18
images/211
(64, 64, 3)
tensor([[0.0249, 0.0247, 0.0264, 0.0138, 0.0288, 0.0182, 0.0364, 0.0198, 0.0171,
         0.0121, 0.0195, 0.0279, 0.0518, 0.0304, 0.0185, 0.0210, 0.0160, 0.0443,
         0.0157, 0.0247, 0.0166, 0.0283, 0.0263, 0.0221, 0.0205, 0.0150, 0.0191,
         0.0274, 0.0227, 0.0229, 0.0207, 0.0412, 0.0262, 0.0178, 0.0342, 0.0320,
         0.0362, 0.0204, 0.0244, 0.0339]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 19
images/397
(64, 64, 3)
tensor([[0.0354, 0.0217, 0.0167, 0.0258, 0.0393, 0.0271, 0.0314, 0.0208, 0.0218,
         0.0170, 0.0150, 0.0220, 0.0365, 0.0500, 0.0281, 0.0152, 0.0273, 0.0491,
         0.0203, 0.0160, 0.0162, 0.0150, 0.0164, 0.0154, 0.0209, 0.0172, 0.0177,
         0.0319, 0.0442, 0.0282, 0.0154, 0.0229, 0.0272, 0.0275, 0.0309, 0.0270,
         0.0273, 0.0170, 0.0279, 0.0179]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 20
images/91
(64, 64, 3)
tensor([[0.0210, 0.0261, 0.0129, 0.0204, 0.0456, 0.0279, 0.0311, 0.0173, 0.0121,
         0.0163, 0.0256, 0.0213, 0.0509, 0.0261, 0.0175, 0.0165, 0.0216, 0.0424,
         0.0223, 0.0232, 0.0125, 0.0199, 0.0266, 0.0209, 0.0249, 0.0345, 0.0245,
         0.0319, 0.0246, 0.0285, 0.0167, 0.0248, 0.0328, 0.0229, 0.0209, 0.0323,
         0.0245, 0.0314, 0.0215, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 21
images/597
(64, 64, 3)
tensor([[0.0291, 0.0291, 0.0150, 0.0128, 0.0199, 0.0264, 0.0359, 0.0149, 0.0197,
         0.0113, 0.0188, 0.0365, 0.0617, 0.0320, 0.0184, 0.0145, 0.0274, 0.0348,
         0.0227, 0.0184, 0.0136, 0.0218, 0.0136, 0.0205, 0.0128, 0.0185, 0.0376,
         0.0258, 0.0518, 0.0149, 0.0213, 0.0267, 0.0215, 0.0261, 0.0190, 0.0455,
         0.0410, 0.0156, 0.0267, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/565
(64, 64, 3)
tensor([[0.0351, 0.0201, 0.0144, 0.0247, 0.0332, 0.0178, 0.0436, 0.0132, 0.0210,
         0.0201, 0.0145, 0.0248, 0.0559, 0.0392, 0.0171, 0.0141, 0.0329, 0.0549,
         0.0153, 0.0180, 0.0169, 0.0236, 0.0224, 0.0205, 0.0165, 0.0189, 0.0247,
         0.0261, 0.0363, 0.0210, 0.0175, 0.0212, 0.0259, 0.0288, 0.0234, 0.0485,
         0.0172, 0.0159, 0.0204, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 23
images/403
(64, 64, 3)
tensor([[0.0147, 0.0235, 0.0182, 0.0182, 0.0443, 0.0239, 0.0331, 0.0164, 0.0219,
         0.0214, 0.0174, 0.0335, 0.0395, 0.0341, 0.0239, 0.0153, 0.0355, 0.0227,
         0.0157, 0.0275, 0.0158, 0.0215, 0.0176, 0.0253, 0.0159, 0.0206, 0.0290,
         0.0269, 0.0312, 0.0201, 0.0192, 0.0250, 0.0168, 0.0329, 0.0316, 0.0395,
         0.0362, 0.0229, 0.0238, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 24
images/53
(64, 64, 3)
tensor([[0.0363, 0.0200, 0.0110, 0.0254, 0.0308, 0.0253, 0.0354, 0.0081, 0.0287,
         0.0201, 0.0202, 0.0316, 0.0361, 0.0219, 0.0259, 0.0202, 0.0231, 0.0319,
         0.0190, 0.0149, 0.0141, 0.0142, 0.0176, 0.0233, 0.0178, 0.0331, 0.0314,
         0.0464, 0.0456, 0.0252, 0.0195, 0.0283, 0.0256, 0.0272, 0.0353, 0.0290,
         0.0262, 0.0147, 0.0161, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/334
(64, 64, 3)
tensor([[0.0308, 0.0213, 0.0281, 0.0169, 0.0315, 0.0189, 0.0286, 0.0218, 0.0136,
         0.0235, 0.0172, 0.0300, 0.0392, 0.0417, 0.0210, 0.0213, 0.0191, 0.0355,
         0.0174, 0.0207, 0.0166, 0.0254, 0.0262, 0.0369, 0.0278, 0.0240, 0.0186,
         0.0304, 0.0262, 0.0308, 0.0149, 0.0300, 0.0229, 0.0230, 0.0155, 0.0413,
         0.0285, 0.0192, 0.0236, 0.0201]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 26
images/161
(64, 64, 3)
tensor([[0.0251, 0.0320, 0.0186, 0.0123, 0.0367, 0.0169, 0.0297, 0.0217, 0.0192,
         0.0261, 0.0112, 0.0341, 0.0309, 0.0378, 0.0285, 0.0216, 0.0195, 0.0392,
         0.0175, 0.0158, 0.0258, 0.0281, 0.0246, 0.0261, 0.0235, 0.0154, 0.0197,
         0.0312, 0.0355, 0.0284, 0.0183, 0.0186, 0.0357, 0.0273, 0.0223, 0.0339,
         0.0293, 0.0151, 0.0202, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 27
images/190
(64, 64, 3)
tensor([[0.0239, 0.0281, 0.0131, 0.0202, 0.0277, 0.0210, 0.0289, 0.0186, 0.0228,
         0.0190, 0.0227, 0.0269, 0.0519, 0.0190, 0.0283, 0.0212, 0.0309, 0.0352,
         0.0244, 0.0309, 0.0168, 0.0179, 0.0224, 0.0157, 0.0146, 0.0267, 0.0343,
         0.0340, 0.0219, 0.0204, 0.0183, 0.0263, 0.0210, 0.0170, 0.0289, 0.0425,
         0.0365, 0.0252, 0.0205, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 28
images/316
(64, 64, 3)
tensor([[0.0355, 0.0238, 0.0148, 0.0228, 0.0317, 0.0202, 0.0472, 0.0152, 0.0155,
         0.0206, 0.0278, 0.0199, 0.0832, 0.0235, 0.0200, 0.0114, 0.0151, 0.0393,
         0.0293, 0.0202, 0.0109, 0.0154, 0.0221, 0.0185, 0.0138, 0.0130, 0.0297,
         0.0279, 0.0203, 0.0210, 0.0212, 0.0216, 0.0288, 0.0213, 0.0334, 0.0461,
         0.0336, 0.0192, 0.0265, 0.0189]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 29
images/483
(64, 64, 3)
tensor([[0.0346, 0.0199, 0.0313, 0.0252, 0.0361, 0.0155, 0.0255, 0.0110, 0.0195,
         0.0221, 0.0191, 0.0317, 0.0336, 0.0247, 0.0285, 0.0182, 0.0127, 0.0420,
         0.0171, 0.0234, 0.0213, 0.0258, 0.0315, 0.0280, 0.0219, 0.0160, 0.0245,
         0.0240, 0.0269, 0.0201, 0.0251, 0.0367, 0.0197, 0.0359, 0.0231, 0.0319,
         0.0373, 0.0148, 0.0204, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 30
images/277
(64, 64, 3)
tensor([[0.0287, 0.0155, 0.0163, 0.0188, 0.0326, 0.0134, 0.0241, 0.0205, 0.0136,
         0.0188, 0.0208, 0.0321, 0.0322, 0.0410, 0.0159, 0.0226, 0.0207, 0.0428,
         0.0266, 0.0357, 0.0264, 0.0302, 0.0220, 0.0189, 0.0389, 0.0266, 0.0235,
         0.0347, 0.0315, 0.0228, 0.0189, 0.0350, 0.0165, 0.0279, 0.0251, 0.0304,
         0.0271, 0.0200, 0.0148, 0.0161]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 31
images/291
(64, 64, 3)
tensor([[0.0337, 0.0254, 0.0284, 0.0110, 0.0346, 0.0197, 0.0338, 0.0202, 0.0170,
         0.0203, 0.0273, 0.0566, 0.0201, 0.0284, 0.0218, 0.0132, 0.0246, 0.0509,
         0.0148, 0.0234, 0.0162, 0.0127, 0.0213, 0.0170, 0.0226, 0.0186, 0.0186,
         0.0311, 0.0434, 0.0211, 0.0182, 0.0357, 0.0309, 0.0201, 0.0198, 0.0186,
         0.0272, 0.0259, 0.0229, 0.0328]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 32
images/9
(64, 64, 3)
tensor([[0.0293, 0.0433, 0.0127, 0.0206, 0.0246, 0.0212, 0.0470, 0.0187, 0.0134,
         0.0165, 0.0184, 0.0268, 0.0381, 0.0246, 0.0472, 0.0256, 0.0296, 0.0298,
         0.0180, 0.0290, 0.0127, 0.0383, 0.0244, 0.0299, 0.0242, 0.0207, 0.0294,
         0.0182, 0.0218, 0.0273, 0.0197, 0.0202, 0.0291, 0.0187, 0.0240, 0.0222,
         0.0222, 0.0240, 0.0186, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 33
images/472
(64, 64, 3)
tensor([[0.0219, 0.0252, 0.0189, 0.0201, 0.0374, 0.0184, 0.0530, 0.0239, 0.0222,
         0.0210, 0.0172, 0.0395, 0.0356, 0.0398, 0.0235, 0.0139, 0.0139, 0.0251,
         0.0291, 0.0191, 0.0273, 0.0178, 0.0187, 0.0157, 0.0223, 0.0229, 0.0251,
         0.0282, 0.0329, 0.0209, 0.0188, 0.0302, 0.0408, 0.0223, 0.0269, 0.0165,
         0.0337, 0.0158, 0.0161, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 34
images/269
(64, 64, 3)
tensor([[0.0397, 0.0166, 0.0198, 0.0148, 0.0296, 0.0162, 0.0276, 0.0179, 0.0211,
         0.0291, 0.0167, 0.0236, 0.0308, 0.0267, 0.0317, 0.0207, 0.0186, 0.0351,
         0.0182, 0.0185, 0.0184, 0.0325, 0.0152, 0.0265, 0.0290, 0.0216, 0.0248,
         0.0477, 0.0190, 0.0439, 0.0189, 0.0313, 0.0285, 0.0180, 0.0330, 0.0248,
         0.0227, 0.0174, 0.0271, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 35
images/568
(64, 64, 3)
tensor([[0.0296, 0.0262, 0.0272, 0.0107, 0.0350, 0.0295, 0.0397, 0.0270, 0.0236,
         0.0188, 0.0197, 0.0230, 0.0314, 0.0510, 0.0213, 0.0172, 0.0146, 0.0370,
         0.0280, 0.0174, 0.0209, 0.0249, 0.0128, 0.0246, 0.0174, 0.0110, 0.0194,
         0.0347, 0.0543, 0.0305, 0.0239, 0.0199, 0.0302, 0.0252, 0.0180, 0.0168,
         0.0173, 0.0206, 0.0207, 0.0288]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 36
images/110
(64, 64, 3)
tensor([[0.0217, 0.0183, 0.0173, 0.0152, 0.0261, 0.0168, 0.0456, 0.0428, 0.0229,
         0.0101, 0.0168, 0.0255, 0.0197, 0.0518, 0.0338, 0.0117, 0.0167, 0.0391,
         0.0147, 0.0313, 0.0167, 0.0239, 0.0198, 0.0171, 0.0211, 0.0203, 0.0185,
         0.0228, 0.0318, 0.0294, 0.0227, 0.0325, 0.0231, 0.0205, 0.0334, 0.0327,
         0.0292, 0.0304, 0.0277, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 37
images/119
(64, 64, 3)
tensor([[0.0204, 0.0297, 0.0214, 0.0186, 0.0337, 0.0194, 0.0338, 0.0168, 0.0160,
         0.0237, 0.0233, 0.0244, 0.0323, 0.0393, 0.0208, 0.0234, 0.0195, 0.0358,
         0.0235, 0.0187, 0.0202, 0.0255, 0.0245, 0.0248, 0.0282, 0.0197, 0.0205,
         0.0333, 0.0352, 0.0292, 0.0167, 0.0245, 0.0330, 0.0205, 0.0213, 0.0367,
         0.0270, 0.0127, 0.0293, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 38
images/508
(64, 64, 3)
tensor([[0.0183, 0.0298, 0.0170, 0.0150, 0.0271, 0.0185, 0.0306, 0.0215, 0.0202,
         0.0162, 0.0142, 0.0602, 0.0299, 0.0257, 0.0325, 0.0217, 0.0148, 0.0387,
         0.0161, 0.0232, 0.0174, 0.0220, 0.0216, 0.0236, 0.0270, 0.0157, 0.0206,
         0.0570, 0.0367, 0.0152, 0.0263, 0.0299, 0.0325, 0.0142, 0.0207, 0.0289,
         0.0342, 0.0161, 0.0233, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 39
images/11
(64, 64, 3)
tensor([[0.0357, 0.0210, 0.0184, 0.0178, 0.0330, 0.0213, 0.0371, 0.0164, 0.0145,
         0.0225, 0.0236, 0.0345, 0.0290, 0.0398, 0.0210, 0.0186, 0.0200, 0.0439,
         0.0187, 0.0203, 0.0324, 0.0262, 0.0197, 0.0233, 0.0216, 0.0165, 0.0232,
         0.0363, 0.0414, 0.0173, 0.0208, 0.0392, 0.0249, 0.0160, 0.0168, 0.0301,
         0.0246, 0.0144, 0.0218, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 40
images/420
(64, 64, 3)
tensor([[0.0377, 0.0319, 0.0122, 0.0250, 0.0257, 0.0358, 0.0416, 0.0122, 0.0124,
         0.0317, 0.0223, 0.0264, 0.0281, 0.0388, 0.0186, 0.0192, 0.0194, 0.0310,
         0.0209, 0.0268, 0.0262, 0.0245, 0.0204, 0.0236, 0.0318, 0.0169, 0.0186,
         0.0288, 0.0321, 0.0213, 0.0193, 0.0294, 0.0282, 0.0250, 0.0195, 0.0199,
         0.0335, 0.0173, 0.0181, 0.0281]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 41
images/353
(64, 64, 3)
tensor([[0.0239, 0.0201, 0.0159, 0.0219, 0.0324, 0.0156, 0.0341, 0.0218, 0.0254,
         0.0120, 0.0164, 0.0274, 0.0325, 0.0521, 0.0195, 0.0284, 0.0242, 0.0513,
         0.0247, 0.0140, 0.0226, 0.0171, 0.0209, 0.0229, 0.0215, 0.0172, 0.0272,
         0.0229, 0.0533, 0.0223, 0.0215, 0.0229, 0.0240, 0.0203, 0.0207, 0.0364,
         0.0256, 0.0172, 0.0157, 0.0344]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 42
images/201
(64, 64, 3)
tensor([[0.0258, 0.0338, 0.0200, 0.0159, 0.0221, 0.0140, 0.0182, 0.0217, 0.0218,
         0.0168, 0.0170, 0.0460, 0.0393, 0.0318, 0.0248, 0.0341, 0.0179, 0.0426,
         0.0120, 0.0251, 0.0220, 0.0296, 0.0251, 0.0217, 0.0200, 0.0154, 0.0319,
         0.0432, 0.0348, 0.0191, 0.0156, 0.0284, 0.0269, 0.0274, 0.0172, 0.0328,
         0.0306, 0.0133, 0.0168, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 43
images/485
(64, 64, 3)
tensor([[0.0232, 0.0215, 0.0164, 0.0177, 0.0381, 0.0208, 0.0271, 0.0198, 0.0113,
         0.0200, 0.0227, 0.0238, 0.0409, 0.0403, 0.0240, 0.0166, 0.0210, 0.0512,
         0.0309, 0.0307, 0.0171, 0.0293, 0.0182, 0.0194, 0.0219, 0.0203, 0.0249,
         0.0350, 0.0334, 0.0256, 0.0197, 0.0266, 0.0198, 0.0293, 0.0164, 0.0199,
         0.0216, 0.0213, 0.0319, 0.0306]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/338
(64, 64, 3)
tensor([[0.0229, 0.0324, 0.0185, 0.0205, 0.0308, 0.0200, 0.0300, 0.0199, 0.0195,
         0.0148, 0.0182, 0.0290, 0.0345, 0.0341, 0.0373, 0.0220, 0.0209, 0.0515,
         0.0212, 0.0256, 0.0162, 0.0254, 0.0164, 0.0209, 0.0220, 0.0206, 0.0305,
         0.0374, 0.0280, 0.0189, 0.0204, 0.0283, 0.0318, 0.0256, 0.0191, 0.0212,
         0.0187, 0.0284, 0.0230, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 45
images/284
(64, 64, 3)
tensor([[0.0358, 0.0243, 0.0162, 0.0172, 0.0233, 0.0157, 0.0213, 0.0217, 0.0217,
         0.0132, 0.0222, 0.0523, 0.0666, 0.0175, 0.0238, 0.0224, 0.0240, 0.0284,
         0.0236, 0.0213, 0.0225, 0.0174, 0.0126, 0.0303, 0.0183, 0.0221, 0.0291,
         0.0275, 0.0365, 0.0239, 0.0173, 0.0241, 0.0259, 0.0287, 0.0165, 0.0465,
         0.0273, 0.0230, 0.0171, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 46
images/126
(64, 64, 3)
tensor([[0.0223, 0.0219, 0.0170, 0.0168, 0.0220, 0.0116, 0.0333, 0.0221, 0.0157,
         0.0210, 0.0229, 0.0271, 0.0565, 0.0290, 0.0243, 0.0196, 0.0134, 0.0203,
         0.0299, 0.0410, 0.0192, 0.0215, 0.0263, 0.0160, 0.0225, 0.0170, 0.0237,
         0.0401, 0.0306, 0.0179, 0.0178, 0.0280, 0.0325, 0.0304, 0.0243, 0.0348,
         0.0267, 0.0264, 0.0350, 0.0218]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 47
images/90
(64, 64, 3)
tensor([[0.0244, 0.0237, 0.0264, 0.0176, 0.0258, 0.0229, 0.0367, 0.0202, 0.0219,
         0.0125, 0.0206, 0.0387, 0.0382, 0.0303, 0.0268, 0.0222, 0.0216, 0.0383,
         0.0167, 0.0163, 0.0208, 0.0208, 0.0221, 0.0146, 0.0240, 0.0197, 0.0236,
         0.0371, 0.0378, 0.0285, 0.0185, 0.0228, 0.0263, 0.0239, 0.0250, 0.0344,
         0.0310, 0.0183, 0.0169, 0.0317]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 1
Session Number: 48
images/294
(64, 64, 3)
tensor([[0.0340, 0.0247, 0.0138, 0.0199, 0.0510, 0.0216, 0.0267, 0.0141, 0.0181,
         0.0160, 0.0185, 0.0254, 0.0338, 0.0317, 0.0216, 0.0185, 0.0291, 0.0290,
         0.0161, 0.0241, 0.0188, 0.0427, 0.0186, 0.0230, 0.0214, 0.0183, 0.0261,
         0.0384, 0.0281, 0.0249, 0.0183, 0.0324, 0.0217, 0.0267, 0.0201, 0.0331,
         0.0309, 0.0218, 0.0187, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 49
images/4
(64, 64, 3)
tensor([[0.0285, 0.0320, 0.0146, 0.0245, 0.0393, 0.0226, 0.0424, 0.0121, 0.0239,
         0.0221, 0.0112, 0.0292, 0.0486, 0.0378, 0.0228, 0.0181, 0.0196, 0.0425,
         0.0163, 0.0221, 0.0262, 0.0239, 0.0200, 0.0193, 0.0187, 0.0148, 0.0231,
         0.0399, 0.0280, 0.0180, 0.0204, 0.0206, 0.0423, 0.0201, 0.0254, 0.0228,
         0.0263, 0.0223, 0.0147, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 50
images/171
(64, 64, 3)
tensor([[0.0303, 0.0349, 0.0153, 0.0101, 0.0402, 0.0179, 0.0309, 0.0200, 0.0112,
         0.0234, 0.0179, 0.0234, 0.0275, 0.0275, 0.0220, 0.0143, 0.0186, 0.0302,
         0.0207, 0.0158, 0.0178, 0.0464, 0.0212, 0.0214, 0.0315, 0.0152, 0.0278,
         0.0378, 0.0439, 0.0284, 0.0151, 0.0341, 0.0313, 0.0248, 0.0122, 0.0283,
         0.0179, 0.0356, 0.0304, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 51
images/137
(64, 64, 3)
tensor([[0.0336, 0.0360, 0.0356, 0.0270, 0.0282, 0.0117, 0.0258, 0.0156, 0.0263,
         0.0172, 0.0223, 0.0317, 0.0286, 0.0350, 0.0214, 0.0181, 0.0232, 0.0213,
         0.0146, 0.0260, 0.0208, 0.0269, 0.0197, 0.0303, 0.0138, 0.0213, 0.0231,
         0.0288, 0.0296, 0.0157, 0.0177, 0.0215, 0.0276, 0.0396, 0.0213, 0.0249,
         0.0362, 0.0168, 0.0235, 0.0417]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/431
(64, 64, 3)
tensor([[0.0427, 0.0189, 0.0193, 0.0130, 0.0276, 0.0281, 0.0235, 0.0179, 0.0179,
         0.0138, 0.0220, 0.0227, 0.0444, 0.0283, 0.0186, 0.0234, 0.0199, 0.0290,
         0.0271, 0.0142, 0.0171, 0.0250, 0.0278, 0.0144, 0.0227, 0.0246, 0.0199,
         0.0325, 0.0418, 0.0233, 0.0206, 0.0278, 0.0377, 0.0325, 0.0306, 0.0258,
         0.0333, 0.0200, 0.0242, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 53
images/244
(64, 64, 3)
tensor([[0.0266, 0.0336, 0.0120, 0.0247, 0.0291, 0.0275, 0.0484, 0.0194, 0.0253,
         0.0290, 0.0146, 0.0341, 0.0339, 0.0261, 0.0299, 0.0204, 0.0174, 0.0293,
         0.0168, 0.0224, 0.0181, 0.0253, 0.0164, 0.0190, 0.0199, 0.0183, 0.0171,
         0.0340, 0.0242, 0.0250, 0.0102, 0.0229, 0.0571, 0.0373, 0.0247, 0.0146,
         0.0265, 0.0119, 0.0173, 0.0400]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 54
images/341
(64, 64, 3)
tensor([[0.0223, 0.0227, 0.0307, 0.0252, 0.0374, 0.0139, 0.0332, 0.0212, 0.0328,
         0.0133, 0.0151, 0.0163, 0.0543, 0.0461, 0.0235, 0.0138, 0.0176, 0.0400,
         0.0207, 0.0159, 0.0134, 0.0217, 0.0161, 0.0164, 0.0208, 0.0199, 0.0179,
         0.0290, 0.0273, 0.0255, 0.0246, 0.0300, 0.0285, 0.0200, 0.0160, 0.0415,
         0.0264, 0.0197, 0.0348, 0.0345]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 55
images/108
(64, 64, 3)
tensor([[0.0244, 0.0202, 0.0225, 0.0214, 0.0330, 0.0181, 0.0382, 0.0145, 0.0185,
         0.0221, 0.0230, 0.0252, 0.0472, 0.0397, 0.0326, 0.0150, 0.0199, 0.0361,
         0.0184, 0.0291, 0.0177, 0.0229, 0.0142, 0.0162, 0.0193, 0.0173, 0.0292,
         0.0366, 0.0277, 0.0239, 0.0193, 0.0230, 0.0411, 0.0262, 0.0350, 0.0240,
         0.0181, 0.0257, 0.0190, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 56
images/371
(64, 64, 3)
tensor([[0.0283, 0.0330, 0.0188, 0.0184, 0.0346, 0.0219, 0.0373, 0.0104, 0.0169,
         0.0201, 0.0195, 0.0183, 0.0424, 0.0438, 0.0278, 0.0166, 0.0184, 0.0422,
         0.0180, 0.0174, 0.0150, 0.0268, 0.0131, 0.0235, 0.0287, 0.0247, 0.0322,
         0.0327, 0.0259, 0.0274, 0.0190, 0.0401, 0.0309, 0.0204, 0.0181, 0.0300,
         0.0257, 0.0160, 0.0272, 0.0184]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 57
images/355
(64, 64, 3)
tensor([[0.0219, 0.0338, 0.0278, 0.0225, 0.0329, 0.0188, 0.0437, 0.0196, 0.0119,
         0.0219, 0.0172, 0.0348, 0.0407, 0.0244, 0.0212, 0.0156, 0.0155, 0.0509,
         0.0287, 0.0192, 0.0200, 0.0174, 0.0174, 0.0157, 0.0234, 0.0227, 0.0323,
         0.0287, 0.0353, 0.0261, 0.0132, 0.0334, 0.0394, 0.0255, 0.0223, 0.0204,
         0.0307, 0.0185, 0.0174, 0.0171]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 58
images/520
(64, 64, 3)
tensor([[0.0305, 0.0290, 0.0131, 0.0226, 0.0332, 0.0148, 0.0277, 0.0117, 0.0162,
         0.0154, 0.0246, 0.0428, 0.0328, 0.0247, 0.0283, 0.0156, 0.0171, 0.0565,
         0.0153, 0.0292, 0.0223, 0.0190, 0.0183, 0.0197, 0.0131, 0.0285, 0.0240,
         0.0363, 0.0323, 0.0239, 0.0204, 0.0153, 0.0229, 0.0238, 0.0267, 0.0309,
         0.0477, 0.0193, 0.0317, 0.0228]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 59
images/466
(64, 64, 3)
tensor([[0.0297, 0.0254, 0.0211, 0.0219, 0.0437, 0.0138, 0.0282, 0.0154, 0.0208,
         0.0162, 0.0242, 0.0277, 0.0399, 0.0368, 0.0277, 0.0163, 0.0185, 0.0298,
         0.0189, 0.0262, 0.0204, 0.0235, 0.0145, 0.0230, 0.0253, 0.0197, 0.0255,
         0.0282, 0.0299, 0.0235, 0.0243, 0.0267, 0.0327, 0.0335, 0.0267, 0.0265,
         0.0232, 0.0135, 0.0243, 0.0330]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 60
images/9
(64, 64, 3)
tensor([[0.0411, 0.0280, 0.0151, 0.0296, 0.0190, 0.0178, 0.0266, 0.0177, 0.0148,
         0.0177, 0.0233, 0.0313, 0.0325, 0.0341, 0.0360, 0.0234, 0.0171, 0.0422,
         0.0198, 0.0196, 0.0181, 0.0333, 0.0260, 0.0207, 0.0251, 0.0210, 0.0247,
         0.0414, 0.0291, 0.0249, 0.0150, 0.0288, 0.0351, 0.0237, 0.0178, 0.0183,
         0.0225, 0.0172, 0.0231, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 61
images/60
(64, 64, 3)
tensor([[0.0334, 0.0240, 0.0242, 0.0174, 0.0360, 0.0135, 0.0343, 0.0250, 0.0202,
         0.0305, 0.0182, 0.0332, 0.0387, 0.0269, 0.0340, 0.0200, 0.0235, 0.0332,
         0.0249, 0.0171, 0.0234, 0.0305, 0.0182, 0.0163, 0.0294, 0.0109, 0.0234,
         0.0183, 0.0202, 0.0170, 0.0141, 0.0421, 0.0277, 0.0209, 0.0197, 0.0316,
         0.0296, 0.0153, 0.0298, 0.0334]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 62
images/214
(64, 64, 3)
tensor([[0.0338, 0.0215, 0.0233, 0.0172, 0.0240, 0.0207, 0.0373, 0.0136, 0.0233,
         0.0136, 0.0196, 0.0359, 0.0341, 0.0216, 0.0393, 0.0204, 0.0232, 0.0267,
         0.0165, 0.0199, 0.0146, 0.0325, 0.0330, 0.0182, 0.0304, 0.0233, 0.0246,
         0.0403, 0.0320, 0.0196, 0.0178, 0.0202, 0.0330, 0.0294, 0.0210, 0.0228,
         0.0199, 0.0241, 0.0267, 0.0310]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 63
images/399
(64, 64, 3)
tensor([[0.0306, 0.0359, 0.0093, 0.0222, 0.0249, 0.0221, 0.0339, 0.0120, 0.0228,
         0.0176, 0.0118, 0.0342, 0.0440, 0.0412, 0.0251, 0.0153, 0.0147, 0.0596,
         0.0209, 0.0284, 0.0149, 0.0307, 0.0190, 0.0188, 0.0320, 0.0174, 0.0289,
         0.0343, 0.0258, 0.0199, 0.0207, 0.0198, 0.0203, 0.0139, 0.0320, 0.0189,
         0.0224, 0.0310, 0.0244, 0.0283]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 64
images/22
(64, 64, 3)
tensor([[0.0256, 0.0317, 0.0156, 0.0121, 0.0326, 0.0254, 0.0285, 0.0198, 0.0181,
         0.0205, 0.0151, 0.0339, 0.0472, 0.0372, 0.0190, 0.0141, 0.0264, 0.0325,
         0.0197, 0.0257, 0.0165, 0.0292, 0.0251, 0.0182, 0.0339, 0.0204, 0.0170,
         0.0327, 0.0388, 0.0325, 0.0185, 0.0322, 0.0253, 0.0124, 0.0176, 0.0382,
         0.0234, 0.0223, 0.0201, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 65
images/79
(64, 64, 3)
tensor([[0.0310, 0.0261, 0.0139, 0.0171, 0.0430, 0.0309, 0.0217, 0.0115, 0.0153,
         0.0234, 0.0155, 0.0232, 0.0540, 0.0282, 0.0219, 0.0196, 0.0195, 0.0185,
         0.0202, 0.0232, 0.0325, 0.0306, 0.0150, 0.0247, 0.0271, 0.0221, 0.0343,
         0.0412, 0.0355, 0.0176, 0.0221, 0.0291, 0.0259, 0.0237, 0.0241, 0.0196,
         0.0345, 0.0233, 0.0176, 0.0218]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 66
images/583
(64, 64, 3)
tensor([[0.0296, 0.0201, 0.0260, 0.0185, 0.0262, 0.0165, 0.0354, 0.0181, 0.0212,
         0.0205, 0.0190, 0.0347, 0.0215, 0.0348, 0.0321, 0.0134, 0.0212, 0.0507,
         0.0178, 0.0227, 0.0150, 0.0288, 0.0189, 0.0227, 0.0236, 0.0185, 0.0170,
         0.0198, 0.0344, 0.0250, 0.0229, 0.0331, 0.0258, 0.0194, 0.0135, 0.0421,
         0.0309, 0.0260, 0.0354, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 67
images/134
(64, 64, 3)
tensor([[0.0319, 0.0272, 0.0260, 0.0185, 0.0177, 0.0253, 0.0408, 0.0276, 0.0152,
         0.0216, 0.0217, 0.0434, 0.0490, 0.0324, 0.0236, 0.0120, 0.0212, 0.0230,
         0.0140, 0.0213, 0.0172, 0.0295, 0.0234, 0.0250, 0.0269, 0.0179, 0.0261,
         0.0266, 0.0362, 0.0262, 0.0232, 0.0230, 0.0162, 0.0216, 0.0243, 0.0349,
         0.0336, 0.0160, 0.0167, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/241
(64, 64, 3)
tensor([[0.0159, 0.0308, 0.0200, 0.0143, 0.0478, 0.0187, 0.0320, 0.0229, 0.0270,
         0.0244, 0.0164, 0.0249, 0.0272, 0.0307, 0.0256, 0.0158, 0.0285, 0.0288,
         0.0183, 0.0242, 0.0153, 0.0172, 0.0219, 0.0210, 0.0218, 0.0182, 0.0194,
         0.0237, 0.0543, 0.0289, 0.0116, 0.0349, 0.0294, 0.0369, 0.0153, 0.0267,
         0.0372, 0.0165, 0.0255, 0.0305]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 69
images/304
(64, 64, 3)
tensor([[0.0212, 0.0252, 0.0111, 0.0158, 0.0299, 0.0193, 0.0369, 0.0154, 0.0268,
         0.0201, 0.0303, 0.0378, 0.0334, 0.0419, 0.0247, 0.0217, 0.0179, 0.0404,
         0.0200, 0.0216, 0.0116, 0.0222, 0.0155, 0.0216, 0.0224, 0.0184, 0.0267,
         0.0304, 0.0424, 0.0286, 0.0216, 0.0392, 0.0320, 0.0141, 0.0310, 0.0321,
         0.0234, 0.0173, 0.0187, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 70
images/378
(64, 64, 3)
tensor([[0.0230, 0.0435, 0.0212, 0.0204, 0.0381, 0.0258, 0.0422, 0.0152, 0.0185,
         0.0192, 0.0238, 0.0353, 0.0454, 0.0306, 0.0275, 0.0150, 0.0156, 0.0265,
         0.0134, 0.0186, 0.0255, 0.0219, 0.0203, 0.0195, 0.0240, 0.0198, 0.0249,
         0.0238, 0.0335, 0.0264, 0.0238, 0.0202, 0.0292, 0.0199, 0.0170, 0.0348,
         0.0321, 0.0179, 0.0221, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 71
images/91
(64, 64, 3)
tensor([[0.0320, 0.0201, 0.0211, 0.0203, 0.0378, 0.0209, 0.0340, 0.0215, 0.0170,
         0.0192, 0.0191, 0.0321, 0.0437, 0.0295, 0.0174, 0.0139, 0.0293, 0.0287,
         0.0139, 0.0201, 0.0175, 0.0207, 0.0233, 0.0159, 0.0228, 0.0212, 0.0207,
         0.0442, 0.0331, 0.0184, 0.0145, 0.0247, 0.0521, 0.0242, 0.0285, 0.0248,
         0.0256, 0.0239, 0.0259, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 72
images/285
(64, 64, 3)
tensor([[0.0257, 0.0267, 0.0176, 0.0134, 0.0287, 0.0159, 0.0345, 0.0225, 0.0176,
         0.0169, 0.0202, 0.0348, 0.0462, 0.0298, 0.0237, 0.0160, 0.0219, 0.0332,
         0.0223, 0.0170, 0.0189, 0.0307, 0.0272, 0.0185, 0.0260, 0.0146, 0.0289,
         0.0295, 0.0454, 0.0313, 0.0139, 0.0234, 0.0211, 0.0354, 0.0292, 0.0377,
         0.0307, 0.0166, 0.0135, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 73
images/166
(64, 64, 3)
tensor([[0.0217, 0.0331, 0.0149, 0.0157, 0.0286, 0.0197, 0.0262, 0.0191, 0.0234,
         0.0194, 0.0239, 0.0217, 0.0211, 0.0245, 0.0361, 0.0173, 0.0206, 0.0545,
         0.0263, 0.0159, 0.0177, 0.0253, 0.0244, 0.0141, 0.0209, 0.0211, 0.0251,
         0.0221, 0.0282, 0.0296, 0.0181, 0.0309, 0.0359, 0.0389, 0.0236, 0.0358,
         0.0322, 0.0210, 0.0181, 0.0333]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 74
images/109
(64, 64, 3)
tensor([[0.0357, 0.0194, 0.0127, 0.0150, 0.0330, 0.0267, 0.0324, 0.0113, 0.0162,
         0.0238, 0.0223, 0.0268, 0.0344, 0.0300, 0.0318, 0.0140, 0.0255, 0.0363,
         0.0180, 0.0178, 0.0147, 0.0194, 0.0189, 0.0288, 0.0231, 0.0198, 0.0184,
         0.0306, 0.0349, 0.0165, 0.0187, 0.0311, 0.0303, 0.0267, 0.0233, 0.0374,
         0.0288, 0.0201, 0.0489, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 75
images/413
(64, 64, 3)
tensor([[0.0189, 0.0381, 0.0129, 0.0198, 0.0417, 0.0226, 0.0257, 0.0275, 0.0217,
         0.0242, 0.0160, 0.0158, 0.0273, 0.0354, 0.0226, 0.0202, 0.0218, 0.0284,
         0.0310, 0.0142, 0.0174, 0.0254, 0.0147, 0.0261, 0.0288, 0.0173, 0.0354,
         0.0374, 0.0574, 0.0290, 0.0141, 0.0359, 0.0307, 0.0297, 0.0184, 0.0256,
         0.0201, 0.0145, 0.0182, 0.0180]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 76
images/511
(64, 64, 3)
tensor([[0.0269, 0.0144, 0.0193, 0.0162, 0.0271, 0.0234, 0.0427, 0.0122, 0.0155,
         0.0168, 0.0245, 0.0395, 0.0483, 0.0317, 0.0268, 0.0239, 0.0186, 0.0200,
         0.0192, 0.0144, 0.0154, 0.0310, 0.0184, 0.0172, 0.0267, 0.0173, 0.0113,
         0.0448, 0.0534, 0.0271, 0.0133, 0.0257, 0.0245, 0.0210, 0.0206, 0.0324,
         0.0433, 0.0209, 0.0246, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 77
images/476
(64, 64, 3)
tensor([[0.0181, 0.0235, 0.0224, 0.0149, 0.0278, 0.0195, 0.0357, 0.0183, 0.0186,
         0.0131, 0.0249, 0.0283, 0.0371, 0.0298, 0.0222, 0.0217, 0.0314, 0.0363,
         0.0247, 0.0202, 0.0235, 0.0223, 0.0190, 0.0238, 0.0207, 0.0173, 0.0234,
         0.0514, 0.0395, 0.0305, 0.0224, 0.0271, 0.0275, 0.0208, 0.0149, 0.0300,
         0.0270, 0.0174, 0.0226, 0.0303]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 78
images/2
(64, 64, 3)
tensor([[0.0287, 0.0319, 0.0140, 0.0295, 0.0270, 0.0144, 0.0321, 0.0189, 0.0194,
         0.0163, 0.0187, 0.0567, 0.0509, 0.0216, 0.0228, 0.0178, 0.0208, 0.0262,
         0.0199, 0.0212, 0.0207, 0.0267, 0.0106, 0.0198, 0.0148, 0.0221, 0.0375,
         0.0236, 0.0356, 0.0392, 0.0109, 0.0287, 0.0206, 0.0187, 0.0267, 0.0266,
         0.0403, 0.0246, 0.0224, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/86
(64, 64, 3)
tensor([[0.0331, 0.0265, 0.0107, 0.0281, 0.0287, 0.0230, 0.0278, 0.0270, 0.0152,
         0.0287, 0.0205, 0.0341, 0.0540, 0.0302, 0.0145, 0.0155, 0.0232, 0.0332,
         0.0232, 0.0262, 0.0180, 0.0217, 0.0133, 0.0266, 0.0241, 0.0194, 0.0198,
         0.0444, 0.0269, 0.0263, 0.0156, 0.0214, 0.0220, 0.0267, 0.0340, 0.0254,
         0.0239, 0.0204, 0.0221, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 80
images/370
(64, 64, 3)
tensor([[0.0177, 0.0289, 0.0278, 0.0145, 0.0376, 0.0166, 0.0386, 0.0221, 0.0193,
         0.0208, 0.0133, 0.0317, 0.0344, 0.0269, 0.0375, 0.0217, 0.0236, 0.0479,
         0.0271, 0.0150, 0.0213, 0.0234, 0.0198, 0.0170, 0.0201, 0.0171, 0.0252,
         0.0305, 0.0353, 0.0231, 0.0197, 0.0264, 0.0229, 0.0316, 0.0248, 0.0252,
         0.0282, 0.0170, 0.0223, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 81
images/279
(64, 64, 3)
tensor([[0.0260, 0.0293, 0.0165, 0.0217, 0.0258, 0.0197, 0.0341, 0.0245, 0.0130,
         0.0250, 0.0133, 0.0233, 0.0412, 0.0345, 0.0261, 0.0202, 0.0181, 0.0356,
         0.0221, 0.0232, 0.0200, 0.0331, 0.0234, 0.0251, 0.0208, 0.0144, 0.0297,
         0.0269, 0.0268, 0.0273, 0.0138, 0.0437, 0.0309, 0.0146, 0.0244, 0.0294,
         0.0287, 0.0247, 0.0222, 0.0270]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 82
images/529
(64, 64, 3)
tensor([[0.0257, 0.0266, 0.0287, 0.0165, 0.0369, 0.0159, 0.0208, 0.0173, 0.0177,
         0.0150, 0.0241, 0.0397, 0.0522, 0.0293, 0.0282, 0.0149, 0.0285, 0.0314,
         0.0233, 0.0169, 0.0162, 0.0311, 0.0357, 0.0193, 0.0182, 0.0211, 0.0233,
         0.0298, 0.0418, 0.0223, 0.0187, 0.0222, 0.0238, 0.0271, 0.0247, 0.0209,
         0.0396, 0.0209, 0.0126, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 83
images/49
(64, 64, 3)
tensor([[0.0257, 0.0355, 0.0227, 0.0242, 0.0335, 0.0182, 0.0285, 0.0136, 0.0150,
         0.0163, 0.0129, 0.0309, 0.0807, 0.0228, 0.0251, 0.0374, 0.0146, 0.0305,
         0.0165, 0.0156, 0.0151, 0.0177, 0.0218, 0.0217, 0.0188, 0.0251, 0.0233,
         0.0275, 0.0289, 0.0337, 0.0183, 0.0259, 0.0249, 0.0251, 0.0313, 0.0325,
         0.0290, 0.0164, 0.0167, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 84
images/78
(64, 64, 3)
tensor([[0.0472, 0.0223, 0.0224, 0.0189, 0.0296, 0.0341, 0.0183, 0.0174, 0.0190,
         0.0203, 0.0238, 0.0425, 0.0298, 0.0296, 0.0218, 0.0261, 0.0310, 0.0306,
         0.0228, 0.0141, 0.0178, 0.0241, 0.0239, 0.0192, 0.0208, 0.0201, 0.0281,
         0.0325, 0.0318, 0.0191, 0.0197, 0.0264, 0.0213, 0.0396, 0.0250, 0.0205,
         0.0265, 0.0145, 0.0270, 0.0205]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 85
images/475
(64, 64, 3)
tensor([[0.0290, 0.0206, 0.0134, 0.0390, 0.0317, 0.0268, 0.0294, 0.0180, 0.0135,
         0.0186, 0.0237, 0.0263, 0.0440, 0.0422, 0.0226, 0.0223, 0.0215, 0.0380,
         0.0218, 0.0208, 0.0198, 0.0153, 0.0195, 0.0199, 0.0194, 0.0159, 0.0300,
         0.0400, 0.0273, 0.0301, 0.0157, 0.0337, 0.0210, 0.0215, 0.0209, 0.0270,
         0.0255, 0.0219, 0.0184, 0.0341]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 86
images/363
(64, 64, 3)
tensor([[0.0310, 0.0221, 0.0127, 0.0186, 0.0314, 0.0186, 0.0248, 0.0160, 0.0188,
         0.0220, 0.0247, 0.0330, 0.0350, 0.0366, 0.0321, 0.0210, 0.0237, 0.0364,
         0.0130, 0.0158, 0.0181, 0.0296, 0.0240, 0.0269, 0.0218, 0.0240, 0.0240,
         0.0407, 0.0307, 0.0237, 0.0206, 0.0272, 0.0351, 0.0163, 0.0294, 0.0219,
         0.0360, 0.0197, 0.0247, 0.0183]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 87
images/119
(64, 64, 3)
tensor([[0.0223, 0.0243, 0.0172, 0.0189, 0.0332, 0.0166, 0.0388, 0.0292, 0.0089,
         0.0229, 0.0206, 0.0424, 0.0440, 0.0262, 0.0170, 0.0163, 0.0190, 0.0316,
         0.0120, 0.0265, 0.0199, 0.0320, 0.0383, 0.0250, 0.0228, 0.0139, 0.0165,
         0.0293, 0.0370, 0.0217, 0.0164, 0.0367, 0.0277, 0.0248, 0.0206, 0.0404,
         0.0179, 0.0205, 0.0290, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 88
images/16
(64, 64, 3)
tensor([[0.0280, 0.0265, 0.0224, 0.0157, 0.0359, 0.0162, 0.0284, 0.0280, 0.0204,
         0.0148, 0.0267, 0.0239, 0.0290, 0.0333, 0.0194, 0.0168, 0.0163, 0.0239,
         0.0280, 0.0257, 0.0147, 0.0259, 0.0224, 0.0206, 0.0203, 0.0165, 0.0210,
         0.0344, 0.0341, 0.0224, 0.0185, 0.0398, 0.0258, 0.0308, 0.0321, 0.0423,
         0.0279, 0.0201, 0.0270, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/40
(64, 64, 3)
tensor([[0.0160, 0.0358, 0.0263, 0.0208, 0.0415, 0.0175, 0.0236, 0.0164, 0.0161,
         0.0184, 0.0148, 0.0265, 0.0632, 0.0347, 0.0302, 0.0228, 0.0183, 0.0418,
         0.0175, 0.0155, 0.0165, 0.0194, 0.0204, 0.0205, 0.0142, 0.0196, 0.0242,
         0.0314, 0.0236, 0.0215, 0.0171, 0.0338, 0.0246, 0.0291, 0.0254, 0.0418,
         0.0257, 0.0214, 0.0230, 0.0290]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 90
images/64
(64, 64, 3)
tensor([[0.0265, 0.0281, 0.0312, 0.0246, 0.0305, 0.0361, 0.0245, 0.0159, 0.0156,
         0.0227, 0.0191, 0.0255, 0.0382, 0.0272, 0.0225, 0.0305, 0.0167, 0.0315,
         0.0174, 0.0190, 0.0283, 0.0193, 0.0316, 0.0232, 0.0228, 0.0236, 0.0216,
         0.0288, 0.0430, 0.0264, 0.0126, 0.0147, 0.0236, 0.0239, 0.0280, 0.0249,
         0.0257, 0.0244, 0.0235, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 91
images/2
(64, 64, 3)
tensor([[0.0299, 0.0292, 0.0202, 0.0211, 0.0227, 0.0244, 0.0273, 0.0194, 0.0182,
         0.0214, 0.0229, 0.0437, 0.0323, 0.0260, 0.0233, 0.0225, 0.0161, 0.0245,
         0.0168, 0.0307, 0.0117, 0.0247, 0.0176, 0.0248, 0.0237, 0.0198, 0.0184,
         0.0431, 0.0349, 0.0358, 0.0216, 0.0589, 0.0250, 0.0220, 0.0199, 0.0236,
         0.0175, 0.0230, 0.0182, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 92
images/141
(64, 64, 3)
tensor([[0.0235, 0.0202, 0.0249, 0.0168, 0.0289, 0.0249, 0.0295, 0.0233, 0.0221,
         0.0190, 0.0148, 0.0268, 0.0494, 0.0261, 0.0195, 0.0189, 0.0144, 0.0444,
         0.0165, 0.0259, 0.0195, 0.0251, 0.0250, 0.0209, 0.0266, 0.0181, 0.0278,
         0.0409, 0.0405, 0.0227, 0.0201, 0.0262, 0.0212, 0.0349, 0.0372, 0.0236,
         0.0178, 0.0216, 0.0222, 0.0181]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 93
images/207
(64, 64, 3)
tensor([[0.0314, 0.0256, 0.0090, 0.0311, 0.0386, 0.0200, 0.0301, 0.0156, 0.0178,
         0.0269, 0.0191, 0.0262, 0.0438, 0.0303, 0.0277, 0.0218, 0.0216, 0.0553,
         0.0183, 0.0193, 0.0193, 0.0263, 0.0248, 0.0166, 0.0227, 0.0237, 0.0351,
         0.0240, 0.0308, 0.0205, 0.0245, 0.0186, 0.0249, 0.0219, 0.0212, 0.0283,
         0.0335, 0.0168, 0.0214, 0.0160]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 94
images/27
(64, 64, 3)
tensor([[0.0260, 0.0348, 0.0229, 0.0247, 0.0204, 0.0189, 0.0300, 0.0115, 0.0185,
         0.0268, 0.0152, 0.0263, 0.0454, 0.0286, 0.0210, 0.0243, 0.0210, 0.0210,
         0.0221, 0.0283, 0.0173, 0.0306, 0.0166, 0.0234, 0.0168, 0.0310, 0.0266,
         0.0366, 0.0297, 0.0237, 0.0146, 0.0299, 0.0343, 0.0226, 0.0174, 0.0360,
         0.0357, 0.0220, 0.0204, 0.0270]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 95
images/274
(64, 64, 3)
tensor([[0.0311, 0.0328, 0.0218, 0.0180, 0.0411, 0.0178, 0.0276, 0.0128, 0.0212,
         0.0203, 0.0272, 0.0300, 0.0325, 0.0319, 0.0239, 0.0147, 0.0209, 0.0211,
         0.0212, 0.0223, 0.0270, 0.0255, 0.0280, 0.0167, 0.0397, 0.0202, 0.0242,
         0.0319, 0.0265, 0.0217, 0.0144, 0.0327, 0.0284, 0.0232, 0.0157, 0.0361,
         0.0225, 0.0177, 0.0281, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 96
images/232
(64, 64, 3)
tensor([[0.0149, 0.0371, 0.0168, 0.0204, 0.0325, 0.0265, 0.0355, 0.0252, 0.0195,
         0.0191, 0.0286, 0.0277, 0.0423, 0.0319, 0.0281, 0.0152, 0.0143, 0.0442,
         0.0237, 0.0184, 0.0197, 0.0300, 0.0132, 0.0299, 0.0221, 0.0172, 0.0259,
         0.0406, 0.0252, 0.0190, 0.0206, 0.0225, 0.0192, 0.0265, 0.0207, 0.0278,
         0.0254, 0.0167, 0.0183, 0.0379]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 97
images/43
(64, 64, 3)
tensor([[0.0245, 0.0150, 0.0203, 0.0197, 0.0499, 0.0144, 0.0373, 0.0185, 0.0176,
         0.0149, 0.0275, 0.0395, 0.0211, 0.0517, 0.0275, 0.0123, 0.0117, 0.0344,
         0.0237, 0.0280, 0.0178, 0.0125, 0.0266, 0.0163, 0.0173, 0.0219, 0.0236,
         0.0284, 0.0277, 0.0201, 0.0114, 0.0246, 0.0394, 0.0295, 0.0259, 0.0351,
         0.0372, 0.0232, 0.0182, 0.0340]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 1
Session Number: 98
images/77
(64, 64, 3)
tensor([[0.0253, 0.0195, 0.0184, 0.0183, 0.0290, 0.0215, 0.0298, 0.0234, 0.0155,
         0.0187, 0.0218, 0.0300, 0.0258, 0.0484, 0.0287, 0.0169, 0.0168, 0.0294,
         0.0327, 0.0252, 0.0155, 0.0241, 0.0214, 0.0242, 0.0245, 0.0205, 0.0242,
         0.0333, 0.0258, 0.0216, 0.0140, 0.0360, 0.0283, 0.0287, 0.0398, 0.0341,
         0.0190, 0.0235, 0.0195, 0.0271]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 99
images/85
(64, 64, 3)
tensor([[0.0279, 0.0265, 0.0118, 0.0255, 0.0412, 0.0292, 0.0326, 0.0176, 0.0190,
         0.0121, 0.0177, 0.0263, 0.0498, 0.0276, 0.0202, 0.0152, 0.0321, 0.0300,
         0.0168, 0.0228, 0.0247, 0.0135, 0.0146, 0.0233, 0.0276, 0.0187, 0.0430,
         0.0306, 0.0285, 0.0221, 0.0217, 0.0380, 0.0430, 0.0227, 0.0190, 0.0285,
         0.0235, 0.0119, 0.0241, 0.0194]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/389
(64, 64, 3)
2018-10-12 16:17:20.199 Python[5894:15633017] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0292, 0.0242, 0.0176, 0.0236, 0.0381, 0.0321, 0.0265, 0.0187, 0.0230,
         0.0173, 0.0165, 0.0220, 0.0322, 0.0332, 0.0367, 0.0297, 0.0208, 0.0313,
         0.0154, 0.0214, 0.0143, 0.0249, 0.0284, 0.0234, 0.0351, 0.0196, 0.0271,
         0.0267, 0.0200, 0.0219, 0.0180, 0.0242, 0.0230, 0.0198, 0.0237, 0.0401,
         0.0242, 0.0310, 0.0255, 0.0198]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 1
images/324
(64, 64, 3)
tensor([[0.0272, 0.0219, 0.0203, 0.0161, 0.0256, 0.0164, 0.0372, 0.0137, 0.0177,
         0.0156, 0.0185, 0.0322, 0.0183, 0.0335, 0.0344, 0.0213, 0.0215, 0.0325,
         0.0157, 0.0278, 0.0156, 0.0320, 0.0240, 0.0256, 0.0204, 0.0252, 0.0182,
         0.0368, 0.0331, 0.0219, 0.0149, 0.0448, 0.0348, 0.0230, 0.0214, 0.0432,
         0.0348, 0.0230, 0.0191, 0.0207]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/556
(64, 64, 3)
tensor([[0.0338, 0.0302, 0.0134, 0.0172, 0.0289, 0.0174, 0.0321, 0.0190, 0.0173,
         0.0160, 0.0252, 0.0296, 0.0375, 0.0434, 0.0291, 0.0234, 0.0344, 0.0520,
         0.0157, 0.0147, 0.0158, 0.0269, 0.0235, 0.0202, 0.0164, 0.0179, 0.0314,
         0.0271, 0.0426, 0.0177, 0.0195, 0.0298, 0.0263, 0.0277, 0.0205, 0.0285,
         0.0233, 0.0191, 0.0203, 0.0153]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 3
images/67
(64, 64, 3)
tensor([[0.0336, 0.0216, 0.0137, 0.0214, 0.0412, 0.0210, 0.0282, 0.0172, 0.0263,
         0.0206, 0.0276, 0.0331, 0.0264, 0.0368, 0.0226, 0.0168, 0.0144, 0.0460,
         0.0183, 0.0287, 0.0173, 0.0243, 0.0147, 0.0183, 0.0225, 0.0190, 0.0189,
         0.0414, 0.0437, 0.0188, 0.0250, 0.0302, 0.0245, 0.0295, 0.0221, 0.0263,
         0.0220, 0.0211, 0.0267, 0.0182]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 4
images/296
(64, 64, 3)
tensor([[0.0224, 0.0274, 0.0285, 0.0112, 0.0566, 0.0209, 0.0252, 0.0166, 0.0161,
         0.0157, 0.0107, 0.0265, 0.0304, 0.0357, 0.0281, 0.0164, 0.0246, 0.0524,
         0.0194, 0.0135, 0.0147, 0.0230, 0.0227, 0.0334, 0.0219, 0.0225, 0.0260,
         0.0208, 0.0335, 0.0260, 0.0234, 0.0373, 0.0195, 0.0314, 0.0219, 0.0251,
         0.0162, 0.0245, 0.0296, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 5
images/534
(64, 64, 3)
tensor([[0.0129, 0.0252, 0.0155, 0.0188, 0.0280, 0.0211, 0.0399, 0.0232, 0.0213,
         0.0226, 0.0251, 0.0295, 0.0354, 0.0306, 0.0390, 0.0360, 0.0218, 0.0379,
         0.0128, 0.0203, 0.0223, 0.0198, 0.0243, 0.0259, 0.0133, 0.0167, 0.0345,
         0.0275, 0.0315, 0.0363, 0.0225, 0.0223, 0.0269, 0.0260, 0.0227, 0.0305,
         0.0191, 0.0135, 0.0224, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 0
Session Number: 6
images/402
(64, 64, 3)
tensor([[0.0344, 0.0443, 0.0202, 0.0153, 0.0173, 0.0281, 0.0304, 0.0164, 0.0193,
         0.0325, 0.0204, 0.0194, 0.0344, 0.0216, 0.0362, 0.0211, 0.0224, 0.0340,
         0.0173, 0.0264, 0.0150, 0.0272, 0.0235, 0.0251, 0.0211, 0.0196, 0.0189,
         0.0355, 0.0268, 0.0287, 0.0268, 0.0307, 0.0270, 0.0247, 0.0177, 0.0305,
         0.0298, 0.0178, 0.0177, 0.0247]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 7
images/376
(64, 64, 3)
tensor([[0.0398, 0.0289, 0.0211, 0.0158, 0.0233, 0.0242, 0.0321, 0.0090, 0.0104,
         0.0149, 0.0170, 0.0292, 0.0691, 0.0220, 0.0177, 0.0315, 0.0231, 0.0254,
         0.0191, 0.0169, 0.0165, 0.0301, 0.0225, 0.0254, 0.0231, 0.0193, 0.0343,
         0.0321, 0.0368, 0.0254, 0.0303, 0.0298, 0.0288, 0.0225, 0.0157, 0.0310,
         0.0289, 0.0165, 0.0143, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/532
(64, 64, 3)
tensor([[0.0283, 0.0181, 0.0143, 0.0208, 0.0317, 0.0281, 0.0327, 0.0174, 0.0160,
         0.0268, 0.0184, 0.0303, 0.0436, 0.0359, 0.0276, 0.0203, 0.0238, 0.0407,
         0.0188, 0.0200, 0.0117, 0.0190, 0.0300, 0.0280, 0.0205, 0.0210, 0.0245,
         0.0343, 0.0405, 0.0202, 0.0126, 0.0307, 0.0301, 0.0145, 0.0188, 0.0257,
         0.0273, 0.0254, 0.0169, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 9
images/366
(64, 64, 3)
tensor([[0.0352, 0.0307, 0.0124, 0.0105, 0.0281, 0.0213, 0.0394, 0.0199, 0.0113,
         0.0263, 0.0209, 0.0279, 0.0401, 0.0304, 0.0256, 0.0174, 0.0241, 0.0292,
         0.0211, 0.0135, 0.0230, 0.0197, 0.0175, 0.0250, 0.0168, 0.0231, 0.0251,
         0.0377, 0.0451, 0.0207, 0.0254, 0.0330, 0.0301, 0.0193, 0.0147, 0.0435,
         0.0230, 0.0150, 0.0260, 0.0308]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 10
images/299
(64, 64, 3)
tensor([[0.0195, 0.0224, 0.0135, 0.0151, 0.0363, 0.0215, 0.0306, 0.0139, 0.0204,
         0.0247, 0.0162, 0.0313, 0.0534, 0.0326, 0.0266, 0.0121, 0.0215, 0.0297,
         0.0211, 0.0262, 0.0152, 0.0209, 0.0276, 0.0246, 0.0153, 0.0131, 0.0387,
         0.0254, 0.0228, 0.0206, 0.0221, 0.0248, 0.0319, 0.0235, 0.0383, 0.0274,
         0.0269, 0.0287, 0.0240, 0.0394]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 11
images/357
(64, 64, 3)
tensor([[0.0228, 0.0312, 0.0221, 0.0166, 0.0317, 0.0286, 0.0267, 0.0189, 0.0195,
         0.0257, 0.0156, 0.0231, 0.0286, 0.0356, 0.0209, 0.0187, 0.0115, 0.0595,
         0.0143, 0.0182, 0.0208, 0.0260, 0.0213, 0.0290, 0.0231, 0.0185, 0.0199,
         0.0245, 0.0400, 0.0378, 0.0183, 0.0333, 0.0391, 0.0201, 0.0278, 0.0191,
         0.0211, 0.0216, 0.0178, 0.0313]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/436
(64, 64, 3)
tensor([[0.0309, 0.0231, 0.0186, 0.0211, 0.0254, 0.0236, 0.0328, 0.0235, 0.0169,
         0.0151, 0.0196, 0.0270, 0.0506, 0.0529, 0.0219, 0.0142, 0.0181, 0.0374,
         0.0152, 0.0188, 0.0184, 0.0248, 0.0244, 0.0300, 0.0176, 0.0177, 0.0180,
         0.0290, 0.0475, 0.0173, 0.0143, 0.0360, 0.0220, 0.0178, 0.0260, 0.0241,
         0.0238, 0.0319, 0.0231, 0.0297]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 13
images/156
(64, 64, 3)
tensor([[0.0219, 0.0255, 0.0222, 0.0197, 0.0256, 0.0351, 0.0231, 0.0199, 0.0141,
         0.0240, 0.0237, 0.0208, 0.0353, 0.0444, 0.0222, 0.0238, 0.0196, 0.0228,
         0.0168, 0.0272, 0.0234, 0.0271, 0.0178, 0.0287, 0.0221, 0.0175, 0.0334,
         0.0384, 0.0243, 0.0176, 0.0233, 0.0274, 0.0384, 0.0209, 0.0328, 0.0244,
         0.0280, 0.0150, 0.0274, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 14
images/375
(64, 64, 3)
tensor([[0.0616, 0.0219, 0.0147, 0.0157, 0.0232, 0.0210, 0.0262, 0.0210, 0.0149,
         0.0184, 0.0120, 0.0240, 0.0430, 0.0284, 0.0327, 0.0272, 0.0212, 0.0473,
         0.0157, 0.0185, 0.0229, 0.0153, 0.0278, 0.0161, 0.0221, 0.0204, 0.0302,
         0.0248, 0.0408, 0.0220, 0.0170, 0.0424, 0.0268, 0.0196, 0.0179, 0.0175,
         0.0187, 0.0164, 0.0402, 0.0323]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 15
images/67
(64, 64, 3)
tensor([[0.0361, 0.0240, 0.0149, 0.0170, 0.0401, 0.0237, 0.0311, 0.0168, 0.0144,
         0.0231, 0.0201, 0.0235, 0.0225, 0.0456, 0.0343, 0.0151, 0.0158, 0.0368,
         0.0209, 0.0256, 0.0190, 0.0214, 0.0246, 0.0213, 0.0263, 0.0182, 0.0144,
         0.0362, 0.0277, 0.0259, 0.0360, 0.0309, 0.0299, 0.0114, 0.0127, 0.0283,
         0.0392, 0.0078, 0.0411, 0.0258]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/152
(64, 64, 3)
tensor([[0.0327, 0.0325, 0.0120, 0.0126, 0.0314, 0.0241, 0.0357, 0.0200, 0.0181,
         0.0272, 0.0172, 0.0225, 0.0366, 0.0231, 0.0210, 0.0210, 0.0200, 0.0507,
         0.0236, 0.0184, 0.0160, 0.0240, 0.0148, 0.0210, 0.0192, 0.0313, 0.0231,
         0.0392, 0.0321, 0.0267, 0.0183, 0.0446, 0.0263, 0.0186, 0.0185, 0.0307,
         0.0243, 0.0216, 0.0239, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 17
images/146
(64, 64, 3)
tensor([[0.0222, 0.0223, 0.0273, 0.0195, 0.0232, 0.0169, 0.0203, 0.0249, 0.0217,
         0.0199, 0.0159, 0.0232, 0.0488, 0.0296, 0.0194, 0.0199, 0.0198, 0.0633,
         0.0246, 0.0153, 0.0123, 0.0202, 0.0245, 0.0159, 0.0161, 0.0245, 0.0202,
         0.0377, 0.0322, 0.0408, 0.0150, 0.0368, 0.0248, 0.0140, 0.0268, 0.0443,
         0.0250, 0.0199, 0.0228, 0.0283]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 18
images/48
(64, 64, 3)
tensor([[0.0202, 0.0296, 0.0180, 0.0157, 0.0345, 0.0255, 0.0510, 0.0179, 0.0139,
         0.0179, 0.0186, 0.0290, 0.0593, 0.0342, 0.0221, 0.0164, 0.0154, 0.0340,
         0.0145, 0.0207, 0.0237, 0.0272, 0.0197, 0.0222, 0.0179, 0.0135, 0.0211,
         0.0327, 0.0332, 0.0257, 0.0239, 0.0386, 0.0238, 0.0174, 0.0355, 0.0256,
         0.0238, 0.0209, 0.0175, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 19
images/171
(64, 64, 3)
tensor([[0.0274, 0.0244, 0.0194, 0.0213, 0.0371, 0.0211, 0.0334, 0.0144, 0.0124,
         0.0239, 0.0183, 0.0233, 0.0237, 0.0292, 0.0238, 0.0162, 0.0275, 0.0533,
         0.0273, 0.0197, 0.0229, 0.0211, 0.0199, 0.0208, 0.0201, 0.0191, 0.0240,
         0.0290, 0.0365, 0.0257, 0.0157, 0.0355, 0.0282, 0.0262, 0.0179, 0.0313,
         0.0310, 0.0246, 0.0222, 0.0313]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 20
images/269
(64, 64, 3)
tensor([[0.0267, 0.0216, 0.0172, 0.0188, 0.0331, 0.0218, 0.0300, 0.0154, 0.0209,
         0.0165, 0.0203, 0.0174, 0.0439, 0.0308, 0.0333, 0.0287, 0.0203, 0.0330,
         0.0176, 0.0197, 0.0151, 0.0190, 0.0153, 0.0197, 0.0299, 0.0259, 0.0215,
         0.0375, 0.0235, 0.0342, 0.0277, 0.0214, 0.0243, 0.0243, 0.0386, 0.0375,
         0.0258, 0.0264, 0.0190, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 21
images/595
(64, 64, 3)
tensor([[0.0295, 0.0291, 0.0179, 0.0127, 0.0211, 0.0198, 0.0360, 0.0173, 0.0125,
         0.0204, 0.0186, 0.0359, 0.0483, 0.0311, 0.0187, 0.0186, 0.0289, 0.0242,
         0.0294, 0.0187, 0.0134, 0.0206, 0.0225, 0.0195, 0.0205, 0.0257, 0.0292,
         0.0351, 0.0453, 0.0177, 0.0153, 0.0238, 0.0261, 0.0227, 0.0228, 0.0465,
         0.0335, 0.0200, 0.0288, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/110
(64, 64, 3)
tensor([[0.0263, 0.0213, 0.0188, 0.0182, 0.0316, 0.0145, 0.0518, 0.0312, 0.0219,
         0.0195, 0.0136, 0.0343, 0.0281, 0.0526, 0.0211, 0.0134, 0.0212, 0.0706,
         0.0118, 0.0248, 0.0148, 0.0272, 0.0230, 0.0236, 0.0197, 0.0132, 0.0187,
         0.0221, 0.0375, 0.0234, 0.0157, 0.0233, 0.0306, 0.0260, 0.0265, 0.0340,
         0.0142, 0.0156, 0.0233, 0.0210]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 23
images/440
(64, 64, 3)
tensor([[0.0150, 0.0210, 0.0230, 0.0142, 0.0357, 0.0266, 0.0367, 0.0275, 0.0195,
         0.0274, 0.0150, 0.0505, 0.0361, 0.0398, 0.0344, 0.0176, 0.0266, 0.0201,
         0.0216, 0.0190, 0.0200, 0.0177, 0.0220, 0.0211, 0.0169, 0.0212, 0.0437,
         0.0162, 0.0211, 0.0282, 0.0161, 0.0273, 0.0232, 0.0270, 0.0274, 0.0314,
         0.0256, 0.0212, 0.0153, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 24
images/66
(64, 64, 3)
tensor([[0.0332, 0.0219, 0.0168, 0.0142, 0.0289, 0.0173, 0.0230, 0.0129, 0.0258,
         0.0214, 0.0182, 0.0412, 0.0278, 0.0256, 0.0309, 0.0179, 0.0201, 0.0339,
         0.0160, 0.0161, 0.0177, 0.0261, 0.0251, 0.0281, 0.0197, 0.0373, 0.0193,
         0.0339, 0.0335, 0.0249, 0.0296, 0.0448, 0.0234, 0.0254, 0.0279, 0.0360,
         0.0291, 0.0150, 0.0164, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/34
(64, 64, 3)
tensor([[0.0292, 0.0316, 0.0158, 0.0245, 0.0231, 0.0222, 0.0266, 0.0173, 0.0158,
         0.0265, 0.0229, 0.0314, 0.0478, 0.0305, 0.0117, 0.0221, 0.0256, 0.0221,
         0.0134, 0.0214, 0.0204, 0.0207, 0.0326, 0.0276, 0.0231, 0.0209, 0.0211,
         0.0529, 0.0299, 0.0355, 0.0150, 0.0398, 0.0239, 0.0182, 0.0166, 0.0231,
         0.0317, 0.0232, 0.0223, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 26
images/193
(64, 64, 3)
tensor([[0.0201, 0.0274, 0.0144, 0.0148, 0.0411, 0.0197, 0.0259, 0.0183, 0.0155,
         0.0252, 0.0161, 0.0243, 0.0226, 0.0492, 0.0365, 0.0106, 0.0177, 0.0451,
         0.0185, 0.0269, 0.0245, 0.0366, 0.0331, 0.0178, 0.0281, 0.0195, 0.0205,
         0.0287, 0.0415, 0.0384, 0.0183, 0.0178, 0.0229, 0.0319, 0.0245, 0.0309,
         0.0202, 0.0147, 0.0188, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 27
images/434
(64, 64, 3)
tensor([[0.0290, 0.0319, 0.0187, 0.0190, 0.0255, 0.0187, 0.0292, 0.0204, 0.0222,
         0.0171, 0.0240, 0.0286, 0.0310, 0.0207, 0.0356, 0.0277, 0.0334, 0.0333,
         0.0206, 0.0268, 0.0234, 0.0225, 0.0238, 0.0130, 0.0219, 0.0138, 0.0431,
         0.0287, 0.0209, 0.0209, 0.0169, 0.0276, 0.0194, 0.0245, 0.0325, 0.0356,
         0.0254, 0.0207, 0.0266, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 28
images/95
(64, 64, 3)
tensor([[0.0319, 0.0214, 0.0182, 0.0129, 0.0314, 0.0190, 0.0458, 0.0194, 0.0149,
         0.0169, 0.0233, 0.0279, 0.0600, 0.0258, 0.0305, 0.0133, 0.0145, 0.0311,
         0.0211, 0.0124, 0.0180, 0.0270, 0.0288, 0.0196, 0.0200, 0.0128, 0.0298,
         0.0267, 0.0210, 0.0215, 0.0203, 0.0327, 0.0264, 0.0297, 0.0371, 0.0366,
         0.0315, 0.0254, 0.0186, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 29
images/406
(64, 64, 3)
tensor([[0.0345, 0.0268, 0.0186, 0.0259, 0.0303, 0.0237, 0.0230, 0.0154, 0.0127,
         0.0191, 0.0256, 0.0298, 0.0285, 0.0296, 0.0213, 0.0222, 0.0210, 0.0376,
         0.0196, 0.0223, 0.0197, 0.0238, 0.0409, 0.0270, 0.0220, 0.0195, 0.0238,
         0.0325, 0.0256, 0.0187, 0.0200, 0.0343, 0.0327, 0.0254, 0.0176, 0.0290,
         0.0372, 0.0178, 0.0176, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 30
images/186
(64, 64, 3)
tensor([[0.0237, 0.0259, 0.0135, 0.0138, 0.0301, 0.0167, 0.0264, 0.0205, 0.0151,
         0.0264, 0.0228, 0.0279, 0.0258, 0.0384, 0.0240, 0.0157, 0.0209, 0.0401,
         0.0216, 0.0268, 0.0201, 0.0330, 0.0204, 0.0228, 0.0344, 0.0164, 0.0157,
         0.0440, 0.0363, 0.0191, 0.0244, 0.0316, 0.0185, 0.0363, 0.0176, 0.0405,
         0.0273, 0.0217, 0.0236, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 31
images/534
(64, 64, 3)
tensor([[0.0292, 0.0195, 0.0269, 0.0166, 0.0242, 0.0200, 0.0382, 0.0185, 0.0271,
         0.0191, 0.0228, 0.0613, 0.0243, 0.0265, 0.0269, 0.0160, 0.0217, 0.0452,
         0.0105, 0.0203, 0.0251, 0.0166, 0.0143, 0.0182, 0.0145, 0.0237, 0.0224,
         0.0299, 0.0425, 0.0218, 0.0203, 0.0301, 0.0403, 0.0223, 0.0170, 0.0198,
         0.0289, 0.0222, 0.0237, 0.0317]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 32
images/368
(64, 64, 3)
tensor([[0.0281, 0.0369, 0.0108, 0.0178, 0.0265, 0.0365, 0.0375, 0.0115, 0.0206,
         0.0173, 0.0208, 0.0337, 0.0393, 0.0202, 0.0303, 0.0273, 0.0290, 0.0344,
         0.0193, 0.0207, 0.0126, 0.0349, 0.0148, 0.0206, 0.0283, 0.0249, 0.0275,
         0.0235, 0.0217, 0.0231, 0.0147, 0.0220, 0.0281, 0.0268, 0.0260, 0.0290,
         0.0309, 0.0291, 0.0177, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 33
images/38
(64, 64, 3)
tensor([[0.0217, 0.0284, 0.0241, 0.0242, 0.0313, 0.0193, 0.0385, 0.0145, 0.0164,
         0.0218, 0.0151, 0.0287, 0.0330, 0.0292, 0.0210, 0.0134, 0.0126, 0.0251,
         0.0277, 0.0167, 0.0267, 0.0256, 0.0257, 0.0158, 0.0278, 0.0257, 0.0284,
         0.0291, 0.0394, 0.0310, 0.0252, 0.0363, 0.0366, 0.0255, 0.0188, 0.0226,
         0.0409, 0.0121, 0.0175, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 34
images/52
(64, 64, 3)
tensor([[0.0437, 0.0345, 0.0176, 0.0222, 0.0302, 0.0192, 0.0218, 0.0209, 0.0125,
         0.0276, 0.0184, 0.0209, 0.0248, 0.0209, 0.0338, 0.0205, 0.0231, 0.0385,
         0.0171, 0.0158, 0.0230, 0.0296, 0.0122, 0.0242, 0.0257, 0.0179, 0.0261,
         0.0333, 0.0299, 0.0291, 0.0174, 0.0372, 0.0233, 0.0204, 0.0228, 0.0248,
         0.0414, 0.0194, 0.0206, 0.0374]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 35
images/515
(64, 64, 3)
tensor([[0.0285, 0.0213, 0.0160, 0.0144, 0.0247, 0.0260, 0.0308, 0.0215, 0.0250,
         0.0179, 0.0176, 0.0284, 0.0566, 0.0511, 0.0201, 0.0231, 0.0148, 0.0445,
         0.0219, 0.0238, 0.0158, 0.0135, 0.0151, 0.0226, 0.0227, 0.0159, 0.0183,
         0.0347, 0.0444, 0.0305, 0.0179, 0.0281, 0.0367, 0.0213, 0.0188, 0.0232,
         0.0216, 0.0241, 0.0190, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 36
images/553
(64, 64, 3)
tensor([[0.0296, 0.0251, 0.0213, 0.0249, 0.0312, 0.0177, 0.0358, 0.0183, 0.0206,
         0.0151, 0.0214, 0.0289, 0.0233, 0.0432, 0.0334, 0.0204, 0.0204, 0.0411,
         0.0132, 0.0263, 0.0153, 0.0318, 0.0144, 0.0145, 0.0265, 0.0215, 0.0163,
         0.0232, 0.0368, 0.0280, 0.0188, 0.0313, 0.0198, 0.0210, 0.0297, 0.0325,
         0.0316, 0.0286, 0.0224, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 37
images/76
(64, 64, 3)
tensor([[0.0240, 0.0403, 0.0199, 0.0148, 0.0273, 0.0189, 0.0287, 0.0115, 0.0208,
         0.0156, 0.0168, 0.0315, 0.0572, 0.0358, 0.0259, 0.0243, 0.0224, 0.0356,
         0.0230, 0.0172, 0.0185, 0.0247, 0.0172, 0.0197, 0.0201, 0.0231, 0.0258,
         0.0407, 0.0406, 0.0308, 0.0168, 0.0225, 0.0284, 0.0263, 0.0188, 0.0238,
         0.0269, 0.0159, 0.0167, 0.0311]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 38
images/577
(64, 64, 3)
tensor([[0.0223, 0.0313, 0.0285, 0.0138, 0.0293, 0.0179, 0.0382, 0.0237, 0.0176,
         0.0148, 0.0135, 0.0398, 0.0374, 0.0319, 0.0326, 0.0195, 0.0134, 0.0279,
         0.0188, 0.0199, 0.0205, 0.0227, 0.0141, 0.0285, 0.0209, 0.0170, 0.0208,
         0.0424, 0.0425, 0.0195, 0.0263, 0.0401, 0.0321, 0.0140, 0.0368, 0.0263,
         0.0263, 0.0195, 0.0150, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 39
images/256
(64, 64, 3)
tensor([[0.0342, 0.0184, 0.0255, 0.0165, 0.0437, 0.0150, 0.0272, 0.0177, 0.0130,
         0.0292, 0.0152, 0.0366, 0.0384, 0.0347, 0.0343, 0.0229, 0.0153, 0.0416,
         0.0188, 0.0229, 0.0376, 0.0284, 0.0157, 0.0203, 0.0219, 0.0131, 0.0256,
         0.0277, 0.0280, 0.0307, 0.0206, 0.0375, 0.0274, 0.0168, 0.0208, 0.0196,
         0.0284, 0.0145, 0.0248, 0.0195]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 40
images/90
(64, 64, 3)
tensor([[0.0344, 0.0291, 0.0195, 0.0227, 0.0267, 0.0278, 0.0489, 0.0128, 0.0175,
         0.0130, 0.0184, 0.0357, 0.0444, 0.0353, 0.0374, 0.0156, 0.0262, 0.0229,
         0.0170, 0.0252, 0.0270, 0.0208, 0.0260, 0.0166, 0.0231, 0.0258, 0.0272,
         0.0217, 0.0318, 0.0215, 0.0186, 0.0228, 0.0326, 0.0307, 0.0244, 0.0246,
         0.0240, 0.0149, 0.0160, 0.0198]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 41
images/169
(64, 64, 3)
tensor([[0.0260, 0.0206, 0.0135, 0.0220, 0.0323, 0.0196, 0.0288, 0.0188, 0.0234,
         0.0162, 0.0222, 0.0240, 0.0386, 0.0462, 0.0307, 0.0308, 0.0230, 0.0401,
         0.0241, 0.0131, 0.0220, 0.0197, 0.0234, 0.0199, 0.0147, 0.0267, 0.0218,
         0.0253, 0.0283, 0.0225, 0.0227, 0.0302, 0.0302, 0.0304, 0.0222, 0.0299,
         0.0260, 0.0197, 0.0177, 0.0328]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 42
images/310
(64, 64, 3)
tensor([[0.0296, 0.0373, 0.0197, 0.0218, 0.0389, 0.0167, 0.0209, 0.0140, 0.0191,
         0.0236, 0.0181, 0.0378, 0.0379, 0.0290, 0.0298, 0.0328, 0.0139, 0.0513,
         0.0142, 0.0242, 0.0219, 0.0224, 0.0208, 0.0176, 0.0143, 0.0187, 0.0369,
         0.0405, 0.0198, 0.0272, 0.0153, 0.0319, 0.0199, 0.0196, 0.0295, 0.0260,
         0.0282, 0.0144, 0.0188, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 43
images/89
(64, 64, 3)
tensor([[0.0319, 0.0245, 0.0209, 0.0191, 0.0347, 0.0229, 0.0307, 0.0151, 0.0124,
         0.0211, 0.0162, 0.0251, 0.0356, 0.0366, 0.0163, 0.0195, 0.0174, 0.0380,
         0.0228, 0.0323, 0.0102, 0.0233, 0.0276, 0.0202, 0.0173, 0.0169, 0.0287,
         0.0480, 0.0399, 0.0200, 0.0190, 0.0344, 0.0184, 0.0268, 0.0214, 0.0287,
         0.0226, 0.0183, 0.0306, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/535
(64, 64, 3)
tensor([[0.0217, 0.0339, 0.0123, 0.0286, 0.0315, 0.0272, 0.0357, 0.0195, 0.0164,
         0.0158, 0.0149, 0.0331, 0.0440, 0.0238, 0.0217, 0.0262, 0.0214, 0.0578,
         0.0183, 0.0287, 0.0181, 0.0250, 0.0166, 0.0253, 0.0226, 0.0229, 0.0222,
         0.0263, 0.0276, 0.0208, 0.0284, 0.0331, 0.0217, 0.0200, 0.0257, 0.0216,
         0.0216, 0.0253, 0.0217, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 45
images/185
(64, 64, 3)
tensor([[0.0548, 0.0260, 0.0154, 0.0215, 0.0243, 0.0137, 0.0142, 0.0246, 0.0197,
         0.0154, 0.0169, 0.0489, 0.0550, 0.0253, 0.0315, 0.0246, 0.0170, 0.0289,
         0.0162, 0.0267, 0.0157, 0.0226, 0.0228, 0.0308, 0.0210, 0.0175, 0.0218,
         0.0258, 0.0271, 0.0204, 0.0205, 0.0434, 0.0197, 0.0291, 0.0208, 0.0329,
         0.0217, 0.0285, 0.0208, 0.0166]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 46
images/294
(64, 64, 3)
tensor([[0.0226, 0.0295, 0.0163, 0.0213, 0.0266, 0.0169, 0.0486, 0.0213, 0.0148,
         0.0194, 0.0192, 0.0198, 0.0472, 0.0272, 0.0204, 0.0176, 0.0207, 0.0260,
         0.0282, 0.0269, 0.0296, 0.0190, 0.0294, 0.0223, 0.0157, 0.0156, 0.0250,
         0.0411, 0.0273, 0.0236, 0.0226, 0.0232, 0.0363, 0.0252, 0.0213, 0.0256,
         0.0200, 0.0353, 0.0270, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 47
images/160
(64, 64, 3)
tensor([[0.0274, 0.0278, 0.0210, 0.0141, 0.0208, 0.0253, 0.0381, 0.0184, 0.0173,
         0.0152, 0.0199, 0.0319, 0.0346, 0.0431, 0.0176, 0.0166, 0.0258, 0.0365,
         0.0144, 0.0233, 0.0161, 0.0171, 0.0172, 0.0174, 0.0226, 0.0177, 0.0182,
         0.0377, 0.0266, 0.0217, 0.0182, 0.0274, 0.0304, 0.0285, 0.0229, 0.0450,
         0.0246, 0.0276, 0.0218, 0.0524]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 48
images/136
(64, 64, 3)
tensor([[0.0254, 0.0301, 0.0109, 0.0162, 0.0347, 0.0222, 0.0356, 0.0180, 0.0216,
         0.0113, 0.0230, 0.0293, 0.0433, 0.0351, 0.0206, 0.0222, 0.0272, 0.0342,
         0.0223, 0.0277, 0.0147, 0.0273, 0.0128, 0.0199, 0.0242, 0.0220, 0.0218,
         0.0281, 0.0291, 0.0213, 0.0197, 0.0238, 0.0197, 0.0260, 0.0279, 0.0382,
         0.0372, 0.0162, 0.0274, 0.0317]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 49
images/520
(64, 64, 3)
tensor([[0.0186, 0.0260, 0.0116, 0.0235, 0.0323, 0.0245, 0.0397, 0.0131, 0.0189,
         0.0248, 0.0243, 0.0364, 0.0624, 0.0344, 0.0288, 0.0186, 0.0167, 0.0301,
         0.0184, 0.0258, 0.0268, 0.0177, 0.0200, 0.0135, 0.0177, 0.0156, 0.0173,
         0.0493, 0.0253, 0.0172, 0.0149, 0.0151, 0.0354, 0.0248, 0.0297, 0.0324,
         0.0318, 0.0224, 0.0206, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 50
images/198
(64, 64, 3)
tensor([[0.0299, 0.0318, 0.0174, 0.0138, 0.0363, 0.0124, 0.0424, 0.0171, 0.0166,
         0.0156, 0.0231, 0.0263, 0.0313, 0.0350, 0.0286, 0.0181, 0.0232, 0.0441,
         0.0129, 0.0133, 0.0203, 0.0463, 0.0197, 0.0270, 0.0183, 0.0127, 0.0274,
         0.0308, 0.0303, 0.0323, 0.0153, 0.0330, 0.0356, 0.0239, 0.0135, 0.0245,
         0.0228, 0.0236, 0.0262, 0.0274]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 51
images/243
(64, 64, 3)
tensor([[0.0382, 0.0355, 0.0256, 0.0260, 0.0261, 0.0133, 0.0249, 0.0182, 0.0222,
         0.0238, 0.0174, 0.0235, 0.0283, 0.0329, 0.0176, 0.0175, 0.0206, 0.0306,
         0.0173, 0.0200, 0.0216, 0.0259, 0.0189, 0.0267, 0.0178, 0.0198, 0.0204,
         0.0338, 0.0370, 0.0159, 0.0160, 0.0271, 0.0323, 0.0444, 0.0157, 0.0228,
         0.0444, 0.0194, 0.0261, 0.0344]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 1
Session Number: 52
images/508
(64, 64, 3)
tensor([[0.0335, 0.0241, 0.0186, 0.0196, 0.0273, 0.0185, 0.0256, 0.0279, 0.0186,
         0.0213, 0.0144, 0.0327, 0.0267, 0.0305, 0.0218, 0.0263, 0.0214, 0.0356,
         0.0166, 0.0122, 0.0162, 0.0287, 0.0249, 0.0207, 0.0246, 0.0216, 0.0216,
         0.0310, 0.0335, 0.0223, 0.0225, 0.0241, 0.0348, 0.0264, 0.0271, 0.0350,
         0.0401, 0.0176, 0.0263, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 53
images/245
(64, 64, 3)
tensor([[0.0270, 0.0354, 0.0111, 0.0199, 0.0458, 0.0167, 0.0299, 0.0182, 0.0244,
         0.0320, 0.0118, 0.0308, 0.0286, 0.0239, 0.0300, 0.0224, 0.0177, 0.0447,
         0.0176, 0.0182, 0.0133, 0.0343, 0.0185, 0.0235, 0.0230, 0.0268, 0.0207,
         0.0217, 0.0306, 0.0236, 0.0107, 0.0231, 0.0440, 0.0223, 0.0265, 0.0246,
         0.0346, 0.0227, 0.0141, 0.0354]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 54
images/494
(64, 64, 3)
tensor([[0.0305, 0.0267, 0.0179, 0.0205, 0.0226, 0.0173, 0.0363, 0.0177, 0.0314,
         0.0119, 0.0225, 0.0157, 0.0435, 0.0498, 0.0245, 0.0241, 0.0230, 0.0348,
         0.0217, 0.0149, 0.0147, 0.0368, 0.0232, 0.0150, 0.0176, 0.0187, 0.0194,
         0.0316, 0.0308, 0.0303, 0.0200, 0.0236, 0.0321, 0.0203, 0.0125, 0.0405,
         0.0252, 0.0146, 0.0374, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 55
images/566
(64, 64, 3)
tensor([[0.0278, 0.0193, 0.0196, 0.0156, 0.0363, 0.0242, 0.0361, 0.0183, 0.0230,
         0.0234, 0.0168, 0.0247, 0.0365, 0.0333, 0.0280, 0.0218, 0.0213, 0.0506,
         0.0217, 0.0265, 0.0168, 0.0242, 0.0175, 0.0169, 0.0228, 0.0142, 0.0266,
         0.0330, 0.0413, 0.0211, 0.0179, 0.0210, 0.0354, 0.0213, 0.0235, 0.0228,
         0.0293, 0.0258, 0.0181, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 56
images/241
(64, 64, 3)
tensor([[0.0239, 0.0282, 0.0140, 0.0191, 0.0500, 0.0213, 0.0301, 0.0164, 0.0184,
         0.0204, 0.0164, 0.0221, 0.0264, 0.0409, 0.0255, 0.0223, 0.0293, 0.0441,
         0.0168, 0.0163, 0.0166, 0.0289, 0.0196, 0.0246, 0.0271, 0.0154, 0.0354,
         0.0193, 0.0325, 0.0282, 0.0160, 0.0462, 0.0339, 0.0186, 0.0187, 0.0274,
         0.0330, 0.0159, 0.0217, 0.0191]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 57
images/177
(64, 64, 3)
tensor([[0.0237, 0.0489, 0.0274, 0.0240, 0.0218, 0.0163, 0.0259, 0.0177, 0.0145,
         0.0203, 0.0335, 0.0250, 0.0469, 0.0220, 0.0230, 0.0183, 0.0129, 0.0470,
         0.0255, 0.0252, 0.0146, 0.0255, 0.0216, 0.0186, 0.0235, 0.0218, 0.0245,
         0.0347, 0.0303, 0.0269, 0.0158, 0.0323, 0.0285, 0.0270, 0.0248, 0.0322,
         0.0226, 0.0210, 0.0180, 0.0157]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 58
images/488
(64, 64, 3)
tensor([[0.0411, 0.0241, 0.0198, 0.0248, 0.0293, 0.0150, 0.0392, 0.0144, 0.0199,
         0.0176, 0.0147, 0.0469, 0.0494, 0.0283, 0.0202, 0.0117, 0.0165, 0.0429,
         0.0184, 0.0265, 0.0138, 0.0190, 0.0249, 0.0273, 0.0159, 0.0212, 0.0283,
         0.0346, 0.0453, 0.0197, 0.0174, 0.0226, 0.0244, 0.0182, 0.0260, 0.0223,
         0.0223, 0.0283, 0.0271, 0.0210]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 59
images/243
(64, 64, 3)
tensor([[0.0314, 0.0261, 0.0183, 0.0243, 0.0361, 0.0174, 0.0212, 0.0249, 0.0215,
         0.0184, 0.0289, 0.0186, 0.0434, 0.0475, 0.0189, 0.0149, 0.0161, 0.0330,
         0.0200, 0.0243, 0.0162, 0.0174, 0.0113, 0.0306, 0.0184, 0.0212, 0.0187,
         0.0340, 0.0376, 0.0234, 0.0220, 0.0216, 0.0271, 0.0332, 0.0215, 0.0361,
         0.0262, 0.0182, 0.0369, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 60
images/421
(64, 64, 3)
tensor([[0.0333, 0.0219, 0.0212, 0.0209, 0.0246, 0.0194, 0.0325, 0.0178, 0.0184,
         0.0176, 0.0167, 0.0407, 0.0312, 0.0285, 0.0307, 0.0151, 0.0132, 0.0506,
         0.0143, 0.0217, 0.0153, 0.0312, 0.0231, 0.0253, 0.0229, 0.0224, 0.0247,
         0.0392, 0.0538, 0.0195, 0.0130, 0.0202, 0.0321, 0.0290, 0.0187, 0.0201,
         0.0313, 0.0226, 0.0162, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 61
images/220
(64, 64, 3)
tensor([[0.0287, 0.0335, 0.0332, 0.0153, 0.0400, 0.0186, 0.0584, 0.0210, 0.0209,
         0.0266, 0.0285, 0.0291, 0.0314, 0.0325, 0.0282, 0.0167, 0.0200, 0.0344,
         0.0168, 0.0154, 0.0234, 0.0260, 0.0149, 0.0173, 0.0242, 0.0158, 0.0167,
         0.0209, 0.0173, 0.0259, 0.0136, 0.0503, 0.0282, 0.0176, 0.0164, 0.0323,
         0.0201, 0.0154, 0.0222, 0.0324]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 62
images/145
(64, 64, 3)
tensor([[0.0407, 0.0249, 0.0191, 0.0164, 0.0318, 0.0175, 0.0297, 0.0097, 0.0213,
         0.0188, 0.0168, 0.0362, 0.0435, 0.0309, 0.0265, 0.0178, 0.0226, 0.0314,
         0.0172, 0.0309, 0.0177, 0.0347, 0.0304, 0.0198, 0.0295, 0.0215, 0.0169,
         0.0412, 0.0273, 0.0222, 0.0169, 0.0229, 0.0276, 0.0204, 0.0201, 0.0291,
         0.0296, 0.0245, 0.0188, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 63
images/25
(64, 64, 3)
tensor([[0.0315, 0.0278, 0.0123, 0.0223, 0.0311, 0.0185, 0.0331, 0.0149, 0.0297,
         0.0170, 0.0192, 0.0276, 0.0478, 0.0345, 0.0342, 0.0190, 0.0143, 0.0484,
         0.0328, 0.0228, 0.0199, 0.0284, 0.0131, 0.0193, 0.0348, 0.0148, 0.0256,
         0.0310, 0.0255, 0.0188, 0.0230, 0.0177, 0.0247, 0.0183, 0.0272, 0.0151,
         0.0226, 0.0262, 0.0232, 0.0318]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 64
images/65
(64, 64, 3)
tensor([[0.0331, 0.0212, 0.0226, 0.0129, 0.0362, 0.0334, 0.0338, 0.0172, 0.0200,
         0.0275, 0.0145, 0.0340, 0.0369, 0.0269, 0.0176, 0.0146, 0.0270, 0.0271,
         0.0193, 0.0204, 0.0195, 0.0311, 0.0250, 0.0239, 0.0269, 0.0229, 0.0195,
         0.0370, 0.0394, 0.0269, 0.0140, 0.0319, 0.0303, 0.0175, 0.0188, 0.0392,
         0.0196, 0.0222, 0.0163, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 65
images/597
(64, 64, 3)
tensor([[0.0269, 0.0307, 0.0139, 0.0112, 0.0414, 0.0319, 0.0248, 0.0138, 0.0158,
         0.0169, 0.0178, 0.0393, 0.0561, 0.0337, 0.0211, 0.0204, 0.0191, 0.0327,
         0.0315, 0.0281, 0.0254, 0.0351, 0.0123, 0.0273, 0.0156, 0.0165, 0.0369,
         0.0351, 0.0325, 0.0167, 0.0133, 0.0366, 0.0237, 0.0231, 0.0186, 0.0228,
         0.0204, 0.0170, 0.0223, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 66
images/395
(64, 64, 3)
tensor([[0.0318, 0.0265, 0.0171, 0.0249, 0.0330, 0.0148, 0.0287, 0.0178, 0.0159,
         0.0134, 0.0257, 0.0284, 0.0373, 0.0377, 0.0286, 0.0151, 0.0199, 0.0491,
         0.0160, 0.0306, 0.0206, 0.0292, 0.0204, 0.0180, 0.0214, 0.0144, 0.0257,
         0.0353, 0.0357, 0.0213, 0.0175, 0.0269, 0.0300, 0.0207, 0.0176, 0.0349,
         0.0280, 0.0225, 0.0279, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 67
images/147
(64, 64, 3)
tensor([[0.0228, 0.0295, 0.0185, 0.0129, 0.0190, 0.0304, 0.0435, 0.0184, 0.0134,
         0.0178, 0.0158, 0.0316, 0.0502, 0.0503, 0.0202, 0.0136, 0.0212, 0.0237,
         0.0158, 0.0240, 0.0165, 0.0249, 0.0143, 0.0298, 0.0264, 0.0172, 0.0259,
         0.0259, 0.0442, 0.0199, 0.0270, 0.0317, 0.0222, 0.0214, 0.0235, 0.0449,
         0.0323, 0.0150, 0.0143, 0.0302]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/460
(64, 64, 3)
tensor([[0.0164, 0.0282, 0.0203, 0.0156, 0.0338, 0.0201, 0.0406, 0.0196, 0.0285,
         0.0280, 0.0240, 0.0238, 0.0595, 0.0260, 0.0233, 0.0131, 0.0199, 0.0324,
         0.0203, 0.0181, 0.0158, 0.0225, 0.0215, 0.0139, 0.0222, 0.0160, 0.0233,
         0.0374, 0.0491, 0.0331, 0.0149, 0.0209, 0.0291, 0.0187, 0.0166, 0.0197,
         0.0450, 0.0183, 0.0214, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 69
images/475
(64, 64, 3)
tensor([[0.0255, 0.0223, 0.0113, 0.0166, 0.0298, 0.0210, 0.0401, 0.0162, 0.0248,
         0.0246, 0.0186, 0.0245, 0.0529, 0.0468, 0.0166, 0.0233, 0.0225, 0.0303,
         0.0165, 0.0184, 0.0155, 0.0250, 0.0148, 0.0231, 0.0269, 0.0126, 0.0282,
         0.0336, 0.0421, 0.0255, 0.0253, 0.0342, 0.0291, 0.0225, 0.0195, 0.0322,
         0.0204, 0.0216, 0.0216, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 70
images/424
(64, 64, 3)
tensor([[0.0297, 0.0282, 0.0177, 0.0241, 0.0290, 0.0265, 0.0423, 0.0147, 0.0238,
         0.0139, 0.0201, 0.0282, 0.0459, 0.0327, 0.0285, 0.0210, 0.0183, 0.0356,
         0.0226, 0.0284, 0.0140, 0.0259, 0.0213, 0.0169, 0.0254, 0.0185, 0.0168,
         0.0244, 0.0299, 0.0319, 0.0217, 0.0237, 0.0356, 0.0202, 0.0238, 0.0289,
         0.0237, 0.0155, 0.0256, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 71
images/6
(64, 64, 3)
tensor([[0.0354, 0.0211, 0.0191, 0.0192, 0.0234, 0.0197, 0.0248, 0.0215, 0.0170,
         0.0178, 0.0210, 0.0327, 0.0506, 0.0228, 0.0228, 0.0193, 0.0187, 0.0220,
         0.0168, 0.0287, 0.0124, 0.0173, 0.0277, 0.0146, 0.0167, 0.0195, 0.0217,
         0.0534, 0.0398, 0.0202, 0.0157, 0.0225, 0.0377, 0.0275, 0.0299, 0.0274,
         0.0302, 0.0322, 0.0334, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 1
Session Number: 72
images/43
(64, 64, 3)
tensor([[0.0288, 0.0240, 0.0201, 0.0124, 0.0476, 0.0142, 0.0335, 0.0224, 0.0156,
         0.0172, 0.0157, 0.0464, 0.0429, 0.0280, 0.0251, 0.0151, 0.0182, 0.0231,
         0.0185, 0.0252, 0.0257, 0.0199, 0.0263, 0.0170, 0.0242, 0.0155, 0.0266,
         0.0384, 0.0259, 0.0211, 0.0112, 0.0238, 0.0277, 0.0360, 0.0427, 0.0328,
         0.0288, 0.0198, 0.0147, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 73
images/310
(64, 64, 3)
tensor([[0.0285, 0.0281, 0.0218, 0.0229, 0.0330, 0.0207, 0.0263, 0.0134, 0.0170,
         0.0223, 0.0231, 0.0240, 0.0207, 0.0219, 0.0286, 0.0150, 0.0195, 0.0511,
         0.0230, 0.0149, 0.0214, 0.0198, 0.0210, 0.0181, 0.0168, 0.0237, 0.0249,
         0.0243, 0.0422, 0.0306, 0.0250, 0.0315, 0.0310, 0.0272, 0.0230, 0.0390,
         0.0374, 0.0223, 0.0187, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 74
images/1
(64, 64, 3)
tensor([[0.0278, 0.0240, 0.0118, 0.0177, 0.0300, 0.0181, 0.0257, 0.0107, 0.0160,
         0.0205, 0.0154, 0.0321, 0.0536, 0.0374, 0.0276, 0.0201, 0.0273, 0.0549,
         0.0175, 0.0195, 0.0176, 0.0146, 0.0118, 0.0158, 0.0221, 0.0193, 0.0222,
         0.0386, 0.0520, 0.0166, 0.0189, 0.0265, 0.0263, 0.0309, 0.0300, 0.0247,
         0.0253, 0.0147, 0.0289, 0.0359]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1 
Session Number: 75
images/550
(64, 64, 3)
tensor([[0.0214, 0.0464, 0.0111, 0.0259, 0.0293, 0.0228, 0.0306, 0.0195, 0.0215,
         0.0228, 0.0163, 0.0168, 0.0257, 0.0379, 0.0316, 0.0257, 0.0191, 0.0307,
         0.0269, 0.0176, 0.0141, 0.0365, 0.0176, 0.0219, 0.0322, 0.0118, 0.0257,
         0.0303, 0.0420, 0.0266, 0.0182, 0.0364, 0.0324, 0.0229, 0.0238, 0.0202,
         0.0231, 0.0223, 0.0211, 0.0216]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 76
images/354
(64, 64, 3)
tensor([[0.0339, 0.0185, 0.0213, 0.0180, 0.0255, 0.0183, 0.0437, 0.0169, 0.0159,
         0.0150, 0.0186, 0.0418, 0.0404, 0.0292, 0.0355, 0.0193, 0.0225, 0.0264,
         0.0161, 0.0183, 0.0145, 0.0219, 0.0216, 0.0210, 0.0179, 0.0268, 0.0163,
         0.0329, 0.0411, 0.0294, 0.0150, 0.0333, 0.0192, 0.0254, 0.0199, 0.0455,
         0.0229, 0.0227, 0.0308, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 77
images/509
(64, 64, 3)
tensor([[0.0224, 0.0194, 0.0154, 0.0265, 0.0332, 0.0248, 0.0303, 0.0203, 0.0268,
         0.0161, 0.0161, 0.0256, 0.0450, 0.0261, 0.0205, 0.0243, 0.0213, 0.0299,
         0.0247, 0.0222, 0.0165, 0.0184, 0.0197, 0.0162, 0.0183, 0.0149, 0.0237,
         0.0377, 0.0442, 0.0351, 0.0158, 0.0337, 0.0238, 0.0423, 0.0132, 0.0286,
         0.0334, 0.0202, 0.0167, 0.0364]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 78
images/455
(64, 64, 3)
tensor([[0.0326, 0.0437, 0.0164, 0.0221, 0.0272, 0.0219, 0.0323, 0.0172, 0.0170,
         0.0194, 0.0220, 0.0473, 0.0432, 0.0295, 0.0245, 0.0170, 0.0201, 0.0328,
         0.0305, 0.0218, 0.0174, 0.0268, 0.0139, 0.0255, 0.0142, 0.0171, 0.0285,
         0.0209, 0.0356, 0.0222, 0.0190, 0.0164, 0.0201, 0.0203, 0.0158, 0.0363,
         0.0418, 0.0231, 0.0211, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/29
(64, 64, 3)
tensor([[0.0269, 0.0222, 0.0128, 0.0149, 0.0420, 0.0189, 0.0312, 0.0172, 0.0235,
         0.0226, 0.0199, 0.0353, 0.0475, 0.0277, 0.0356, 0.0238, 0.0201, 0.0346,
         0.0230, 0.0237, 0.0152, 0.0356, 0.0180, 0.0190, 0.0219, 0.0171, 0.0227,
         0.0459, 0.0295, 0.0236, 0.0233, 0.0166, 0.0199, 0.0243, 0.0262, 0.0267,
         0.0195, 0.0271, 0.0192, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 80
images/326
(64, 64, 3)
tensor([[0.0288, 0.0212, 0.0252, 0.0280, 0.0418, 0.0139, 0.0311, 0.0163, 0.0224,
         0.0191, 0.0151, 0.0423, 0.0270, 0.0241, 0.0405, 0.0162, 0.0165, 0.0292,
         0.0175, 0.0220, 0.0230, 0.0338, 0.0174, 0.0143, 0.0265, 0.0161, 0.0267,
         0.0340, 0.0344, 0.0207, 0.0163, 0.0274, 0.0244, 0.0362, 0.0273, 0.0228,
         0.0259, 0.0232, 0.0250, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 81
images/298
(64, 64, 3)
tensor([[0.0240, 0.0189, 0.0207, 0.0221, 0.0259, 0.0199, 0.0273, 0.0239, 0.0198,
         0.0260, 0.0183, 0.0369, 0.0293, 0.0205, 0.0203, 0.0213, 0.0176, 0.0341,
         0.0187, 0.0324, 0.0182, 0.0361, 0.0209, 0.0217, 0.0196, 0.0215, 0.0306,
         0.0358, 0.0337, 0.0250, 0.0237, 0.0419, 0.0318, 0.0141, 0.0300, 0.0208,
         0.0220, 0.0307, 0.0246, 0.0196]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 82
images/513
(64, 64, 3)
tensor([[0.0274, 0.0312, 0.0214, 0.0150, 0.0406, 0.0212, 0.0230, 0.0166, 0.0167,
         0.0220, 0.0227, 0.0348, 0.0445, 0.0363, 0.0248, 0.0172, 0.0273, 0.0395,
         0.0213, 0.0141, 0.0223, 0.0261, 0.0248, 0.0238, 0.0204, 0.0330, 0.0280,
         0.0233, 0.0297, 0.0330, 0.0121, 0.0294, 0.0223, 0.0200, 0.0228, 0.0207,
         0.0381, 0.0222, 0.0137, 0.0168]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 83
images/283
(64, 64, 3)
tensor([[0.0361, 0.0465, 0.0153, 0.0229, 0.0281, 0.0176, 0.0321, 0.0122, 0.0124,
         0.0143, 0.0222, 0.0371, 0.0325, 0.0202, 0.0243, 0.0216, 0.0192, 0.0279,
         0.0144, 0.0205, 0.0220, 0.0250, 0.0203, 0.0212, 0.0193, 0.0346, 0.0226,
         0.0276, 0.0309, 0.0310, 0.0132, 0.0372, 0.0347, 0.0309, 0.0208, 0.0406,
         0.0362, 0.0184, 0.0146, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 84
images/593
(64, 64, 3)
tensor([[0.0431, 0.0246, 0.0192, 0.0158, 0.0231, 0.0256, 0.0297, 0.0247, 0.0215,
         0.0219, 0.0249, 0.0395, 0.0200, 0.0265, 0.0253, 0.0170, 0.0331, 0.0349,
         0.0194, 0.0179, 0.0148, 0.0357, 0.0169, 0.0309, 0.0203, 0.0173, 0.0199,
         0.0305, 0.0372, 0.0208, 0.0183, 0.0276, 0.0238, 0.0240, 0.0232, 0.0273,
         0.0271, 0.0175, 0.0310, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 85
images/433
(64, 64, 3)
tensor([[0.0321, 0.0324, 0.0120, 0.0417, 0.0294, 0.0207, 0.0314, 0.0117, 0.0127,
         0.0164, 0.0268, 0.0199, 0.0369, 0.0409, 0.0249, 0.0243, 0.0249, 0.0392,
         0.0160, 0.0197, 0.0165, 0.0179, 0.0161, 0.0169, 0.0185, 0.0196, 0.0342,
         0.0316, 0.0271, 0.0227, 0.0158, 0.0368, 0.0223, 0.0283, 0.0262, 0.0345,
         0.0260, 0.0224, 0.0162, 0.0366]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 86
images/572
(64, 64, 3)
tensor([[0.0267, 0.0255, 0.0148, 0.0123, 0.0264, 0.0158, 0.0348, 0.0187, 0.0142,
         0.0184, 0.0203, 0.0379, 0.0332, 0.0272, 0.0302, 0.0173, 0.0289, 0.0345,
         0.0195, 0.0140, 0.0183, 0.0258, 0.0204, 0.0253, 0.0254, 0.0250, 0.0321,
         0.0338, 0.0337, 0.0250, 0.0148, 0.0388, 0.0305, 0.0219, 0.0308, 0.0221,
         0.0417, 0.0232, 0.0214, 0.0196]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 87
images/267
(64, 64, 3)
tensor([[0.0236, 0.0236, 0.0122, 0.0155, 0.0316, 0.0218, 0.0381, 0.0198, 0.0156,
         0.0162, 0.0189, 0.0395, 0.0401, 0.0271, 0.0272, 0.0187, 0.0177, 0.0325,
         0.0153, 0.0266, 0.0136, 0.0431, 0.0233, 0.0230, 0.0214, 0.0171, 0.0213,
         0.0251, 0.0252, 0.0323, 0.0158, 0.0348, 0.0358, 0.0249, 0.0326, 0.0333,
         0.0233, 0.0211, 0.0279, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 88
images/147
(64, 64, 3)
tensor([[0.0364, 0.0254, 0.0159, 0.0150, 0.0280, 0.0202, 0.0425, 0.0207, 0.0148,
         0.0151, 0.0322, 0.0279, 0.0465, 0.0294, 0.0183, 0.0165, 0.0222, 0.0331,
         0.0265, 0.0235, 0.0157, 0.0184, 0.0200, 0.0270, 0.0159, 0.0214, 0.0273,
         0.0226, 0.0505, 0.0191, 0.0241, 0.0267, 0.0164, 0.0219, 0.0295, 0.0402,
         0.0327, 0.0123, 0.0238, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/518
(64, 64, 3)
tensor([[0.0298, 0.0270, 0.0171, 0.0229, 0.0453, 0.0190, 0.0273, 0.0186, 0.0184,
         0.0241, 0.0096, 0.0191, 0.0686, 0.0373, 0.0278, 0.0206, 0.0124, 0.0335,
         0.0227, 0.0182, 0.0382, 0.0172, 0.0227, 0.0166, 0.0207, 0.0150, 0.0335,
         0.0355, 0.0207, 0.0180, 0.0128, 0.0293, 0.0241, 0.0380, 0.0292, 0.0232,
         0.0254, 0.0177, 0.0171, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 90
images/415
(64, 64, 3)
tensor([[0.0283, 0.0256, 0.0210, 0.0331, 0.0324, 0.0378, 0.0320, 0.0135, 0.0192,
         0.0193, 0.0186, 0.0367, 0.0356, 0.0298, 0.0366, 0.0298, 0.0147, 0.0227,
         0.0182, 0.0252, 0.0184, 0.0245, 0.0261, 0.0247, 0.0204, 0.0153, 0.0320,
         0.0343, 0.0299, 0.0245, 0.0153, 0.0138, 0.0219, 0.0185, 0.0268, 0.0356,
         0.0211, 0.0199, 0.0246, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 91
images/179
(64, 64, 3)
tensor([[0.0248, 0.0251, 0.0270, 0.0226, 0.0250, 0.0306, 0.0320, 0.0248, 0.0202,
         0.0239, 0.0197, 0.0353, 0.0270, 0.0238, 0.0210, 0.0298, 0.0167, 0.0231,
         0.0172, 0.0248, 0.0196, 0.0188, 0.0264, 0.0238, 0.0180, 0.0220, 0.0261,
         0.0436, 0.0244, 0.0343, 0.0216, 0.0469, 0.0212, 0.0264, 0.0206, 0.0305,
         0.0144, 0.0152, 0.0229, 0.0291]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 92
images/370
(64, 64, 3)
tensor([[0.0163, 0.0301, 0.0249, 0.0163, 0.0299, 0.0309, 0.0206, 0.0228, 0.0268,
         0.0298, 0.0141, 0.0206, 0.0699, 0.0303, 0.0222, 0.0150, 0.0240, 0.0416,
         0.0232, 0.0201, 0.0179, 0.0201, 0.0149, 0.0242, 0.0236, 0.0114, 0.0256,
         0.0299, 0.0501, 0.0200, 0.0218, 0.0233, 0.0231, 0.0342, 0.0303, 0.0236,
         0.0179, 0.0230, 0.0175, 0.0180]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 93
images/165
(64, 64, 3)
tensor([[0.0325, 0.0396, 0.0137, 0.0333, 0.0175, 0.0237, 0.0224, 0.0141, 0.0173,
         0.0309, 0.0227, 0.0237, 0.0549, 0.0275, 0.0283, 0.0223, 0.0161, 0.0373,
         0.0182, 0.0194, 0.0122, 0.0235, 0.0254, 0.0170, 0.0255, 0.0183, 0.0353,
         0.0241, 0.0292, 0.0343, 0.0292, 0.0171, 0.0210, 0.0247, 0.0258, 0.0246,
         0.0342, 0.0216, 0.0209, 0.0207]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 94
images/431
(64, 64, 3)
tensor([[0.0329, 0.0292, 0.0170, 0.0255, 0.0312, 0.0340, 0.0291, 0.0101, 0.0249,
         0.0237, 0.0169, 0.0271, 0.0478, 0.0353, 0.0150, 0.0154, 0.0210, 0.0232,
         0.0193, 0.0220, 0.0189, 0.0270, 0.0208, 0.0175, 0.0191, 0.0204, 0.0273,
         0.0445, 0.0329, 0.0239, 0.0117, 0.0235, 0.0369, 0.0166, 0.0157, 0.0355,
         0.0284, 0.0294, 0.0251, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 95
images/28
(64, 64, 3)
tensor([[0.0298, 0.0318, 0.0141, 0.0188, 0.0274, 0.0197, 0.0336, 0.0140, 0.0208,
         0.0167, 0.0145, 0.0267, 0.0650, 0.0286, 0.0204, 0.0164, 0.0167, 0.0241,
         0.0232, 0.0188, 0.0261, 0.0351, 0.0221, 0.0163, 0.0311, 0.0182, 0.0300,
         0.0221, 0.0335, 0.0223, 0.0103, 0.0397, 0.0312, 0.0225, 0.0146, 0.0326,
         0.0298, 0.0181, 0.0285, 0.0346]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 96
images/423
(64, 64, 3)
tensor([[0.0206, 0.0199, 0.0220, 0.0169, 0.0364, 0.0223, 0.0435, 0.0247, 0.0165,
         0.0209, 0.0237, 0.0354, 0.0254, 0.0303, 0.0300, 0.0205, 0.0132, 0.0587,
         0.0241, 0.0250, 0.0163, 0.0209, 0.0132, 0.0195, 0.0229, 0.0210, 0.0196,
         0.0369, 0.0253, 0.0197, 0.0271, 0.0367, 0.0168, 0.0267, 0.0279, 0.0311,
         0.0191, 0.0173, 0.0253, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 97
images/121
(64, 64, 3)
tensor([[0.0211, 0.0209, 0.0134, 0.0234, 0.0341, 0.0198, 0.0487, 0.0235, 0.0132,
         0.0162, 0.0358, 0.0339, 0.0294, 0.0317, 0.0311, 0.0144, 0.0146, 0.0347,
         0.0382, 0.0178, 0.0132, 0.0193, 0.0206, 0.0236, 0.0198, 0.0246, 0.0233,
         0.0324, 0.0333, 0.0179, 0.0186, 0.0247, 0.0346, 0.0254, 0.0229, 0.0288,
         0.0336, 0.0226, 0.0214, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 98
images/446
(64, 64, 3)
tensor([[0.0356, 0.0249, 0.0175, 0.0117, 0.0260, 0.0146, 0.0328, 0.0168, 0.0150,
         0.0156, 0.0222, 0.0263, 0.0407, 0.0470, 0.0350, 0.0187, 0.0163, 0.0345,
         0.0312, 0.0171, 0.0150, 0.0280, 0.0210, 0.0155, 0.0209, 0.0204, 0.0323,
         0.0405, 0.0273, 0.0220, 0.0128, 0.0289, 0.0285, 0.0309, 0.0267, 0.0381,
         0.0258, 0.0170, 0.0182, 0.0307]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 99
images/400
(64, 64, 3)
tensor([[0.0350, 0.0304, 0.0162, 0.0198, 0.0375, 0.0195, 0.0301, 0.0139, 0.0181,
         0.0113, 0.0153, 0.0350, 0.0481, 0.0298, 0.0278, 0.0161, 0.0227, 0.0460,
         0.0185, 0.0218, 0.0259, 0.0186, 0.0212, 0.0259, 0.0214, 0.0197, 0.0324,
         0.0271, 0.0270, 0.0236, 0.0213, 0.0342, 0.0254, 0.0257, 0.0240, 0.0331,
         0.0175, 0.0162, 0.0237, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Saving the weights
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/363
(64, 64, 3)
2018-10-12 16:42:38.376 Python[6406:15646368] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0287, 0.0185, 0.0222, 0.0246, 0.0368, 0.0199, 0.0238, 0.0160, 0.0189,
         0.0163, 0.0148, 0.0240, 0.0271, 0.0307, 0.0384, 0.0221, 0.0168, 0.0275,
         0.0153, 0.0217, 0.0131, 0.0227, 0.0396, 0.0205, 0.0319, 0.0327, 0.0222,
         0.0304, 0.0342, 0.0236, 0.0206, 0.0274, 0.0235, 0.0184, 0.0228, 0.0374,
         0.0408, 0.0317, 0.0207, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Reward should be either 0 or 1
 Please enter a reward
Enter Reward Again: 0
Session Number: 1
images/192
(64, 64, 3)
tensor([[0.0279, 0.0218, 0.0242, 0.0198, 0.0338, 0.0214, 0.0288, 0.0202, 0.0189,
         0.0216, 0.0203, 0.0369, 0.0248, 0.0327, 0.0217, 0.0173, 0.0236, 0.0405,
         0.0141, 0.0311, 0.0186, 0.0268, 0.0179, 0.0327, 0.0178, 0.0213, 0.0192,
         0.0310, 0.0379, 0.0189, 0.0155, 0.0342, 0.0231, 0.0205, 0.0225, 0.0303,
         0.0465, 0.0230, 0.0226, 0.0182]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Reward should be either 0 or 1
 Please enter a reward
Enter Reward Again: 0
Session Number: 2
images/296
(64, 64, 3)
tensor([[0.0370, 0.0300, 0.0186, 0.0192, 0.0407, 0.0205, 0.0295, 0.0133, 0.0152,
         0.0158, 0.0203, 0.0278, 0.0365, 0.0378, 0.0305, 0.0164, 0.0294, 0.0367,
         0.0198, 0.0156, 0.0164, 0.0263, 0.0268, 0.0238, 0.0161, 0.0171, 0.0293,
         0.0185, 0.0311, 0.0191, 0.0388, 0.0256, 0.0246, 0.0259, 0.0256, 0.0342,
         0.0223, 0.0216, 0.0291, 0.0172]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Reward should be either 0 or 1
 Please enter a reward
Enter Reward Again: -1
Breaking
Saving the weights
0 number of +1 rewards in 2 images
Saving the weights
0 number of +1 rewards in 2 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
  File "Torch_reinforce01.py", line 146
    if reward==1:
                ^
SyntaxError: invalid syntax
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/439
(64, 64, 3)
2018-10-12 22:07:35.378 Python[7017:15663059] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0300, 0.0203, 0.0201, 0.0224, 0.0312, 0.0244, 0.0298, 0.0173, 0.0164,
         0.0169, 0.0167, 0.0229, 0.0411, 0.0348, 0.0325, 0.0245, 0.0179, 0.0288,
         0.0138, 0.0229, 0.0145, 0.0198, 0.0256, 0.0277, 0.0373, 0.0221, 0.0145,
         0.0201, 0.0249, 0.0232, 0.0196, 0.0459, 0.0205, 0.0184, 0.0208, 0.0458,
         0.0426, 0.0239, 0.0293, 0.0186]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 1
images/59
(64, 64, 3)
tensor([[0.0260, 0.0241, 0.0235, 0.0154, 0.0356, 0.0146, 0.0303, 0.0121, 0.0126,
         0.0169, 0.0218, 0.0255, 0.0192, 0.0340, 0.0247, 0.0152, 0.0265, 0.0429,
         0.0184, 0.0273, 0.0139, 0.0312, 0.0169, 0.0261, 0.0301, 0.0166, 0.0152,
         0.0451, 0.0309, 0.0219, 0.0132, 0.0409, 0.0258, 0.0238, 0.0196, 0.0341,
         0.0548, 0.0225, 0.0208, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/274
(64, 64, 3)
tensor([[0.0355, 0.0295, 0.0172, 0.0246, 0.0522, 0.0291, 0.0219, 0.0122, 0.0128,
         0.0274, 0.0315, 0.0280, 0.0292, 0.0425, 0.0216, 0.0234, 0.0279, 0.0405,
         0.0172, 0.0182, 0.0197, 0.0175, 0.0258, 0.0260, 0.0213, 0.0228, 0.0245,
         0.0243, 0.0380, 0.0201, 0.0214, 0.0252, 0.0284, 0.0227, 0.0214, 0.0252,
         0.0223, 0.0167, 0.0184, 0.0161]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 3
images/240
(64, 64, 3)
tensor([[0.0293, 0.0252, 0.0211, 0.0231, 0.0344, 0.0151, 0.0400, 0.0156, 0.0254,
         0.0200, 0.0216, 0.0249, 0.0316, 0.0388, 0.0267, 0.0241, 0.0183, 0.0433,
         0.0134, 0.0278, 0.0163, 0.0247, 0.0194, 0.0184, 0.0223, 0.0122, 0.0259,
         0.0418, 0.0359, 0.0210, 0.0200, 0.0168, 0.0279, 0.0314, 0.0292, 0.0267,
         0.0171, 0.0278, 0.0258, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 4
images/112
(64, 64, 3)
tensor([[0.0169, 0.0326, 0.0185, 0.0143, 0.0477, 0.0185, 0.0268, 0.0170, 0.0183,
         0.0182, 0.0189, 0.0423, 0.0301, 0.0339, 0.0294, 0.0184, 0.0253, 0.0490,
         0.0149, 0.0198, 0.0170, 0.0187, 0.0225, 0.0206, 0.0243, 0.0234, 0.0403,
         0.0249, 0.0282, 0.0258, 0.0124, 0.0395, 0.0278, 0.0300, 0.0262, 0.0234,
         0.0215, 0.0214, 0.0162, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 5
images/582
(64, 64, 3)
tensor([[0.0194, 0.0276, 0.0186, 0.0178, 0.0189, 0.0248, 0.0408, 0.0190, 0.0162,
         0.0286, 0.0219, 0.0283, 0.0364, 0.0401, 0.0210, 0.0301, 0.0248, 0.0389,
         0.0140, 0.0235, 0.0134, 0.0163, 0.0247, 0.0257, 0.0155, 0.0185, 0.0217,
         0.0370, 0.0292, 0.0343, 0.0183, 0.0286, 0.0247, 0.0290, 0.0280, 0.0340,
         0.0201, 0.0168, 0.0196, 0.0339]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 6
images/517
(64, 64, 3)
tensor([[0.0404, 0.0326, 0.0179, 0.0126, 0.0270, 0.0216, 0.0264, 0.0222, 0.0191,
         0.0242, 0.0224, 0.0317, 0.0318, 0.0218, 0.0250, 0.0198, 0.0237, 0.0415,
         0.0138, 0.0251, 0.0147, 0.0301, 0.0232, 0.0321, 0.0202, 0.0191, 0.0197,
         0.0343, 0.0393, 0.0248, 0.0304, 0.0331, 0.0201, 0.0192, 0.0169, 0.0319,
         0.0194, 0.0184, 0.0323, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 7
images/485
(64, 64, 3)
tensor([[0.0312, 0.0259, 0.0203, 0.0131, 0.0287, 0.0187, 0.0219, 0.0127, 0.0140,
         0.0123, 0.0250, 0.0267, 0.0451, 0.0362, 0.0310, 0.0301, 0.0227, 0.0309,
         0.0261, 0.0249, 0.0169, 0.0272, 0.0204, 0.0273, 0.0252, 0.0198, 0.0380,
         0.0341, 0.0411, 0.0251, 0.0230, 0.0223, 0.0224, 0.0301, 0.0189, 0.0226,
         0.0275, 0.0179, 0.0166, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 8
images/53
(64, 64, 3)
tensor([[0.0221, 0.0268, 0.0112, 0.0221, 0.0230, 0.0227, 0.0247, 0.0147, 0.0219,
         0.0277, 0.0145, 0.0293, 0.0496, 0.0240, 0.0305, 0.0229, 0.0263, 0.0300,
         0.0179, 0.0209, 0.0113, 0.0183, 0.0259, 0.0242, 0.0154, 0.0283, 0.0251,
         0.0391, 0.0486, 0.0244, 0.0151, 0.0314, 0.0268, 0.0285, 0.0356, 0.0196,
         0.0290, 0.0234, 0.0188, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 9
images/368
(64, 64, 3)
tensor([[0.0347, 0.0391, 0.0094, 0.0155, 0.0331, 0.0278, 0.0495, 0.0144, 0.0191,
         0.0288, 0.0210, 0.0290, 0.0299, 0.0325, 0.0222, 0.0197, 0.0272, 0.0355,
         0.0167, 0.0103, 0.0153, 0.0199, 0.0160, 0.0184, 0.0217, 0.0226, 0.0320,
         0.0223, 0.0461, 0.0238, 0.0181, 0.0227, 0.0256, 0.0214, 0.0166, 0.0596,
         0.0185, 0.0172, 0.0222, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 10
images/133
(64, 64, 3)
tensor([[0.0177, 0.0161, 0.0285, 0.0126, 0.0377, 0.0175, 0.0333, 0.0183, 0.0218,
         0.0213, 0.0183, 0.0283, 0.0375, 0.0304, 0.0239, 0.0141, 0.0202, 0.0262,
         0.0201, 0.0256, 0.0120, 0.0160, 0.0236, 0.0190, 0.0200, 0.0178, 0.0458,
         0.0300, 0.0354, 0.0189, 0.0297, 0.0326, 0.0260, 0.0261, 0.0272, 0.0365,
         0.0343, 0.0179, 0.0274, 0.0343]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 11
images/508
(64, 64, 3)
tensor([[0.0183, 0.0252, 0.0249, 0.0184, 0.0351, 0.0280, 0.0231, 0.0175, 0.0260,
         0.0237, 0.0092, 0.0385, 0.0253, 0.0295, 0.0189, 0.0198, 0.0150, 0.0516,
         0.0127, 0.0188, 0.0139, 0.0259, 0.0280, 0.0321, 0.0245, 0.0162, 0.0226,
         0.0346, 0.0438, 0.0262, 0.0142, 0.0322, 0.0332, 0.0184, 0.0176, 0.0245,
         0.0349, 0.0293, 0.0214, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/553
(64, 64, 3)
tensor([[0.0366, 0.0331, 0.0162, 0.0202, 0.0360, 0.0238, 0.0332, 0.0151, 0.0223,
         0.0178, 0.0210, 0.0250, 0.0321, 0.0522, 0.0247, 0.0245, 0.0221, 0.0455,
         0.0186, 0.0177, 0.0241, 0.0283, 0.0209, 0.0208, 0.0208, 0.0207, 0.0255,
         0.0237, 0.0412, 0.0186, 0.0102, 0.0326, 0.0193, 0.0163, 0.0276, 0.0213,
         0.0216, 0.0265, 0.0187, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 13
images/296
(64, 64, 3)
tensor([[0.0239, 0.0239, 0.0203, 0.0141, 0.0341, 0.0449, 0.0462, 0.0219, 0.0110,
         0.0177, 0.0236, 0.0202, 0.0392, 0.0346, 0.0199, 0.0242, 0.0136, 0.0233,
         0.0175, 0.0233, 0.0168, 0.0282, 0.0175, 0.0224, 0.0219, 0.0184, 0.0226,
         0.0369, 0.0297, 0.0142, 0.0220, 0.0265, 0.0333, 0.0148, 0.0376, 0.0270,
         0.0284, 0.0168, 0.0307, 0.0371]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 14
images/543
(64, 64, 3)
tensor([[0.0399, 0.0257, 0.0120, 0.0150, 0.0194, 0.0194, 0.0235, 0.0221, 0.0122,
         0.0199, 0.0229, 0.0202, 0.0468, 0.0284, 0.0247, 0.0190, 0.0243, 0.0540,
         0.0157, 0.0198, 0.0171, 0.0225, 0.0266, 0.0162, 0.0201, 0.0234, 0.0354,
         0.0259, 0.0316, 0.0311, 0.0148, 0.0450, 0.0418, 0.0169, 0.0133, 0.0245,
         0.0244, 0.0178, 0.0348, 0.0316]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 15
images/150
(64, 64, 3)
tensor([[0.0330, 0.0215, 0.0170, 0.0135, 0.0361, 0.0226, 0.0314, 0.0180, 0.0216,
         0.0241, 0.0174, 0.0371, 0.0266, 0.0356, 0.0394, 0.0234, 0.0152, 0.0309,
         0.0189, 0.0265, 0.0178, 0.0351, 0.0165, 0.0213, 0.0247, 0.0131, 0.0246,
         0.0265, 0.0242, 0.0330, 0.0237, 0.0328, 0.0307, 0.0120, 0.0148, 0.0238,
         0.0342, 0.0156, 0.0368, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/294
(64, 64, 3)
tensor([[0.0254, 0.0273, 0.0141, 0.0179, 0.0469, 0.0143, 0.0454, 0.0186, 0.0202,
         0.0243, 0.0221, 0.0162, 0.0367, 0.0272, 0.0227, 0.0142, 0.0200, 0.0433,
         0.0218, 0.0275, 0.0161, 0.0230, 0.0147, 0.0241, 0.0223, 0.0282, 0.0291,
         0.0388, 0.0293, 0.0278, 0.0217, 0.0339, 0.0241, 0.0159, 0.0216, 0.0367,
         0.0227, 0.0215, 0.0271, 0.0153]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 17
images/426
(64, 64, 3)
tensor([[0.0295, 0.0252, 0.0241, 0.0156, 0.0304, 0.0168, 0.0397, 0.0267, 0.0250,
         0.0259, 0.0193, 0.0311, 0.0457, 0.0367, 0.0219, 0.0176, 0.0168, 0.0561,
         0.0206, 0.0142, 0.0135, 0.0221, 0.0176, 0.0215, 0.0191, 0.0192, 0.0219,
         0.0251, 0.0320, 0.0321, 0.0141, 0.0309, 0.0210, 0.0190, 0.0246, 0.0214,
         0.0324, 0.0205, 0.0290, 0.0240]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 18
images/504
(64, 64, 3)
tensor([[0.0175, 0.0230, 0.0181, 0.0217, 0.0349, 0.0167, 0.0325, 0.0164, 0.0188,
         0.0202, 0.0157, 0.0228, 0.0533, 0.0264, 0.0196, 0.0177, 0.0266, 0.0314,
         0.0237, 0.0208, 0.0201, 0.0221, 0.0151, 0.0149, 0.0189, 0.0150, 0.0305,
         0.0365, 0.0356, 0.0222, 0.0197, 0.0292, 0.0259, 0.0306, 0.0285, 0.0365,
         0.0467, 0.0226, 0.0191, 0.0328]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 19
images/365
(64, 64, 3)
tensor([[0.0313, 0.0171, 0.0240, 0.0192, 0.0331, 0.0189, 0.0336, 0.0130, 0.0158,
         0.0186, 0.0137, 0.0273, 0.0399, 0.0332, 0.0238, 0.0140, 0.0193, 0.0466,
         0.0251, 0.0194, 0.0253, 0.0146, 0.0178, 0.0155, 0.0171, 0.0191, 0.0237,
         0.0338, 0.0334, 0.0310, 0.0247, 0.0364, 0.0267, 0.0308, 0.0301, 0.0327,
         0.0324, 0.0162, 0.0280, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 20
images/570
(64, 64, 3)
tensor([[0.0184, 0.0206, 0.0196, 0.0226, 0.0484, 0.0222, 0.0397, 0.0150, 0.0153,
         0.0168, 0.0199, 0.0276, 0.0449, 0.0302, 0.0240, 0.0263, 0.0166, 0.0336,
         0.0209, 0.0275, 0.0190, 0.0150, 0.0181, 0.0198, 0.0228, 0.0248, 0.0266,
         0.0241, 0.0335, 0.0210, 0.0242, 0.0237, 0.0162, 0.0203, 0.0355, 0.0354,
         0.0273, 0.0266, 0.0232, 0.0327]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 21
images/296
(64, 64, 3)
tensor([[0.0273, 0.0334, 0.0213, 0.0166, 0.0298, 0.0203, 0.0310, 0.0165, 0.0164,
         0.0128, 0.0156, 0.0251, 0.0475, 0.0306, 0.0197, 0.0170, 0.0264, 0.0284,
         0.0228, 0.0158, 0.0116, 0.0192, 0.0187, 0.0272, 0.0206, 0.0256, 0.0293,
         0.0284, 0.0412, 0.0143, 0.0408, 0.0278, 0.0222, 0.0238, 0.0231, 0.0371,
         0.0280, 0.0247, 0.0353, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 22
images/587
(64, 64, 3)
tensor([[0.0249, 0.0288, 0.0167, 0.0214, 0.0260, 0.0180, 0.0445, 0.0180, 0.0181,
         0.0255, 0.0177, 0.0247, 0.0394, 0.0299, 0.0135, 0.0137, 0.0259, 0.0496,
         0.0184, 0.0205, 0.0191, 0.0219, 0.0246, 0.0251, 0.0188, 0.0154, 0.0184,
         0.0272, 0.0476, 0.0226, 0.0161, 0.0342, 0.0199, 0.0385, 0.0305, 0.0420,
         0.0146, 0.0163, 0.0230, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 23
images/50
(64, 64, 3)
tensor([[0.0196, 0.0251, 0.0230, 0.0157, 0.0348, 0.0273, 0.0315, 0.0192, 0.0229,
         0.0341, 0.0144, 0.0341, 0.0314, 0.0263, 0.0279, 0.0158, 0.0215, 0.0243,
         0.0257, 0.0219, 0.0145, 0.0197, 0.0284, 0.0247, 0.0173, 0.0269, 0.0302,
         0.0261, 0.0258, 0.0291, 0.0239, 0.0309, 0.0234, 0.0301, 0.0330, 0.0261,
         0.0214, 0.0229, 0.0181, 0.0309]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 24
images/357
(64, 64, 3)
tensor([[0.0266, 0.0234, 0.0132, 0.0181, 0.0394, 0.0184, 0.0308, 0.0150, 0.0208,
         0.0297, 0.0190, 0.0315, 0.0289, 0.0262, 0.0199, 0.0189, 0.0200, 0.0284,
         0.0153, 0.0144, 0.0213, 0.0246, 0.0199, 0.0256, 0.0221, 0.0407, 0.0186,
         0.0391, 0.0412, 0.0249, 0.0240, 0.0472, 0.0330, 0.0213, 0.0244, 0.0305,
         0.0208, 0.0219, 0.0178, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/494
(64, 64, 3)
tensor([[0.0368, 0.0262, 0.0130, 0.0158, 0.0185, 0.0224, 0.0274, 0.0201, 0.0130,
         0.0174, 0.0239, 0.0234, 0.0567, 0.0357, 0.0170, 0.0241, 0.0211, 0.0413,
         0.0191, 0.0164, 0.0187, 0.0276, 0.0381, 0.0326, 0.0233, 0.0237, 0.0226,
         0.0377, 0.0226, 0.0428, 0.0120, 0.0386, 0.0234, 0.0147, 0.0132, 0.0311,
         0.0254, 0.0177, 0.0279, 0.0172]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 26
images/509
(64, 64, 3)
tensor([[0.0223, 0.0312, 0.0171, 0.0197, 0.0402, 0.0114, 0.0341, 0.0178, 0.0195,
         0.0257, 0.0119, 0.0325, 0.0220, 0.0389, 0.0324, 0.0250, 0.0146, 0.0331,
         0.0154, 0.0260, 0.0220, 0.0388, 0.0275, 0.0177, 0.0175, 0.0147, 0.0211,
         0.0414, 0.0366, 0.0310, 0.0219, 0.0162, 0.0265, 0.0348, 0.0140, 0.0318,
         0.0257, 0.0151, 0.0183, 0.0367]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 27
images/563
(64, 64, 3)
tensor([[0.0262, 0.0224, 0.0162, 0.0185, 0.0258, 0.0183, 0.0244, 0.0114, 0.0216,
         0.0150, 0.0189, 0.0214, 0.0442, 0.0343, 0.0303, 0.0233, 0.0418, 0.0395,
         0.0182, 0.0301, 0.0211, 0.0215, 0.0237, 0.0151, 0.0190, 0.0249, 0.0326,
         0.0255, 0.0334, 0.0243, 0.0149, 0.0247, 0.0183, 0.0242, 0.0273, 0.0412,
         0.0321, 0.0294, 0.0194, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 0
Session Number: 28
images/144
(64, 64, 3)
tensor([[0.0418, 0.0264, 0.0216, 0.0192, 0.0345, 0.0198, 0.0372, 0.0133, 0.0141,
         0.0220, 0.0246, 0.0251, 0.0563, 0.0339, 0.0199, 0.0131, 0.0126, 0.0347,
         0.0255, 0.0159, 0.0166, 0.0137, 0.0359, 0.0264, 0.0135, 0.0153, 0.0234,
         0.0240, 0.0241, 0.0281, 0.0231, 0.0327, 0.0186, 0.0317, 0.0296, 0.0422,
         0.0320, 0.0215, 0.0186, 0.0174]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 29
images/462
(64, 64, 3)
tensor([[0.0314, 0.0169, 0.0286, 0.0257, 0.0344, 0.0243, 0.0333, 0.0180, 0.0213,
         0.0197, 0.0197, 0.0345, 0.0344, 0.0230, 0.0199, 0.0252, 0.0150, 0.0356,
         0.0151, 0.0195, 0.0232, 0.0203, 0.0392, 0.0180, 0.0241, 0.0153, 0.0260,
         0.0280, 0.0231, 0.0204, 0.0270, 0.0409, 0.0287, 0.0273, 0.0232, 0.0363,
         0.0235, 0.0139, 0.0184, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 30
images/589
(64, 64, 3)
tensor([[0.0298, 0.0302, 0.0110, 0.0177, 0.0354, 0.0182, 0.0297, 0.0188, 0.0176,
         0.0168, 0.0189, 0.0356, 0.0260, 0.0333, 0.0208, 0.0148, 0.0155, 0.0379,
         0.0208, 0.0299, 0.0262, 0.0356, 0.0194, 0.0200, 0.0354, 0.0239, 0.0179,
         0.0439, 0.0282, 0.0239, 0.0200, 0.0384, 0.0196, 0.0245, 0.0237, 0.0326,
         0.0370, 0.0183, 0.0154, 0.0176]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 31
images/391
(64, 64, 3)
tensor([[0.0229, 0.0252, 0.0246, 0.0139, 0.0287, 0.0234, 0.0433, 0.0204, 0.0164,
         0.0173, 0.0249, 0.0571, 0.0208, 0.0301, 0.0204, 0.0131, 0.0201, 0.0434,
         0.0136, 0.0287, 0.0169, 0.0256, 0.0208, 0.0193, 0.0185, 0.0139, 0.0227,
         0.0289, 0.0548, 0.0183, 0.0154, 0.0292, 0.0360, 0.0208, 0.0178, 0.0258,
         0.0260, 0.0309, 0.0163, 0.0334]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 32
images/303
(64, 64, 3)
tensor([[0.0238, 0.0361, 0.0180, 0.0189, 0.0284, 0.0219, 0.0346, 0.0138, 0.0155,
         0.0237, 0.0192, 0.0196, 0.0321, 0.0217, 0.0482, 0.0260, 0.0367, 0.0369,
         0.0321, 0.0235, 0.0138, 0.0284, 0.0185, 0.0266, 0.0223, 0.0237, 0.0278,
         0.0211, 0.0236, 0.0302, 0.0173, 0.0205, 0.0208, 0.0315, 0.0216, 0.0257,
         0.0235, 0.0286, 0.0217, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 33
images/267
(64, 64, 3)
tensor([[0.0314, 0.0214, 0.0185, 0.0208, 0.0318, 0.0210, 0.0478, 0.0158, 0.0158,
         0.0182, 0.0196, 0.0280, 0.0333, 0.0326, 0.0231, 0.0107, 0.0175, 0.0326,
         0.0335, 0.0253, 0.0211, 0.0268, 0.0225, 0.0171, 0.0363, 0.0188, 0.0181,
         0.0297, 0.0261, 0.0255, 0.0188, 0.0327, 0.0369, 0.0289, 0.0206, 0.0268,
         0.0321, 0.0146, 0.0246, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 34
images/100
(64, 64, 3)
tensor([[0.0403, 0.0335, 0.0230, 0.0211, 0.0240, 0.0136, 0.0256, 0.0144, 0.0158,
         0.0347, 0.0189, 0.0311, 0.0241, 0.0220, 0.0290, 0.0152, 0.0209, 0.0329,
         0.0174, 0.0161, 0.0187, 0.0370, 0.0141, 0.0252, 0.0246, 0.0139, 0.0201,
         0.0459, 0.0412, 0.0296, 0.0137, 0.0315, 0.0265, 0.0244, 0.0197, 0.0269,
         0.0453, 0.0171, 0.0223, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 35
images/464
(64, 64, 3)
tensor([[0.0309, 0.0307, 0.0204, 0.0110, 0.0228, 0.0243, 0.0363, 0.0188, 0.0195,
         0.0200, 0.0164, 0.0230, 0.0467, 0.0439, 0.0196, 0.0214, 0.0248, 0.0519,
         0.0151, 0.0166, 0.0162, 0.0183, 0.0197, 0.0238, 0.0183, 0.0177, 0.0223,
         0.0279, 0.0524, 0.0256, 0.0193, 0.0190, 0.0329, 0.0262, 0.0245, 0.0319,
         0.0272, 0.0164, 0.0205, 0.0258]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 36
images/57
(64, 64, 3)
tensor([[0.0282, 0.0230, 0.0173, 0.0250, 0.0323, 0.0223, 0.0441, 0.0298, 0.0159,
         0.0150, 0.0233, 0.0243, 0.0371, 0.0407, 0.0285, 0.0113, 0.0160, 0.0380,
         0.0167, 0.0252, 0.0153, 0.0226, 0.0199, 0.0148, 0.0181, 0.0215, 0.0190,
         0.0229, 0.0369, 0.0314, 0.0267, 0.0281, 0.0186, 0.0244, 0.0288, 0.0391,
         0.0317, 0.0207, 0.0278, 0.0179]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 37
images/158
(64, 64, 3)
tensor([[0.0186, 0.0322, 0.0171, 0.0191, 0.0300, 0.0190, 0.0350, 0.0111, 0.0184,
         0.0176, 0.0188, 0.0493, 0.0410, 0.0418, 0.0231, 0.0253, 0.0284, 0.0324,
         0.0159, 0.0180, 0.0204, 0.0239, 0.0177, 0.0157, 0.0192, 0.0170, 0.0200,
         0.0444, 0.0400, 0.0338, 0.0197, 0.0192, 0.0337, 0.0203, 0.0172, 0.0281,
         0.0257, 0.0153, 0.0183, 0.0381]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 38
images/387
(64, 64, 3)
tensor([[0.0241, 0.0257, 0.0322, 0.0123, 0.0293, 0.0203, 0.0355, 0.0232, 0.0115,
         0.0167, 0.0157, 0.0458, 0.0376, 0.0260, 0.0274, 0.0174, 0.0168, 0.0314,
         0.0289, 0.0216, 0.0200, 0.0201, 0.0135, 0.0321, 0.0240, 0.0197, 0.0186,
         0.0569, 0.0381, 0.0202, 0.0192, 0.0393, 0.0316, 0.0157, 0.0296, 0.0280,
         0.0219, 0.0176, 0.0126, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 39
images/551
(64, 64, 3)
tensor([[0.0409, 0.0210, 0.0189, 0.0200, 0.0384, 0.0223, 0.0285, 0.0204, 0.0143,
         0.0266, 0.0207, 0.0344, 0.0364, 0.0380, 0.0227, 0.0246, 0.0207, 0.0416,
         0.0187, 0.0180, 0.0186, 0.0163, 0.0277, 0.0275, 0.0295, 0.0199, 0.0196,
         0.0335, 0.0272, 0.0193, 0.0180, 0.0334, 0.0235, 0.0119, 0.0246, 0.0415,
         0.0266, 0.0100, 0.0216, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 40
images/575
(64, 64, 3)
tensor([[0.0344, 0.0406, 0.0107, 0.0195, 0.0333, 0.0269, 0.0398, 0.0128, 0.0135,
         0.0162, 0.0147, 0.0214, 0.0433, 0.0377, 0.0323, 0.0183, 0.0270, 0.0389,
         0.0232, 0.0222, 0.0243, 0.0239, 0.0234, 0.0251, 0.0183, 0.0211, 0.0267,
         0.0251, 0.0319, 0.0250, 0.0188, 0.0245, 0.0402, 0.0257, 0.0217, 0.0177,
         0.0225, 0.0175, 0.0170, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 41
images/301
(64, 64, 3)
tensor([[0.0257, 0.0253, 0.0124, 0.0234, 0.0383, 0.0145, 0.0408, 0.0130, 0.0211,
         0.0164, 0.0187, 0.0242, 0.0415, 0.0342, 0.0153, 0.0207, 0.0239, 0.0460,
         0.0174, 0.0109, 0.0261, 0.0152, 0.0149, 0.0213, 0.0243, 0.0290, 0.0365,
         0.0388, 0.0300, 0.0263, 0.0210, 0.0246, 0.0417, 0.0181, 0.0157, 0.0265,
         0.0320, 0.0131, 0.0249, 0.0360]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 1
Session Number: 42
images/223
(64, 64, 3)
tensor([[0.0303, 0.0319, 0.0136, 0.0270, 0.0265, 0.0170, 0.0225, 0.0195, 0.0300,
         0.0225, 0.0170, 0.0272, 0.0423, 0.0339, 0.0321, 0.0301, 0.0146, 0.0487,
         0.0150, 0.0185, 0.0220, 0.0216, 0.0169, 0.0174, 0.0184, 0.0137, 0.0464,
         0.0232, 0.0290, 0.0219, 0.0171, 0.0234, 0.0225, 0.0278, 0.0435, 0.0201,
         0.0304, 0.0167, 0.0205, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/388
(64, 64, 3)
tensor([[0.0363, 0.0133, 0.0214, 0.0172, 0.0309, 0.0208, 0.0314, 0.0190, 0.0118,
         0.0360, 0.0170, 0.0209, 0.0417, 0.0395, 0.0246, 0.0161, 0.0197, 0.0539,
         0.0256, 0.0246, 0.0124, 0.0234, 0.0239, 0.0183, 0.0177, 0.0195, 0.0378,
         0.0437, 0.0269, 0.0195, 0.0208, 0.0260, 0.0168, 0.0223, 0.0210, 0.0283,
         0.0217, 0.0196, 0.0393, 0.0195]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/399
(64, 64, 3)
tensor([[0.0306, 0.0393, 0.0166, 0.0197, 0.0267, 0.0250, 0.0312, 0.0161, 0.0186,
         0.0165, 0.0160, 0.0231, 0.0381, 0.0352, 0.0321, 0.0201, 0.0180, 0.0462,
         0.0166, 0.0203, 0.0162, 0.0270, 0.0195, 0.0237, 0.0209, 0.0204, 0.0267,
         0.0320, 0.0256, 0.0267, 0.0259, 0.0299, 0.0294, 0.0265, 0.0254, 0.0203,
         0.0237, 0.0319, 0.0177, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 45
images/506
(64, 64, 3)
tensor([[0.0348, 0.0291, 0.0163, 0.0199, 0.0177, 0.0191, 0.0190, 0.0291, 0.0227,
         0.0171, 0.0179, 0.0298, 0.0675, 0.0267, 0.0258, 0.0328, 0.0182, 0.0337,
         0.0210, 0.0269, 0.0160, 0.0210, 0.0189, 0.0326, 0.0169, 0.0120, 0.0288,
         0.0252, 0.0315, 0.0291, 0.0212, 0.0333, 0.0210, 0.0282, 0.0202, 0.0367,
         0.0214, 0.0199, 0.0174, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 46
images/67
(64, 64, 3)
tensor([[0.0270, 0.0277, 0.0137, 0.0183, 0.0317, 0.0191, 0.0306, 0.0259, 0.0197,
         0.0254, 0.0240, 0.0333, 0.0383, 0.0339, 0.0264, 0.0167, 0.0225, 0.0243,
         0.0246, 0.0298, 0.0191, 0.0192, 0.0244, 0.0236, 0.0162, 0.0198, 0.0286,
         0.0353, 0.0286, 0.0257, 0.0170, 0.0271, 0.0323, 0.0348, 0.0206, 0.0225,
         0.0206, 0.0204, 0.0238, 0.0274]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 47
images/169
(64, 64, 3)
tensor([[0.0275, 0.0175, 0.0151, 0.0148, 0.0245, 0.0159, 0.0300, 0.0235, 0.0249,
         0.0183, 0.0245, 0.0344, 0.0379, 0.0369, 0.0227, 0.0203, 0.0191, 0.0437,
         0.0134, 0.0181, 0.0143, 0.0210, 0.0190, 0.0156, 0.0238, 0.0247, 0.0199,
         0.0347, 0.0349, 0.0213, 0.0155, 0.0263, 0.0293, 0.0268, 0.0278, 0.0444,
         0.0304, 0.0224, 0.0173, 0.0477]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 48
images/285
(64, 64, 3)
tensor([[0.0270, 0.0192, 0.0141, 0.0148, 0.0389, 0.0203, 0.0332, 0.0171, 0.0164,
         0.0157, 0.0215, 0.0355, 0.0326, 0.0271, 0.0164, 0.0309, 0.0262, 0.0376,
         0.0243, 0.0268, 0.0124, 0.0288, 0.0179, 0.0192, 0.0269, 0.0225, 0.0258,
         0.0251, 0.0378, 0.0291, 0.0176, 0.0283, 0.0136, 0.0283, 0.0248, 0.0400,
         0.0339, 0.0164, 0.0201, 0.0357]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 49
images/581
(64, 64, 3)
tensor([[0.0309, 0.0224, 0.0201, 0.0235, 0.0264, 0.0240, 0.0377, 0.0146, 0.0184,
         0.0234, 0.0189, 0.0343, 0.0362, 0.0411, 0.0194, 0.0212, 0.0188, 0.0537,
         0.0193, 0.0291, 0.0169, 0.0231, 0.0142, 0.0186, 0.0245, 0.0233, 0.0188,
         0.0304, 0.0349, 0.0139, 0.0270, 0.0229, 0.0366, 0.0173, 0.0185, 0.0327,
         0.0280, 0.0141, 0.0249, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 50
images/522
(64, 64, 3)
tensor([[0.0315, 0.0339, 0.0205, 0.0133, 0.0530, 0.0173, 0.0355, 0.0171, 0.0179,
         0.0222, 0.0202, 0.0319, 0.0308, 0.0303, 0.0209, 0.0183, 0.0211, 0.0283,
         0.0136, 0.0125, 0.0224, 0.0252, 0.0212, 0.0208, 0.0284, 0.0161, 0.0248,
         0.0274, 0.0471, 0.0221, 0.0139, 0.0355, 0.0267, 0.0224, 0.0179, 0.0295,
         0.0199, 0.0255, 0.0309, 0.0320]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 51
images/498
(64, 64, 3)
tensor([[0.0301, 0.0303, 0.0264, 0.0193, 0.0278, 0.0115, 0.0245, 0.0250, 0.0206,
         0.0166, 0.0226, 0.0287, 0.0302, 0.0345, 0.0203, 0.0151, 0.0246, 0.0303,
         0.0151, 0.0219, 0.0188, 0.0265, 0.0162, 0.0276, 0.0147, 0.0264, 0.0271,
         0.0308, 0.0381, 0.0154, 0.0189, 0.0307, 0.0314, 0.0441, 0.0155, 0.0218,
         0.0325, 0.0193, 0.0306, 0.0384]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/84
(64, 64, 3)
tensor([[0.0338, 0.0213, 0.0278, 0.0170, 0.0304, 0.0245, 0.0216, 0.0257, 0.0120,
         0.0183, 0.0256, 0.0170, 0.0365, 0.0226, 0.0203, 0.0246, 0.0146, 0.0296,
         0.0202, 0.0129, 0.0186, 0.0261, 0.0258, 0.0182, 0.0369, 0.0213, 0.0243,
         0.0400, 0.0300, 0.0273, 0.0344, 0.0259, 0.0300, 0.0213, 0.0339, 0.0250,
         0.0312, 0.0261, 0.0188, 0.0285]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 53
images/374
(64, 64, 3)
tensor([[0.0289, 0.0380, 0.0078, 0.0153, 0.0356, 0.0186, 0.0395, 0.0161, 0.0219,
         0.0283, 0.0105, 0.0348, 0.0329, 0.0321, 0.0323, 0.0220, 0.0255, 0.0420,
         0.0167, 0.0204, 0.0121, 0.0224, 0.0164, 0.0202, 0.0214, 0.0210, 0.0250,
         0.0237, 0.0376, 0.0237, 0.0118, 0.0193, 0.0454, 0.0234, 0.0268, 0.0212,
         0.0366, 0.0148, 0.0200, 0.0379]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 54
images/489
(64, 64, 3)
tensor([[0.0244, 0.0250, 0.0215, 0.0167, 0.0350, 0.0133, 0.0350, 0.0243, 0.0215,
         0.0110, 0.0140, 0.0378, 0.0528, 0.0356, 0.0216, 0.0182, 0.0187, 0.0296,
         0.0275, 0.0209, 0.0190, 0.0250, 0.0170, 0.0131, 0.0192, 0.0210, 0.0196,
         0.0309, 0.0313, 0.0263, 0.0229, 0.0292, 0.0332, 0.0194, 0.0285, 0.0370,
         0.0263, 0.0208, 0.0177, 0.0380]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 55
images/224
(64, 64, 3)
tensor([[0.0279, 0.0213, 0.0202, 0.0142, 0.0270, 0.0252, 0.0361, 0.0201, 0.0176,
         0.0197, 0.0173, 0.0270, 0.0542, 0.0274, 0.0252, 0.0198, 0.0184, 0.0433,
         0.0237, 0.0167, 0.0232, 0.0264, 0.0113, 0.0159, 0.0179, 0.0166, 0.0304,
         0.0445, 0.0333, 0.0283, 0.0208, 0.0235, 0.0481, 0.0164, 0.0241, 0.0226,
         0.0135, 0.0356, 0.0199, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 0
Session Number: 56
images/405
(64, 64, 3)
tensor([[0.0224, 0.0350, 0.0168, 0.0230, 0.0424, 0.0186, 0.0343, 0.0140, 0.0185,
         0.0233, 0.0175, 0.0181, 0.0446, 0.0304, 0.0342, 0.0218, 0.0235, 0.0360,
         0.0200, 0.0148, 0.0148, 0.0257, 0.0166, 0.0196, 0.0170, 0.0232, 0.0352,
         0.0306, 0.0276, 0.0351, 0.0152, 0.0417, 0.0222, 0.0151, 0.0182, 0.0336,
         0.0342, 0.0183, 0.0206, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 57
images/367
(64, 64, 3)
tensor([[0.0238, 0.0351, 0.0323, 0.0290, 0.0356, 0.0212, 0.0318, 0.0147, 0.0149,
         0.0203, 0.0308, 0.0185, 0.0384, 0.0267, 0.0274, 0.0159, 0.0200, 0.0419,
         0.0241, 0.0253, 0.0195, 0.0151, 0.0225, 0.0180, 0.0191, 0.0227, 0.0214,
         0.0270, 0.0287, 0.0267, 0.0146, 0.0398, 0.0274, 0.0244, 0.0193, 0.0348,
         0.0305, 0.0208, 0.0182, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 58
images/377
(64, 64, 3)
tensor([[0.0316, 0.0381, 0.0194, 0.0213, 0.0465, 0.0153, 0.0439, 0.0104, 0.0149,
         0.0259, 0.0156, 0.0369, 0.0448, 0.0270, 0.0284, 0.0129, 0.0159, 0.0599,
         0.0293, 0.0255, 0.0195, 0.0119, 0.0182, 0.0212, 0.0152, 0.0229, 0.0257,
         0.0281, 0.0256, 0.0302, 0.0157, 0.0176, 0.0214, 0.0198, 0.0237, 0.0201,
         0.0367, 0.0199, 0.0212, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 1
Session Number: 59
images/381
(64, 64, 3)
tensor([[0.0204, 0.0211, 0.0168, 0.0178, 0.0329, 0.0144, 0.0237, 0.0192, 0.0150,
         0.0183, 0.0260, 0.0266, 0.0407, 0.0452, 0.0415, 0.0182, 0.0220, 0.0331,
         0.0232, 0.0274, 0.0159, 0.0288, 0.0278, 0.0310, 0.0188, 0.0165, 0.0189,
         0.0222, 0.0373, 0.0184, 0.0219, 0.0211, 0.0228, 0.0428, 0.0311, 0.0330,
         0.0233, 0.0142, 0.0230, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 0
Session Number: 60
images/505
(64, 64, 3)
tensor([[0.0316, 0.0265, 0.0184, 0.0198, 0.0265, 0.0197, 0.0220, 0.0182, 0.0193,
         0.0248, 0.0213, 0.0364, 0.0264, 0.0219, 0.0209, 0.0139, 0.0175, 0.0417,
         0.0247, 0.0176, 0.0192, 0.0338, 0.0206, 0.0240, 0.0217, 0.0238, 0.0254,
         0.0335, 0.0437, 0.0267, 0.0129, 0.0333, 0.0364, 0.0247, 0.0118, 0.0187,
         0.0516, 0.0175, 0.0219, 0.0297]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 61
images/141
(64, 64, 3)
tensor([[0.0286, 0.0314, 0.0333, 0.0228, 0.0405, 0.0245, 0.0330, 0.0260, 0.0255,
         0.0218, 0.0218, 0.0277, 0.0389, 0.0283, 0.0211, 0.0196, 0.0162, 0.0342,
         0.0225, 0.0200, 0.0273, 0.0240, 0.0209, 0.0179, 0.0272, 0.0191, 0.0192,
         0.0258, 0.0260, 0.0263, 0.0125, 0.0310, 0.0273, 0.0227, 0.0225, 0.0302,
         0.0219, 0.0130, 0.0239, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 62
images/78
(64, 64, 3)
tensor([[0.0360, 0.0255, 0.0197, 0.0156, 0.0402, 0.0218, 0.0293, 0.0135, 0.0210,
         0.0204, 0.0201, 0.0382, 0.0373, 0.0235, 0.0291, 0.0150, 0.0279, 0.0266,
         0.0200, 0.0246, 0.0174, 0.0301, 0.0281, 0.0238, 0.0224, 0.0219, 0.0255,
         0.0298, 0.0233, 0.0195, 0.0221, 0.0226, 0.0334, 0.0293, 0.0219, 0.0331,
         0.0224, 0.0193, 0.0257, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 63
images/364
(64, 64, 3)
tensor([[0.0201, 0.0199, 0.0117, 0.0281, 0.0380, 0.0161, 0.0316, 0.0092, 0.0312,
         0.0167, 0.0156, 0.0309, 0.0321, 0.0315, 0.0226, 0.0202, 0.0164, 0.0758,
         0.0261, 0.0214, 0.0195, 0.0260, 0.0211, 0.0135, 0.0255, 0.0138, 0.0237,
         0.0500, 0.0414, 0.0155, 0.0188, 0.0261, 0.0208, 0.0136, 0.0227, 0.0228,
         0.0208, 0.0217, 0.0258, 0.0420]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 64
images/376
(64, 64, 3)
tensor([[0.0258, 0.0404, 0.0248, 0.0119, 0.0319, 0.0253, 0.0399, 0.0138, 0.0140,
         0.0196, 0.0131, 0.0293, 0.0496, 0.0253, 0.0188, 0.0177, 0.0254, 0.0265,
         0.0241, 0.0168, 0.0216, 0.0304, 0.0318, 0.0209, 0.0274, 0.0156, 0.0206,
         0.0404, 0.0309, 0.0340, 0.0180, 0.0305, 0.0219, 0.0140, 0.0158, 0.0492,
         0.0183, 0.0184, 0.0185, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 65
images/462
(64, 64, 3)
tensor([[0.0204, 0.0273, 0.0230, 0.0153, 0.0477, 0.0364, 0.0273, 0.0216, 0.0138,
         0.0151, 0.0164, 0.0315, 0.0449, 0.0244, 0.0273, 0.0212, 0.0199, 0.0241,
         0.0247, 0.0200, 0.0216, 0.0248, 0.0189, 0.0307, 0.0239, 0.0212, 0.0431,
         0.0305, 0.0274, 0.0218, 0.0213, 0.0338, 0.0220, 0.0202, 0.0209, 0.0312,
         0.0255, 0.0181, 0.0205, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 66
images/91
(64, 64, 3)
tensor([[0.0248, 0.0343, 0.0231, 0.0220, 0.0399, 0.0140, 0.0256, 0.0149, 0.0161,
         0.0232, 0.0221, 0.0294, 0.0289, 0.0361, 0.0292, 0.0132, 0.0229, 0.0521,
         0.0180, 0.0259, 0.0256, 0.0234, 0.0241, 0.0154, 0.0193, 0.0121, 0.0255,
         0.0300, 0.0251, 0.0251, 0.0167, 0.0358, 0.0409, 0.0260, 0.0137, 0.0368,
         0.0273, 0.0169, 0.0214, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 1
Session Number: 67
images/227
(64, 64, 3)
tensor([[0.0335, 0.0314, 0.0188, 0.0180, 0.0207, 0.0284, 0.0396, 0.0215, 0.0124,
         0.0246, 0.0172, 0.0426, 0.0397, 0.0289, 0.0189, 0.0094, 0.0195, 0.0313,
         0.0173, 0.0241, 0.0205, 0.0200, 0.0266, 0.0298, 0.0296, 0.0204, 0.0258,
         0.0265, 0.0405, 0.0198, 0.0269, 0.0308, 0.0220, 0.0169, 0.0147, 0.0324,
         0.0287, 0.0228, 0.0145, 0.0331]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 68
images/245
(64, 64, 3)
tensor([[0.0217, 0.0355, 0.0183, 0.0137, 0.0346, 0.0130, 0.0236, 0.0228, 0.0273,
         0.0285, 0.0168, 0.0237, 0.0343, 0.0256, 0.0223, 0.0168, 0.0292, 0.0273,
         0.0193, 0.0183, 0.0193, 0.0265, 0.0232, 0.0166, 0.0243, 0.0227, 0.0244,
         0.0335, 0.0526, 0.0335, 0.0144, 0.0303, 0.0237, 0.0264, 0.0178, 0.0248,
         0.0468, 0.0162, 0.0178, 0.0323]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 69
images/400
(64, 64, 3)
tensor([[0.0276, 0.0328, 0.0145, 0.0167, 0.0322, 0.0171, 0.0307, 0.0125, 0.0175,
         0.0141, 0.0252, 0.0330, 0.0350, 0.0639, 0.0251, 0.0207, 0.0229, 0.0426,
         0.0201, 0.0189, 0.0172, 0.0243, 0.0185, 0.0246, 0.0234, 0.0143, 0.0217,
         0.0227, 0.0412, 0.0272, 0.0241, 0.0279, 0.0289, 0.0191, 0.0314, 0.0329,
         0.0208, 0.0187, 0.0196, 0.0182]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 1
Session Number: 70
images/354
(64, 64, 3)
tensor([[0.0372, 0.0313, 0.0154, 0.0223, 0.0459, 0.0202, 0.0382, 0.0114, 0.0157,
         0.0115, 0.0155, 0.0329, 0.0397, 0.0364, 0.0399, 0.0204, 0.0195, 0.0391,
         0.0147, 0.0220, 0.0167, 0.0314, 0.0232, 0.0225, 0.0221, 0.0282, 0.0241,
         0.0236, 0.0283, 0.0259, 0.0250, 0.0201, 0.0229, 0.0178, 0.0154, 0.0276,
         0.0146, 0.0228, 0.0332, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 71
images/392
(64, 64, 3)
tensor([[0.0274, 0.0182, 0.0253, 0.0158, 0.0278, 0.0157, 0.0359, 0.0161, 0.0169,
         0.0253, 0.0176, 0.0330, 0.0419, 0.0292, 0.0218, 0.0148, 0.0253, 0.0332,
         0.0145, 0.0235, 0.0153, 0.0289, 0.0153, 0.0190, 0.0236, 0.0213, 0.0210,
         0.0457, 0.0326, 0.0204, 0.0184, 0.0290, 0.0457, 0.0199, 0.0316, 0.0270,
         0.0264, 0.0210, 0.0283, 0.0305]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 72
images/39
(64, 64, 3)
tensor([[0.0265, 0.0219, 0.0208, 0.0132, 0.0435, 0.0156, 0.0252, 0.0267, 0.0184,
         0.0149, 0.0164, 0.0512, 0.0412, 0.0303, 0.0212, 0.0161, 0.0259, 0.0332,
         0.0223, 0.0185, 0.0209, 0.0283, 0.0243, 0.0201, 0.0275, 0.0146, 0.0282,
         0.0342, 0.0332, 0.0236, 0.0119, 0.0241, 0.0184, 0.0268, 0.0345, 0.0368,
         0.0287, 0.0253, 0.0140, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 73
images/113
(64, 64, 3)
tensor([[0.0303, 0.0252, 0.0163, 0.0167, 0.0374, 0.0173, 0.0272, 0.0162, 0.0202,
         0.0226, 0.0316, 0.0207, 0.0251, 0.0309, 0.0287, 0.0143, 0.0204, 0.0561,
         0.0145, 0.0108, 0.0145, 0.0179, 0.0244, 0.0127, 0.0295, 0.0214, 0.0215,
         0.0199, 0.0464, 0.0306, 0.0160, 0.0323, 0.0371, 0.0310, 0.0232, 0.0399,
         0.0297, 0.0222, 0.0211, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 74
images/24
(64, 64, 3)
tensor([[0.0352, 0.0279, 0.0130, 0.0122, 0.0259, 0.0249, 0.0223, 0.0119, 0.0114,
         0.0163, 0.0223, 0.0322, 0.0524, 0.0310, 0.0259, 0.0209, 0.0268, 0.0408,
         0.0206, 0.0169, 0.0162, 0.0194, 0.0212, 0.0288, 0.0247, 0.0205, 0.0207,
         0.0276, 0.0464, 0.0139, 0.0185, 0.0201, 0.0197, 0.0304, 0.0286, 0.0333,
         0.0281, 0.0213, 0.0376, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 75
images/439
(64, 64, 3)
tensor([[0.0198, 0.0406, 0.0113, 0.0301, 0.0275, 0.0291, 0.0300, 0.0187, 0.0175,
         0.0214, 0.0190, 0.0146, 0.0341, 0.0444, 0.0282, 0.0335, 0.0166, 0.0272,
         0.0415, 0.0172, 0.0175, 0.0287, 0.0151, 0.0199, 0.0281, 0.0144, 0.0229,
         0.0180, 0.0394, 0.0286, 0.0151, 0.0416, 0.0289, 0.0265, 0.0236, 0.0324,
         0.0201, 0.0138, 0.0167, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 76
images/97
(64, 64, 3)
tensor([[0.0117, 0.0209, 0.0173, 0.0156, 0.0369, 0.0229, 0.0473, 0.0133, 0.0186,
         0.0161, 0.0182, 0.0574, 0.0466, 0.0302, 0.0351, 0.0221, 0.0167, 0.0227,
         0.0256, 0.0154, 0.0199, 0.0185, 0.0225, 0.0162, 0.0210, 0.0193, 0.0171,
         0.0315, 0.0442, 0.0260, 0.0125, 0.0216, 0.0196, 0.0233, 0.0177, 0.0569,
         0.0243, 0.0225, 0.0142, 0.0406]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 77
images/472
(64, 64, 3)
tensor([[0.0170, 0.0230, 0.0213, 0.0154, 0.0335, 0.0168, 0.0242, 0.0254, 0.0192,
         0.0205, 0.0152, 0.0269, 0.0359, 0.0368, 0.0271, 0.0172, 0.0266, 0.0290,
         0.0196, 0.0221, 0.0271, 0.0139, 0.0179, 0.0202, 0.0234, 0.0162, 0.0199,
         0.0369, 0.0315, 0.0183, 0.0180, 0.0355, 0.0481, 0.0348, 0.0175, 0.0236,
         0.0424, 0.0183, 0.0144, 0.0491]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 78
images/238
(64, 64, 3)
tensor([[0.0381, 0.0302, 0.0187, 0.0222, 0.0269, 0.0173, 0.0239, 0.0170, 0.0173,
         0.0181, 0.0211, 0.0448, 0.0462, 0.0286, 0.0237, 0.0184, 0.0242, 0.0289,
         0.0233, 0.0193, 0.0161, 0.0200, 0.0156, 0.0247, 0.0165, 0.0192, 0.0389,
         0.0265, 0.0352, 0.0245, 0.0146, 0.0164, 0.0258, 0.0166, 0.0279, 0.0294,
         0.0409, 0.0272, 0.0254, 0.0306]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/492
(64, 64, 3)
tensor([[0.0209, 0.0221, 0.0184, 0.0194, 0.0493, 0.0218, 0.0295, 0.0177, 0.0242,
         0.0193, 0.0248, 0.0370, 0.0345, 0.0315, 0.0241, 0.0259, 0.0227, 0.0374,
         0.0220, 0.0243, 0.0144, 0.0249, 0.0172, 0.0245, 0.0287, 0.0163, 0.0219,
         0.0402, 0.0280, 0.0230, 0.0142, 0.0264, 0.0226, 0.0285, 0.0313, 0.0278,
         0.0181, 0.0201, 0.0212, 0.0240]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 80
images/253
(64, 64, 3)
tensor([[0.0268, 0.0233, 0.0179, 0.0177, 0.0455, 0.0138, 0.0297, 0.0160, 0.0193,
         0.0185, 0.0180, 0.0319, 0.0309, 0.0271, 0.0344, 0.0191, 0.0219, 0.0369,
         0.0227, 0.0164, 0.0189, 0.0277, 0.0212, 0.0303, 0.0162, 0.0193, 0.0278,
         0.0263, 0.0309, 0.0188, 0.0225, 0.0328, 0.0242, 0.0307, 0.0320, 0.0364,
         0.0236, 0.0196, 0.0264, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 81
images/119
(64, 64, 3)
tensor([[0.0240, 0.0195, 0.0216, 0.0203, 0.0470, 0.0198, 0.0310, 0.0257, 0.0202,
         0.0237, 0.0155, 0.0305, 0.0312, 0.0268, 0.0218, 0.0195, 0.0164, 0.0503,
         0.0171, 0.0326, 0.0182, 0.0292, 0.0277, 0.0250, 0.0194, 0.0197, 0.0266,
         0.0234, 0.0283, 0.0274, 0.0187, 0.0366, 0.0290, 0.0159, 0.0251, 0.0287,
         0.0206, 0.0222, 0.0242, 0.0194]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 82
images/555
(64, 64, 3)
tensor([[0.0261, 0.0348, 0.0213, 0.0134, 0.0383, 0.0174, 0.0257, 0.0170, 0.0161,
         0.0140, 0.0239, 0.0365, 0.0464, 0.0287, 0.0300, 0.0174, 0.0243, 0.0350,
         0.0246, 0.0171, 0.0161, 0.0293, 0.0242, 0.0286, 0.0171, 0.0249, 0.0265,
         0.0270, 0.0410, 0.0351, 0.0153, 0.0279, 0.0236, 0.0252, 0.0233, 0.0254,
         0.0264, 0.0255, 0.0102, 0.0196]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 83
images/266
(64, 64, 3)
tensor([[0.0336, 0.0403, 0.0161, 0.0147, 0.0281, 0.0168, 0.0262, 0.0162, 0.0129,
         0.0138, 0.0184, 0.0326, 0.0512, 0.0259, 0.0213, 0.0255, 0.0192, 0.0286,
         0.0166, 0.0244, 0.0168, 0.0242, 0.0180, 0.0278, 0.0249, 0.0228, 0.0282,
         0.0418, 0.0368, 0.0214, 0.0171, 0.0324, 0.0250, 0.0170, 0.0239, 0.0366,
         0.0281, 0.0154, 0.0225, 0.0369]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 84
images/375
(64, 64, 3)
tensor([[0.0464, 0.0227, 0.0210, 0.0264, 0.0303, 0.0232, 0.0246, 0.0179, 0.0142,
         0.0253, 0.0170, 0.0483, 0.0287, 0.0252, 0.0244, 0.0384, 0.0266, 0.0344,
         0.0173, 0.0152, 0.0254, 0.0238, 0.0238, 0.0197, 0.0229, 0.0171, 0.0199,
         0.0290, 0.0345, 0.0157, 0.0158, 0.0235, 0.0217, 0.0232, 0.0242, 0.0302,
         0.0354, 0.0092, 0.0317, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 85
images/106
(64, 64, 3)
tensor([[0.0180, 0.0333, 0.0155, 0.0268, 0.0280, 0.0181, 0.0371, 0.0247, 0.0141,
         0.0191, 0.0274, 0.0272, 0.0297, 0.0301, 0.0313, 0.0327, 0.0210, 0.0312,
         0.0198, 0.0203, 0.0177, 0.0192, 0.0185, 0.0171, 0.0194, 0.0191, 0.0307,
         0.0453, 0.0300, 0.0279, 0.0195, 0.0272, 0.0292, 0.0184, 0.0386, 0.0200,
         0.0191, 0.0178, 0.0264, 0.0337]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 86
images/315
(64, 64, 3)
tensor([[0.0240, 0.0374, 0.0136, 0.0159, 0.0308, 0.0158, 0.0371, 0.0178, 0.0141,
         0.0211, 0.0211, 0.0301, 0.0367, 0.0306, 0.0201, 0.0231, 0.0285, 0.0311,
         0.0197, 0.0121, 0.0168, 0.0197, 0.0168, 0.0262, 0.0213, 0.0181, 0.0423,
         0.0328, 0.0382, 0.0193, 0.0155, 0.0432, 0.0327, 0.0236, 0.0381, 0.0179,
         0.0299, 0.0179, 0.0258, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 87
images/593
(64, 64, 3)
tensor([[0.0314, 0.0236, 0.0143, 0.0139, 0.0213, 0.0218, 0.0377, 0.0215, 0.0160,
         0.0199, 0.0250, 0.0440, 0.0434, 0.0287, 0.0219, 0.0189, 0.0197, 0.0296,
         0.0163, 0.0289, 0.0151, 0.0415, 0.0264, 0.0228, 0.0169, 0.0142, 0.0202,
         0.0321, 0.0240, 0.0271, 0.0177, 0.0356, 0.0277, 0.0225, 0.0243, 0.0301,
         0.0257, 0.0263, 0.0288, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 88
images/242
(64, 64, 3)
tensor([[0.0323, 0.0274, 0.0154, 0.0165, 0.0321, 0.0187, 0.0483, 0.0289, 0.0210,
         0.0139, 0.0322, 0.0314, 0.0355, 0.0296, 0.0179, 0.0205, 0.0175, 0.0420,
         0.0229, 0.0256, 0.0140, 0.0212, 0.0217, 0.0183, 0.0165, 0.0304, 0.0252,
         0.0230, 0.0247, 0.0208, 0.0186, 0.0300, 0.0267, 0.0219, 0.0279, 0.0337,
         0.0301, 0.0152, 0.0250, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/396
(64, 64, 3)
tensor([[0.0211, 0.0371, 0.0246, 0.0134, 0.0281, 0.0161, 0.0319, 0.0207, 0.0192,
         0.0240, 0.0129, 0.0211, 0.0593, 0.0310, 0.0289, 0.0229, 0.0120, 0.0414,
         0.0320, 0.0211, 0.0158, 0.0198, 0.0173, 0.0213, 0.0238, 0.0194, 0.0275,
         0.0334, 0.0230, 0.0224, 0.0170, 0.0234, 0.0208, 0.0390, 0.0208, 0.0383,
         0.0180, 0.0330, 0.0211, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 90
images/388
(64, 64, 3)
tensor([[0.0265, 0.0153, 0.0269, 0.0206, 0.0366, 0.0275, 0.0337, 0.0195, 0.0208,
         0.0199, 0.0138, 0.0334, 0.0380, 0.0274, 0.0297, 0.0225, 0.0190, 0.0338,
         0.0177, 0.0203, 0.0249, 0.0194, 0.0215, 0.0265, 0.0264, 0.0170, 0.0263,
         0.0391, 0.0427, 0.0306, 0.0205, 0.0152, 0.0152, 0.0245, 0.0205, 0.0317,
         0.0301, 0.0184, 0.0245, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 91
images/457
(64, 64, 3)
tensor([[0.0211, 0.0365, 0.0139, 0.0161, 0.0170, 0.0256, 0.0310, 0.0221, 0.0160,
         0.0233, 0.0222, 0.0504, 0.0443, 0.0234, 0.0292, 0.0241, 0.0194, 0.0232,
         0.0157, 0.0258, 0.0200, 0.0294, 0.0188, 0.0303, 0.0288, 0.0144, 0.0311,
         0.0318, 0.0287, 0.0340, 0.0237, 0.0358, 0.0277, 0.0241, 0.0149, 0.0206,
         0.0137, 0.0137, 0.0199, 0.0384]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 92
images/468
(64, 64, 3)
tensor([[0.0240, 0.0374, 0.0233, 0.0168, 0.0265, 0.0292, 0.0223, 0.0166, 0.0185,
         0.0299, 0.0190, 0.0257, 0.0467, 0.0185, 0.0172, 0.0155, 0.0267, 0.0272,
         0.0167, 0.0257, 0.0142, 0.0290, 0.0168, 0.0397, 0.0237, 0.0168, 0.0233,
         0.0333, 0.0440, 0.0222, 0.0230, 0.0239, 0.0257, 0.0357, 0.0292, 0.0300,
         0.0174, 0.0235, 0.0213, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 93
images/455
(64, 64, 3)
tensor([[0.0252, 0.0412, 0.0113, 0.0260, 0.0401, 0.0295, 0.0338, 0.0156, 0.0202,
         0.0186, 0.0249, 0.0200, 0.0363, 0.0357, 0.0286, 0.0227, 0.0179, 0.0445,
         0.0221, 0.0199, 0.0153, 0.0197, 0.0261, 0.0225, 0.0226, 0.0170, 0.0297,
         0.0177, 0.0242, 0.0242, 0.0336, 0.0236, 0.0254, 0.0322, 0.0174, 0.0304,
         0.0294, 0.0160, 0.0196, 0.0193]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 94
images/142
(64, 64, 3)
tensor([[0.0372, 0.0321, 0.0215, 0.0293, 0.0317, 0.0246, 0.0286, 0.0123, 0.0217,
         0.0262, 0.0242, 0.0249, 0.0492, 0.0325, 0.0188, 0.0198, 0.0187, 0.0303,
         0.0195, 0.0268, 0.0158, 0.0244, 0.0166, 0.0193, 0.0177, 0.0241, 0.0204,
         0.0320, 0.0336, 0.0268, 0.0153, 0.0242, 0.0316, 0.0171, 0.0174, 0.0235,
         0.0351, 0.0251, 0.0272, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 95
images/411
(64, 64, 3)
tensor([[0.0297, 0.0249, 0.0259, 0.0211, 0.0374, 0.0193, 0.0324, 0.0182, 0.0202,
         0.0168, 0.0171, 0.0425, 0.0373, 0.0300, 0.0280, 0.0191, 0.0257, 0.0354,
         0.0255, 0.0199, 0.0236, 0.0306, 0.0206, 0.0273, 0.0379, 0.0169, 0.0243,
         0.0162, 0.0269, 0.0205, 0.0153, 0.0280, 0.0299, 0.0181, 0.0145, 0.0286,
         0.0285, 0.0194, 0.0244, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 96
images/385
(64, 64, 3)
tensor([[0.0180, 0.0264, 0.0183, 0.0147, 0.0379, 0.0347, 0.0431, 0.0213, 0.0186,
         0.0226, 0.0294, 0.0299, 0.0568, 0.0212, 0.0277, 0.0137, 0.0209, 0.0343,
         0.0192, 0.0229, 0.0151, 0.0210, 0.0147, 0.0239, 0.0174, 0.0191, 0.0217,
         0.0465, 0.0287, 0.0205, 0.0284, 0.0210, 0.0200, 0.0349, 0.0280, 0.0215,
         0.0214, 0.0108, 0.0216, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 97
images/105
(64, 64, 3)
tensor([[0.0212, 0.0251, 0.0188, 0.0271, 0.0339, 0.0193, 0.0392, 0.0165, 0.0172,
         0.0179, 0.0289, 0.0299, 0.0324, 0.0315, 0.0335, 0.0141, 0.0185, 0.0371,
         0.0328, 0.0243, 0.0164, 0.0147, 0.0243, 0.0191, 0.0172, 0.0177, 0.0208,
         0.0382, 0.0297, 0.0252, 0.0196, 0.0260, 0.0278, 0.0348, 0.0205, 0.0331,
         0.0337, 0.0174, 0.0219, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 98
images/116
(64, 64, 3)
tensor([[0.0378, 0.0201, 0.0210, 0.0129, 0.0248, 0.0259, 0.0362, 0.0177, 0.0146,
         0.0174, 0.0241, 0.0271, 0.0301, 0.0415, 0.0324, 0.0168, 0.0176, 0.0335,
         0.0235, 0.0218, 0.0231, 0.0274, 0.0201, 0.0209, 0.0195, 0.0200, 0.0380,
         0.0356, 0.0242, 0.0178, 0.0136, 0.0399, 0.0185, 0.0265, 0.0221, 0.0380,
         0.0220, 0.0202, 0.0207, 0.0353]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 99
images/199
(64, 64, 3)
tensor([[0.0267, 0.0313, 0.0139, 0.0208, 0.0256, 0.0235, 0.0390, 0.0216, 0.0217,
         0.0166, 0.0222, 0.0281, 0.0464, 0.0254, 0.0260, 0.0159, 0.0262, 0.0345,
         0.0253, 0.0200, 0.0209, 0.0167, 0.0135, 0.0285, 0.0147, 0.0250, 0.0258,
         0.0374, 0.0281, 0.0219, 0.0204, 0.0340, 0.0286, 0.0272, 0.0137, 0.0355,
         0.0298, 0.0180, 0.0298, 0.0196]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Saving the weights
25 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/240
(64, 64, 3)
2018-10-12 22:17:01.075 Python[7178:15666898] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0307, 0.0222, 0.0256, 0.0168, 0.0426, 0.0171, 0.0288, 0.0144, 0.0162,
         0.0250, 0.0169, 0.0220, 0.0256, 0.0289, 0.0350, 0.0245, 0.0245, 0.0291,
         0.0121, 0.0214, 0.0102, 0.0251, 0.0319, 0.0239, 0.0255, 0.0253, 0.0224,
         0.0367, 0.0340, 0.0210, 0.0200, 0.0261, 0.0210, 0.0271, 0.0227, 0.0277,
         0.0296, 0.0401, 0.0233, 0.0271]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 1
images/280
(64, 64, 3)
tensor([[0.0200, 0.0204, 0.0145, 0.0191, 0.0269, 0.0164, 0.0235, 0.0211, 0.0179,
         0.0129, 0.0188, 0.0344, 0.0308, 0.0415, 0.0252, 0.0203, 0.0212, 0.0340,
         0.0128, 0.0266, 0.0173, 0.0266, 0.0163, 0.0200, 0.0204, 0.0207, 0.0198,
         0.0472, 0.0337, 0.0231, 0.0154, 0.0461, 0.0214, 0.0380, 0.0166, 0.0505,
         0.0443, 0.0215, 0.0184, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/145
(64, 64, 3)
tensor([[0.0321, 0.0283, 0.0116, 0.0205, 0.0332, 0.0170, 0.0321, 0.0143, 0.0147,
         0.0175, 0.0297, 0.0337, 0.0349, 0.0476, 0.0280, 0.0216, 0.0331, 0.0522,
         0.0168, 0.0122, 0.0135, 0.0231, 0.0172, 0.0266, 0.0141, 0.0167, 0.0224,
         0.0307, 0.0400, 0.0169, 0.0182, 0.0243, 0.0284, 0.0255, 0.0275, 0.0331,
         0.0318, 0.0212, 0.0180, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 3
images/452
(64, 64, 3)
tensor([[0.0367, 0.0266, 0.0197, 0.0227, 0.0248, 0.0180, 0.0279, 0.0159, 0.0186,
         0.0130, 0.0304, 0.0340, 0.0352, 0.0428, 0.0232, 0.0178, 0.0151, 0.0479,
         0.0152, 0.0275, 0.0134, 0.0259, 0.0213, 0.0236, 0.0171, 0.0156, 0.0203,
         0.0513, 0.0347, 0.0201, 0.0201, 0.0199, 0.0266, 0.0255, 0.0319, 0.0286,
         0.0227, 0.0271, 0.0225, 0.0187]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 4
images/253
(64, 64, 3)
tensor([[0.0234, 0.0301, 0.0155, 0.0130, 0.0498, 0.0167, 0.0283, 0.0158, 0.0150,
         0.0172, 0.0154, 0.0389, 0.0294, 0.0447, 0.0364, 0.0137, 0.0220, 0.0471,
         0.0119, 0.0145, 0.0164, 0.0224, 0.0198, 0.0283, 0.0198, 0.0202, 0.0375,
         0.0238, 0.0396, 0.0236, 0.0136, 0.0385, 0.0276, 0.0299, 0.0282, 0.0237,
         0.0188, 0.0226, 0.0190, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 5
images/489
(64, 64, 3)
tensor([[0.0176, 0.0335, 0.0169, 0.0134, 0.0254, 0.0220, 0.0284, 0.0344, 0.0172,
         0.0176, 0.0177, 0.0404, 0.0359, 0.0340, 0.0255, 0.0349, 0.0273, 0.0257,
         0.0222, 0.0281, 0.0163, 0.0198, 0.0192, 0.0281, 0.0145, 0.0291, 0.0238,
         0.0251, 0.0383, 0.0287, 0.0142, 0.0285, 0.0295, 0.0204, 0.0292, 0.0285,
         0.0208, 0.0178, 0.0187, 0.0312]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 0
Session Number: 6
images/538
(64, 64, 3)
tensor([[0.0309, 0.0332, 0.0214, 0.0159, 0.0256, 0.0249, 0.0263, 0.0242, 0.0174,
         0.0274, 0.0150, 0.0286, 0.0254, 0.0245, 0.0310, 0.0248, 0.0189, 0.0350,
         0.0184, 0.0223, 0.0173, 0.0255, 0.0276, 0.0270, 0.0197, 0.0172, 0.0218,
         0.0348, 0.0439, 0.0178, 0.0297, 0.0224, 0.0262, 0.0212, 0.0225, 0.0244,
         0.0280, 0.0258, 0.0307, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 7
images/23
(64, 64, 3)
tensor([[0.0258, 0.0278, 0.0234, 0.0138, 0.0366, 0.0168, 0.0234, 0.0125, 0.0174,
         0.0165, 0.0201, 0.0396, 0.0518, 0.0223, 0.0208, 0.0254, 0.0212, 0.0259,
         0.0157, 0.0197, 0.0161, 0.0293, 0.0162, 0.0295, 0.0256, 0.0226, 0.0439,
         0.0359, 0.0326, 0.0256, 0.0297, 0.0284, 0.0192, 0.0359, 0.0180, 0.0338,
         0.0291, 0.0114, 0.0206, 0.0200]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/364
(64, 64, 3)
tensor([[0.0208, 0.0218, 0.0131, 0.0219, 0.0332, 0.0209, 0.0273, 0.0170, 0.0195,
         0.0214, 0.0155, 0.0253, 0.0480, 0.0294, 0.0192, 0.0181, 0.0309, 0.0531,
         0.0241, 0.0174, 0.0114, 0.0201, 0.0383, 0.0160, 0.0118, 0.0198, 0.0260,
         0.0300, 0.0464, 0.0181, 0.0116, 0.0327, 0.0341, 0.0257, 0.0230, 0.0337,
         0.0302, 0.0200, 0.0184, 0.0352]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 9
images/480
(64, 64, 3)
tensor([[0.0250, 0.0275, 0.0091, 0.0118, 0.0214, 0.0158, 0.0407, 0.0240, 0.0227,
         0.0264, 0.0205, 0.0272, 0.0372, 0.0367, 0.0279, 0.0169, 0.0368, 0.0365,
         0.0197, 0.0118, 0.0168, 0.0248, 0.0129, 0.0225, 0.0186, 0.0205, 0.0294,
         0.0245, 0.0487, 0.0250, 0.0232, 0.0302, 0.0296, 0.0224, 0.0186, 0.0447,
         0.0218, 0.0181, 0.0249, 0.0274]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 10
images/592
(64, 64, 3)
tensor([[0.0239, 0.0208, 0.0143, 0.0120, 0.0533, 0.0225, 0.0353, 0.0128, 0.0243,
         0.0270, 0.0175, 0.0353, 0.0412, 0.0301, 0.0344, 0.0135, 0.0185, 0.0351,
         0.0240, 0.0226, 0.0150, 0.0252, 0.0193, 0.0235, 0.0188, 0.0188, 0.0368,
         0.0247, 0.0264, 0.0274, 0.0240, 0.0258, 0.0349, 0.0158, 0.0286, 0.0196,
         0.0220, 0.0254, 0.0256, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 11
images/118
(64, 64, 3)
tensor([[0.0209, 0.0252, 0.0348, 0.0196, 0.0355, 0.0296, 0.0363, 0.0107, 0.0249,
         0.0200, 0.0159, 0.0323, 0.0306, 0.0208, 0.0240, 0.0148, 0.0159, 0.0494,
         0.0199, 0.0147, 0.0136, 0.0221, 0.0213, 0.0415, 0.0160, 0.0167, 0.0257,
         0.0218, 0.0391, 0.0397, 0.0204, 0.0238, 0.0231, 0.0205, 0.0276, 0.0286,
         0.0386, 0.0181, 0.0236, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 12
images/368
(64, 64, 3)
tensor([[0.0330, 0.0337, 0.0153, 0.0179, 0.0358, 0.0278, 0.0364, 0.0146, 0.0209,
         0.0136, 0.0164, 0.0317, 0.0423, 0.0290, 0.0215, 0.0236, 0.0153, 0.0470,
         0.0144, 0.0158, 0.0216, 0.0314, 0.0167, 0.0186, 0.0301, 0.0230, 0.0186,
         0.0303, 0.0415, 0.0158, 0.0141, 0.0270, 0.0225, 0.0169, 0.0188, 0.0270,
         0.0292, 0.0383, 0.0230, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 13
images/302
(64, 64, 3)
tensor([[0.0240, 0.0269, 0.0192, 0.0146, 0.0211, 0.0319, 0.0474, 0.0209, 0.0163,
         0.0203, 0.0348, 0.0305, 0.0365, 0.0266, 0.0135, 0.0275, 0.0200, 0.0260,
         0.0164, 0.0261, 0.0189, 0.0204, 0.0166, 0.0241, 0.0233, 0.0162, 0.0309,
         0.0350, 0.0318, 0.0224, 0.0176, 0.0418, 0.0356, 0.0190, 0.0377, 0.0228,
         0.0260, 0.0155, 0.0238, 0.0201]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 14
images/288
(64, 64, 3)
tensor([[0.0471, 0.0294, 0.0146, 0.0089, 0.0190, 0.0253, 0.0271, 0.0242, 0.0153,
         0.0135, 0.0138, 0.0342, 0.0379, 0.0268, 0.0336, 0.0163, 0.0263, 0.0422,
         0.0132, 0.0169, 0.0191, 0.0205, 0.0256, 0.0159, 0.0300, 0.0191, 0.0291,
         0.0243, 0.0300, 0.0248, 0.0273, 0.0512, 0.0336, 0.0216, 0.0138, 0.0230,
         0.0227, 0.0181, 0.0394, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 15
images/580
(64, 64, 3)
tensor([[0.0276, 0.0275, 0.0184, 0.0157, 0.0339, 0.0163, 0.0301, 0.0168, 0.0175,
         0.0181, 0.0217, 0.0254, 0.0229, 0.0389, 0.0305, 0.0195, 0.0161, 0.0297,
         0.0168, 0.0207, 0.0197, 0.0314, 0.0226, 0.0215, 0.0267, 0.0188, 0.0194,
         0.0408, 0.0255, 0.0352, 0.0331, 0.0373, 0.0310, 0.0148, 0.0120, 0.0320,
         0.0355, 0.0096, 0.0431, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/301
(64, 64, 3)
tensor([[0.0237, 0.0421, 0.0144, 0.0172, 0.0442, 0.0199, 0.0492, 0.0153, 0.0197,
         0.0265, 0.0215, 0.0259, 0.0407, 0.0241, 0.0202, 0.0145, 0.0180, 0.0417,
         0.0158, 0.0203, 0.0223, 0.0157, 0.0152, 0.0226, 0.0241, 0.0329, 0.0316,
         0.0366, 0.0256, 0.0236, 0.0181, 0.0368, 0.0208, 0.0166, 0.0187, 0.0407,
         0.0200, 0.0162, 0.0272, 0.0200]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 17
images/574
(64, 64, 3)
tensor([[0.0223, 0.0336, 0.0238, 0.0149, 0.0226, 0.0183, 0.0211, 0.0218, 0.0180,
         0.0269, 0.0143, 0.0293, 0.0392, 0.0265, 0.0307, 0.0223, 0.0199, 0.0745,
         0.0183, 0.0118, 0.0174, 0.0202, 0.0222, 0.0231, 0.0310, 0.0186, 0.0239,
         0.0302, 0.0313, 0.0310, 0.0198, 0.0400, 0.0302, 0.0189, 0.0217, 0.0260,
         0.0229, 0.0151, 0.0195, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 18
images/251
(64, 64, 3)
tensor([[0.0242, 0.0228, 0.0265, 0.0144, 0.0279, 0.0197, 0.0433, 0.0207, 0.0172,
         0.0157, 0.0253, 0.0267, 0.0350, 0.0318, 0.0154, 0.0229, 0.0175, 0.0399,
         0.0163, 0.0210, 0.0165, 0.0256, 0.0178, 0.0175, 0.0204, 0.0206, 0.0241,
         0.0357, 0.0339, 0.0299, 0.0239, 0.0336, 0.0275, 0.0215, 0.0368, 0.0271,
         0.0355, 0.0170, 0.0252, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 19
images/553
(64, 64, 3)
tensor([[0.0285, 0.0311, 0.0228, 0.0241, 0.0384, 0.0228, 0.0323, 0.0151, 0.0196,
         0.0235, 0.0160, 0.0381, 0.0255, 0.0394, 0.0331, 0.0202, 0.0254, 0.0394,
         0.0261, 0.0210, 0.0229, 0.0222, 0.0139, 0.0143, 0.0194, 0.0114, 0.0178,
         0.0252, 0.0418, 0.0212, 0.0140, 0.0303, 0.0328, 0.0242, 0.0256, 0.0230,
         0.0309, 0.0245, 0.0201, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 20
images/542
(64, 64, 3)
tensor([[0.0288, 0.0227, 0.0151, 0.0173, 0.0515, 0.0239, 0.0348, 0.0207, 0.0163,
         0.0135, 0.0189, 0.0239, 0.0419, 0.0267, 0.0241, 0.0230, 0.0196, 0.0319,
         0.0174, 0.0278, 0.0182, 0.0209, 0.0191, 0.0204, 0.0266, 0.0233, 0.0265,
         0.0288, 0.0264, 0.0274, 0.0247, 0.0280, 0.0265, 0.0215, 0.0201, 0.0340,
         0.0241, 0.0272, 0.0291, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 21
images/299
(64, 64, 3)
tensor([[0.0225, 0.0300, 0.0168, 0.0167, 0.0276, 0.0197, 0.0348, 0.0159, 0.0299,
         0.0195, 0.0156, 0.0327, 0.0599, 0.0303, 0.0142, 0.0169, 0.0244, 0.0430,
         0.0245, 0.0213, 0.0121, 0.0218, 0.0151, 0.0274, 0.0106, 0.0192, 0.0298,
         0.0310, 0.0431, 0.0182, 0.0143, 0.0338, 0.0274, 0.0191, 0.0289, 0.0371,
         0.0297, 0.0199, 0.0225, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/573
(64, 64, 3)
tensor([[0.0311, 0.0253, 0.0144, 0.0175, 0.0290, 0.0156, 0.0354, 0.0167, 0.0164,
         0.0208, 0.0188, 0.0288, 0.0431, 0.0404, 0.0190, 0.0130, 0.0257, 0.0495,
         0.0158, 0.0227, 0.0116, 0.0247, 0.0244, 0.0300, 0.0133, 0.0127, 0.0284,
         0.0308, 0.0305, 0.0182, 0.0143, 0.0293, 0.0221, 0.0410, 0.0309, 0.0613,
         0.0176, 0.0171, 0.0204, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 23
images/416
(64, 64, 3)
tensor([[0.0157, 0.0165, 0.0143, 0.0161, 0.0553, 0.0232, 0.0311, 0.0243, 0.0156,
         0.0267, 0.0182, 0.0262, 0.0301, 0.0305, 0.0351, 0.0189, 0.0280, 0.0248,
         0.0200, 0.0195, 0.0159, 0.0246, 0.0246, 0.0265, 0.0216, 0.0324, 0.0271,
         0.0288, 0.0267, 0.0275, 0.0132, 0.0309, 0.0225, 0.0247, 0.0345, 0.0381,
         0.0309, 0.0192, 0.0165, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 24
images/572
(64, 64, 3)
tensor([[0.0277, 0.0242, 0.0169, 0.0154, 0.0410, 0.0205, 0.0226, 0.0157, 0.0218,
         0.0253, 0.0141, 0.0402, 0.0343, 0.0245, 0.0276, 0.0158, 0.0240, 0.0315,
         0.0144, 0.0141, 0.0218, 0.0263, 0.0208, 0.0267, 0.0250, 0.0351, 0.0256,
         0.0401, 0.0326, 0.0230, 0.0220, 0.0366, 0.0263, 0.0204, 0.0257, 0.0342,
         0.0306, 0.0198, 0.0151, 0.0205]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/285
(64, 64, 3)
tensor([[0.0303, 0.0204, 0.0137, 0.0125, 0.0232, 0.0198, 0.0269, 0.0212, 0.0123,
         0.0209, 0.0231, 0.0365, 0.0457, 0.0302, 0.0220, 0.0241, 0.0217, 0.0309,
         0.0160, 0.0200, 0.0162, 0.0340, 0.0461, 0.0283, 0.0334, 0.0199, 0.0202,
         0.0340, 0.0377, 0.0408, 0.0155, 0.0281, 0.0246, 0.0167, 0.0160, 0.0379,
         0.0266, 0.0196, 0.0156, 0.0175]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 26
images/98
(64, 64, 3)
tensor([[0.0245, 0.0329, 0.0177, 0.0154, 0.0501, 0.0149, 0.0305, 0.0288, 0.0158,
         0.0274, 0.0152, 0.0279, 0.0214, 0.0386, 0.0417, 0.0147, 0.0130, 0.0425,
         0.0188, 0.0256, 0.0300, 0.0361, 0.0167, 0.0250, 0.0267, 0.0124, 0.0188,
         0.0351, 0.0305, 0.0315, 0.0195, 0.0235, 0.0233, 0.0255, 0.0214, 0.0218,
         0.0213, 0.0138, 0.0267, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 27
images/543
(64, 64, 3)
tensor([[0.0336, 0.0324, 0.0148, 0.0230, 0.0233, 0.0137, 0.0252, 0.0132, 0.0181,
         0.0175, 0.0323, 0.0232, 0.0515, 0.0202, 0.0259, 0.0284, 0.0285, 0.0277,
         0.0184, 0.0378, 0.0188, 0.0247, 0.0183, 0.0144, 0.0129, 0.0210, 0.0382,
         0.0359, 0.0177, 0.0237, 0.0157, 0.0224, 0.0259, 0.0233, 0.0303, 0.0409,
         0.0297, 0.0199, 0.0218, 0.0357]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 28
images/61
(64, 64, 3)
tensor([[0.0390, 0.0208, 0.0142, 0.0176, 0.0363, 0.0173, 0.0430, 0.0170, 0.0152,
         0.0178, 0.0198, 0.0189, 0.0633, 0.0381, 0.0211, 0.0142, 0.0154, 0.0320,
         0.0221, 0.0181, 0.0157, 0.0193, 0.0287, 0.0214, 0.0186, 0.0196, 0.0252,
         0.0234, 0.0231, 0.0317, 0.0241, 0.0247, 0.0206, 0.0246, 0.0325, 0.0509,
         0.0308, 0.0238, 0.0227, 0.0175]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Session Number: 29
images/405
(64, 64, 3)
tensor([[0.0290, 0.0237, 0.0176, 0.0277, 0.0330, 0.0203, 0.0276, 0.0155, 0.0215,
         0.0199, 0.0150, 0.0232, 0.0434, 0.0292, 0.0264, 0.0278, 0.0196, 0.0357,
         0.0215, 0.0245, 0.0273, 0.0284, 0.0295, 0.0241, 0.0193, 0.0116, 0.0311,
         0.0307, 0.0287, 0.0226, 0.0213, 0.0411, 0.0268, 0.0242, 0.0203, 0.0354,
         0.0286, 0.0101, 0.0151, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 30
images/454
(64, 64, 3)
tensor([[0.0293, 0.0248, 0.0126, 0.0217, 0.0262, 0.0138, 0.0299, 0.0160, 0.0146,
         0.0175, 0.0317, 0.0274, 0.0273, 0.0376, 0.0211, 0.0136, 0.0223, 0.0317,
         0.0230, 0.0272, 0.0226, 0.0313, 0.0217, 0.0190, 0.0404, 0.0218, 0.0183,
         0.0302, 0.0326, 0.0245, 0.0171, 0.0343, 0.0265, 0.0396, 0.0250, 0.0273,
         0.0272, 0.0227, 0.0266, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 31
images/220
(64, 64, 3)
tensor([[0.0262, 0.0236, 0.0210, 0.0141, 0.0270, 0.0159, 0.0387, 0.0214, 0.0192,
         0.0192, 0.0246, 0.0591, 0.0233, 0.0344, 0.0180, 0.0219, 0.0205, 0.0403,
         0.0140, 0.0182, 0.0161, 0.0217, 0.0202, 0.0224, 0.0197, 0.0240, 0.0192,
         0.0254, 0.0316, 0.0236, 0.0157, 0.0358, 0.0333, 0.0174, 0.0231, 0.0206,
         0.0270, 0.0298, 0.0215, 0.0514]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 32
images/415
(64, 64, 3)
tensor([[0.0243, 0.0357, 0.0133, 0.0243, 0.0298, 0.0337, 0.0370, 0.0154, 0.0165,
         0.0194, 0.0226, 0.0223, 0.0448, 0.0264, 0.0473, 0.0237, 0.0241, 0.0282,
         0.0262, 0.0301, 0.0116, 0.0326, 0.0187, 0.0212, 0.0229, 0.0221, 0.0359,
         0.0194, 0.0294, 0.0249, 0.0216, 0.0179, 0.0190, 0.0218, 0.0217, 0.0255,
         0.0227, 0.0238, 0.0187, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 33
images/441
(64, 64, 3)
tensor([[0.0268, 0.0308, 0.0185, 0.0245, 0.0458, 0.0232, 0.0421, 0.0168, 0.0149,
         0.0262, 0.0168, 0.0307, 0.0343, 0.0317, 0.0242, 0.0106, 0.0225, 0.0309,
         0.0405, 0.0163, 0.0246, 0.0219, 0.0199, 0.0193, 0.0219, 0.0185, 0.0217,
         0.0237, 0.0424, 0.0250, 0.0146, 0.0387, 0.0310, 0.0271, 0.0184, 0.0198,
         0.0302, 0.0162, 0.0171, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 34
images/59
(64, 64, 3)
tensor([[0.0292, 0.0245, 0.0187, 0.0187, 0.0295, 0.0171, 0.0233, 0.0140, 0.0146,
         0.0168, 0.0220, 0.0214, 0.0334, 0.0198, 0.0209, 0.0138, 0.0224, 0.0453,
         0.0231, 0.0215, 0.0153, 0.0305, 0.0170, 0.0239, 0.0257, 0.0191, 0.0297,
         0.0476, 0.0309, 0.0376, 0.0193, 0.0347, 0.0329, 0.0144, 0.0222, 0.0355,
         0.0332, 0.0216, 0.0307, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 35
images/513
(64, 64, 3)
tensor([[0.0280, 0.0289, 0.0127, 0.0134, 0.0353, 0.0249, 0.0335, 0.0272, 0.0304,
         0.0208, 0.0169, 0.0274, 0.0517, 0.0459, 0.0234, 0.0200, 0.0200, 0.0341,
         0.0233, 0.0159, 0.0202, 0.0187, 0.0205, 0.0251, 0.0241, 0.0158, 0.0247,
         0.0243, 0.0524, 0.0292, 0.0171, 0.0225, 0.0226, 0.0226, 0.0238, 0.0236,
         0.0189, 0.0203, 0.0186, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 36
images/509
(64, 64, 3)
tensor([[0.0278, 0.0255, 0.0159, 0.0335, 0.0287, 0.0205, 0.0408, 0.0223, 0.0189,
         0.0164, 0.0148, 0.0240, 0.0290, 0.0320, 0.0239, 0.0192, 0.0158, 0.0458,
         0.0130, 0.0228, 0.0129, 0.0210, 0.0170, 0.0149, 0.0170, 0.0232, 0.0219,
         0.0329, 0.0468, 0.0304, 0.0209, 0.0337, 0.0204, 0.0251, 0.0280, 0.0398,
         0.0293, 0.0215, 0.0224, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 37
images/584
(64, 64, 3)
tensor([[0.0195, 0.0342, 0.0188, 0.0159, 0.0410, 0.0273, 0.0410, 0.0134, 0.0191,
         0.0143, 0.0198, 0.0281, 0.0525, 0.0386, 0.0200, 0.0267, 0.0248, 0.0398,
         0.0192, 0.0159, 0.0217, 0.0275, 0.0240, 0.0314, 0.0177, 0.0228, 0.0207,
         0.0368, 0.0292, 0.0215, 0.0187, 0.0212, 0.0268, 0.0215, 0.0237, 0.0261,
         0.0211, 0.0150, 0.0186, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 38
images/513
(64, 64, 3)
tensor([[0.0240, 0.0277, 0.0206, 0.0140, 0.0342, 0.0211, 0.0320, 0.0195, 0.0217,
         0.0173, 0.0168, 0.0407, 0.0343, 0.0267, 0.0381, 0.0204, 0.0160, 0.0374,
         0.0257, 0.0170, 0.0224, 0.0211, 0.0151, 0.0265, 0.0240, 0.0210, 0.0231,
         0.0367, 0.0312, 0.0228, 0.0274, 0.0286, 0.0235, 0.0183, 0.0347, 0.0328,
         0.0253, 0.0207, 0.0200, 0.0195]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 39
images/126
(64, 64, 3)
tensor([[0.0338, 0.0205, 0.0245, 0.0157, 0.0368, 0.0147, 0.0306, 0.0190, 0.0145,
         0.0335, 0.0139, 0.0188, 0.0418, 0.0388, 0.0221, 0.0218, 0.0135, 0.0372,
         0.0218, 0.0196, 0.0199, 0.0284, 0.0197, 0.0215, 0.0265, 0.0217, 0.0205,
         0.0348, 0.0278, 0.0214, 0.0133, 0.0514, 0.0347, 0.0133, 0.0290, 0.0253,
         0.0268, 0.0192, 0.0291, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 1
Session Number: 40
images/406
(64, 64, 3)
tensor([[0.0249, 0.0383, 0.0118, 0.0365, 0.0313, 0.0265, 0.0310, 0.0174, 0.0146,
         0.0159, 0.0221, 0.0225, 0.0228, 0.0412, 0.0221, 0.0165, 0.0255, 0.0288,
         0.0173, 0.0285, 0.0202, 0.0228, 0.0284, 0.0185, 0.0243, 0.0308, 0.0218,
         0.0295, 0.0408, 0.0259, 0.0165, 0.0297, 0.0361, 0.0238, 0.0176, 0.0257,
         0.0262, 0.0260, 0.0171, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 41
images/503
(64, 64, 3)
tensor([[0.0374, 0.0210, 0.0157, 0.0176, 0.0260, 0.0167, 0.0397, 0.0172, 0.0230,
         0.0162, 0.0225, 0.0221, 0.0346, 0.0320, 0.0188, 0.0297, 0.0215, 0.0474,
         0.0261, 0.0111, 0.0244, 0.0170, 0.0140, 0.0192, 0.0167, 0.0227, 0.0221,
         0.0382, 0.0317, 0.0234, 0.0192, 0.0284, 0.0370, 0.0281, 0.0226, 0.0299,
         0.0379, 0.0171, 0.0242, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 42
images/256
(64, 64, 3)
tensor([[0.0284, 0.0203, 0.0193, 0.0174, 0.0370, 0.0153, 0.0262, 0.0249, 0.0223,
         0.0229, 0.0180, 0.0460, 0.0585, 0.0307, 0.0304, 0.0293, 0.0179, 0.0362,
         0.0192, 0.0225, 0.0281, 0.0200, 0.0228, 0.0140, 0.0144, 0.0142, 0.0357,
         0.0381, 0.0170, 0.0331, 0.0190, 0.0252, 0.0192, 0.0230, 0.0282, 0.0310,
         0.0239, 0.0140, 0.0205, 0.0159]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 43
images/76
(64, 64, 3)
tensor([[0.0281, 0.0261, 0.0141, 0.0121, 0.0265, 0.0212, 0.0269, 0.0169, 0.0141,
         0.0268, 0.0254, 0.0330, 0.0471, 0.0326, 0.0311, 0.0146, 0.0188, 0.0620,
         0.0271, 0.0221, 0.0137, 0.0215, 0.0222, 0.0177, 0.0200, 0.0133, 0.0267,
         0.0360, 0.0326, 0.0153, 0.0272, 0.0363, 0.0221, 0.0287, 0.0197, 0.0226,
         0.0211, 0.0244, 0.0267, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/593
(64, 64, 3)
tensor([[0.0302, 0.0301, 0.0160, 0.0168, 0.0318, 0.0211, 0.0291, 0.0226, 0.0213,
         0.0151, 0.0166, 0.0302, 0.0343, 0.0379, 0.0344, 0.0180, 0.0200, 0.0410,
         0.0167, 0.0273, 0.0174, 0.0279, 0.0187, 0.0251, 0.0175, 0.0149, 0.0281,
         0.0368, 0.0302, 0.0213, 0.0209, 0.0301, 0.0276, 0.0329, 0.0218, 0.0275,
         0.0199, 0.0265, 0.0193, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 45
images/364
(64, 64, 3)
tensor([[0.0414, 0.0196, 0.0219, 0.0216, 0.0285, 0.0151, 0.0206, 0.0177, 0.0212,
         0.0133, 0.0140, 0.0396, 0.0389, 0.0301, 0.0247, 0.0269, 0.0191, 0.0370,
         0.0205, 0.0222, 0.0188, 0.0218, 0.0195, 0.0220, 0.0163, 0.0184, 0.0315,
         0.0362, 0.0449, 0.0208, 0.0172, 0.0361, 0.0243, 0.0372, 0.0158, 0.0312,
         0.0222, 0.0179, 0.0189, 0.0349]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 46
images/173
(64, 64, 3)
tensor([[0.0226, 0.0286, 0.0153, 0.0144, 0.0307, 0.0172, 0.0484, 0.0189, 0.0118,
         0.0154, 0.0180, 0.0251, 0.0563, 0.0281, 0.0244, 0.0138, 0.0182, 0.0287,
         0.0195, 0.0303, 0.0213, 0.0281, 0.0316, 0.0195, 0.0140, 0.0135, 0.0320,
         0.0351, 0.0341, 0.0254, 0.0182, 0.0354, 0.0421, 0.0291, 0.0186, 0.0278,
         0.0241, 0.0197, 0.0215, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 47
images/343
(64, 64, 3)
tensor([[0.0324, 0.0272, 0.0192, 0.0209, 0.0294, 0.0354, 0.0379, 0.0182, 0.0177,
         0.0206, 0.0229, 0.0276, 0.0459, 0.0300, 0.0144, 0.0228, 0.0172, 0.0294,
         0.0227, 0.0203, 0.0100, 0.0202, 0.0110, 0.0216, 0.0181, 0.0167, 0.0239,
         0.0380, 0.0339, 0.0238, 0.0184, 0.0202, 0.0282, 0.0249, 0.0264, 0.0405,
         0.0374, 0.0222, 0.0172, 0.0353]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 0
Session Number: 48
images/47
(64, 64, 3)
tensor([[0.0329, 0.0204, 0.0200, 0.0156, 0.0438, 0.0225, 0.0281, 0.0102, 0.0224,
         0.0157, 0.0205, 0.0483, 0.0309, 0.0317, 0.0203, 0.0236, 0.0187, 0.0340,
         0.0189, 0.0301, 0.0254, 0.0347, 0.0164, 0.0207, 0.0208, 0.0210, 0.0319,
         0.0282, 0.0272, 0.0230, 0.0226, 0.0294, 0.0162, 0.0287, 0.0302, 0.0195,
         0.0339, 0.0173, 0.0182, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 49
images/582
(64, 64, 3)
tensor([[0.0226, 0.0328, 0.0176, 0.0184, 0.0285, 0.0244, 0.0450, 0.0181, 0.0205,
         0.0353, 0.0179, 0.0248, 0.0560, 0.0427, 0.0225, 0.0173, 0.0180, 0.0439,
         0.0216, 0.0226, 0.0144, 0.0193, 0.0166, 0.0136, 0.0142, 0.0141, 0.0174,
         0.0501, 0.0303, 0.0230, 0.0111, 0.0249, 0.0288, 0.0215, 0.0243, 0.0255,
         0.0238, 0.0185, 0.0314, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 50
images/18
(64, 64, 3)
tensor([[0.0451, 0.0269, 0.0173, 0.0156, 0.0467, 0.0184, 0.0429, 0.0172, 0.0159,
         0.0180, 0.0221, 0.0288, 0.0251, 0.0349, 0.0226, 0.0183, 0.0184, 0.0296,
         0.0163, 0.0160, 0.0266, 0.0275, 0.0202, 0.0282, 0.0266, 0.0160, 0.0221,
         0.0238, 0.0291, 0.0271, 0.0129, 0.0320, 0.0339, 0.0209, 0.0199, 0.0285,
         0.0287, 0.0252, 0.0323, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 51
images/421
(64, 64, 3)
tensor([[0.0333, 0.0336, 0.0241, 0.0179, 0.0276, 0.0124, 0.0300, 0.0213, 0.0260,
         0.0163, 0.0166, 0.0416, 0.0328, 0.0359, 0.0205, 0.0166, 0.0224, 0.0441,
         0.0160, 0.0209, 0.0148, 0.0248, 0.0200, 0.0245, 0.0111, 0.0180, 0.0279,
         0.0353, 0.0399, 0.0194, 0.0178, 0.0221, 0.0342, 0.0374, 0.0196, 0.0211,
         0.0313, 0.0233, 0.0202, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/572
(64, 64, 3)
tensor([[0.0371, 0.0196, 0.0248, 0.0124, 0.0359, 0.0259, 0.0227, 0.0242, 0.0153,
         0.0212, 0.0178, 0.0209, 0.0372, 0.0282, 0.0245, 0.0198, 0.0186, 0.0250,
         0.0262, 0.0181, 0.0199, 0.0205, 0.0210, 0.0175, 0.0333, 0.0272, 0.0237,
         0.0311, 0.0302, 0.0287, 0.0257, 0.0221, 0.0406, 0.0221, 0.0351, 0.0294,
         0.0402, 0.0209, 0.0187, 0.0170]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 53
images/327
(64, 64, 3)
tensor([[0.0329, 0.0341, 0.0168, 0.0234, 0.0368, 0.0149, 0.0341, 0.0284, 0.0219,
         0.0299, 0.0186, 0.0341, 0.0351, 0.0293, 0.0295, 0.0157, 0.0135, 0.0322,
         0.0141, 0.0221, 0.0185, 0.0255, 0.0192, 0.0206, 0.0274, 0.0136, 0.0226,
         0.0289, 0.0220, 0.0282, 0.0107, 0.0205, 0.0466, 0.0204, 0.0312, 0.0203,
         0.0260, 0.0209, 0.0208, 0.0384]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 54
images/556
(64, 64, 3)
tensor([[0.0244, 0.0259, 0.0208, 0.0142, 0.0326, 0.0133, 0.0361, 0.0231, 0.0308,
         0.0115, 0.0210, 0.0251, 0.0495, 0.0473, 0.0229, 0.0203, 0.0223, 0.0393,
         0.0222, 0.0186, 0.0149, 0.0296, 0.0203, 0.0139, 0.0212, 0.0158, 0.0257,
         0.0333, 0.0318, 0.0283, 0.0225, 0.0237, 0.0308, 0.0197, 0.0238, 0.0319,
         0.0256, 0.0142, 0.0254, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 55
images/148
(64, 64, 3)
tensor([[0.0257, 0.0251, 0.0189, 0.0185, 0.0401, 0.0198, 0.0388, 0.0191, 0.0220,
         0.0206, 0.0157, 0.0240, 0.0494, 0.0266, 0.0302, 0.0185, 0.0211, 0.0494,
         0.0174, 0.0197, 0.0249, 0.0215, 0.0125, 0.0153, 0.0187, 0.0165, 0.0273,
         0.0284, 0.0254, 0.0328, 0.0249, 0.0272, 0.0382, 0.0219, 0.0291, 0.0262,
         0.0271, 0.0255, 0.0123, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 56
images/546
(64, 64, 3)
tensor([[0.0224, 0.0352, 0.0123, 0.0191, 0.0410, 0.0237, 0.0288, 0.0153, 0.0232,
         0.0172, 0.0146, 0.0188, 0.0347, 0.0449, 0.0269, 0.0187, 0.0201, 0.0260,
         0.0217, 0.0136, 0.0119, 0.0333, 0.0165, 0.0283, 0.0250, 0.0284, 0.0421,
         0.0227, 0.0298, 0.0291, 0.0183, 0.0442, 0.0240, 0.0179, 0.0247, 0.0356,
         0.0264, 0.0199, 0.0221, 0.0218]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 57
images/144
(64, 64, 3)
tensor([[0.0230, 0.0419, 0.0261, 0.0215, 0.0218, 0.0243, 0.0274, 0.0189, 0.0101,
         0.0256, 0.0383, 0.0229, 0.0468, 0.0247, 0.0211, 0.0186, 0.0167, 0.0383,
         0.0234, 0.0191, 0.0195, 0.0139, 0.0255, 0.0249, 0.0271, 0.0211, 0.0190,
         0.0306, 0.0378, 0.0344, 0.0166, 0.0332, 0.0242, 0.0309, 0.0205, 0.0341,
         0.0272, 0.0170, 0.0151, 0.0170]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 58
images/52
(64, 64, 3)
tensor([[0.0448, 0.0368, 0.0183, 0.0188, 0.0413, 0.0148, 0.0300, 0.0132, 0.0136,
         0.0197, 0.0207, 0.0284, 0.0362, 0.0293, 0.0262, 0.0171, 0.0162, 0.0495,
         0.0198, 0.0223, 0.0181, 0.0161, 0.0188, 0.0206, 0.0123, 0.0215, 0.0315,
         0.0277, 0.0323, 0.0220, 0.0212, 0.0195, 0.0181, 0.0149, 0.0279, 0.0219,
         0.0517, 0.0210, 0.0325, 0.0332]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 59
images/346
(64, 64, 3)
tensor([[0.0224, 0.0254, 0.0204, 0.0177, 0.0429, 0.0202, 0.0233, 0.0215, 0.0220,
         0.0150, 0.0236, 0.0343, 0.0422, 0.0371, 0.0167, 0.0123, 0.0166, 0.0342,
         0.0171, 0.0279, 0.0149, 0.0261, 0.0212, 0.0231, 0.0202, 0.0206, 0.0208,
         0.0365, 0.0383, 0.0202, 0.0148, 0.0250, 0.0291, 0.0243, 0.0342, 0.0468,
         0.0220, 0.0144, 0.0292, 0.0258]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 60
images/566
(64, 64, 3)
tensor([[0.0418, 0.0196, 0.0190, 0.0234, 0.0302, 0.0218, 0.0285, 0.0187, 0.0172,
         0.0175, 0.0209, 0.0407, 0.0264, 0.0273, 0.0245, 0.0197, 0.0147, 0.0480,
         0.0236, 0.0180, 0.0126, 0.0357, 0.0207, 0.0305, 0.0262, 0.0226, 0.0284,
         0.0360, 0.0419, 0.0183, 0.0129, 0.0271, 0.0247, 0.0245, 0.0196, 0.0171,
         0.0319, 0.0171, 0.0230, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 61
images/100
(64, 64, 3)
tensor([[0.0258, 0.0366, 0.0246, 0.0203, 0.0265, 0.0156, 0.0368, 0.0169, 0.0180,
         0.0284, 0.0174, 0.0294, 0.0514, 0.0216, 0.0321, 0.0156, 0.0243, 0.0376,
         0.0205, 0.0175, 0.0211, 0.0305, 0.0165, 0.0181, 0.0258, 0.0123, 0.0235,
         0.0232, 0.0358, 0.0238, 0.0139, 0.0280, 0.0258, 0.0268, 0.0203, 0.0313,
         0.0348, 0.0173, 0.0305, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 62
images/9
(64, 64, 3)
tensor([[0.0286, 0.0348, 0.0208, 0.0240, 0.0355, 0.0159, 0.0305, 0.0131, 0.0182,
         0.0214, 0.0138, 0.0293, 0.0331, 0.0335, 0.0415, 0.0194, 0.0293, 0.0256,
         0.0149, 0.0277, 0.0254, 0.0260, 0.0269, 0.0212, 0.0287, 0.0184, 0.0213,
         0.0316, 0.0212, 0.0268, 0.0151, 0.0210, 0.0412, 0.0232, 0.0164, 0.0267,
         0.0234, 0.0204, 0.0208, 0.0333]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 63
images/583
(64, 64, 3)
tensor([[0.0264, 0.0296, 0.0160, 0.0183, 0.0230, 0.0270, 0.0400, 0.0167, 0.0287,
         0.0160, 0.0136, 0.0432, 0.0301, 0.0306, 0.0266, 0.0238, 0.0183, 0.0405,
         0.0251, 0.0244, 0.0142, 0.0315, 0.0163, 0.0217, 0.0383, 0.0144, 0.0211,
         0.0337, 0.0358, 0.0198, 0.0327, 0.0166, 0.0209, 0.0167, 0.0220, 0.0255,
         0.0211, 0.0181, 0.0246, 0.0369]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 64
images/441
(64, 64, 3)
tensor([[0.0343, 0.0326, 0.0182, 0.0156, 0.0321, 0.0237, 0.0310, 0.0144, 0.0235,
         0.0296, 0.0185, 0.0343, 0.0424, 0.0277, 0.0210, 0.0194, 0.0202, 0.0325,
         0.0250, 0.0256, 0.0200, 0.0193, 0.0233, 0.0174, 0.0262, 0.0219, 0.0158,
         0.0361, 0.0370, 0.0255, 0.0144, 0.0275, 0.0268, 0.0235, 0.0206, 0.0428,
         0.0181, 0.0238, 0.0195, 0.0188]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 65
images/255
(64, 64, 3)
tensor([[0.0227, 0.0260, 0.0184, 0.0135, 0.0454, 0.0337, 0.0255, 0.0149, 0.0126,
         0.0182, 0.0160, 0.0386, 0.0357, 0.0384, 0.0285, 0.0197, 0.0224, 0.0242,
         0.0289, 0.0303, 0.0209, 0.0296, 0.0143, 0.0253, 0.0191, 0.0162, 0.0364,
         0.0462, 0.0331, 0.0218, 0.0161, 0.0322, 0.0296, 0.0221, 0.0225, 0.0256,
         0.0195, 0.0221, 0.0144, 0.0191]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 66
images/368
(64, 64, 3)
tensor([[0.0185, 0.0344, 0.0208, 0.0160, 0.0297, 0.0216, 0.0489, 0.0109, 0.0151,
         0.0208, 0.0190, 0.0306, 0.0293, 0.0264, 0.0344, 0.0161, 0.0178, 0.0582,
         0.0166, 0.0266, 0.0225, 0.0252, 0.0204, 0.0151, 0.0240, 0.0174, 0.0304,
         0.0175, 0.0248, 0.0204, 0.0141, 0.0338, 0.0245, 0.0211, 0.0148, 0.0450,
         0.0332, 0.0265, 0.0275, 0.0302]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 67
images/597
(64, 64, 3)
tensor([[0.0314, 0.0299, 0.0194, 0.0138, 0.0222, 0.0249, 0.0487, 0.0237, 0.0147,
         0.0229, 0.0244, 0.0383, 0.0458, 0.0336, 0.0205, 0.0111, 0.0168, 0.0281,
         0.0179, 0.0283, 0.0198, 0.0245, 0.0170, 0.0221, 0.0240, 0.0186, 0.0271,
         0.0240, 0.0418, 0.0265, 0.0195, 0.0427, 0.0250, 0.0184, 0.0165, 0.0345,
         0.0300, 0.0153, 0.0158, 0.0201]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/515
(64, 64, 3)
tensor([[0.0152, 0.0376, 0.0247, 0.0109, 0.0345, 0.0113, 0.0445, 0.0184, 0.0222,
         0.0292, 0.0200, 0.0339, 0.0566, 0.0258, 0.0296, 0.0181, 0.0223, 0.0299,
         0.0165, 0.0199, 0.0212, 0.0181, 0.0162, 0.0160, 0.0238, 0.0172, 0.0176,
         0.0250, 0.0498, 0.0254, 0.0114, 0.0222, 0.0349, 0.0235, 0.0166, 0.0217,
         0.0417, 0.0186, 0.0219, 0.0359]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1 
Session Number: 69
images/392
(64, 64, 3)
tensor([[0.0334, 0.0251, 0.0128, 0.0126, 0.0384, 0.0175, 0.0408, 0.0127, 0.0216,
         0.0191, 0.0245, 0.0214, 0.0508, 0.0361, 0.0251, 0.0177, 0.0214, 0.0554,
         0.0184, 0.0161, 0.0106, 0.0284, 0.0108, 0.0175, 0.0181, 0.0175, 0.0229,
         0.0334, 0.0354, 0.0306, 0.0194, 0.0364, 0.0412, 0.0144, 0.0351, 0.0292,
         0.0152, 0.0197, 0.0180, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 70
images/111
(64, 64, 3)
tensor([[0.0293, 0.0288, 0.0203, 0.0256, 0.0338, 0.0194, 0.0355, 0.0169, 0.0213,
         0.0189, 0.0217, 0.0333, 0.0357, 0.0303, 0.0289, 0.0176, 0.0161, 0.0311,
         0.0218, 0.0255, 0.0186, 0.0347, 0.0203, 0.0182, 0.0250, 0.0236, 0.0241,
         0.0212, 0.0252, 0.0382, 0.0211, 0.0314, 0.0273, 0.0164, 0.0174, 0.0322,
         0.0180, 0.0201, 0.0331, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 71
images/166
(64, 64, 3)
tensor([[0.0291, 0.0186, 0.0193, 0.0151, 0.0252, 0.0210, 0.0293, 0.0205, 0.0182,
         0.0257, 0.0158, 0.0235, 0.0295, 0.0368, 0.0259, 0.0117, 0.0192, 0.0318,
         0.0144, 0.0298, 0.0185, 0.0259, 0.0241, 0.0204, 0.0178, 0.0214, 0.0276,
         0.0425, 0.0292, 0.0183, 0.0163, 0.0315, 0.0404, 0.0357, 0.0239, 0.0286,
         0.0308, 0.0218, 0.0379, 0.0270]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 72
images/427
(64, 64, 3)
tensor([[0.0315, 0.0322, 0.0227, 0.0143, 0.0348, 0.0208, 0.0320, 0.0226, 0.0176,
         0.0143, 0.0186, 0.0339, 0.0433, 0.0299, 0.0201, 0.0168, 0.0137, 0.0289,
         0.0192, 0.0140, 0.0201, 0.0321, 0.0261, 0.0179, 0.0275, 0.0153, 0.0270,
         0.0331, 0.0328, 0.0286, 0.0149, 0.0328, 0.0185, 0.0396, 0.0304, 0.0346,
         0.0329, 0.0167, 0.0158, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 73
images/130
(64, 64, 3)
tensor([[0.0242, 0.0302, 0.0168, 0.0198, 0.0333, 0.0168, 0.0377, 0.0114, 0.0186,
         0.0238, 0.0272, 0.0257, 0.0263, 0.0202, 0.0260, 0.0137, 0.0182, 0.0379,
         0.0231, 0.0187, 0.0131, 0.0235, 0.0217, 0.0139, 0.0230, 0.0210, 0.0224,
         0.0228, 0.0287, 0.0273, 0.0164, 0.0350, 0.0439, 0.0355, 0.0211, 0.0428,
         0.0365, 0.0255, 0.0251, 0.0312]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 74
images/588
(64, 64, 3)
tensor([[0.0392, 0.0232, 0.0152, 0.0132, 0.0301, 0.0287, 0.0228, 0.0112, 0.0136,
         0.0171, 0.0193, 0.0464, 0.0525, 0.0184, 0.0257, 0.0172, 0.0181, 0.0386,
         0.0235, 0.0138, 0.0174, 0.0191, 0.0203, 0.0276, 0.0243, 0.0168, 0.0225,
         0.0355, 0.0450, 0.0140, 0.0197, 0.0268, 0.0198, 0.0336, 0.0225, 0.0244,
         0.0285, 0.0215, 0.0405, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 75
images/332
(64, 64, 3)
tensor([[0.0221, 0.0355, 0.0127, 0.0277, 0.0365, 0.0230, 0.0298, 0.0177, 0.0183,
         0.0244, 0.0162, 0.0160, 0.0437, 0.0322, 0.0236, 0.0252, 0.0188, 0.0336,
         0.0326, 0.0164, 0.0221, 0.0256, 0.0192, 0.0260, 0.0283, 0.0188, 0.0286,
         0.0397, 0.0336, 0.0202, 0.0146, 0.0346, 0.0201, 0.0244, 0.0174, 0.0407,
         0.0158, 0.0181, 0.0217, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 76
images/239
(64, 64, 3)
tensor([[0.0210, 0.0206, 0.0182, 0.0140, 0.0264, 0.0188, 0.0448, 0.0137, 0.0203,
         0.0174, 0.0161, 0.0603, 0.0387, 0.0262, 0.0418, 0.0306, 0.0157, 0.0301,
         0.0239, 0.0159, 0.0192, 0.0202, 0.0253, 0.0185, 0.0171, 0.0187, 0.0209,
         0.0285, 0.0375, 0.0279, 0.0133, 0.0206, 0.0218, 0.0229, 0.0292, 0.0419,
         0.0387, 0.0190, 0.0173, 0.0270]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 77
images/73
(64, 64, 3)
tensor([[0.0227, 0.0177, 0.0221, 0.0119, 0.0479, 0.0176, 0.0298, 0.0210, 0.0187,
         0.0146, 0.0180, 0.0261, 0.0338, 0.0324, 0.0227, 0.0230, 0.0283, 0.0561,
         0.0205, 0.0228, 0.0169, 0.0181, 0.0175, 0.0218, 0.0272, 0.0132, 0.0228,
         0.0317, 0.0367, 0.0316, 0.0209, 0.0377, 0.0353, 0.0316, 0.0208, 0.0247,
         0.0211, 0.0129, 0.0161, 0.0339]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 78
images/517
(64, 64, 3)
tensor([[0.0359, 0.0251, 0.0158, 0.0189, 0.0261, 0.0153, 0.0420, 0.0221, 0.0167,
         0.0190, 0.0257, 0.0506, 0.0297, 0.0263, 0.0255, 0.0206, 0.0213, 0.0294,
         0.0220, 0.0191, 0.0225, 0.0302, 0.0146, 0.0242, 0.0148, 0.0236, 0.0347,
         0.0193, 0.0404, 0.0314, 0.0163, 0.0211, 0.0185, 0.0168, 0.0210, 0.0284,
         0.0382, 0.0231, 0.0361, 0.0179]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 79
images/203
(64, 64, 3)
tensor([[0.0332, 0.0267, 0.0156, 0.0212, 0.0388, 0.0213, 0.0272, 0.0212, 0.0153,
         0.0234, 0.0248, 0.0340, 0.0542, 0.0247, 0.0204, 0.0212, 0.0138, 0.0365,
         0.0255, 0.0246, 0.0149, 0.0331, 0.0254, 0.0186, 0.0246, 0.0255, 0.0179,
         0.0420, 0.0224, 0.0304, 0.0188, 0.0241, 0.0247, 0.0197, 0.0199, 0.0249,
         0.0160, 0.0282, 0.0236, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 80
images/468
(64, 64, 3)
tensor([[0.0224, 0.0307, 0.0177, 0.0190, 0.0319, 0.0161, 0.0261, 0.0202, 0.0194,
         0.0223, 0.0155, 0.0345, 0.0370, 0.0185, 0.0293, 0.0215, 0.0258, 0.0351,
         0.0231, 0.0182, 0.0195, 0.0312, 0.0144, 0.0290, 0.0224, 0.0157, 0.0261,
         0.0336, 0.0246, 0.0250, 0.0218, 0.0293, 0.0211, 0.0370, 0.0234, 0.0327,
         0.0261, 0.0180, 0.0330, 0.0320]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 81
images/585
(64, 64, 3)
tensor([[0.0225, 0.0195, 0.0223, 0.0152, 0.0351, 0.0259, 0.0307, 0.0176, 0.0167,
         0.0293, 0.0142, 0.0260, 0.0234, 0.0228, 0.0283, 0.0197, 0.0193, 0.0692,
         0.0229, 0.0273, 0.0184, 0.0362, 0.0227, 0.0208, 0.0168, 0.0161, 0.0277,
         0.0355, 0.0295, 0.0289, 0.0139, 0.0270, 0.0358, 0.0164, 0.0310, 0.0215,
         0.0275, 0.0234, 0.0210, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 82
images/371
(64, 64, 3)
tensor([[0.0267, 0.0343, 0.0225, 0.0156, 0.0429, 0.0208, 0.0327, 0.0192, 0.0145,
         0.0190, 0.0268, 0.0349, 0.0500, 0.0231, 0.0180, 0.0178, 0.0272, 0.0337,
         0.0215, 0.0140, 0.0185, 0.0328, 0.0242, 0.0238, 0.0221, 0.0281, 0.0277,
         0.0271, 0.0383, 0.0177, 0.0176, 0.0300, 0.0268, 0.0224, 0.0173, 0.0216,
         0.0382, 0.0198, 0.0161, 0.0147]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 83
images/484
(64, 64, 3)
tensor([[0.0286, 0.0408, 0.0162, 0.0229, 0.0227, 0.0181, 0.0260, 0.0116, 0.0148,
         0.0139, 0.0197, 0.0306, 0.0541, 0.0307, 0.0378, 0.0226, 0.0211, 0.0373,
         0.0160, 0.0263, 0.0173, 0.0260, 0.0175, 0.0231, 0.0206, 0.0191, 0.0298,
         0.0310, 0.0264, 0.0235, 0.0188, 0.0279, 0.0202, 0.0310, 0.0318, 0.0318,
         0.0287, 0.0200, 0.0172, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 84
images/41
(64, 64, 3)
tensor([[0.0337, 0.0242, 0.0195, 0.0200, 0.0312, 0.0215, 0.0258, 0.0208, 0.0153,
         0.0275, 0.0211, 0.0380, 0.0358, 0.0273, 0.0191, 0.0232, 0.0346, 0.0361,
         0.0208, 0.0120, 0.0202, 0.0280, 0.0214, 0.0202, 0.0218, 0.0199, 0.0206,
         0.0386, 0.0368, 0.0180, 0.0203, 0.0236, 0.0215, 0.0233, 0.0180, 0.0348,
         0.0387, 0.0117, 0.0275, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 85
images/192
(64, 64, 3)
tensor([[0.0202, 0.0275, 0.0194, 0.0289, 0.0348, 0.0222, 0.0291, 0.0169, 0.0130,
         0.0217, 0.0233, 0.0265, 0.0284, 0.0427, 0.0295, 0.0224, 0.0282, 0.0513,
         0.0181, 0.0260, 0.0215, 0.0224, 0.0122, 0.0196, 0.0146, 0.0202, 0.0228,
         0.0328, 0.0357, 0.0179, 0.0165, 0.0266, 0.0267, 0.0219, 0.0309, 0.0287,
         0.0311, 0.0209, 0.0198, 0.0270]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 86
images/300
(64, 64, 3)
tensor([[0.0249, 0.0253, 0.0107, 0.0126, 0.0231, 0.0155, 0.0337, 0.0243, 0.0148,
         0.0220, 0.0392, 0.0344, 0.0372, 0.0400, 0.0231, 0.0148, 0.0285, 0.0239,
         0.0179, 0.0122, 0.0183, 0.0298, 0.0206, 0.0297, 0.0168, 0.0156, 0.0397,
         0.0330, 0.0237, 0.0233, 0.0106, 0.0345, 0.0334, 0.0266, 0.0399, 0.0253,
         0.0315, 0.0175, 0.0339, 0.0185]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 87
images/371
(64, 64, 3)
tensor([[0.0355, 0.0322, 0.0150, 0.0178, 0.0273, 0.0294, 0.0391, 0.0177, 0.0137,
         0.0175, 0.0256, 0.0390, 0.0514, 0.0235, 0.0259, 0.0217, 0.0187, 0.0343,
         0.0166, 0.0150, 0.0229, 0.0352, 0.0194, 0.0159, 0.0217, 0.0181, 0.0207,
         0.0345, 0.0365, 0.0207, 0.0189, 0.0256, 0.0275, 0.0293, 0.0203, 0.0241,
         0.0167, 0.0186, 0.0318, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 88
images/285
(64, 64, 3)
tensor([[0.0240, 0.0231, 0.0153, 0.0184, 0.0369, 0.0221, 0.0524, 0.0248, 0.0183,
         0.0197, 0.0322, 0.0309, 0.0437, 0.0310, 0.0205, 0.0132, 0.0203, 0.0361,
         0.0246, 0.0235, 0.0138, 0.0238, 0.0278, 0.0207, 0.0237, 0.0169, 0.0198,
         0.0244, 0.0349, 0.0250, 0.0146, 0.0260, 0.0221, 0.0206, 0.0247, 0.0387,
         0.0308, 0.0139, 0.0202, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/112
(64, 64, 3)
tensor([[0.0270, 0.0259, 0.0214, 0.0138, 0.0383, 0.0208, 0.0240, 0.0154, 0.0191,
         0.0175, 0.0200, 0.0366, 0.0507, 0.0416, 0.0255, 0.0189, 0.0201, 0.0476,
         0.0165, 0.0200, 0.0185, 0.0152, 0.0219, 0.0259, 0.0195, 0.0212, 0.0249,
         0.0316, 0.0284, 0.0203, 0.0173, 0.0291, 0.0304, 0.0279, 0.0180, 0.0343,
         0.0277, 0.0198, 0.0187, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 90
images/567
(64, 64, 3)
tensor([[0.0246, 0.0216, 0.0253, 0.0268, 0.0410, 0.0265, 0.0293, 0.0195, 0.0149,
         0.0185, 0.0149, 0.0374, 0.0268, 0.0307, 0.0279, 0.0261, 0.0208, 0.0227,
         0.0146, 0.0301, 0.0188, 0.0287, 0.0249, 0.0367, 0.0275, 0.0183, 0.0276,
         0.0316, 0.0419, 0.0184, 0.0117, 0.0169, 0.0186, 0.0206, 0.0262, 0.0250,
         0.0319, 0.0246, 0.0254, 0.0247]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 91
images/551
(64, 64, 3)
tensor([[0.0258, 0.0377, 0.0185, 0.0309, 0.0251, 0.0252, 0.0283, 0.0208, 0.0149,
         0.0286, 0.0162, 0.0507, 0.0389, 0.0218, 0.0207, 0.0225, 0.0188, 0.0280,
         0.0249, 0.0220, 0.0118, 0.0148, 0.0212, 0.0219, 0.0208, 0.0157, 0.0206,
         0.0434, 0.0361, 0.0253, 0.0177, 0.0411, 0.0200, 0.0213, 0.0232, 0.0311,
         0.0212, 0.0192, 0.0191, 0.0342]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 92
images/551
(64, 64, 3)
tensor([[0.0278, 0.0310, 0.0181, 0.0229, 0.0209, 0.0208, 0.0264, 0.0194, 0.0219,
         0.0229, 0.0228, 0.0267, 0.0409, 0.0284, 0.0227, 0.0231, 0.0208, 0.0407,
         0.0170, 0.0202, 0.0184, 0.0191, 0.0171, 0.0266, 0.0231, 0.0118, 0.0233,
         0.0299, 0.0440, 0.0203, 0.0228, 0.0313, 0.0228, 0.0278, 0.0256, 0.0401,
         0.0250, 0.0182, 0.0298, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 93
images/457
(64, 64, 3)
tensor([[0.0254, 0.0417, 0.0132, 0.0198, 0.0352, 0.0271, 0.0280, 0.0163, 0.0172,
         0.0243, 0.0252, 0.0259, 0.0423, 0.0316, 0.0245, 0.0245, 0.0219, 0.0405,
         0.0198, 0.0159, 0.0206, 0.0317, 0.0228, 0.0204, 0.0220, 0.0162, 0.0326,
         0.0219, 0.0379, 0.0278, 0.0256, 0.0216, 0.0286, 0.0283, 0.0166, 0.0213,
         0.0256, 0.0140, 0.0200, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 94
images/64
(64, 64, 3)
tensor([[0.0235, 0.0429, 0.0323, 0.0304, 0.0318, 0.0224, 0.0259, 0.0109, 0.0254,
         0.0292, 0.0200, 0.0247, 0.0617, 0.0278, 0.0209, 0.0202, 0.0116, 0.0247,
         0.0171, 0.0244, 0.0255, 0.0194, 0.0147, 0.0185, 0.0196, 0.0301, 0.0245,
         0.0335, 0.0282, 0.0221, 0.0139, 0.0208, 0.0267, 0.0188, 0.0180, 0.0273,
         0.0258, 0.0301, 0.0242, 0.0303]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 95
images/145
(64, 64, 3)
tensor([[0.0271, 0.0311, 0.0178, 0.0211, 0.0340, 0.0158, 0.0285, 0.0148, 0.0172,
         0.0214, 0.0203, 0.0286, 0.0522, 0.0401, 0.0283, 0.0142, 0.0197, 0.0342,
         0.0211, 0.0211, 0.0230, 0.0311, 0.0173, 0.0233, 0.0285, 0.0151, 0.0214,
         0.0287, 0.0279, 0.0222, 0.0134, 0.0543, 0.0288, 0.0217, 0.0137, 0.0234,
         0.0252, 0.0205, 0.0227, 0.0294]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 96
images/216
(64, 64, 3)
tensor([[0.0230, 0.0342, 0.0152, 0.0165, 0.0315, 0.0242, 0.0428, 0.0223, 0.0190,
         0.0183, 0.0275, 0.0402, 0.0466, 0.0244, 0.0258, 0.0200, 0.0130, 0.0441,
         0.0172, 0.0204, 0.0208, 0.0278, 0.0200, 0.0219, 0.0228, 0.0271, 0.0254,
         0.0375, 0.0248, 0.0229, 0.0266, 0.0269, 0.0202, 0.0221, 0.0202, 0.0323,
         0.0242, 0.0114, 0.0180, 0.0208]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 97
images/57
(64, 64, 3)
tensor([[0.0271, 0.0177, 0.0172, 0.0184, 0.0399, 0.0319, 0.0531, 0.0136, 0.0146,
         0.0227, 0.0410, 0.0332, 0.0288, 0.0381, 0.0218, 0.0114, 0.0145, 0.0341,
         0.0294, 0.0221, 0.0143, 0.0127, 0.0251, 0.0157, 0.0170, 0.0232, 0.0181,
         0.0288, 0.0346, 0.0220, 0.0193, 0.0209, 0.0243, 0.0327, 0.0212, 0.0294,
         0.0466, 0.0145, 0.0312, 0.0178]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 98
images/537
(64, 64, 3)
tensor([[0.0325, 0.0283, 0.0205, 0.0178, 0.0288, 0.0191, 0.0397, 0.0190, 0.0164,
         0.0185, 0.0257, 0.0244, 0.0330, 0.0343, 0.0197, 0.0129, 0.0219, 0.0267,
         0.0244, 0.0179, 0.0163, 0.0238, 0.0154, 0.0214, 0.0169, 0.0239, 0.0252,
         0.0419, 0.0216, 0.0187, 0.0145, 0.0414, 0.0287, 0.0317, 0.0253, 0.0499,
         0.0278, 0.0175, 0.0292, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 99
images/57
(64, 64, 3)
tensor([[0.0331, 0.0282, 0.0161, 0.0179, 0.0335, 0.0224, 0.0404, 0.0167, 0.0234,
         0.0248, 0.0208, 0.0271, 0.0459, 0.0278, 0.0228, 0.0109, 0.0241, 0.0316,
         0.0253, 0.0213, 0.0180, 0.0209, 0.0228, 0.0169, 0.0189, 0.0177, 0.0250,
         0.0302, 0.0325, 0.0247, 0.0229, 0.0365, 0.0292, 0.0255, 0.0218, 0.0310,
         0.0283, 0.0140, 0.0292, 0.0200]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Saving the weights
25 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
2Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/29
(64, 64, 3)
2018-10-12 22:23:49.615 Python[7351:15671767] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0303, 0.0202, 0.0167, 0.0215, 0.0315, 0.0205, 0.0319, 0.0181, 0.0191,
         0.0164, 0.0139, 0.0230, 0.0442, 0.0428, 0.0467, 0.0322, 0.0202, 0.0264,
         0.0207, 0.0219, 0.0159, 0.0210, 0.0328, 0.0242, 0.0297, 0.0249, 0.0172,
         0.0276, 0.0268, 0.0165, 0.0228, 0.0295, 0.0212, 0.0211, 0.0217, 0.0309,
         0.0289, 0.0268, 0.0220, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 1
images/574
(64, 64, 3)
tensor([[0.0365, 0.0258, 0.0196, 0.0135, 0.0336, 0.0190, 0.0240, 0.0273, 0.0165,
         0.0191, 0.0164, 0.0306, 0.0258, 0.0307, 0.0285, 0.0205, 0.0156, 0.0507,
         0.0176, 0.0204, 0.0165, 0.0208, 0.0157, 0.0300, 0.0339, 0.0199, 0.0152,
         0.0356, 0.0275, 0.0272, 0.0199, 0.0424, 0.0237, 0.0282, 0.0197, 0.0263,
         0.0416, 0.0243, 0.0151, 0.0249]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/314
(64, 64, 3)
tensor([[0.0244, 0.0310, 0.0134, 0.0177, 0.0284, 0.0160, 0.0306, 0.0181, 0.0195,
         0.0149, 0.0247, 0.0315, 0.0370, 0.0343, 0.0312, 0.0240, 0.0285, 0.0422,
         0.0206, 0.0119, 0.0239, 0.0260, 0.0233, 0.0275, 0.0201, 0.0207, 0.0218,
         0.0260, 0.0406, 0.0186, 0.0144, 0.0346, 0.0305, 0.0322, 0.0234, 0.0411,
         0.0255, 0.0151, 0.0187, 0.0160]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 3
images/334
(64, 64, 3)
tensor([[0.0283, 0.0317, 0.0214, 0.0172, 0.0386, 0.0215, 0.0350, 0.0187, 0.0231,
         0.0208, 0.0256, 0.0232, 0.0331, 0.0341, 0.0238, 0.0173, 0.0161, 0.0425,
         0.0186, 0.0206, 0.0216, 0.0219, 0.0139, 0.0249, 0.0281, 0.0168, 0.0192,
         0.0374, 0.0299, 0.0227, 0.0290, 0.0224, 0.0234, 0.0347, 0.0248, 0.0295,
         0.0214, 0.0256, 0.0249, 0.0168]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 4
images/321
(64, 64, 3)
tensor([[0.0184, 0.0260, 0.0239, 0.0163, 0.0427, 0.0199, 0.0157, 0.0168, 0.0153,
         0.0275, 0.0154, 0.0400, 0.0300, 0.0281, 0.0280, 0.0214, 0.0285, 0.0483,
         0.0160, 0.0174, 0.0168, 0.0280, 0.0235, 0.0246, 0.0168, 0.0271, 0.0297,
         0.0396, 0.0259, 0.0243, 0.0131, 0.0323, 0.0178, 0.0244, 0.0284, 0.0246,
         0.0228, 0.0238, 0.0170, 0.0436]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 5
images/467
(64, 64, 3)
tensor([[0.0230, 0.0282, 0.0174, 0.0156, 0.0234, 0.0240, 0.0287, 0.0244, 0.0135,
         0.0238, 0.0267, 0.0326, 0.0330, 0.0339, 0.0271, 0.0359, 0.0238, 0.0444,
         0.0155, 0.0175, 0.0152, 0.0182, 0.0268, 0.0221, 0.0162, 0.0217, 0.0231,
         0.0262, 0.0367, 0.0307, 0.0187, 0.0200, 0.0298, 0.0251, 0.0320, 0.0395,
         0.0201, 0.0143, 0.0195, 0.0319]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 6
images/415
(64, 64, 3)
tensor([[0.0371, 0.0265, 0.0161, 0.0251, 0.0253, 0.0258, 0.0291, 0.0215, 0.0251,
         0.0340, 0.0207, 0.0268, 0.0317, 0.0297, 0.0561, 0.0213, 0.0121, 0.0396,
         0.0152, 0.0354, 0.0116, 0.0259, 0.0221, 0.0199, 0.0174, 0.0164, 0.0246,
         0.0340, 0.0256, 0.0198, 0.0243, 0.0224, 0.0241, 0.0203, 0.0199, 0.0309,
         0.0199, 0.0181, 0.0206, 0.0283]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 7
images/340
(64, 64, 3)
tensor([[0.0446, 0.0278, 0.0241, 0.0170, 0.0190, 0.0182, 0.0347, 0.0113, 0.0169,
         0.0175, 0.0226, 0.0340, 0.0506, 0.0322, 0.0213, 0.0327, 0.0235, 0.0244,
         0.0152, 0.0216, 0.0153, 0.0200, 0.0163, 0.0309, 0.0185, 0.0215, 0.0409,
         0.0458, 0.0254, 0.0205, 0.0260, 0.0243, 0.0226, 0.0218, 0.0145, 0.0323,
         0.0316, 0.0147, 0.0171, 0.0309]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/491
(64, 64, 3)
tensor([[0.0274, 0.0282, 0.0143, 0.0149, 0.0357, 0.0236, 0.0288, 0.0302, 0.0207,
         0.0224, 0.0220, 0.0285, 0.0427, 0.0256, 0.0339, 0.0237, 0.0280, 0.0291,
         0.0288, 0.0193, 0.0098, 0.0167, 0.0288, 0.0305, 0.0165, 0.0189, 0.0243,
         0.0290, 0.0302, 0.0192, 0.0122, 0.0278, 0.0271, 0.0200, 0.0238, 0.0229,
         0.0227, 0.0185, 0.0254, 0.0478]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 9
images/465
(64, 64, 3)
tensor([[0.0273, 0.0330, 0.0096, 0.0169, 0.0286, 0.0127, 0.0404, 0.0164, 0.0124,
         0.0275, 0.0193, 0.0220, 0.0381, 0.0334, 0.0244, 0.0113, 0.0195, 0.0450,
         0.0211, 0.0142, 0.0215, 0.0174, 0.0134, 0.0217, 0.0167, 0.0157, 0.0309,
         0.0419, 0.0636, 0.0211, 0.0147, 0.0302, 0.0306, 0.0228, 0.0155, 0.0495,
         0.0268, 0.0192, 0.0273, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 10
images/595
(64, 64, 3)
tensor([[0.0254, 0.0228, 0.0196, 0.0141, 0.0399, 0.0192, 0.0310, 0.0161, 0.0206,
         0.0247, 0.0241, 0.0314, 0.0388, 0.0239, 0.0301, 0.0106, 0.0170, 0.0270,
         0.0271, 0.0270, 0.0164, 0.0224, 0.0269, 0.0292, 0.0178, 0.0166, 0.0342,
         0.0213, 0.0263, 0.0206, 0.0179, 0.0283, 0.0333, 0.0246, 0.0285, 0.0306,
         0.0329, 0.0216, 0.0325, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 11
images/400
(64, 64, 3)
tensor([[0.0201, 0.0352, 0.0354, 0.0158, 0.0425, 0.0200, 0.0221, 0.0135, 0.0297,
         0.0139, 0.0119, 0.0400, 0.0262, 0.0355, 0.0241, 0.0182, 0.0133, 0.0518,
         0.0133, 0.0227, 0.0188, 0.0228, 0.0221, 0.0307, 0.0210, 0.0176, 0.0239,
         0.0229, 0.0336, 0.0357, 0.0200, 0.0231, 0.0251, 0.0128, 0.0360, 0.0255,
         0.0281, 0.0258, 0.0166, 0.0326]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/515
(64, 64, 3)
tensor([[0.0305, 0.0251, 0.0204, 0.0201, 0.0316, 0.0186, 0.0263, 0.0169, 0.0220,
         0.0173, 0.0169, 0.0298, 0.0472, 0.0346, 0.0225, 0.0237, 0.0137, 0.0370,
         0.0173, 0.0191, 0.0174, 0.0239, 0.0210, 0.0281, 0.0226, 0.0228, 0.0174,
         0.0403, 0.0390, 0.0180, 0.0109, 0.0327, 0.0267, 0.0239, 0.0265, 0.0258,
         0.0239, 0.0299, 0.0247, 0.0340]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 13
images/150
(64, 64, 3)
tensor([[0.0197, 0.0204, 0.0196, 0.0117, 0.0301, 0.0458, 0.0483, 0.0241, 0.0148,
         0.0246, 0.0302, 0.0443, 0.0441, 0.0247, 0.0201, 0.0234, 0.0128, 0.0207,
         0.0144, 0.0277, 0.0260, 0.0284, 0.0133, 0.0210, 0.0225, 0.0131, 0.0274,
         0.0355, 0.0275, 0.0197, 0.0159, 0.0341, 0.0303, 0.0173, 0.0291, 0.0177,
         0.0290, 0.0171, 0.0294, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 14
images/432
(64, 64, 3)
tensor([[0.0413, 0.0190, 0.0151, 0.0166, 0.0232, 0.0234, 0.0285, 0.0151, 0.0179,
         0.0160, 0.0251, 0.0195, 0.0371, 0.0390, 0.0297, 0.0209, 0.0226, 0.0394,
         0.0145, 0.0206, 0.0156, 0.0159, 0.0324, 0.0197, 0.0219, 0.0259, 0.0266,
         0.0278, 0.0400, 0.0177, 0.0261, 0.0538, 0.0345, 0.0163, 0.0143, 0.0140,
         0.0172, 0.0202, 0.0374, 0.0383]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 15
images/301
(64, 64, 3)
tensor([[0.0242, 0.0319, 0.0169, 0.0235, 0.0410, 0.0167, 0.0317, 0.0127, 0.0149,
         0.0272, 0.0192, 0.0277, 0.0260, 0.0305, 0.0376, 0.0164, 0.0134, 0.0280,
         0.0144, 0.0231, 0.0231, 0.0202, 0.0216, 0.0232, 0.0268, 0.0211, 0.0236,
         0.0361, 0.0243, 0.0300, 0.0207, 0.0290, 0.0327, 0.0116, 0.0191, 0.0355,
         0.0394, 0.0147, 0.0353, 0.0351]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 16
images/363
(64, 64, 3)
tensor([[0.0297, 0.0317, 0.0155, 0.0187, 0.0266, 0.0153, 0.0355, 0.0166, 0.0278,
         0.0228, 0.0224, 0.0188, 0.0491, 0.0272, 0.0301, 0.0159, 0.0246, 0.0486,
         0.0201, 0.0227, 0.0155, 0.0222, 0.0193, 0.0206, 0.0156, 0.0396, 0.0255,
         0.0389, 0.0275, 0.0275, 0.0196, 0.0286, 0.0268, 0.0169, 0.0192, 0.0406,
         0.0254, 0.0187, 0.0179, 0.0143]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 17
images/484
(64, 64, 3)
tensor([[0.0176, 0.0252, 0.0224, 0.0288, 0.0284, 0.0194, 0.0223, 0.0171, 0.0168,
         0.0207, 0.0130, 0.0186, 0.0441, 0.0525, 0.0310, 0.0156, 0.0239, 0.0596,
         0.0205, 0.0166, 0.0190, 0.0308, 0.0246, 0.0179, 0.0215, 0.0139, 0.0306,
         0.0264, 0.0272, 0.0341, 0.0149, 0.0363, 0.0292, 0.0197, 0.0240, 0.0274,
         0.0216, 0.0211, 0.0212, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 18
images/404
(64, 64, 3)
tensor([[0.0204, 0.0243, 0.0173, 0.0158, 0.0335, 0.0181, 0.0389, 0.0195, 0.0152,
         0.0163, 0.0127, 0.0302, 0.0462, 0.0345, 0.0165, 0.0211, 0.0274, 0.0312,
         0.0174, 0.0231, 0.0238, 0.0236, 0.0185, 0.0178, 0.0209, 0.0179, 0.0271,
         0.0333, 0.0407, 0.0203, 0.0180, 0.0310, 0.0331, 0.0241, 0.0311, 0.0268,
         0.0469, 0.0158, 0.0217, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 19
images/477
(64, 64, 3)
tensor([[0.0238, 0.0274, 0.0244, 0.0307, 0.0279, 0.0273, 0.0336, 0.0156, 0.0211,
         0.0273, 0.0168, 0.0312, 0.0485, 0.0363, 0.0212, 0.0159, 0.0198, 0.0511,
         0.0273, 0.0205, 0.0183, 0.0159, 0.0187, 0.0129, 0.0164, 0.0151, 0.0214,
         0.0271, 0.0284, 0.0272, 0.0125, 0.0442, 0.0208, 0.0260, 0.0241, 0.0264,
         0.0344, 0.0224, 0.0194, 0.0208]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 20
images/598
(64, 64, 3)
tensor([[0.0255, 0.0230, 0.0172, 0.0169, 0.0548, 0.0218, 0.0293, 0.0174, 0.0171,
         0.0189, 0.0210, 0.0266, 0.0449, 0.0247, 0.0256, 0.0240, 0.0212, 0.0312,
         0.0231, 0.0252, 0.0174, 0.0169, 0.0177, 0.0231, 0.0239, 0.0193, 0.0221,
         0.0397, 0.0252, 0.0281, 0.0199, 0.0309, 0.0326, 0.0184, 0.0338, 0.0260,
         0.0251, 0.0226, 0.0255, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 21
images/108
(64, 64, 3)
tensor([[0.0294, 0.0257, 0.0200, 0.0170, 0.0221, 0.0228, 0.0289, 0.0168, 0.0222,
         0.0179, 0.0202, 0.0260, 0.0622, 0.0347, 0.0203, 0.0121, 0.0261, 0.0295,
         0.0204, 0.0201, 0.0138, 0.0214, 0.0174, 0.0254, 0.0135, 0.0256, 0.0231,
         0.0359, 0.0367, 0.0220, 0.0253, 0.0289, 0.0264, 0.0205, 0.0312, 0.0408,
         0.0327, 0.0176, 0.0241, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 22
images/118
(64, 64, 3)
tensor([[0.0358, 0.0219, 0.0316, 0.0222, 0.0223, 0.0210, 0.0533, 0.0160, 0.0140,
         0.0262, 0.0153, 0.0294, 0.0410, 0.0271, 0.0219, 0.0115, 0.0226, 0.0629,
         0.0135, 0.0158, 0.0132, 0.0219, 0.0196, 0.0268, 0.0144, 0.0097, 0.0223,
         0.0224, 0.0375, 0.0264, 0.0168, 0.0259, 0.0266, 0.0313, 0.0213, 0.0465,
         0.0230, 0.0130, 0.0328, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 23
images/105
(64, 64, 3)
tensor([[0.0206, 0.0207, 0.0199, 0.0183, 0.0420, 0.0220, 0.0321, 0.0161, 0.0184,
         0.0289, 0.0171, 0.0284, 0.0397, 0.0359, 0.0314, 0.0197, 0.0322, 0.0298,
         0.0228, 0.0182, 0.0176, 0.0202, 0.0231, 0.0217, 0.0173, 0.0183, 0.0301,
         0.0301, 0.0337, 0.0249, 0.0209, 0.0282, 0.0202, 0.0320, 0.0319, 0.0281,
         0.0233, 0.0175, 0.0248, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 24
images/504
(64, 64, 3)
tensor([[0.0193, 0.0198, 0.0211, 0.0162, 0.0394, 0.0221, 0.0259, 0.0168, 0.0223,
         0.0192, 0.0184, 0.0386, 0.0369, 0.0183, 0.0277, 0.0156, 0.0214, 0.0246,
         0.0222, 0.0151, 0.0177, 0.0222, 0.0215, 0.0298, 0.0205, 0.0285, 0.0263,
         0.0353, 0.0491, 0.0202, 0.0249, 0.0388, 0.0218, 0.0286, 0.0294, 0.0395,
         0.0261, 0.0208, 0.0154, 0.0228]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/156
(64, 64, 3)
tensor([[0.0282, 0.0267, 0.0213, 0.0168, 0.0218, 0.0193, 0.0185, 0.0238, 0.0102,
         0.0252, 0.0187, 0.0231, 0.0482, 0.0360, 0.0211, 0.0227, 0.0336, 0.0391,
         0.0183, 0.0208, 0.0155, 0.0257, 0.0352, 0.0317, 0.0206, 0.0211, 0.0267,
         0.0414, 0.0254, 0.0365, 0.0163, 0.0370, 0.0208, 0.0168, 0.0135, 0.0358,
         0.0281, 0.0167, 0.0224, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 26
images/134
(64, 64, 3)
tensor([[0.0241, 0.0340, 0.0187, 0.0151, 0.0402, 0.0181, 0.0327, 0.0153, 0.0153,
         0.0225, 0.0174, 0.0345, 0.0254, 0.0328, 0.0337, 0.0134, 0.0179, 0.0291,
         0.0138, 0.0231, 0.0287, 0.0351, 0.0304, 0.0231, 0.0218, 0.0138, 0.0174,
         0.0412, 0.0387, 0.0408, 0.0217, 0.0176, 0.0220, 0.0266, 0.0183, 0.0383,
         0.0322, 0.0145, 0.0163, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 27
images/21
(64, 64, 3)
tensor([[0.0294, 0.0300, 0.0200, 0.0179, 0.0248, 0.0211, 0.0370, 0.0107, 0.0322,
         0.0173, 0.0192, 0.0331, 0.0424, 0.0230, 0.0249, 0.0263, 0.0303, 0.0331,
         0.0230, 0.0327, 0.0242, 0.0249, 0.0149, 0.0154, 0.0142, 0.0267, 0.0333,
         0.0355, 0.0312, 0.0194, 0.0181, 0.0246, 0.0194, 0.0204, 0.0297, 0.0306,
         0.0213, 0.0188, 0.0206, 0.0285]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 28
images/423
(64, 64, 3)
tensor([[0.0346, 0.0240, 0.0231, 0.0148, 0.0325, 0.0197, 0.0536, 0.0178, 0.0130,
         0.0196, 0.0282, 0.0268, 0.0522, 0.0312, 0.0188, 0.0111, 0.0148, 0.0320,
         0.0205, 0.0172, 0.0122, 0.0196, 0.0264, 0.0156, 0.0151, 0.0186, 0.0227,
         0.0230, 0.0172, 0.0176, 0.0270, 0.0403, 0.0308, 0.0244, 0.0290, 0.0473,
         0.0394, 0.0184, 0.0282, 0.0216]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 29
images/293
(64, 64, 3)
tensor([[0.0374, 0.0254, 0.0221, 0.0238, 0.0357, 0.0139, 0.0260, 0.0119, 0.0148,
         0.0227, 0.0218, 0.0222, 0.0253, 0.0264, 0.0227, 0.0188, 0.0157, 0.0297,
         0.0146, 0.0296, 0.0197, 0.0385, 0.0332, 0.0263, 0.0237, 0.0171, 0.0223,
         0.0436, 0.0247, 0.0189, 0.0257, 0.0406, 0.0303, 0.0306, 0.0163, 0.0233,
         0.0400, 0.0129, 0.0229, 0.0288]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 30
images/583
(64, 64, 3)
tensor([[0.0331, 0.0211, 0.0170, 0.0184, 0.0230, 0.0160, 0.0315, 0.0238, 0.0185,
         0.0231, 0.0254, 0.0307, 0.0262, 0.0357, 0.0211, 0.0166, 0.0205, 0.0361,
         0.0201, 0.0243, 0.0253, 0.0251, 0.0184, 0.0244, 0.0426, 0.0309, 0.0168,
         0.0427, 0.0288, 0.0232, 0.0232, 0.0272, 0.0196, 0.0240, 0.0196, 0.0281,
         0.0251, 0.0211, 0.0289, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 31
images/190
(64, 64, 3)
tensor([[0.0259, 0.0203, 0.0173, 0.0170, 0.0200, 0.0240, 0.0327, 0.0365, 0.0176,
         0.0184, 0.0215, 0.0609, 0.0268, 0.0232, 0.0136, 0.0163, 0.0300, 0.0338,
         0.0162, 0.0233, 0.0155, 0.0173, 0.0174, 0.0214, 0.0178, 0.0268, 0.0186,
         0.0306, 0.0370, 0.0227, 0.0243, 0.0311, 0.0335, 0.0118, 0.0220, 0.0276,
         0.0365, 0.0368, 0.0231, 0.0329]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 32
images/339
(64, 64, 3)
tensor([[0.0204, 0.0345, 0.0177, 0.0165, 0.0378, 0.0175, 0.0310, 0.0175, 0.0124,
         0.0204, 0.0252, 0.0317, 0.0315, 0.0293, 0.0383, 0.0249, 0.0277, 0.0287,
         0.0263, 0.0291, 0.0150, 0.0284, 0.0168, 0.0256, 0.0288, 0.0195, 0.0262,
         0.0192, 0.0259, 0.0281, 0.0195, 0.0229, 0.0278, 0.0301, 0.0331, 0.0236,
         0.0250, 0.0259, 0.0181, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 33
images/391
(64, 64, 3)
tensor([[0.0194, 0.0285, 0.0158, 0.0180, 0.0332, 0.0281, 0.0525, 0.0162, 0.0176,
         0.0225, 0.0203, 0.0367, 0.0369, 0.0321, 0.0315, 0.0125, 0.0185, 0.0375,
         0.0287, 0.0195, 0.0206, 0.0275, 0.0210, 0.0183, 0.0324, 0.0140, 0.0188,
         0.0231, 0.0375, 0.0183, 0.0201, 0.0384, 0.0312, 0.0231, 0.0167, 0.0242,
         0.0298, 0.0136, 0.0211, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 34
images/478
(64, 64, 3)
tensor([[0.0304, 0.0228, 0.0179, 0.0168, 0.0205, 0.0218, 0.0222, 0.0166, 0.0207,
         0.0193, 0.0287, 0.0462, 0.0213, 0.0274, 0.0260, 0.0242, 0.0268, 0.0344,
         0.0224, 0.0184, 0.0149, 0.0335, 0.0243, 0.0222, 0.0255, 0.0211, 0.0242,
         0.0365, 0.0310, 0.0399, 0.0137, 0.0234, 0.0314, 0.0222, 0.0275, 0.0395,
         0.0200, 0.0220, 0.0195, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 35
images/355
(64, 64, 3)
tensor([[0.0242, 0.0264, 0.0230, 0.0213, 0.0409, 0.0228, 0.0315, 0.0165, 0.0168,
         0.0231, 0.0153, 0.0273, 0.0355, 0.0493, 0.0200, 0.0163, 0.0163, 0.0373,
         0.0234, 0.0209, 0.0202, 0.0135, 0.0202, 0.0282, 0.0234, 0.0182, 0.0293,
         0.0219, 0.0652, 0.0243, 0.0141, 0.0322, 0.0324, 0.0257, 0.0244, 0.0201,
         0.0232, 0.0178, 0.0162, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 36
images/181
(64, 64, 3)
tensor([[0.0234, 0.0255, 0.0172, 0.0326, 0.0291, 0.0169, 0.0400, 0.0189, 0.0237,
         0.0103, 0.0148, 0.0285, 0.0419, 0.0406, 0.0235, 0.0135, 0.0133, 0.0411,
         0.0140, 0.0238, 0.0148, 0.0245, 0.0268, 0.0161, 0.0232, 0.0174, 0.0242,
         0.0276, 0.0275, 0.0265, 0.0311, 0.0284, 0.0178, 0.0223, 0.0329, 0.0479,
         0.0338, 0.0204, 0.0204, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 37
images/487
(64, 64, 3)
tensor([[0.0279, 0.0237, 0.0195, 0.0147, 0.0436, 0.0191, 0.0317, 0.0170, 0.0184,
         0.0181, 0.0206, 0.0324, 0.0533, 0.0344, 0.0239, 0.0184, 0.0289, 0.0317,
         0.0229, 0.0139, 0.0216, 0.0227, 0.0255, 0.0236, 0.0196, 0.0214, 0.0259,
         0.0347, 0.0276, 0.0344, 0.0150, 0.0222, 0.0214, 0.0228, 0.0184, 0.0386,
         0.0230, 0.0193, 0.0260, 0.0223]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 38
images/519
(64, 64, 3)
tensor([[0.0201, 0.0250, 0.0197, 0.0122, 0.0199, 0.0162, 0.0407, 0.0238, 0.0181,
         0.0162, 0.0245, 0.0384, 0.0271, 0.0239, 0.0296, 0.0172, 0.0183, 0.0325,
         0.0199, 0.0208, 0.0171, 0.0340, 0.0216, 0.0179, 0.0205, 0.0180, 0.0197,
         0.0555, 0.0292, 0.0172, 0.0347, 0.0299, 0.0330, 0.0203, 0.0243, 0.0380,
         0.0304, 0.0199, 0.0297, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 39
images/343
(64, 64, 3)
tensor([[0.0566, 0.0265, 0.0191, 0.0194, 0.0393, 0.0278, 0.0429, 0.0189, 0.0136,
         0.0241, 0.0183, 0.0263, 0.0405, 0.0385, 0.0155, 0.0151, 0.0145, 0.0332,
         0.0182, 0.0157, 0.0188, 0.0256, 0.0178, 0.0241, 0.0233, 0.0175, 0.0230,
         0.0416, 0.0327, 0.0226, 0.0192, 0.0279, 0.0272, 0.0166, 0.0172, 0.0315,
         0.0200, 0.0168, 0.0263, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 40
images/353
(64, 64, 3)
tensor([[0.0405, 0.0309, 0.0155, 0.0274, 0.0369, 0.0256, 0.0369, 0.0184, 0.0169,
         0.0190, 0.0137, 0.0202, 0.0384, 0.0532, 0.0213, 0.0181, 0.0230, 0.0313,
         0.0177, 0.0258, 0.0196, 0.0232, 0.0243, 0.0207, 0.0229, 0.0190, 0.0241,
         0.0282, 0.0317, 0.0243, 0.0195, 0.0280, 0.0279, 0.0196, 0.0203, 0.0220,
         0.0247, 0.0197, 0.0207, 0.0290]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 41
images/360
(64, 64, 3)
tensor([[0.0242, 0.0196, 0.0136, 0.0227, 0.0253, 0.0210, 0.0304, 0.0152, 0.0285,
         0.0158, 0.0248, 0.0212, 0.0416, 0.0387, 0.0240, 0.0357, 0.0269, 0.0362,
         0.0274, 0.0103, 0.0249, 0.0160, 0.0170, 0.0145, 0.0172, 0.0214, 0.0256,
         0.0423, 0.0383, 0.0198, 0.0215, 0.0255, 0.0303, 0.0251, 0.0232, 0.0275,
         0.0327, 0.0166, 0.0281, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 1
Session Number: 42
images/16
(64, 64, 3)
tensor([[0.0256, 0.0277, 0.0245, 0.0195, 0.0318, 0.0141, 0.0174, 0.0227, 0.0221,
         0.0204, 0.0192, 0.0248, 0.0383, 0.0304, 0.0276, 0.0382, 0.0172, 0.0342,
         0.0244, 0.0215, 0.0187, 0.0246, 0.0237, 0.0208, 0.0238, 0.0132, 0.0302,
         0.0327, 0.0255, 0.0249, 0.0189, 0.0298, 0.0228, 0.0314, 0.0315, 0.0454,
         0.0228, 0.0151, 0.0203, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/249
(64, 64, 3)
tensor([[0.0294, 0.0189, 0.0144, 0.0257, 0.0332, 0.0257, 0.0226, 0.0207, 0.0158,
         0.0240, 0.0168, 0.0199, 0.0445, 0.0494, 0.0191, 0.0172, 0.0202, 0.0484,
         0.0209, 0.0298, 0.0085, 0.0273, 0.0206, 0.0160, 0.0220, 0.0270, 0.0373,
         0.0343, 0.0319, 0.0277, 0.0196, 0.0239, 0.0199, 0.0235, 0.0220, 0.0303,
         0.0247, 0.0214, 0.0225, 0.0228]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/12
(64, 64, 3)
tensor([[0.0203, 0.0366, 0.0171, 0.0378, 0.0326, 0.0246, 0.0237, 0.0166, 0.0222,
         0.0216, 0.0138, 0.0218, 0.0474, 0.0324, 0.0211, 0.0216, 0.0217, 0.0406,
         0.0287, 0.0330, 0.0213, 0.0242, 0.0182, 0.0205, 0.0229, 0.0206, 0.0287,
         0.0285, 0.0250, 0.0183, 0.0172, 0.0270, 0.0295, 0.0231, 0.0216, 0.0230,
         0.0227, 0.0279, 0.0231, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 45
images/475
(64, 64, 3)
tensor([[0.0316, 0.0180, 0.0148, 0.0287, 0.0301, 0.0186, 0.0192, 0.0328, 0.0200,
         0.0134, 0.0144, 0.0455, 0.0635, 0.0244, 0.0225, 0.0274, 0.0177, 0.0375,
         0.0241, 0.0203, 0.0149, 0.0160, 0.0205, 0.0229, 0.0203, 0.0161, 0.0294,
         0.0266, 0.0265, 0.0222, 0.0218, 0.0376, 0.0205, 0.0338, 0.0176, 0.0420,
         0.0213, 0.0220, 0.0182, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 46
images/396
(64, 64, 3)
tensor([[0.0343, 0.0253, 0.0164, 0.0176, 0.0214, 0.0168, 0.0411, 0.0308, 0.0161,
         0.0181, 0.0229, 0.0229, 0.0508, 0.0245, 0.0344, 0.0207, 0.0143, 0.0245,
         0.0285, 0.0296, 0.0191, 0.0204, 0.0190, 0.0147, 0.0185, 0.0130, 0.0228,
         0.0395, 0.0260, 0.0232, 0.0206, 0.0198, 0.0269, 0.0368, 0.0193, 0.0363,
         0.0214, 0.0335, 0.0323, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 47
images/229
(64, 64, 3)
tensor([[0.0259, 0.0320, 0.0229, 0.0156, 0.0228, 0.0201, 0.0313, 0.0195, 0.0234,
         0.0192, 0.0267, 0.0313, 0.0293, 0.0324, 0.0202, 0.0202, 0.0174, 0.0423,
         0.0112, 0.0179, 0.0179, 0.0223, 0.0144, 0.0223, 0.0263, 0.0233, 0.0185,
         0.0394, 0.0229, 0.0275, 0.0219, 0.0376, 0.0380, 0.0309, 0.0232, 0.0286,
         0.0271, 0.0185, 0.0188, 0.0390]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 48
images/5
(64, 64, 3)
tensor([[0.0330, 0.0265, 0.0157, 0.0109, 0.0373, 0.0207, 0.0376, 0.0173, 0.0215,
         0.0154, 0.0200, 0.0405, 0.0288, 0.0329, 0.0234, 0.0193, 0.0236, 0.0396,
         0.0121, 0.0185, 0.0218, 0.0324, 0.0139, 0.0198, 0.0223, 0.0190, 0.0350,
         0.0340, 0.0254, 0.0226, 0.0220, 0.0297, 0.0189, 0.0240, 0.0252, 0.0326,
         0.0367, 0.0174, 0.0276, 0.0249]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 49
images/551
(64, 64, 3)
tensor([[0.0245, 0.0344, 0.0107, 0.0256, 0.0226, 0.0229, 0.0411, 0.0189, 0.0198,
         0.0336, 0.0189, 0.0370, 0.0526, 0.0307, 0.0305, 0.0209, 0.0155, 0.0262,
         0.0209, 0.0263, 0.0241, 0.0203, 0.0194, 0.0168, 0.0203, 0.0142, 0.0178,
         0.0336, 0.0308, 0.0172, 0.0159, 0.0200, 0.0354, 0.0201, 0.0277, 0.0264,
         0.0325, 0.0197, 0.0301, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 50
images/381
(64, 64, 3)
tensor([[0.0362, 0.0289, 0.0217, 0.0101, 0.0386, 0.0192, 0.0303, 0.0162, 0.0153,
         0.0258, 0.0247, 0.0247, 0.0371, 0.0388, 0.0346, 0.0177, 0.0227, 0.0348,
         0.0188, 0.0151, 0.0199, 0.0379, 0.0276, 0.0220, 0.0252, 0.0119, 0.0192,
         0.0159, 0.0376, 0.0297, 0.0134, 0.0217, 0.0384, 0.0315, 0.0155, 0.0348,
         0.0204, 0.0218, 0.0230, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 51
images/502
(64, 64, 3)
tensor([[0.0372, 0.0339, 0.0222, 0.0261, 0.0272, 0.0143, 0.0290, 0.0211, 0.0218,
         0.0178, 0.0153, 0.0359, 0.0289, 0.0309, 0.0206, 0.0141, 0.0193, 0.0383,
         0.0218, 0.0246, 0.0197, 0.0232, 0.0164, 0.0338, 0.0128, 0.0172, 0.0239,
         0.0319, 0.0415, 0.0156, 0.0209, 0.0364, 0.0250, 0.0306, 0.0303, 0.0220,
         0.0252, 0.0171, 0.0229, 0.0332]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/38
(64, 64, 3)
tensor([[0.0321, 0.0226, 0.0203, 0.0280, 0.0307, 0.0197, 0.0246, 0.0223, 0.0192,
         0.0211, 0.0226, 0.0156, 0.0303, 0.0330, 0.0167, 0.0286, 0.0183, 0.0214,
         0.0252, 0.0159, 0.0218, 0.0233, 0.0281, 0.0158, 0.0215, 0.0320, 0.0227,
         0.0298, 0.0355, 0.0277, 0.0231, 0.0331, 0.0285, 0.0249, 0.0248, 0.0305,
         0.0472, 0.0172, 0.0198, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 53
images/298
(64, 64, 3)
tensor([[0.0282, 0.0342, 0.0151, 0.0165, 0.0371, 0.0210, 0.0352, 0.0176, 0.0213,
         0.0312, 0.0201, 0.0349, 0.0413, 0.0305, 0.0216, 0.0180, 0.0262, 0.0275,
         0.0203, 0.0203, 0.0184, 0.0216, 0.0195, 0.0212, 0.0245, 0.0132, 0.0245,
         0.0340, 0.0281, 0.0224, 0.0120, 0.0182, 0.0500, 0.0283, 0.0268, 0.0153,
         0.0318, 0.0211, 0.0222, 0.0288]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 54
images/441
(64, 64, 3)
tensor([[0.0257, 0.0222, 0.0231, 0.0242, 0.0389, 0.0135, 0.0369, 0.0158, 0.0255,
         0.0162, 0.0227, 0.0238, 0.0547, 0.0307, 0.0208, 0.0175, 0.0124, 0.0354,
         0.0186, 0.0190, 0.0131, 0.0242, 0.0184, 0.0167, 0.0233, 0.0184, 0.0186,
         0.0487, 0.0338, 0.0191, 0.0139, 0.0279, 0.0343, 0.0243, 0.0238, 0.0395,
         0.0311, 0.0223, 0.0249, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 55
images/412
(64, 64, 3)
tensor([[0.0316, 0.0195, 0.0129, 0.0168, 0.0368, 0.0232, 0.0388, 0.0174, 0.0224,
         0.0187, 0.0236, 0.0266, 0.0683, 0.0354, 0.0324, 0.0181, 0.0173, 0.0410,
         0.0200, 0.0192, 0.0148, 0.0232, 0.0128, 0.0130, 0.0217, 0.0239, 0.0246,
         0.0276, 0.0262, 0.0290, 0.0242, 0.0228, 0.0318, 0.0221, 0.0269, 0.0223,
         0.0234, 0.0273, 0.0126, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 56
images/363
(64, 64, 3)
tensor([[0.0227, 0.0289, 0.0201, 0.0211, 0.0381, 0.0225, 0.0337, 0.0159, 0.0233,
         0.0188, 0.0098, 0.0222, 0.0426, 0.0362, 0.0292, 0.0248, 0.0191, 0.0365,
         0.0174, 0.0174, 0.0232, 0.0329, 0.0207, 0.0251, 0.0192, 0.0306, 0.0290,
         0.0310, 0.0340, 0.0297, 0.0156, 0.0307, 0.0289, 0.0140, 0.0206, 0.0259,
         0.0304, 0.0196, 0.0171, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 57
images/133
(64, 64, 3)
tensor([[0.0182, 0.0314, 0.0313, 0.0205, 0.0259, 0.0177, 0.0374, 0.0191, 0.0143,
         0.0221, 0.0296, 0.0247, 0.0326, 0.0250, 0.0204, 0.0195, 0.0175, 0.0305,
         0.0205, 0.0330, 0.0169, 0.0135, 0.0172, 0.0167, 0.0235, 0.0246, 0.0295,
         0.0376, 0.0288, 0.0248, 0.0185, 0.0303, 0.0348, 0.0325, 0.0184, 0.0386,
         0.0340, 0.0191, 0.0258, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 58
images/360
(64, 64, 3)
tensor([[0.0422, 0.0247, 0.0188, 0.0225, 0.0257, 0.0158, 0.0431, 0.0167, 0.0156,
         0.0265, 0.0198, 0.0246, 0.0375, 0.0326, 0.0224, 0.0172, 0.0183, 0.0706,
         0.0202, 0.0192, 0.0203, 0.0195, 0.0179, 0.0151, 0.0156, 0.0196, 0.0218,
         0.0480, 0.0405, 0.0223, 0.0148, 0.0147, 0.0246, 0.0164, 0.0284, 0.0214,
         0.0280, 0.0178, 0.0298, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 1
Session Number: 59
images/554
(64, 64, 3)
tensor([[0.0239, 0.0216, 0.0180, 0.0182, 0.0394, 0.0208, 0.0286, 0.0332, 0.0259,
         0.0158, 0.0207, 0.0294, 0.0371, 0.0454, 0.0345, 0.0186, 0.0235, 0.0392,
         0.0181, 0.0269, 0.0158, 0.0259, 0.0156, 0.0223, 0.0203, 0.0192, 0.0208,
         0.0267, 0.0273, 0.0252, 0.0194, 0.0276, 0.0347, 0.0303, 0.0223, 0.0241,
         0.0219, 0.0148, 0.0285, 0.0184]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 60
images/16
(64, 64, 3)
tensor([[0.0376, 0.0229, 0.0239, 0.0306, 0.0359, 0.0201, 0.0183, 0.0222, 0.0153,
         0.0161, 0.0175, 0.0218, 0.0270, 0.0297, 0.0203, 0.0154, 0.0144, 0.0327,
         0.0286, 0.0236, 0.0128, 0.0350, 0.0262, 0.0355, 0.0205, 0.0185, 0.0307,
         0.0381, 0.0338, 0.0228, 0.0168, 0.0286, 0.0252, 0.0354, 0.0268, 0.0244,
         0.0321, 0.0186, 0.0184, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 61
images/162
(64, 64, 3)
tensor([[0.0215, 0.0335, 0.0224, 0.0267, 0.0386, 0.0141, 0.0369, 0.0207, 0.0235,
         0.0378, 0.0198, 0.0278, 0.0326, 0.0243, 0.0300, 0.0130, 0.0274, 0.0313,
         0.0175, 0.0207, 0.0179, 0.0272, 0.0163, 0.0222, 0.0252, 0.0179, 0.0188,
         0.0179, 0.0294, 0.0214, 0.0163, 0.0385, 0.0358, 0.0261, 0.0163, 0.0358,
         0.0274, 0.0166, 0.0261, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 62
images/336
(64, 64, 3)
tensor([[0.0304, 0.0300, 0.0193, 0.0128, 0.0393, 0.0199, 0.0303, 0.0105, 0.0275,
         0.0172, 0.0138, 0.0291, 0.0459, 0.0282, 0.0243, 0.0185, 0.0235, 0.0243,
         0.0201, 0.0284, 0.0205, 0.0386, 0.0238, 0.0155, 0.0233, 0.0189, 0.0219,
         0.0405, 0.0396, 0.0263, 0.0137, 0.0202, 0.0245, 0.0285, 0.0137, 0.0339,
         0.0312, 0.0175, 0.0252, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 63
images/246
(64, 64, 3)
tensor([[0.0212, 0.0335, 0.0105, 0.0299, 0.0399, 0.0280, 0.0325, 0.0108, 0.0303,
         0.0211, 0.0183, 0.0284, 0.0273, 0.0304, 0.0306, 0.0231, 0.0164, 0.0646,
         0.0213, 0.0199, 0.0164, 0.0248, 0.0144, 0.0213, 0.0323, 0.0119, 0.0181,
         0.0334, 0.0340, 0.0163, 0.0194, 0.0290, 0.0214, 0.0169, 0.0192, 0.0246,
         0.0211, 0.0339, 0.0223, 0.0313]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 64
images/451
(64, 64, 3)
tensor([[0.0238, 0.0316, 0.0195, 0.0108, 0.0337, 0.0254, 0.0255, 0.0223, 0.0227,
         0.0235, 0.0157, 0.0401, 0.0346, 0.0377, 0.0196, 0.0164, 0.0264, 0.0213,
         0.0274, 0.0203, 0.0153, 0.0300, 0.0221, 0.0185, 0.0295, 0.0154, 0.0138,
         0.0335, 0.0443, 0.0366, 0.0169, 0.0335, 0.0233, 0.0195, 0.0179, 0.0406,
         0.0259, 0.0205, 0.0207, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 65
images/430
(64, 64, 3)
tensor([[0.0175, 0.0277, 0.0150, 0.0136, 0.0448, 0.0389, 0.0192, 0.0155, 0.0167,
         0.0142, 0.0201, 0.0438, 0.0544, 0.0292, 0.0328, 0.0282, 0.0189, 0.0290,
         0.0232, 0.0183, 0.0257, 0.0297, 0.0192, 0.0277, 0.0163, 0.0180, 0.0372,
         0.0352, 0.0320, 0.0167, 0.0172, 0.0319, 0.0221, 0.0205, 0.0291, 0.0212,
         0.0284, 0.0207, 0.0136, 0.0167]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 66
images/280
(64, 64, 3)
tensor([[0.0174, 0.0172, 0.0195, 0.0245, 0.0251, 0.0143, 0.0390, 0.0267, 0.0126,
         0.0115, 0.0210, 0.0318, 0.0356, 0.0363, 0.0355, 0.0155, 0.0171, 0.0452,
         0.0163, 0.0251, 0.0209, 0.0208, 0.0236, 0.0115, 0.0170, 0.0161, 0.0326,
         0.0292, 0.0333, 0.0273, 0.0170, 0.0335, 0.0267, 0.0341, 0.0176, 0.0408,
         0.0389, 0.0210, 0.0297, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 67
images/404
(64, 64, 3)
tensor([[0.0264, 0.0280, 0.0179, 0.0167, 0.0193, 0.0190, 0.0355, 0.0309, 0.0128,
         0.0250, 0.0237, 0.0348, 0.0407, 0.0392, 0.0211, 0.0146, 0.0244, 0.0217,
         0.0170, 0.0199, 0.0205, 0.0199, 0.0198, 0.0286, 0.0280, 0.0213, 0.0255,
         0.0258, 0.0401, 0.0258, 0.0230, 0.0471, 0.0309, 0.0202, 0.0276, 0.0234,
         0.0297, 0.0224, 0.0128, 0.0189]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/64
(64, 64, 3)
tensor([[0.0173, 0.0351, 0.0183, 0.0200, 0.0371, 0.0149, 0.0346, 0.0165, 0.0188,
         0.0249, 0.0214, 0.0225, 0.0530, 0.0235, 0.0203, 0.0190, 0.0287, 0.0398,
         0.0219, 0.0198, 0.0207, 0.0184, 0.0201, 0.0123, 0.0208, 0.0190, 0.0186,
         0.0262, 0.0744, 0.0270, 0.0116, 0.0179, 0.0336, 0.0217, 0.0180, 0.0239,
         0.0305, 0.0247, 0.0220, 0.0312]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 69
images/361
(64, 64, 3)
tensor([[0.0287, 0.0414, 0.0164, 0.0128, 0.0212, 0.0202, 0.0253, 0.0156, 0.0222,
         0.0249, 0.0272, 0.0223, 0.0520, 0.0506, 0.0307, 0.0310, 0.0202, 0.0306,
         0.0193, 0.0162, 0.0163, 0.0261, 0.0138, 0.0197, 0.0325, 0.0106, 0.0200,
         0.0285, 0.0269, 0.0334, 0.0184, 0.0313, 0.0267, 0.0159, 0.0286, 0.0333,
         0.0169, 0.0257, 0.0212, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 70
images/130
(64, 64, 3)
tensor([[0.0261, 0.0327, 0.0179, 0.0198, 0.0436, 0.0172, 0.0510, 0.0103, 0.0178,
         0.0175, 0.0177, 0.0367, 0.0346, 0.0331, 0.0390, 0.0135, 0.0158, 0.0265,
         0.0158, 0.0245, 0.0230, 0.0268, 0.0212, 0.0191, 0.0242, 0.0165, 0.0236,
         0.0272, 0.0249, 0.0237, 0.0251, 0.0275, 0.0241, 0.0208, 0.0180, 0.0377,
         0.0247, 0.0159, 0.0303, 0.0344]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 71
images/222
(64, 64, 3)
tensor([[0.0303, 0.0200, 0.0209, 0.0145, 0.0355, 0.0187, 0.0324, 0.0194, 0.0155,
         0.0269, 0.0226, 0.0401, 0.0365, 0.0283, 0.0223, 0.0166, 0.0211, 0.0289,
         0.0127, 0.0306, 0.0177, 0.0259, 0.0195, 0.0191, 0.0257, 0.0228, 0.0315,
         0.0385, 0.0342, 0.0166, 0.0144, 0.0326, 0.0394, 0.0318, 0.0203, 0.0172,
         0.0262, 0.0196, 0.0288, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 72
images/473
(64, 64, 3)
tensor([[0.0226, 0.0363, 0.0199, 0.0141, 0.0473, 0.0184, 0.0283, 0.0232, 0.0162,
         0.0137, 0.0207, 0.0271, 0.0510, 0.0287, 0.0275, 0.0127, 0.0197, 0.0275,
         0.0246, 0.0169, 0.0194, 0.0199, 0.0216, 0.0232, 0.0254, 0.0160, 0.0263,
         0.0357, 0.0348, 0.0229, 0.0148, 0.0347, 0.0264, 0.0334, 0.0280, 0.0276,
         0.0319, 0.0190, 0.0161, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 73
images/366
(64, 64, 3)
tensor([[0.0284, 0.0286, 0.0192, 0.0175, 0.0300, 0.0203, 0.0319, 0.0141, 0.0162,
         0.0221, 0.0280, 0.0211, 0.0318, 0.0277, 0.0274, 0.0181, 0.0246, 0.0455,
         0.0267, 0.0134, 0.0164, 0.0187, 0.0180, 0.0151, 0.0260, 0.0249, 0.0183,
         0.0345, 0.0301, 0.0239, 0.0200, 0.0314, 0.0448, 0.0247, 0.0221, 0.0324,
         0.0336, 0.0231, 0.0184, 0.0309]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 74
images/109
(64, 64, 3)
tensor([[0.0357, 0.0194, 0.0127, 0.0150, 0.0330, 0.0267, 0.0324, 0.0113, 0.0162,
         0.0238, 0.0223, 0.0268, 0.0344, 0.0300, 0.0318, 0.0140, 0.0255, 0.0363,
         0.0180, 0.0178, 0.0147, 0.0194, 0.0189, 0.0288, 0.0231, 0.0198, 0.0184,
         0.0306, 0.0349, 0.0165, 0.0187, 0.0311, 0.0303, 0.0267, 0.0233, 0.0374,
         0.0288, 0.0201, 0.0489, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 75
images/73
(64, 64, 3)
tensor([[0.0215, 0.0321, 0.0128, 0.0232, 0.0431, 0.0201, 0.0252, 0.0264, 0.0169,
         0.0202, 0.0130, 0.0203, 0.0275, 0.0412, 0.0258, 0.0376, 0.0188, 0.0294,
         0.0456, 0.0175, 0.0144, 0.0208, 0.0236, 0.0204, 0.0329, 0.0150, 0.0274,
         0.0243, 0.0529, 0.0254, 0.0174, 0.0316, 0.0244, 0.0226, 0.0211, 0.0238,
         0.0193, 0.0161, 0.0259, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 76
images/593
(64, 64, 3)
tensor([[0.0298, 0.0205, 0.0233, 0.0140, 0.0300, 0.0158, 0.0362, 0.0167, 0.0248,
         0.0183, 0.0164, 0.0409, 0.0473, 0.0288, 0.0348, 0.0215, 0.0213, 0.0255,
         0.0199, 0.0232, 0.0141, 0.0262, 0.0224, 0.0257, 0.0155, 0.0165, 0.0198,
         0.0400, 0.0309, 0.0322, 0.0164, 0.0291, 0.0230, 0.0208, 0.0253, 0.0389,
         0.0240, 0.0230, 0.0186, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 77
images/50
(64, 64, 3)
tensor([[0.0209, 0.0262, 0.0254, 0.0196, 0.0287, 0.0226, 0.0303, 0.0155, 0.0197,
         0.0154, 0.0230, 0.0253, 0.0356, 0.0324, 0.0222, 0.0257, 0.0237, 0.0446,
         0.0327, 0.0218, 0.0218, 0.0173, 0.0245, 0.0161, 0.0196, 0.0134, 0.0233,
         0.0317, 0.0280, 0.0294, 0.0190, 0.0317, 0.0384, 0.0208, 0.0215, 0.0251,
         0.0280, 0.0164, 0.0208, 0.0418]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 78
images/581
(64, 64, 3)
tensor([[0.0261, 0.0243, 0.0213, 0.0229, 0.0372, 0.0187, 0.0247, 0.0176, 0.0248,
         0.0236, 0.0176, 0.0364, 0.0476, 0.0297, 0.0244, 0.0185, 0.0246, 0.0272,
         0.0253, 0.0222, 0.0165, 0.0210, 0.0131, 0.0236, 0.0187, 0.0291, 0.0331,
         0.0246, 0.0263, 0.0259, 0.0135, 0.0200, 0.0209, 0.0188, 0.0181, 0.0431,
         0.0377, 0.0177, 0.0306, 0.0331]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/185
(64, 64, 3)
tensor([[0.0285, 0.0258, 0.0156, 0.0205, 0.0453, 0.0180, 0.0205, 0.0212, 0.0203,
         0.0313, 0.0196, 0.0331, 0.0422, 0.0216, 0.0222, 0.0199, 0.0213, 0.0336,
         0.0226, 0.0189, 0.0123, 0.0335, 0.0210, 0.0304, 0.0271, 0.0197, 0.0213,
         0.0509, 0.0279, 0.0226, 0.0179, 0.0255, 0.0188, 0.0250, 0.0230, 0.0290,
         0.0227, 0.0264, 0.0213, 0.0216]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 80
images/124
(64, 64, 3)
tensor([[0.0268, 0.0261, 0.0207, 0.0161, 0.0371, 0.0162, 0.0503, 0.0183, 0.0194,
         0.0171, 0.0160, 0.0524, 0.0321, 0.0174, 0.0321, 0.0167, 0.0246, 0.0356,
         0.0202, 0.0191, 0.0291, 0.0266, 0.0208, 0.0148, 0.0236, 0.0231, 0.0218,
         0.0203, 0.0277, 0.0252, 0.0190, 0.0304, 0.0270, 0.0389, 0.0237, 0.0270,
         0.0275, 0.0190, 0.0184, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 81
images/475
(64, 64, 3)
tensor([[0.0268, 0.0180, 0.0172, 0.0231, 0.0271, 0.0256, 0.0314, 0.0238, 0.0192,
         0.0167, 0.0109, 0.0256, 0.0341, 0.0306, 0.0235, 0.0201, 0.0168, 0.0524,
         0.0189, 0.0267, 0.0159, 0.0382, 0.0196, 0.0276, 0.0183, 0.0254, 0.0254,
         0.0311, 0.0286, 0.0235, 0.0216, 0.0445, 0.0212, 0.0137, 0.0187, 0.0286,
         0.0260, 0.0271, 0.0272, 0.0291]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 82
images/63
(64, 64, 3)
tensor([[0.0273, 0.0343, 0.0272, 0.0140, 0.0506, 0.0188, 0.0167, 0.0132, 0.0099,
         0.0157, 0.0193, 0.0395, 0.0337, 0.0249, 0.0219, 0.0203, 0.0238, 0.0330,
         0.0203, 0.0221, 0.0157, 0.0413, 0.0359, 0.0271, 0.0253, 0.0238, 0.0254,
         0.0325, 0.0347, 0.0146, 0.0142, 0.0285, 0.0247, 0.0285, 0.0223, 0.0258,
         0.0378, 0.0200, 0.0140, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 83
images/317
(64, 64, 3)
tensor([[0.0345, 0.0410, 0.0158, 0.0263, 0.0187, 0.0103, 0.0219, 0.0108, 0.0151,
         0.0154, 0.0236, 0.0218, 0.0587, 0.0327, 0.0333, 0.0227, 0.0166, 0.0358,
         0.0147, 0.0318, 0.0134, 0.0197, 0.0261, 0.0200, 0.0191, 0.0206, 0.0243,
         0.0332, 0.0249, 0.0311, 0.0142, 0.0256, 0.0291, 0.0265, 0.0234, 0.0365,
         0.0414, 0.0244, 0.0218, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 84
images/301
(64, 64, 3)
tensor([[0.0320, 0.0318, 0.0121, 0.0216, 0.0357, 0.0268, 0.0276, 0.0234, 0.0194,
         0.0259, 0.0190, 0.0425, 0.0286, 0.0197, 0.0197, 0.0166, 0.0280, 0.0332,
         0.0166, 0.0137, 0.0214, 0.0290, 0.0203, 0.0213, 0.0219, 0.0213, 0.0270,
         0.0384, 0.0381, 0.0236, 0.0183, 0.0253, 0.0245, 0.0291, 0.0172, 0.0283,
         0.0368, 0.0138, 0.0275, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 0
Session Number: 85
images/488
(64, 64, 3)
tensor([[0.0232, 0.0295, 0.0180, 0.0291, 0.0186, 0.0176, 0.0329, 0.0150, 0.0145,
         0.0164, 0.0216, 0.0298, 0.0285, 0.0354, 0.0248, 0.0201, 0.0213, 0.0344,
         0.0216, 0.0341, 0.0165, 0.0247, 0.0172, 0.0275, 0.0133, 0.0162, 0.0273,
         0.0600, 0.0389, 0.0183, 0.0134, 0.0366, 0.0273, 0.0251, 0.0204, 0.0240,
         0.0264, 0.0239, 0.0237, 0.0328]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 86
images/533
(64, 64, 3)
tensor([[0.0223, 0.0252, 0.0145, 0.0136, 0.0347, 0.0128, 0.0258, 0.0171, 0.0150,
         0.0259, 0.0195, 0.0449, 0.0518, 0.0288, 0.0207, 0.0155, 0.0282, 0.0304,
         0.0234, 0.0136, 0.0251, 0.0291, 0.0184, 0.0187, 0.0224, 0.0147, 0.0310,
         0.0344, 0.0355, 0.0198, 0.0160, 0.0322, 0.0325, 0.0312, 0.0424, 0.0204,
         0.0287, 0.0239, 0.0197, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 87
images/312
(64, 64, 3)
tensor([[0.0262, 0.0325, 0.0142, 0.0192, 0.0251, 0.0335, 0.0303, 0.0155, 0.0125,
         0.0188, 0.0241, 0.0409, 0.0416, 0.0305, 0.0206, 0.0208, 0.0132, 0.0284,
         0.0197, 0.0251, 0.0182, 0.0413, 0.0215, 0.0217, 0.0172, 0.0173, 0.0251,
         0.0282, 0.0320, 0.0230, 0.0233, 0.0369, 0.0222, 0.0222, 0.0214, 0.0302,
         0.0181, 0.0305, 0.0289, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 88
images/476
(64, 64, 3)
tensor([[0.0270, 0.0279, 0.0163, 0.0126, 0.0251, 0.0190, 0.0543, 0.0261, 0.0184,
         0.0146, 0.0388, 0.0289, 0.0562, 0.0262, 0.0181, 0.0199, 0.0185, 0.0256,
         0.0196, 0.0246, 0.0132, 0.0241, 0.0236, 0.0242, 0.0142, 0.0263, 0.0254,
         0.0391, 0.0352, 0.0197, 0.0204, 0.0229, 0.0243, 0.0172, 0.0283, 0.0376,
         0.0224, 0.0134, 0.0277, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/325
(64, 64, 3)
tensor([[0.0232, 0.0240, 0.0225, 0.0121, 0.0492, 0.0224, 0.0257, 0.0144, 0.0195,
         0.0162, 0.0105, 0.0217, 0.0614, 0.0292, 0.0292, 0.0204, 0.0177, 0.0415,
         0.0218, 0.0203, 0.0152, 0.0232, 0.0202, 0.0205, 0.0216, 0.0183, 0.0293,
         0.0370, 0.0210, 0.0237, 0.0142, 0.0272, 0.0274, 0.0386, 0.0212, 0.0305,
         0.0351, 0.0225, 0.0242, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 90
images/553
(64, 64, 3)
tensor([[0.0285, 0.0250, 0.0292, 0.0214, 0.0371, 0.0234, 0.0252, 0.0129, 0.0189,
         0.0152, 0.0179, 0.0428, 0.0273, 0.0375, 0.0291, 0.0325, 0.0213, 0.0235,
         0.0170, 0.0243, 0.0222, 0.0292, 0.0297, 0.0257, 0.0341, 0.0180, 0.0230,
         0.0265, 0.0440, 0.0278, 0.0150, 0.0159, 0.0196, 0.0212, 0.0251, 0.0251,
         0.0263, 0.0203, 0.0186, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 91
images/132
(64, 64, 3)
tensor([[0.0262, 0.0379, 0.0209, 0.0190, 0.0217, 0.0286, 0.0349, 0.0205, 0.0220,
         0.0278, 0.0151, 0.0456, 0.0408, 0.0208, 0.0177, 0.0216, 0.0209, 0.0266,
         0.0269, 0.0177, 0.0152, 0.0287, 0.0217, 0.0257, 0.0115, 0.0153, 0.0279,
         0.0295, 0.0216, 0.0264, 0.0258, 0.0439, 0.0224, 0.0231, 0.0249, 0.0332,
         0.0160, 0.0221, 0.0200, 0.0317]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 92
images/168
(64, 64, 3)
tensor([[0.0189, 0.0272, 0.0162, 0.0163, 0.0233, 0.0217, 0.0282, 0.0261, 0.0185,
         0.0274, 0.0188, 0.0226, 0.0352, 0.0279, 0.0254, 0.0151, 0.0235, 0.0466,
         0.0152, 0.0278, 0.0153, 0.0246, 0.0224, 0.0308, 0.0207, 0.0149, 0.0235,
         0.0303, 0.0406, 0.0287, 0.0251, 0.0369, 0.0310, 0.0281, 0.0264, 0.0286,
         0.0238, 0.0247, 0.0224, 0.0194]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 93
images/557
(64, 64, 3)
tensor([[0.0308, 0.0329, 0.0107, 0.0257, 0.0261, 0.0224, 0.0269, 0.0151, 0.0179,
         0.0328, 0.0163, 0.0159, 0.0516, 0.0318, 0.0276, 0.0249, 0.0260, 0.0409,
         0.0198, 0.0150, 0.0174, 0.0212, 0.0264, 0.0181, 0.0199, 0.0199, 0.0474,
         0.0217, 0.0335, 0.0362, 0.0219, 0.0219, 0.0278, 0.0272, 0.0216, 0.0205,
         0.0299, 0.0201, 0.0193, 0.0170]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 94
images/17
(64, 64, 3)
tensor([[0.0338, 0.0368, 0.0183, 0.0253, 0.0275, 0.0290, 0.0304, 0.0141, 0.0193,
         0.0377, 0.0195, 0.0184, 0.0412, 0.0434, 0.0211, 0.0128, 0.0174, 0.0257,
         0.0183, 0.0312, 0.0172, 0.0285, 0.0203, 0.0205, 0.0207, 0.0179, 0.0248,
         0.0327, 0.0233, 0.0261, 0.0166, 0.0272, 0.0334, 0.0181, 0.0139, 0.0312,
         0.0281, 0.0328, 0.0275, 0.0181]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 95
images/535
(64, 64, 3)
tensor([[0.0302, 0.0209, 0.0204, 0.0261, 0.0322, 0.0267, 0.0320, 0.0157, 0.0167,
         0.0207, 0.0166, 0.0337, 0.0621, 0.0312, 0.0243, 0.0203, 0.0261, 0.0297,
         0.0176, 0.0172, 0.0201, 0.0345, 0.0176, 0.0203, 0.0314, 0.0191, 0.0233,
         0.0273, 0.0324, 0.0217, 0.0169, 0.0259, 0.0275, 0.0191, 0.0203, 0.0286,
         0.0219, 0.0192, 0.0276, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 96
images/292
(64, 64, 3)
tensor([[0.0183, 0.0247, 0.0215, 0.0178, 0.0371, 0.0203, 0.0296, 0.0284, 0.0197,
         0.0227, 0.0355, 0.0265, 0.0411, 0.0320, 0.0243, 0.0200, 0.0202, 0.0329,
         0.0219, 0.0263, 0.0187, 0.0287, 0.0149, 0.0229, 0.0202, 0.0166, 0.0205,
         0.0468, 0.0264, 0.0224, 0.0245, 0.0281, 0.0294, 0.0278, 0.0241, 0.0231,
         0.0257, 0.0134, 0.0187, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 97
images/328
(64, 64, 3)
tensor([[0.0277, 0.0197, 0.0216, 0.0251, 0.0343, 0.0180, 0.0318, 0.0183, 0.0145,
         0.0219, 0.0304, 0.0325, 0.0220, 0.0417, 0.0324, 0.0141, 0.0167, 0.0267,
         0.0253, 0.0227, 0.0132, 0.0172, 0.0245, 0.0153, 0.0188, 0.0189, 0.0261,
         0.0334, 0.0318, 0.0195, 0.0158, 0.0124, 0.0373, 0.0304, 0.0280, 0.0303,
         0.0450, 0.0225, 0.0213, 0.0412]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 98
images/277
(64, 64, 3)
tensor([[0.0368, 0.0237, 0.0170, 0.0092, 0.0214, 0.0180, 0.0261, 0.0182, 0.0169,
         0.0170, 0.0236, 0.0311, 0.0425, 0.0423, 0.0272, 0.0199, 0.0175, 0.0415,
         0.0291, 0.0223, 0.0151, 0.0235, 0.0201, 0.0142, 0.0209, 0.0216, 0.0301,
         0.0379, 0.0255, 0.0213, 0.0123, 0.0290, 0.0203, 0.0395, 0.0320, 0.0477,
         0.0299, 0.0180, 0.0153, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 99
images/136
(64, 64, 3)
tensor([[0.0195, 0.0262, 0.0174, 0.0152, 0.0577, 0.0255, 0.0366, 0.0241, 0.0231,
         0.0112, 0.0278, 0.0217, 0.0467, 0.0304, 0.0216, 0.0140, 0.0235, 0.0334,
         0.0305, 0.0319, 0.0182, 0.0223, 0.0142, 0.0224, 0.0192, 0.0156, 0.0237,
         0.0271, 0.0222, 0.0224, 0.0120, 0.0337, 0.0251, 0.0365, 0.0194, 0.0415,
         0.0273, 0.0219, 0.0200, 0.0174]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Saving the weights
38 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/58
(64, 64, 3)
2018-10-12 23:47:44.485 Python[7585:15677159] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0263, 0.0298, 0.0165, 0.0205, 0.0374, 0.0154, 0.0366, 0.0150, 0.0145,
         0.0169, 0.0164, 0.0171, 0.0261, 0.0256, 0.0414, 0.0221, 0.0178, 0.0317,
         0.0166, 0.0199, 0.0121, 0.0272, 0.0317, 0.0294, 0.0398, 0.0235, 0.0192,
         0.0270, 0.0307, 0.0147, 0.0230, 0.0321, 0.0215, 0.0243, 0.0223, 0.0326,
         0.0391, 0.0408, 0.0233, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 1
images/484
(64, 64, 3)
tensor([[0.0236, 0.0327, 0.0160, 0.0233, 0.0244, 0.0248, 0.0290, 0.0155, 0.0158,
         0.0133, 0.0205, 0.0287, 0.0281, 0.0448, 0.0230, 0.0106, 0.0291, 0.0478,
         0.0161, 0.0234, 0.0160, 0.0450, 0.0176, 0.0329, 0.0224, 0.0146, 0.0288,
         0.0293, 0.0286, 0.0228, 0.0142, 0.0379, 0.0210, 0.0259, 0.0177, 0.0367,
         0.0333, 0.0224, 0.0169, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/503
(64, 64, 3)
tensor([[0.0328, 0.0299, 0.0167, 0.0180, 0.0288, 0.0274, 0.0270, 0.0143, 0.0136,
         0.0271, 0.0323, 0.0213, 0.0413, 0.0345, 0.0243, 0.0180, 0.0251, 0.0449,
         0.0186, 0.0202, 0.0190, 0.0194, 0.0173, 0.0334, 0.0166, 0.0169, 0.0258,
         0.0230, 0.0291, 0.0175, 0.0205, 0.0289, 0.0279, 0.0318, 0.0316, 0.0335,
         0.0349, 0.0239, 0.0174, 0.0155]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 3
images/384
(64, 64, 3)
tensor([[0.0328, 0.0276, 0.0132, 0.0282, 0.0266, 0.0179, 0.0341, 0.0185, 0.0224,
         0.0137, 0.0353, 0.0297, 0.0262, 0.0295, 0.0268, 0.0224, 0.0164, 0.0412,
         0.0208, 0.0306, 0.0131, 0.0195, 0.0173, 0.0228, 0.0219, 0.0174, 0.0217,
         0.0364, 0.0277, 0.0246, 0.0276, 0.0229, 0.0213, 0.0338, 0.0214, 0.0283,
         0.0244, 0.0334, 0.0273, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 4
images/405
(64, 64, 3)
tensor([[0.0202, 0.0322, 0.0187, 0.0230, 0.0470, 0.0236, 0.0288, 0.0165, 0.0179,
         0.0227, 0.0163, 0.0261, 0.0270, 0.0361, 0.0443, 0.0182, 0.0247, 0.0337,
         0.0224, 0.0169, 0.0148, 0.0233, 0.0212, 0.0200, 0.0155, 0.0233, 0.0391,
         0.0309, 0.0273, 0.0284, 0.0144, 0.0408, 0.0198, 0.0309, 0.0296, 0.0272,
         0.0213, 0.0185, 0.0174, 0.0196]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 5
images/400
(64, 64, 3)
tensor([[0.0252, 0.0367, 0.0209, 0.0192, 0.0283, 0.0181, 0.0272, 0.0148, 0.0191,
         0.0252, 0.0193, 0.0371, 0.0322, 0.0435, 0.0283, 0.0333, 0.0207, 0.0327,
         0.0128, 0.0236, 0.0243, 0.0214, 0.0251, 0.0213, 0.0156, 0.0175, 0.0227,
         0.0204, 0.0372, 0.0319, 0.0223, 0.0251, 0.0273, 0.0190, 0.0232, 0.0394,
         0.0211, 0.0124, 0.0216, 0.0331]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 0
Session Number: 6
images/487
(64, 64, 3)
tensor([[0.0315, 0.0240, 0.0238, 0.0184, 0.0336, 0.0275, 0.0297, 0.0238, 0.0200,
         0.0249, 0.0140, 0.0213, 0.0513, 0.0306, 0.0296, 0.0140, 0.0206, 0.0347,
         0.0192, 0.0218, 0.0130, 0.0215, 0.0276, 0.0221, 0.0139, 0.0195, 0.0258,
         0.0334, 0.0303, 0.0219, 0.0302, 0.0274, 0.0195, 0.0290, 0.0190, 0.0415,
         0.0253, 0.0191, 0.0211, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 7
images/344
(64, 64, 3)
tensor([[0.0371, 0.0257, 0.0154, 0.0202, 0.0194, 0.0166, 0.0313, 0.0145, 0.0149,
         0.0130, 0.0215, 0.0318, 0.0471, 0.0312, 0.0224, 0.0271, 0.0186, 0.0367,
         0.0114, 0.0217, 0.0139, 0.0284, 0.0184, 0.0258, 0.0270, 0.0233, 0.0418,
         0.0382, 0.0341, 0.0234, 0.0364, 0.0273, 0.0211, 0.0225, 0.0172, 0.0280,
         0.0284, 0.0239, 0.0149, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 8
images/192
(64, 64, 3)
tensor([[0.0264, 0.0243, 0.0158, 0.0218, 0.0301, 0.0257, 0.0327, 0.0207, 0.0189,
         0.0283, 0.0169, 0.0294, 0.0407, 0.0315, 0.0212, 0.0227, 0.0227, 0.0425,
         0.0178, 0.0252, 0.0121, 0.0180, 0.0231, 0.0266, 0.0117, 0.0283, 0.0208,
         0.0231, 0.0447, 0.0242, 0.0129, 0.0308, 0.0347, 0.0183, 0.0295, 0.0249,
         0.0301, 0.0234, 0.0189, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 9
images/248
(64, 64, 3)
tensor([[0.0372, 0.0237, 0.0103, 0.0145, 0.0257, 0.0236, 0.0416, 0.0156, 0.0150,
         0.0220, 0.0189, 0.0292, 0.0258, 0.0450, 0.0200, 0.0163, 0.0279, 0.0357,
         0.0149, 0.0152, 0.0167, 0.0235, 0.0174, 0.0277, 0.0202, 0.0216, 0.0328,
         0.0290, 0.0689, 0.0267, 0.0169, 0.0196, 0.0280, 0.0200, 0.0186, 0.0402,
         0.0253, 0.0209, 0.0206, 0.0271]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 10
images/221
(64, 64, 3)
tensor([[0.0143, 0.0313, 0.0186, 0.0119, 0.0531, 0.0185, 0.0361, 0.0184, 0.0159,
         0.0244, 0.0169, 0.0230, 0.0320, 0.0289, 0.0321, 0.0111, 0.0216, 0.0336,
         0.0182, 0.0177, 0.0123, 0.0213, 0.0275, 0.0262, 0.0193, 0.0148, 0.0282,
         0.0279, 0.0271, 0.0189, 0.0220, 0.0233, 0.0403, 0.0355, 0.0264, 0.0330,
         0.0388, 0.0219, 0.0281, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 11
images/553
(64, 64, 3)
tensor([[0.0205, 0.0271, 0.0387, 0.0162, 0.0426, 0.0306, 0.0267, 0.0185, 0.0257,
         0.0225, 0.0151, 0.0462, 0.0190, 0.0248, 0.0224, 0.0262, 0.0181, 0.0436,
         0.0161, 0.0218, 0.0178, 0.0263, 0.0152, 0.0294, 0.0230, 0.0184, 0.0221,
         0.0224, 0.0513, 0.0332, 0.0152, 0.0256, 0.0237, 0.0200, 0.0292, 0.0237,
         0.0216, 0.0227, 0.0140, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 12
images/515
(64, 64, 3)
tensor([[0.0305, 0.0251, 0.0204, 0.0201, 0.0316, 0.0186, 0.0263, 0.0169, 0.0220,
         0.0173, 0.0169, 0.0298, 0.0472, 0.0346, 0.0225, 0.0237, 0.0137, 0.0370,
         0.0173, 0.0191, 0.0174, 0.0239, 0.0210, 0.0281, 0.0226, 0.0228, 0.0174,
         0.0403, 0.0390, 0.0180, 0.0109, 0.0327, 0.0267, 0.0239, 0.0265, 0.0258,
         0.0239, 0.0299, 0.0247, 0.0340]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 13
images/221
(64, 64, 3)
tensor([[0.0199, 0.0337, 0.0179, 0.0109, 0.0255, 0.0382, 0.0557, 0.0316, 0.0115,
         0.0216, 0.0298, 0.0254, 0.0451, 0.0254, 0.0130, 0.0230, 0.0166, 0.0211,
         0.0155, 0.0179, 0.0160, 0.0215, 0.0148, 0.0275, 0.0272, 0.0118, 0.0264,
         0.0404, 0.0293, 0.0112, 0.0196, 0.0381, 0.0359, 0.0164, 0.0285, 0.0327,
         0.0303, 0.0108, 0.0364, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 14
images/104
(64, 64, 3)
tensor([[0.0368, 0.0235, 0.0161, 0.0153, 0.0259, 0.0235, 0.0383, 0.0243, 0.0213,
         0.0184, 0.0229, 0.0265, 0.0344, 0.0337, 0.0267, 0.0163, 0.0210, 0.0346,
         0.0153, 0.0185, 0.0195, 0.0194, 0.0269, 0.0191, 0.0279, 0.0195, 0.0258,
         0.0265, 0.0328, 0.0154, 0.0183, 0.0463, 0.0244, 0.0244, 0.0193, 0.0189,
         0.0288, 0.0169, 0.0448, 0.0316]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 15
images/355
(64, 64, 3)
tensor([[0.0270, 0.0203, 0.0190, 0.0204, 0.0435, 0.0221, 0.0356, 0.0154, 0.0135,
         0.0198, 0.0147, 0.0315, 0.0286, 0.0402, 0.0383, 0.0171, 0.0130, 0.0350,
         0.0181, 0.0249, 0.0224, 0.0183, 0.0272, 0.0200, 0.0300, 0.0206, 0.0250,
         0.0276, 0.0267, 0.0230, 0.0228, 0.0456, 0.0315, 0.0123, 0.0169, 0.0225,
         0.0428, 0.0089, 0.0301, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/558
(64, 64, 3)
tensor([[0.0360, 0.0322, 0.0103, 0.0116, 0.0271, 0.0211, 0.0345, 0.0226, 0.0232,
         0.0259, 0.0208, 0.0181, 0.0353, 0.0409, 0.0241, 0.0185, 0.0184, 0.0352,
         0.0249, 0.0245, 0.0149, 0.0219, 0.0170, 0.0225, 0.0230, 0.0235, 0.0189,
         0.0374, 0.0374, 0.0316, 0.0209, 0.0348, 0.0233, 0.0302, 0.0270, 0.0294,
         0.0170, 0.0216, 0.0174, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 17
images/247
(64, 64, 3)
tensor([[0.0238, 0.0234, 0.0286, 0.0260, 0.0305, 0.0172, 0.0242, 0.0197, 0.0237,
         0.0166, 0.0173, 0.0193, 0.0433, 0.0600, 0.0312, 0.0122, 0.0189, 0.0442,
         0.0175, 0.0155, 0.0156, 0.0255, 0.0177, 0.0234, 0.0177, 0.0136, 0.0233,
         0.0444, 0.0350, 0.0292, 0.0214, 0.0306, 0.0212, 0.0176, 0.0297, 0.0271,
         0.0303, 0.0207, 0.0179, 0.0249]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 18
images/314
(64, 64, 3)
tensor([[0.0182, 0.0240, 0.0186, 0.0162, 0.0287, 0.0199, 0.0355, 0.0205, 0.0159,
         0.0151, 0.0118, 0.0260, 0.0528, 0.0349, 0.0214, 0.0223, 0.0155, 0.0291,
         0.0204, 0.0314, 0.0304, 0.0283, 0.0234, 0.0186, 0.0222, 0.0191, 0.0258,
         0.0286, 0.0400, 0.0254, 0.0202, 0.0388, 0.0271, 0.0205, 0.0229, 0.0277,
         0.0395, 0.0158, 0.0171, 0.0305]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 19
images/298
(64, 64, 3)
tensor([[0.0337, 0.0219, 0.0199, 0.0223, 0.0322, 0.0310, 0.0381, 0.0154, 0.0168,
         0.0205, 0.0152, 0.0333, 0.0464, 0.0328, 0.0178, 0.0167, 0.0208, 0.0367,
         0.0326, 0.0184, 0.0244, 0.0166, 0.0190, 0.0157, 0.0166, 0.0131, 0.0185,
         0.0398, 0.0338, 0.0256, 0.0210, 0.0279, 0.0362, 0.0222, 0.0242, 0.0235,
         0.0288, 0.0222, 0.0263, 0.0218]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 1
Session Number: 20
images/96
(64, 64, 3)
tensor([[0.0261, 0.0209, 0.0154, 0.0157, 0.0388, 0.0272, 0.0357, 0.0136, 0.0165,
         0.0180, 0.0210, 0.0240, 0.0523, 0.0203, 0.0225, 0.0230, 0.0184, 0.0343,
         0.0174, 0.0254, 0.0158, 0.0214, 0.0180, 0.0219, 0.0326, 0.0234, 0.0234,
         0.0293, 0.0291, 0.0376, 0.0298, 0.0262, 0.0178, 0.0246, 0.0257, 0.0372,
         0.0339, 0.0234, 0.0216, 0.0210]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 21
images/476
(64, 64, 3)
tensor([[0.0210, 0.0329, 0.0127, 0.0113, 0.0160, 0.0222, 0.0305, 0.0165, 0.0180,
         0.0129, 0.0228, 0.0331, 0.0621, 0.0345, 0.0193, 0.0193, 0.0258, 0.0251,
         0.0296, 0.0205, 0.0143, 0.0269, 0.0173, 0.0217, 0.0195, 0.0287, 0.0281,
         0.0490, 0.0422, 0.0190, 0.0310, 0.0181, 0.0187, 0.0173, 0.0190, 0.0503,
         0.0247, 0.0169, 0.0291, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/161
(64, 64, 3)
tensor([[0.0317, 0.0327, 0.0189, 0.0157, 0.0194, 0.0147, 0.0394, 0.0220, 0.0164,
         0.0270, 0.0124, 0.0334, 0.0460, 0.0413, 0.0206, 0.0191, 0.0228, 0.0462,
         0.0149, 0.0151, 0.0144, 0.0234, 0.0213, 0.0253, 0.0200, 0.0146, 0.0193,
         0.0250, 0.0393, 0.0224, 0.0129, 0.0271, 0.0309, 0.0344, 0.0309, 0.0427,
         0.0220, 0.0137, 0.0257, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 23
images/475
(64, 64, 3)
tensor([[0.0190, 0.0129, 0.0155, 0.0176, 0.0392, 0.0342, 0.0395, 0.0215, 0.0209,
         0.0303, 0.0149, 0.0346, 0.0472, 0.0360, 0.0253, 0.0181, 0.0308, 0.0262,
         0.0221, 0.0157, 0.0212, 0.0210, 0.0252, 0.0286, 0.0206, 0.0214, 0.0274,
         0.0195, 0.0234, 0.0249, 0.0179, 0.0293, 0.0207, 0.0327, 0.0283, 0.0311,
         0.0256, 0.0198, 0.0186, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 24
images/553
(64, 64, 3)
tensor([[0.0259, 0.0280, 0.0153, 0.0128, 0.0470, 0.0203, 0.0334, 0.0110, 0.0227,
         0.0275, 0.0209, 0.0374, 0.0279, 0.0326, 0.0290, 0.0206, 0.0238, 0.0335,
         0.0173, 0.0179, 0.0186, 0.0225, 0.0193, 0.0237, 0.0280, 0.0279, 0.0222,
         0.0369, 0.0378, 0.0225, 0.0213, 0.0367, 0.0203, 0.0242, 0.0309, 0.0289,
         0.0194, 0.0183, 0.0135, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/306
(64, 64, 3)
tensor([[0.0468, 0.0212, 0.0139, 0.0141, 0.0217, 0.0214, 0.0256, 0.0219, 0.0097,
         0.0184, 0.0201, 0.0245, 0.0604, 0.0223, 0.0168, 0.0236, 0.0188, 0.0262,
         0.0145, 0.0204, 0.0237, 0.0308, 0.0350, 0.0343, 0.0224, 0.0284, 0.0230,
         0.0506, 0.0245, 0.0259, 0.0149, 0.0468, 0.0323, 0.0136, 0.0180, 0.0248,
         0.0307, 0.0147, 0.0226, 0.0210]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 26
images/358
(64, 64, 3)
tensor([[0.0206, 0.0245, 0.0189, 0.0163, 0.0369, 0.0135, 0.0337, 0.0166, 0.0156,
         0.0253, 0.0138, 0.0365, 0.0207, 0.0383, 0.0288, 0.0157, 0.0217, 0.0425,
         0.0156, 0.0190, 0.0304, 0.0362, 0.0266, 0.0262, 0.0221, 0.0136, 0.0188,
         0.0382, 0.0440, 0.0326, 0.0196, 0.0214, 0.0259, 0.0279, 0.0243, 0.0307,
         0.0299, 0.0156, 0.0174, 0.0240]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 27
images/141
(64, 64, 3)
tensor([[0.0198, 0.0326, 0.0212, 0.0196, 0.0329, 0.0161, 0.0239, 0.0166, 0.0205,
         0.0152, 0.0209, 0.0290, 0.0419, 0.0264, 0.0285, 0.0224, 0.0272, 0.0269,
         0.0240, 0.0297, 0.0257, 0.0222, 0.0292, 0.0130, 0.0210, 0.0245, 0.0429,
         0.0294, 0.0237, 0.0195, 0.0178, 0.0254, 0.0224, 0.0331, 0.0288, 0.0326,
         0.0259, 0.0161, 0.0226, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 28
images/450
(64, 64, 3)
tensor([[0.0313, 0.0239, 0.0179, 0.0184, 0.0328, 0.0249, 0.0366, 0.0181, 0.0180,
         0.0241, 0.0250, 0.0321, 0.0540, 0.0255, 0.0200, 0.0144, 0.0202, 0.0448,
         0.0236, 0.0188, 0.0167, 0.0190, 0.0226, 0.0197, 0.0133, 0.0141, 0.0277,
         0.0215, 0.0262, 0.0132, 0.0217, 0.0383, 0.0202, 0.0276, 0.0343, 0.0354,
         0.0419, 0.0181, 0.0229, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 29
images/268
(64, 64, 3)
tensor([[0.0290, 0.0216, 0.0286, 0.0261, 0.0414, 0.0257, 0.0276, 0.0141, 0.0225,
         0.0242, 0.0192, 0.0252, 0.0362, 0.0253, 0.0202, 0.0178, 0.0149, 0.0327,
         0.0172, 0.0277, 0.0145, 0.0219, 0.0392, 0.0263, 0.0218, 0.0129, 0.0247,
         0.0320, 0.0276, 0.0199, 0.0264, 0.0324, 0.0306, 0.0299, 0.0230, 0.0269,
         0.0216, 0.0204, 0.0207, 0.0301]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 30
images/122
(64, 64, 3)
tensor([[0.0320, 0.0271, 0.0127, 0.0217, 0.0270, 0.0138, 0.0228, 0.0202, 0.0138,
         0.0199, 0.0249, 0.0266, 0.0302, 0.0344, 0.0168, 0.0173, 0.0168, 0.0556,
         0.0211, 0.0316, 0.0199, 0.0291, 0.0237, 0.0186, 0.0353, 0.0323, 0.0168,
         0.0410, 0.0383, 0.0220, 0.0182, 0.0380, 0.0230, 0.0217, 0.0201, 0.0285,
         0.0231, 0.0189, 0.0186, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 31
images/363
(64, 64, 3)
tensor([[0.0321, 0.0171, 0.0278, 0.0163, 0.0303, 0.0176, 0.0257, 0.0183, 0.0190,
         0.0286, 0.0151, 0.0630, 0.0254, 0.0319, 0.0244, 0.0143, 0.0180, 0.0399,
         0.0132, 0.0243, 0.0149, 0.0201, 0.0227, 0.0201, 0.0143, 0.0291, 0.0204,
         0.0331, 0.0415, 0.0282, 0.0194, 0.0284, 0.0344, 0.0142, 0.0220, 0.0226,
         0.0340, 0.0340, 0.0136, 0.0304]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 1
Session Number: 32
images/267
(64, 64, 3)
tensor([[0.0254, 0.0339, 0.0138, 0.0203, 0.0254, 0.0218, 0.0431, 0.0148, 0.0179,
         0.0173, 0.0262, 0.0293, 0.0324, 0.0215, 0.0297, 0.0185, 0.0250, 0.0334,
         0.0239, 0.0281, 0.0098, 0.0372, 0.0235, 0.0230, 0.0246, 0.0221, 0.0264,
         0.0235, 0.0167, 0.0332, 0.0159, 0.0264, 0.0390, 0.0251, 0.0247, 0.0267,
         0.0284, 0.0278, 0.0179, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 33
images/411
(64, 64, 3)
tensor([[0.0293, 0.0218, 0.0165, 0.0141, 0.0394, 0.0191, 0.0448, 0.0227, 0.0134,
         0.0200, 0.0153, 0.0429, 0.0372, 0.0325, 0.0236, 0.0160, 0.0177, 0.0454,
         0.0280, 0.0156, 0.0207, 0.0257, 0.0236, 0.0168, 0.0333, 0.0201, 0.0205,
         0.0204, 0.0373, 0.0238, 0.0192, 0.0318, 0.0356, 0.0212, 0.0204, 0.0192,
         0.0352, 0.0126, 0.0220, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 34
images/530
(64, 64, 3)
tensor([[0.0285, 0.0339, 0.0147, 0.0187, 0.0317, 0.0179, 0.0189, 0.0189, 0.0160,
         0.0315, 0.0169, 0.0262, 0.0425, 0.0217, 0.0242, 0.0200, 0.0220, 0.0404,
         0.0160, 0.0188, 0.0182, 0.0322, 0.0189, 0.0236, 0.0216, 0.0218, 0.0408,
         0.0464, 0.0348, 0.0275, 0.0138, 0.0254, 0.0232, 0.0234, 0.0233, 0.0266,
         0.0259, 0.0244, 0.0227, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 35
images/375
(64, 64, 3)
tensor([[0.0401, 0.0252, 0.0236, 0.0142, 0.0259, 0.0268, 0.0323, 0.0180, 0.0179,
         0.0207, 0.0147, 0.0265, 0.0441, 0.0434, 0.0241, 0.0270, 0.0176, 0.0504,
         0.0168, 0.0200, 0.0219, 0.0151, 0.0182, 0.0249, 0.0196, 0.0138, 0.0233,
         0.0270, 0.0566, 0.0260, 0.0165, 0.0210, 0.0223, 0.0201, 0.0271, 0.0249,
         0.0236, 0.0136, 0.0281, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 36
images/346
(64, 64, 3)
tensor([[0.0189, 0.0214, 0.0205, 0.0214, 0.0321, 0.0223, 0.0410, 0.0223, 0.0205,
         0.0112, 0.0167, 0.0276, 0.0347, 0.0351, 0.0224, 0.0120, 0.0182, 0.0518,
         0.0083, 0.0227, 0.0167, 0.0342, 0.0189, 0.0155, 0.0183, 0.0227, 0.0231,
         0.0341, 0.0347, 0.0208, 0.0192, 0.0355, 0.0174, 0.0220, 0.0365, 0.0474,
         0.0317, 0.0261, 0.0232, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 37
images/569
(64, 64, 3)
tensor([[0.0234, 0.0305, 0.0224, 0.0121, 0.0249, 0.0180, 0.0312, 0.0129, 0.0147,
         0.0200, 0.0239, 0.0399, 0.0353, 0.0259, 0.0270, 0.0233, 0.0159, 0.0402,
         0.0219, 0.0205, 0.0169, 0.0310, 0.0217, 0.0202, 0.0225, 0.0185, 0.0251,
         0.0396, 0.0356, 0.0358, 0.0179, 0.0314, 0.0299, 0.0211, 0.0225, 0.0258,
         0.0295, 0.0199, 0.0226, 0.0285]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 38
images/77
(64, 64, 3)
tensor([[0.0226, 0.0179, 0.0263, 0.0132, 0.0247, 0.0165, 0.0393, 0.0256, 0.0189,
         0.0178, 0.0217, 0.0382, 0.0305, 0.0348, 0.0325, 0.0174, 0.0161, 0.0294,
         0.0253, 0.0265, 0.0232, 0.0197, 0.0214, 0.0298, 0.0301, 0.0161, 0.0240,
         0.0400, 0.0262, 0.0253, 0.0224, 0.0269, 0.0288, 0.0224, 0.0329, 0.0338,
         0.0226, 0.0201, 0.0180, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 39
images/25
(64, 64, 3)
tensor([[0.0367, 0.0208, 0.0187, 0.0170, 0.0353, 0.0259, 0.0289, 0.0220, 0.0202,
         0.0273, 0.0224, 0.0184, 0.0461, 0.0455, 0.0258, 0.0162, 0.0170, 0.0406,
         0.0211, 0.0222, 0.0225, 0.0261, 0.0132, 0.0228, 0.0286, 0.0198, 0.0199,
         0.0291, 0.0255, 0.0261, 0.0207, 0.0303, 0.0450, 0.0164, 0.0205, 0.0213,
         0.0290, 0.0164, 0.0185, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 40
images/441
(64, 64, 3)
tensor([[0.0285, 0.0372, 0.0127, 0.0313, 0.0377, 0.0379, 0.0380, 0.0128, 0.0125,
         0.0247, 0.0187, 0.0219, 0.0344, 0.0309, 0.0195, 0.0167, 0.0237, 0.0325,
         0.0205, 0.0260, 0.0248, 0.0229, 0.0243, 0.0176, 0.0253, 0.0264, 0.0227,
         0.0304, 0.0352, 0.0216, 0.0151, 0.0295, 0.0297, 0.0265, 0.0216, 0.0224,
         0.0274, 0.0204, 0.0146, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 41
images/585
(64, 64, 3)
tensor([[0.0227, 0.0206, 0.0142, 0.0175, 0.0300, 0.0222, 0.0373, 0.0139, 0.0163,
         0.0133, 0.0246, 0.0215, 0.0384, 0.0449, 0.0244, 0.0347, 0.0295, 0.0596,
         0.0189, 0.0128, 0.0215, 0.0206, 0.0161, 0.0176, 0.0213, 0.0149, 0.0252,
         0.0342, 0.0458, 0.0195, 0.0235, 0.0166, 0.0261, 0.0211, 0.0252, 0.0310,
         0.0371, 0.0150, 0.0217, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 42
images/469
(64, 64, 3)
tensor([[0.0316, 0.0272, 0.0129, 0.0220, 0.0278, 0.0168, 0.0260, 0.0163, 0.0179,
         0.0183, 0.0135, 0.0455, 0.0578, 0.0269, 0.0344, 0.0322, 0.0150, 0.0441,
         0.0203, 0.0214, 0.0199, 0.0174, 0.0226, 0.0181, 0.0182, 0.0183, 0.0317,
         0.0426, 0.0238, 0.0202, 0.0185, 0.0367, 0.0225, 0.0240, 0.0264, 0.0300,
         0.0238, 0.0145, 0.0223, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 43
images/496
(64, 64, 3)
tensor([[0.0308, 0.0220, 0.0201, 0.0155, 0.0306, 0.0172, 0.0354, 0.0217, 0.0164,
         0.0212, 0.0192, 0.0273, 0.0369, 0.0435, 0.0182, 0.0144, 0.0189, 0.0649,
         0.0221, 0.0289, 0.0147, 0.0307, 0.0194, 0.0134, 0.0206, 0.0188, 0.0301,
         0.0312, 0.0217, 0.0207, 0.0185, 0.0267, 0.0234, 0.0334, 0.0194, 0.0310,
         0.0220, 0.0177, 0.0376, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/168
(64, 64, 3)
tensor([[0.0157, 0.0368, 0.0160, 0.0200, 0.0368, 0.0214, 0.0317, 0.0196, 0.0187,
         0.0164, 0.0153, 0.0300, 0.0400, 0.0375, 0.0290, 0.0241, 0.0287, 0.0550,
         0.0160, 0.0335, 0.0140, 0.0215, 0.0172, 0.0290, 0.0232, 0.0179, 0.0249,
         0.0250, 0.0285, 0.0209, 0.0219, 0.0321, 0.0214, 0.0262, 0.0210, 0.0268,
         0.0221, 0.0229, 0.0220, 0.0192]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 45
images/145
(64, 64, 3)
tensor([[0.0430, 0.0196, 0.0241, 0.0174, 0.0203, 0.0145, 0.0219, 0.0218, 0.0197,
         0.0145, 0.0197, 0.0439, 0.0524, 0.0306, 0.0310, 0.0215, 0.0180, 0.0352,
         0.0201, 0.0216, 0.0184, 0.0207, 0.0165, 0.0261, 0.0195, 0.0166, 0.0411,
         0.0299, 0.0322, 0.0225, 0.0157, 0.0404, 0.0266, 0.0262, 0.0196, 0.0297,
         0.0218, 0.0189, 0.0212, 0.0257]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 46
images/571
(64, 64, 3)
tensor([[0.0233, 0.0333, 0.0150, 0.0163, 0.0296, 0.0168, 0.0625, 0.0207, 0.0218,
         0.0182, 0.0191, 0.0219, 0.0484, 0.0475, 0.0238, 0.0152, 0.0215, 0.0272,
         0.0237, 0.0310, 0.0222, 0.0168, 0.0288, 0.0180, 0.0128, 0.0166, 0.0333,
         0.0348, 0.0214, 0.0223, 0.0199, 0.0217, 0.0285, 0.0331, 0.0195, 0.0272,
         0.0182, 0.0211, 0.0221, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 47
images/19
(64, 64, 3)
tensor([[0.0403, 0.0267, 0.0175, 0.0144, 0.0278, 0.0252, 0.0213, 0.0178, 0.0179,
         0.0229, 0.0216, 0.0301, 0.0266, 0.0366, 0.0258, 0.0197, 0.0302, 0.0429,
         0.0166, 0.0239, 0.0127, 0.0285, 0.0183, 0.0216, 0.0248, 0.0201, 0.0171,
         0.0243, 0.0312, 0.0201, 0.0169, 0.0305, 0.0297, 0.0243, 0.0256, 0.0277,
         0.0396, 0.0275, 0.0213, 0.0323]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 48
images/453
(64, 64, 3)
tensor([[0.0278, 0.0231, 0.0169, 0.0146, 0.0425, 0.0180, 0.0219, 0.0128, 0.0238,
         0.0132, 0.0242, 0.0589, 0.0271, 0.0281, 0.0245, 0.0269, 0.0196, 0.0297,
         0.0220, 0.0291, 0.0203, 0.0275, 0.0155, 0.0201, 0.0254, 0.0251, 0.0253,
         0.0315, 0.0282, 0.0247, 0.0230, 0.0260, 0.0201, 0.0259, 0.0219, 0.0296,
         0.0345, 0.0147, 0.0251, 0.0313]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 1
Session Number: 49
images/336
(64, 64, 3)
tensor([[0.0236, 0.0213, 0.0180, 0.0208, 0.0304, 0.0279, 0.0477, 0.0174, 0.0206,
         0.0297, 0.0171, 0.0303, 0.0488, 0.0356, 0.0212, 0.0235, 0.0194, 0.0304,
         0.0248, 0.0274, 0.0274, 0.0239, 0.0195, 0.0149, 0.0204, 0.0148, 0.0233,
         0.0369, 0.0284, 0.0179, 0.0156, 0.0180, 0.0341, 0.0292, 0.0271, 0.0274,
         0.0254, 0.0171, 0.0217, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 50
images/299
(64, 64, 3)
tensor([[0.0240, 0.0250, 0.0202, 0.0144, 0.0406, 0.0187, 0.0385, 0.0149, 0.0170,
         0.0211, 0.0168, 0.0226, 0.0307, 0.0364, 0.0281, 0.0194, 0.0158, 0.0423,
         0.0160, 0.0174, 0.0232, 0.0322, 0.0238, 0.0243, 0.0195, 0.0128, 0.0265,
         0.0269, 0.0406, 0.0216, 0.0159, 0.0413, 0.0304, 0.0220, 0.0212, 0.0300,
         0.0216, 0.0258, 0.0298, 0.0309]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: q
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 174, in <module>
    main()
  File "Torch_reinforce01.py", line 144, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: 'q'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/327
(64, 64, 3)
2018-10-12 23:54:25.489 Python[7767:15680773] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0322, 0.0188, 0.0195, 0.0325, 0.0293, 0.0207, 0.0271, 0.0214, 0.0235,
         0.0162, 0.0188, 0.0239, 0.0320, 0.0298, 0.0405, 0.0194, 0.0157, 0.0255,
         0.0129, 0.0223, 0.0173, 0.0282, 0.0281, 0.0231, 0.0366, 0.0223, 0.0278,
         0.0303, 0.0235, 0.0197, 0.0161, 0.0286, 0.0222, 0.0227, 0.0298, 0.0270,
         0.0310, 0.0397, 0.0243, 0.0196]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 1
images/339
(64, 64, 3)
tensor([[0.0270, 0.0235, 0.0239, 0.0119, 0.0433, 0.0199, 0.0231, 0.0211, 0.0181,
         0.0153, 0.0212, 0.0464, 0.0210, 0.0362, 0.0270, 0.0213, 0.0228, 0.0370,
         0.0208, 0.0332, 0.0201, 0.0292, 0.0183, 0.0292, 0.0295, 0.0179, 0.0182,
         0.0327, 0.0306, 0.0186, 0.0147, 0.0330, 0.0237, 0.0356, 0.0256, 0.0261,
         0.0250, 0.0172, 0.0165, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/589
(64, 64, 3)
tensor([[0.0330, 0.0348, 0.0135, 0.0235, 0.0276, 0.0222, 0.0301, 0.0130, 0.0146,
         0.0207, 0.0202, 0.0356, 0.0355, 0.0281, 0.0271, 0.0215, 0.0214, 0.0274,
         0.0174, 0.0129, 0.0182, 0.0220, 0.0240, 0.0277, 0.0186, 0.0133, 0.0297,
         0.0342, 0.0493, 0.0189, 0.0256, 0.0319, 0.0273, 0.0278, 0.0358, 0.0278,
         0.0307, 0.0201, 0.0207, 0.0162]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 3
images/397
(64, 64, 3)
tensor([[0.0349, 0.0271, 0.0186, 0.0256, 0.0331, 0.0184, 0.0277, 0.0217, 0.0307,
         0.0127, 0.0337, 0.0291, 0.0321, 0.0359, 0.0261, 0.0153, 0.0196, 0.0355,
         0.0140, 0.0230, 0.0164, 0.0180, 0.0205, 0.0201, 0.0232, 0.0173, 0.0197,
         0.0435, 0.0439, 0.0180, 0.0240, 0.0169, 0.0212, 0.0339, 0.0301, 0.0263,
         0.0225, 0.0281, 0.0259, 0.0157]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 4
images/441
(64, 64, 3)
tensor([[0.0238, 0.0378, 0.0190, 0.0214, 0.0488, 0.0221, 0.0302, 0.0138, 0.0208,
         0.0312, 0.0144, 0.0391, 0.0336, 0.0290, 0.0266, 0.0175, 0.0178, 0.0394,
         0.0194, 0.0151, 0.0168, 0.0211, 0.0204, 0.0226, 0.0187, 0.0286, 0.0378,
         0.0309, 0.0289, 0.0255, 0.0081, 0.0327, 0.0232, 0.0285, 0.0314, 0.0226,
         0.0210, 0.0206, 0.0166, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 5
images/590
(64, 64, 3)
tensor([[0.0168, 0.0339, 0.0216, 0.0134, 0.0296, 0.0163, 0.0336, 0.0199, 0.0186,
         0.0207, 0.0237, 0.0337, 0.0301, 0.0313, 0.0313, 0.0328, 0.0223, 0.0365,
         0.0137, 0.0263, 0.0275, 0.0214, 0.0228, 0.0213, 0.0216, 0.0217, 0.0244,
         0.0276, 0.0273, 0.0276, 0.0226, 0.0283, 0.0284, 0.0270, 0.0200, 0.0327,
         0.0234, 0.0153, 0.0221, 0.0305]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 6
images/169
(64, 64, 3)
tensor([[0.0425, 0.0259, 0.0215, 0.0192, 0.0230, 0.0229, 0.0224, 0.0160, 0.0282,
         0.0243, 0.0189, 0.0264, 0.0374, 0.0245, 0.0412, 0.0208, 0.0134, 0.0412,
         0.0194, 0.0244, 0.0162, 0.0199, 0.0266, 0.0252, 0.0173, 0.0200, 0.0224,
         0.0301, 0.0374, 0.0239, 0.0226, 0.0264, 0.0243, 0.0249, 0.0201, 0.0327,
         0.0252, 0.0205, 0.0191, 0.0316]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 7
images/133
(64, 64, 3)
tensor([[0.0293, 0.0255, 0.0257, 0.0159, 0.0268, 0.0154, 0.0323, 0.0131, 0.0154,
         0.0127, 0.0190, 0.0409, 0.0319, 0.0296, 0.0149, 0.0324, 0.0197, 0.0217,
         0.0136, 0.0272, 0.0176, 0.0230, 0.0162, 0.0233, 0.0229, 0.0194, 0.0427,
         0.0532, 0.0473, 0.0180, 0.0285, 0.0302, 0.0220, 0.0336, 0.0166, 0.0297,
         0.0296, 0.0181, 0.0174, 0.0274]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/125
(64, 64, 3)
tensor([[0.0225, 0.0249, 0.0173, 0.0226, 0.0303, 0.0223, 0.0208, 0.0216, 0.0189,
         0.0300, 0.0162, 0.0424, 0.0437, 0.0169, 0.0230, 0.0250, 0.0249, 0.0454,
         0.0244, 0.0225, 0.0144, 0.0214, 0.0301, 0.0263, 0.0188, 0.0294, 0.0185,
         0.0265, 0.0336, 0.0183, 0.0147, 0.0276, 0.0263, 0.0191, 0.0203, 0.0305,
         0.0285, 0.0224, 0.0196, 0.0381]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 9
images/422
(64, 64, 3)
tensor([[0.0214, 0.0268, 0.0140, 0.0174, 0.0281, 0.0179, 0.0451, 0.0209, 0.0154,
         0.0259, 0.0248, 0.0172, 0.0377, 0.0437, 0.0227, 0.0119, 0.0275, 0.0332,
         0.0180, 0.0145, 0.0203, 0.0167, 0.0166, 0.0258, 0.0181, 0.0178, 0.0337,
         0.0260, 0.0561, 0.0226, 0.0277, 0.0342, 0.0345, 0.0205, 0.0139, 0.0417,
         0.0183, 0.0165, 0.0302, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 10
images/540
(64, 64, 3)
tensor([[0.0219, 0.0202, 0.0166, 0.0124, 0.0534, 0.0160, 0.0294, 0.0122, 0.0198,
         0.0240, 0.0190, 0.0337, 0.0444, 0.0280, 0.0296, 0.0117, 0.0228, 0.0295,
         0.0237, 0.0176, 0.0165, 0.0205, 0.0223, 0.0269, 0.0194, 0.0236, 0.0391,
         0.0205, 0.0293, 0.0241, 0.0243, 0.0249, 0.0339, 0.0225, 0.0313, 0.0275,
         0.0333, 0.0261, 0.0220, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 11
images/246
(64, 64, 3)
tensor([[0.0224, 0.0244, 0.0258, 0.0182, 0.0395, 0.0372, 0.0297, 0.0144, 0.0202,
         0.0264, 0.0137, 0.0254, 0.0271, 0.0327, 0.0221, 0.0154, 0.0188, 0.0447,
         0.0149, 0.0204, 0.0202, 0.0209, 0.0199, 0.0367, 0.0232, 0.0158, 0.0217,
         0.0285, 0.0503, 0.0292, 0.0156, 0.0230, 0.0259, 0.0196, 0.0277, 0.0224,
         0.0348, 0.0321, 0.0160, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/49
(64, 64, 3)
tensor([[0.0298, 0.0272, 0.0220, 0.0208, 0.0417, 0.0205, 0.0263, 0.0166, 0.0212,
         0.0143, 0.0192, 0.0244, 0.0629, 0.0406, 0.0156, 0.0316, 0.0174, 0.0366,
         0.0175, 0.0144, 0.0184, 0.0225, 0.0265, 0.0247, 0.0193, 0.0247, 0.0203,
         0.0303, 0.0375, 0.0233, 0.0129, 0.0307, 0.0218, 0.0139, 0.0248, 0.0232,
         0.0290, 0.0189, 0.0197, 0.0368]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 13
images/434
(64, 64, 3)
tensor([[0.0216, 0.0267, 0.0223, 0.0128, 0.0257, 0.0459, 0.0353, 0.0267, 0.0108,
         0.0278, 0.0246, 0.0282, 0.0362, 0.0340, 0.0172, 0.0231, 0.0181, 0.0271,
         0.0168, 0.0220, 0.0159, 0.0274, 0.0207, 0.0212, 0.0274, 0.0098, 0.0341,
         0.0347, 0.0273, 0.0157, 0.0179, 0.0242, 0.0319, 0.0171, 0.0327, 0.0292,
         0.0327, 0.0183, 0.0356, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 14
images/210
(64, 64, 3)
tensor([[0.0429, 0.0242, 0.0194, 0.0141, 0.0204, 0.0242, 0.0420, 0.0194, 0.0159,
         0.0162, 0.0182, 0.0305, 0.0223, 0.0249, 0.0327, 0.0218, 0.0182, 0.0479,
         0.0142, 0.0231, 0.0146, 0.0197, 0.0277, 0.0138, 0.0167, 0.0296, 0.0336,
         0.0252, 0.0315, 0.0206, 0.0209, 0.0528, 0.0308, 0.0167, 0.0175, 0.0209,
         0.0188, 0.0162, 0.0524, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 15
images/147
(64, 64, 3)
tensor([[0.0289, 0.0346, 0.0150, 0.0150, 0.0350, 0.0242, 0.0389, 0.0127, 0.0147,
         0.0233, 0.0164, 0.0306, 0.0313, 0.0318, 0.0344, 0.0182, 0.0175, 0.0316,
         0.0152, 0.0251, 0.0198, 0.0233, 0.0165, 0.0287, 0.0256, 0.0173, 0.0213,
         0.0317, 0.0263, 0.0227, 0.0289, 0.0324, 0.0230, 0.0152, 0.0199, 0.0377,
         0.0453, 0.0092, 0.0318, 0.0290]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/408
(64, 64, 3)
tensor([[0.0324, 0.0228, 0.0092, 0.0157, 0.0258, 0.0183, 0.0420, 0.0189, 0.0173,
         0.0193, 0.0205, 0.0196, 0.0430, 0.0344, 0.0209, 0.0187, 0.0236, 0.0543,
         0.0192, 0.0257, 0.0203, 0.0249, 0.0198, 0.0166, 0.0218, 0.0306, 0.0206,
         0.0246, 0.0309, 0.0230, 0.0121, 0.0538, 0.0251, 0.0182, 0.0260, 0.0455,
         0.0215, 0.0250, 0.0230, 0.0149]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 17
images/10
(64, 64, 3)
tensor([[0.0240, 0.0209, 0.0207, 0.0156, 0.0365, 0.0178, 0.0283, 0.0182, 0.0236,
         0.0221, 0.0176, 0.0279, 0.0336, 0.0372, 0.0304, 0.0198, 0.0225, 0.0751,
         0.0205, 0.0161, 0.0167, 0.0210, 0.0337, 0.0185, 0.0200, 0.0180, 0.0235,
         0.0274, 0.0249, 0.0374, 0.0137, 0.0305, 0.0235, 0.0170, 0.0269, 0.0324,
         0.0270, 0.0117, 0.0226, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 18
images/428
(64, 64, 3)
tensor([[0.0191, 0.0277, 0.0239, 0.0199, 0.0220, 0.0163, 0.0330, 0.0181, 0.0149,
         0.0153, 0.0123, 0.0286, 0.0518, 0.0336, 0.0181, 0.0268, 0.0162, 0.0281,
         0.0144, 0.0240, 0.0205, 0.0274, 0.0284, 0.0244, 0.0182, 0.0159, 0.0386,
         0.0370, 0.0347, 0.0166, 0.0169, 0.0288, 0.0309, 0.0217, 0.0424, 0.0315,
         0.0272, 0.0177, 0.0180, 0.0392]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 19
images/592
(64, 64, 3)
tensor([[0.0332, 0.0267, 0.0173, 0.0199, 0.0395, 0.0246, 0.0397, 0.0179, 0.0178,
         0.0195, 0.0101, 0.0312, 0.0359, 0.0401, 0.0282, 0.0207, 0.0276, 0.0523,
         0.0285, 0.0178, 0.0182, 0.0219, 0.0123, 0.0189, 0.0132, 0.0139, 0.0240,
         0.0272, 0.0310, 0.0223, 0.0149, 0.0274, 0.0409, 0.0164, 0.0252, 0.0183,
         0.0282, 0.0196, 0.0282, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 20
images/284
(64, 64, 3)
tensor([[0.0287, 0.0267, 0.0169, 0.0268, 0.0272, 0.0319, 0.0290, 0.0161, 0.0117,
         0.0153, 0.0229, 0.0277, 0.0561, 0.0246, 0.0202, 0.0182, 0.0142, 0.0350,
         0.0165, 0.0202, 0.0193, 0.0240, 0.0169, 0.0211, 0.0227, 0.0360, 0.0259,
         0.0337, 0.0374, 0.0219, 0.0289, 0.0203, 0.0220, 0.0167, 0.0241, 0.0324,
         0.0347, 0.0351, 0.0173, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 21
images/145
(64, 64, 3)
tensor([[0.0294, 0.0306, 0.0229, 0.0140, 0.0205, 0.0192, 0.0232, 0.0146, 0.0177,
         0.0185, 0.0243, 0.0301, 0.0526, 0.0327, 0.0265, 0.0157, 0.0231, 0.0310,
         0.0202, 0.0194, 0.0125, 0.0233, 0.0151, 0.0233, 0.0185, 0.0202, 0.0262,
         0.0444, 0.0373, 0.0184, 0.0261, 0.0330, 0.0226, 0.0233, 0.0222, 0.0388,
         0.0387, 0.0209, 0.0221, 0.0270]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/252
(64, 64, 3)
tensor([[0.0300, 0.0374, 0.0195, 0.0152, 0.0192, 0.0171, 0.0427, 0.0175, 0.0195,
         0.0247, 0.0140, 0.0215, 0.0406, 0.0475, 0.0231, 0.0262, 0.0197, 0.0497,
         0.0157, 0.0196, 0.0152, 0.0270, 0.0196, 0.0246, 0.0241, 0.0127, 0.0203,
         0.0220, 0.0300, 0.0206, 0.0191, 0.0273, 0.0312, 0.0307, 0.0288, 0.0394,
         0.0164, 0.0171, 0.0213, 0.0326]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 23
images/494
(64, 64, 3)
tensor([[0.0209, 0.0230, 0.0204, 0.0147, 0.0286, 0.0309, 0.0404, 0.0221, 0.0152,
         0.0257, 0.0185, 0.0247, 0.0390, 0.0325, 0.0340, 0.0145, 0.0309, 0.0208,
         0.0265, 0.0147, 0.0179, 0.0290, 0.0245, 0.0256, 0.0166, 0.0233, 0.0327,
         0.0227, 0.0252, 0.0336, 0.0159, 0.0327, 0.0201, 0.0312, 0.0294, 0.0268,
         0.0271, 0.0234, 0.0236, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 24
images/40
(64, 64, 3)
tensor([[0.0216, 0.0207, 0.0201, 0.0242, 0.0386, 0.0189, 0.0256, 0.0115, 0.0289,
         0.0199, 0.0185, 0.0373, 0.0389, 0.0212, 0.0292, 0.0168, 0.0193, 0.0344,
         0.0164, 0.0134, 0.0167, 0.0254, 0.0216, 0.0198, 0.0143, 0.0349, 0.0206,
         0.0389, 0.0400, 0.0277, 0.0293, 0.0380, 0.0250, 0.0273, 0.0245, 0.0466,
         0.0187, 0.0144, 0.0206, 0.0204]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/289
(64, 64, 3)
tensor([[0.0212, 0.0202, 0.0122, 0.0199, 0.0236, 0.0150, 0.0333, 0.0184, 0.0129,
         0.0185, 0.0185, 0.0401, 0.0487, 0.0314, 0.0163, 0.0238, 0.0225, 0.0364,
         0.0119, 0.0261, 0.0216, 0.0303, 0.0294, 0.0317, 0.0270, 0.0211, 0.0192,
         0.0449, 0.0406, 0.0433, 0.0166, 0.0330, 0.0265, 0.0147, 0.0156, 0.0321,
         0.0241, 0.0169, 0.0171, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 26
images/484
(64, 64, 3)
tensor([[0.0168, 0.0287, 0.0153, 0.0208, 0.0392, 0.0155, 0.0261, 0.0181, 0.0145,
         0.0189, 0.0150, 0.0303, 0.0306, 0.0519, 0.0284, 0.0121, 0.0184, 0.0319,
         0.0159, 0.0264, 0.0282, 0.0494, 0.0239, 0.0242, 0.0251, 0.0139, 0.0280,
         0.0365, 0.0326, 0.0268, 0.0190, 0.0221, 0.0255, 0.0280, 0.0236, 0.0312,
         0.0191, 0.0161, 0.0211, 0.0308]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 27
images/201
(64, 64, 3)
tensor([[0.0313, 0.0473, 0.0156, 0.0150, 0.0183, 0.0130, 0.0277, 0.0199, 0.0226,
         0.0128, 0.0203, 0.0322, 0.0355, 0.0224, 0.0271, 0.0344, 0.0358, 0.0335,
         0.0137, 0.0235, 0.0203, 0.0296, 0.0241, 0.0174, 0.0187, 0.0160, 0.0392,
         0.0335, 0.0302, 0.0180, 0.0177, 0.0218, 0.0209, 0.0219, 0.0219, 0.0318,
         0.0342, 0.0204, 0.0294, 0.0312]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 0
Session Number: 28
images/354
(64, 64, 3)
tensor([[0.0420, 0.0225, 0.0181, 0.0153, 0.0313, 0.0159, 0.0375, 0.0176, 0.0169,
         0.0191, 0.0273, 0.0261, 0.0589, 0.0292, 0.0227, 0.0082, 0.0170, 0.0424,
         0.0193, 0.0159, 0.0123, 0.0255, 0.0261, 0.0282, 0.0158, 0.0173, 0.0269,
         0.0251, 0.0240, 0.0229, 0.0282, 0.0339, 0.0175, 0.0253, 0.0228, 0.0389,
         0.0348, 0.0188, 0.0332, 0.0189]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 29
images/446
(64, 64, 3)
tensor([[0.0335, 0.0249, 0.0216, 0.0239, 0.0350, 0.0171, 0.0283, 0.0114, 0.0176,
         0.0307, 0.0219, 0.0183, 0.0392, 0.0302, 0.0213, 0.0249, 0.0165, 0.0295,
         0.0148, 0.0296, 0.0203, 0.0300, 0.0294, 0.0213, 0.0255, 0.0146, 0.0239,
         0.0326, 0.0287, 0.0186, 0.0201, 0.0339, 0.0300, 0.0297, 0.0262, 0.0316,
         0.0341, 0.0151, 0.0200, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 30
images/591
(64, 64, 3)
tensor([[0.0372, 0.0256, 0.0173, 0.0170, 0.0280, 0.0096, 0.0339, 0.0226, 0.0209,
         0.0242, 0.0228, 0.0302, 0.0274, 0.0287, 0.0205, 0.0215, 0.0184, 0.0322,
         0.0198, 0.0306, 0.0248, 0.0335, 0.0163, 0.0218, 0.0333, 0.0286, 0.0166,
         0.0466, 0.0277, 0.0266, 0.0207, 0.0289, 0.0212, 0.0253, 0.0223, 0.0255,
         0.0248, 0.0251, 0.0227, 0.0193]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 31
images/559
(64, 64, 3)
tensor([[0.0298, 0.0267, 0.0224, 0.0147, 0.0300, 0.0207, 0.0294, 0.0195, 0.0179,
         0.0239, 0.0246, 0.0392, 0.0167, 0.0320, 0.0197, 0.0165, 0.0256, 0.0453,
         0.0163, 0.0186, 0.0167, 0.0165, 0.0245, 0.0265, 0.0182, 0.0200, 0.0223,
         0.0350, 0.0408, 0.0227, 0.0162, 0.0398, 0.0313, 0.0156, 0.0133, 0.0269,
         0.0364, 0.0279, 0.0218, 0.0382]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 32
images/248
(64, 64, 3)
tensor([[0.0202, 0.0299, 0.0112, 0.0197, 0.0327, 0.0345, 0.0418, 0.0150, 0.0103,
         0.0140, 0.0289, 0.0363, 0.0341, 0.0308, 0.0285, 0.0261, 0.0354, 0.0341,
         0.0208, 0.0273, 0.0132, 0.0294, 0.0226, 0.0202, 0.0225, 0.0238, 0.0366,
         0.0260, 0.0327, 0.0231, 0.0136, 0.0151, 0.0254, 0.0253, 0.0240, 0.0259,
         0.0267, 0.0210, 0.0205, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 33
images/384
(64, 64, 3)
tensor([[0.0314, 0.0245, 0.0137, 0.0222, 0.0328, 0.0270, 0.0413, 0.0176, 0.0156,
         0.0191, 0.0152, 0.0447, 0.0392, 0.0236, 0.0233, 0.0135, 0.0170, 0.0367,
         0.0378, 0.0162, 0.0199, 0.0164, 0.0267, 0.0173, 0.0299, 0.0187, 0.0199,
         0.0231, 0.0335, 0.0237, 0.0193, 0.0418, 0.0324, 0.0277, 0.0140, 0.0269,
         0.0326, 0.0146, 0.0181, 0.0313]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 34
images/584
(64, 64, 3)
tensor([[0.0284, 0.0193, 0.0203, 0.0140, 0.0274, 0.0276, 0.0241, 0.0183, 0.0153,
         0.0199, 0.0211, 0.0212, 0.0314, 0.0248, 0.0282, 0.0182, 0.0235, 0.0483,
         0.0172, 0.0137, 0.0194, 0.0334, 0.0239, 0.0264, 0.0284, 0.0205, 0.0259,
         0.0419, 0.0318, 0.0239, 0.0226, 0.0318, 0.0283, 0.0248, 0.0278, 0.0326,
         0.0246, 0.0184, 0.0264, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 35
images/168
(64, 64, 3)
tensor([[0.0215, 0.0246, 0.0224, 0.0124, 0.0351, 0.0250, 0.0259, 0.0218, 0.0175,
         0.0211, 0.0146, 0.0248, 0.0302, 0.0506, 0.0257, 0.0209, 0.0218, 0.0550,
         0.0220, 0.0237, 0.0134, 0.0159, 0.0238, 0.0345, 0.0188, 0.0179, 0.0235,
         0.0223, 0.0451, 0.0331, 0.0159, 0.0283, 0.0272, 0.0267, 0.0192, 0.0301,
         0.0232, 0.0243, 0.0166, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 36
images/375
(64, 64, 3)
tensor([[0.0322, 0.0250, 0.0176, 0.0288, 0.0306, 0.0228, 0.0373, 0.0201, 0.0125,
         0.0144, 0.0136, 0.0196, 0.0287, 0.0419, 0.0313, 0.0224, 0.0186, 0.0325,
         0.0160, 0.0247, 0.0165, 0.0168, 0.0183, 0.0136, 0.0171, 0.0184, 0.0164,
         0.0328, 0.0365, 0.0192, 0.0343, 0.0346, 0.0141, 0.0173, 0.0309, 0.0589,
         0.0305, 0.0206, 0.0329, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 37
images/407
(64, 64, 3)
tensor([[0.0261, 0.0300, 0.0182, 0.0148, 0.0351, 0.0143, 0.0310, 0.0134, 0.0279,
         0.0154, 0.0224, 0.0424, 0.0319, 0.0436, 0.0226, 0.0261, 0.0208, 0.0279,
         0.0200, 0.0207, 0.0193, 0.0243, 0.0179, 0.0249, 0.0250, 0.0250, 0.0223,
         0.0395, 0.0295, 0.0274, 0.0181, 0.0312, 0.0321, 0.0187, 0.0194, 0.0233,
         0.0261, 0.0159, 0.0232, 0.0325]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 38
images/266
(64, 64, 3)
tensor([[0.0198, 0.0293, 0.0302, 0.0124, 0.0304, 0.0155, 0.0369, 0.0249, 0.0179,
         0.0192, 0.0168, 0.0381, 0.0361, 0.0297, 0.0246, 0.0178, 0.0181, 0.0335,
         0.0231, 0.0219, 0.0214, 0.0235, 0.0137, 0.0303, 0.0229, 0.0216, 0.0226,
         0.0379, 0.0307, 0.0208, 0.0310, 0.0350, 0.0255, 0.0129, 0.0267, 0.0406,
         0.0254, 0.0157, 0.0219, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 39
images/255
(64, 64, 3)
tensor([[0.0424, 0.0170, 0.0171, 0.0183, 0.0475, 0.0210, 0.0285, 0.0171, 0.0157,
         0.0227, 0.0160, 0.0249, 0.0356, 0.0407, 0.0159, 0.0200, 0.0184, 0.0513,
         0.0245, 0.0171, 0.0220, 0.0248, 0.0188, 0.0216, 0.0270, 0.0186, 0.0235,
         0.0456, 0.0317, 0.0234, 0.0130, 0.0435, 0.0354, 0.0129, 0.0226, 0.0228,
         0.0171, 0.0198, 0.0202, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 40
images/66
(64, 64, 3)
tensor([[0.0318, 0.0299, 0.0220, 0.0199, 0.0309, 0.0229, 0.0328, 0.0185, 0.0175,
         0.0180, 0.0150, 0.0300, 0.0345, 0.0374, 0.0246, 0.0199, 0.0214, 0.0340,
         0.0133, 0.0253, 0.0234, 0.0272, 0.0264, 0.0225, 0.0212, 0.0260, 0.0164,
         0.0283, 0.0316, 0.0279, 0.0214, 0.0374, 0.0323, 0.0242, 0.0240, 0.0229,
         0.0284, 0.0161, 0.0174, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 41
images/256
(64, 64, 3)
tensor([[0.0310, 0.0213, 0.0167, 0.0180, 0.0289, 0.0145, 0.0452, 0.0181, 0.0220,
         0.0120, 0.0208, 0.0393, 0.0422, 0.0335, 0.0263, 0.0314, 0.0218, 0.0422,
         0.0251, 0.0157, 0.0319, 0.0177, 0.0194, 0.0171, 0.0167, 0.0199, 0.0363,
         0.0228, 0.0264, 0.0370, 0.0315, 0.0262, 0.0253, 0.0214, 0.0214, 0.0208,
         0.0263, 0.0162, 0.0190, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 42
images/349
(64, 64, 3)
tensor([[0.0285, 0.0323, 0.0174, 0.0242, 0.0365, 0.0176, 0.0197, 0.0238, 0.0229,
         0.0215, 0.0173, 0.0312, 0.0391, 0.0291, 0.0218, 0.0339, 0.0198, 0.0434,
         0.0201, 0.0307, 0.0199, 0.0236, 0.0240, 0.0212, 0.0161, 0.0178, 0.0261,
         0.0353, 0.0267, 0.0265, 0.0154, 0.0327, 0.0207, 0.0221, 0.0290, 0.0227,
         0.0306, 0.0185, 0.0207, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/471
(64, 64, 3)
tensor([[0.0279, 0.0181, 0.0130, 0.0223, 0.0276, 0.0287, 0.0286, 0.0177, 0.0119,
         0.0227, 0.0319, 0.0195, 0.0443, 0.0442, 0.0212, 0.0132, 0.0151, 0.0507,
         0.0232, 0.0264, 0.0118, 0.0289, 0.0233, 0.0155, 0.0202, 0.0164, 0.0249,
         0.0467, 0.0283, 0.0190, 0.0218, 0.0347, 0.0198, 0.0365, 0.0255, 0.0204,
         0.0261, 0.0189, 0.0275, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/330
(64, 64, 3)
tensor([[0.0188, 0.0431, 0.0132, 0.0207, 0.0368, 0.0223, 0.0322, 0.0158, 0.0225,
         0.0153, 0.0145, 0.0251, 0.0408, 0.0300, 0.0318, 0.0233, 0.0255, 0.0376,
         0.0144, 0.0302, 0.0202, 0.0266, 0.0159, 0.0255, 0.0177, 0.0191, 0.0280,
         0.0312, 0.0265, 0.0210, 0.0243, 0.0329, 0.0310, 0.0280, 0.0235, 0.0212,
         0.0205, 0.0288, 0.0232, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 45
images/294
(64, 64, 3)
tensor([[0.0287, 0.0203, 0.0209, 0.0225, 0.0351, 0.0137, 0.0198, 0.0190, 0.0216,
         0.0183, 0.0170, 0.0410, 0.0452, 0.0197, 0.0226, 0.0236, 0.0202, 0.0376,
         0.0252, 0.0267, 0.0200, 0.0184, 0.0174, 0.0304, 0.0180, 0.0155, 0.0299,
         0.0345, 0.0415, 0.0294, 0.0156, 0.0411, 0.0257, 0.0350, 0.0190, 0.0332,
         0.0193, 0.0196, 0.0195, 0.0182]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 46
images/279
(64, 64, 3)
tensor([[0.0232, 0.0375, 0.0178, 0.0130, 0.0292, 0.0158, 0.0421, 0.0193, 0.0123,
         0.0220, 0.0195, 0.0175, 0.0638, 0.0276, 0.0272, 0.0177, 0.0161, 0.0207,
         0.0292, 0.0276, 0.0228, 0.0201, 0.0314, 0.0220, 0.0189, 0.0105, 0.0315,
         0.0370, 0.0238, 0.0300, 0.0188, 0.0283, 0.0331, 0.0305, 0.0196, 0.0284,
         0.0213, 0.0265, 0.0200, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 47
images/451
(64, 64, 3)
tensor([[0.0202, 0.0237, 0.0165, 0.0141, 0.0269, 0.0318, 0.0339, 0.0270, 0.0195,
         0.0153, 0.0236, 0.0354, 0.0302, 0.0370, 0.0214, 0.0214, 0.0193, 0.0397,
         0.0152, 0.0167, 0.0132, 0.0231, 0.0205, 0.0187, 0.0282, 0.0174, 0.0198,
         0.0436, 0.0322, 0.0239, 0.0186, 0.0255, 0.0261, 0.0354, 0.0266, 0.0457,
         0.0270, 0.0163, 0.0187, 0.0306]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 48
images/520
(64, 64, 3)
tensor([[0.0265, 0.0235, 0.0137, 0.0191, 0.0396, 0.0180, 0.0276, 0.0099, 0.0180,
         0.0186, 0.0206, 0.0316, 0.0356, 0.0279, 0.0303, 0.0183, 0.0257, 0.0339,
         0.0140, 0.0258, 0.0204, 0.0260, 0.0161, 0.0260, 0.0233, 0.0290, 0.0320,
         0.0383, 0.0292, 0.0147, 0.0211, 0.0225, 0.0226, 0.0271, 0.0314, 0.0299,
         0.0455, 0.0180, 0.0204, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 1
Session Number: 49
images/272
(64, 64, 3)
tensor([[0.0379, 0.0229, 0.0190, 0.0214, 0.0270, 0.0255, 0.0390, 0.0198, 0.0198,
         0.0217, 0.0198, 0.0332, 0.0424, 0.0366, 0.0195, 0.0173, 0.0174, 0.0377,
         0.0214, 0.0247, 0.0207, 0.0214, 0.0202, 0.0180, 0.0163, 0.0191, 0.0216,
         0.0487, 0.0340, 0.0188, 0.0197, 0.0223, 0.0353, 0.0230, 0.0258, 0.0222,
         0.0263, 0.0163, 0.0248, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 50
images/309
(64, 64, 3)
tensor([[0.0263, 0.0402, 0.0179, 0.0128, 0.0446, 0.0212, 0.0282, 0.0136, 0.0153,
         0.0197, 0.0176, 0.0268, 0.0310, 0.0266, 0.0247, 0.0174, 0.0167, 0.0356,
         0.0212, 0.0203, 0.0233, 0.0387, 0.0182, 0.0162, 0.0276, 0.0160, 0.0235,
         0.0222, 0.0419, 0.0240, 0.0112, 0.0445, 0.0317, 0.0218, 0.0198, 0.0307,
         0.0489, 0.0171, 0.0217, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 1
Session Number: 51
images/514
(64, 64, 3)
tensor([[0.0379, 0.0407, 0.0204, 0.0259, 0.0228, 0.0147, 0.0241, 0.0162, 0.0262,
         0.0163, 0.0147, 0.0444, 0.0353, 0.0277, 0.0174, 0.0162, 0.0210, 0.0386,
         0.0158, 0.0247, 0.0282, 0.0344, 0.0242, 0.0298, 0.0128, 0.0179, 0.0203,
         0.0303, 0.0353, 0.0201, 0.0144, 0.0314, 0.0372, 0.0262, 0.0148, 0.0189,
         0.0321, 0.0199, 0.0146, 0.0360]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/161
(64, 64, 3)
tensor([[0.0366, 0.0267, 0.0271, 0.0186, 0.0316, 0.0183, 0.0274, 0.0265, 0.0228,
         0.0206, 0.0191, 0.0179, 0.0381, 0.0337, 0.0200, 0.0216, 0.0185, 0.0268,
         0.0208, 0.0117, 0.0174, 0.0288, 0.0202, 0.0185, 0.0351, 0.0246, 0.0213,
         0.0264, 0.0304, 0.0323, 0.0171, 0.0260, 0.0393, 0.0321, 0.0288, 0.0204,
         0.0344, 0.0178, 0.0192, 0.0257]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 53
images/437
(64, 64, 3)
tensor([[0.0381, 0.0336, 0.0090, 0.0214, 0.0425, 0.0177, 0.0250, 0.0168, 0.0251,
         0.0252, 0.0180, 0.0256, 0.0274, 0.0302, 0.0350, 0.0207, 0.0196, 0.0434,
         0.0163, 0.0215, 0.0259, 0.0313, 0.0189, 0.0201, 0.0243, 0.0193, 0.0323,
         0.0231, 0.0294, 0.0227, 0.0087, 0.0317, 0.0484, 0.0226, 0.0208, 0.0167,
         0.0274, 0.0206, 0.0162, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 54
images/99
(64, 64, 3)
tensor([[0.0284, 0.0225, 0.0207, 0.0185, 0.0393, 0.0116, 0.0301, 0.0164, 0.0287,
         0.0123, 0.0207, 0.0167, 0.0635, 0.0465, 0.0205, 0.0157, 0.0130, 0.0477,
         0.0266, 0.0179, 0.0106, 0.0229, 0.0225, 0.0132, 0.0154, 0.0126, 0.0182,
         0.0320, 0.0316, 0.0281, 0.0179, 0.0207, 0.0301, 0.0243, 0.0246, 0.0371,
         0.0318, 0.0230, 0.0237, 0.0423]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 55
images/202
(64, 64, 3)
tensor([[0.0395, 0.0202, 0.0198, 0.0244, 0.0324, 0.0227, 0.0381, 0.0192, 0.0204,
         0.0187, 0.0234, 0.0199, 0.0395, 0.0302, 0.0283, 0.0189, 0.0290, 0.0446,
         0.0223, 0.0161, 0.0144, 0.0231, 0.0130, 0.0181, 0.0156, 0.0199, 0.0254,
         0.0372, 0.0411, 0.0320, 0.0207, 0.0238, 0.0359, 0.0201, 0.0184, 0.0201,
         0.0196, 0.0268, 0.0207, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 56
images/31
(64, 64, 3)
tensor([[0.0282, 0.0289, 0.0148, 0.0191, 0.0383, 0.0191, 0.0330, 0.0104, 0.0209,
         0.0208, 0.0152, 0.0165, 0.0403, 0.0426, 0.0356, 0.0180, 0.0193, 0.0458,
         0.0216, 0.0159, 0.0124, 0.0357, 0.0185, 0.0197, 0.0182, 0.0174, 0.0379,
         0.0253, 0.0361, 0.0278, 0.0184, 0.0389, 0.0242, 0.0207, 0.0168, 0.0295,
         0.0392, 0.0159, 0.0224, 0.0205]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 57
images/313
(64, 64, 3)
tensor([[0.0196, 0.0309, 0.0267, 0.0228, 0.0225, 0.0186, 0.0420, 0.0200, 0.0112,
         0.0213, 0.0243, 0.0209, 0.0427, 0.0235, 0.0234, 0.0153, 0.0213, 0.0386,
         0.0314, 0.0197, 0.0190, 0.0195, 0.0202, 0.0214, 0.0224, 0.0193, 0.0292,
         0.0212, 0.0407, 0.0285, 0.0176, 0.0318, 0.0272, 0.0313, 0.0211, 0.0299,
         0.0321, 0.0181, 0.0223, 0.0303]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 58
images/541
(64, 64, 3)
tensor([[0.0403, 0.0286, 0.0140, 0.0141, 0.0334, 0.0116, 0.0394, 0.0103, 0.0147,
         0.0202, 0.0150, 0.0564, 0.0375, 0.0296, 0.0250, 0.0144, 0.0167, 0.0724,
         0.0203, 0.0198, 0.0144, 0.0223, 0.0224, 0.0202, 0.0203, 0.0243, 0.0281,
         0.0349, 0.0406, 0.0296, 0.0179, 0.0167, 0.0254, 0.0136, 0.0268, 0.0204,
         0.0318, 0.0173, 0.0226, 0.0167]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 59
images/40
(64, 64, 3)
tensor([[0.0250, 0.0243, 0.0273, 0.0315, 0.0358, 0.0135, 0.0233, 0.0161, 0.0160,
         0.0167, 0.0217, 0.0247, 0.0508, 0.0323, 0.0340, 0.0151, 0.0174, 0.0302,
         0.0224, 0.0216, 0.0136, 0.0315, 0.0197, 0.0244, 0.0155, 0.0195, 0.0171,
         0.0367, 0.0428, 0.0213, 0.0203, 0.0206, 0.0297, 0.0359, 0.0244, 0.0319,
         0.0202, 0.0170, 0.0337, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 60
images/191
(64, 64, 3)
tensor([[0.0315, 0.0299, 0.0176, 0.0230, 0.0295, 0.0202, 0.0239, 0.0177, 0.0140,
         0.0239, 0.0188, 0.0341, 0.0327, 0.0306, 0.0258, 0.0147, 0.0182, 0.0352,
         0.0181, 0.0144, 0.0148, 0.0302, 0.0299, 0.0257, 0.0252, 0.0276, 0.0297,
         0.0399, 0.0407, 0.0270, 0.0125, 0.0221, 0.0237, 0.0295, 0.0220, 0.0211,
         0.0394, 0.0157, 0.0195, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 61
images/445
(64, 64, 3)
tensor([[0.0338, 0.0303, 0.0372, 0.0205, 0.0468, 0.0113, 0.0415, 0.0275, 0.0244,
         0.0257, 0.0207, 0.0318, 0.0313, 0.0252, 0.0236, 0.0127, 0.0335, 0.0240,
         0.0159, 0.0161, 0.0173, 0.0199, 0.0144, 0.0243, 0.0208, 0.0141, 0.0252,
         0.0155, 0.0330, 0.0247, 0.0107, 0.0274, 0.0343, 0.0238, 0.0200, 0.0295,
         0.0229, 0.0222, 0.0301, 0.0361]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 62
images/537
(64, 64, 3)
tensor([[0.0256, 0.0337, 0.0199, 0.0149, 0.0321, 0.0180, 0.0450, 0.0124, 0.0204,
         0.0189, 0.0214, 0.0370, 0.0396, 0.0268, 0.0236, 0.0126, 0.0319, 0.0332,
         0.0157, 0.0300, 0.0178, 0.0348, 0.0208, 0.0252, 0.0246, 0.0174, 0.0185,
         0.0327, 0.0307, 0.0238, 0.0159, 0.0267, 0.0360, 0.0227, 0.0156, 0.0361,
         0.0234, 0.0160, 0.0260, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 63
images/11
(64, 64, 3)
tensor([[0.0217, 0.0305, 0.0096, 0.0303, 0.0263, 0.0231, 0.0417, 0.0111, 0.0223,
         0.0176, 0.0184, 0.0301, 0.0397, 0.0311, 0.0267, 0.0223, 0.0154, 0.0615,
         0.0253, 0.0235, 0.0156, 0.0236, 0.0192, 0.0197, 0.0277, 0.0144, 0.0257,
         0.0317, 0.0420, 0.0166, 0.0273, 0.0263, 0.0196, 0.0160, 0.0213, 0.0239,
         0.0239, 0.0232, 0.0193, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 64
images/8
(64, 64, 3)
tensor([[0.0372, 0.0360, 0.0199, 0.0127, 0.0248, 0.0239, 0.0288, 0.0152, 0.0191,
         0.0235, 0.0154, 0.0360, 0.0316, 0.0274, 0.0218, 0.0231, 0.0243, 0.0371,
         0.0192, 0.0200, 0.0206, 0.0307, 0.0164, 0.0139, 0.0264, 0.0200, 0.0161,
         0.0282, 0.0391, 0.0306, 0.0166, 0.0437, 0.0283, 0.0143, 0.0177, 0.0355,
         0.0208, 0.0200, 0.0357, 0.0285]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 65
images/244
(64, 64, 3)
tensor([[0.0278, 0.0247, 0.0153, 0.0159, 0.0396, 0.0402, 0.0359, 0.0142, 0.0141,
         0.0187, 0.0168, 0.0353, 0.0411, 0.0214, 0.0322, 0.0197, 0.0212, 0.0232,
         0.0289, 0.0287, 0.0248, 0.0259, 0.0151, 0.0278, 0.0227, 0.0231, 0.0270,
         0.0374, 0.0317, 0.0215, 0.0238, 0.0306, 0.0228, 0.0284, 0.0158, 0.0248,
         0.0236, 0.0169, 0.0200, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 66
images/180
(64, 64, 3)
tensor([[0.0236, 0.0283, 0.0280, 0.0185, 0.0393, 0.0150, 0.0398, 0.0158, 0.0183,
         0.0184, 0.0213, 0.0235, 0.0345, 0.0297, 0.0249, 0.0187, 0.0202, 0.0445,
         0.0179, 0.0316, 0.0217, 0.0196, 0.0158, 0.0139, 0.0159, 0.0116, 0.0322,
         0.0320, 0.0386, 0.0202, 0.0212, 0.0266, 0.0257, 0.0260, 0.0122, 0.0352,
         0.0290, 0.0198, 0.0342, 0.0367]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 67
images/153
(64, 64, 3)
tensor([[0.0323, 0.0273, 0.0163, 0.0136, 0.0204, 0.0265, 0.0332, 0.0264, 0.0141,
         0.0227, 0.0199, 0.0460, 0.0382, 0.0276, 0.0178, 0.0169, 0.0233, 0.0254,
         0.0197, 0.0258, 0.0242, 0.0215, 0.0131, 0.0304, 0.0315, 0.0212, 0.0317,
         0.0224, 0.0348, 0.0222, 0.0239, 0.0356, 0.0295, 0.0161, 0.0206, 0.0304,
         0.0302, 0.0240, 0.0176, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/438
(64, 64, 3)
tensor([[0.0218, 0.0310, 0.0215, 0.0206, 0.0326, 0.0153, 0.0391, 0.0215, 0.0291,
         0.0238, 0.0192, 0.0202, 0.0515, 0.0291, 0.0237, 0.0146, 0.0274, 0.0273,
         0.0186, 0.0262, 0.0198, 0.0214, 0.0212, 0.0175, 0.0235, 0.0186, 0.0239,
         0.0342, 0.0376, 0.0426, 0.0118, 0.0238, 0.0343, 0.0202, 0.0184, 0.0206,
         0.0376, 0.0166, 0.0161, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 69
images/299
(64, 64, 3)
tensor([[0.0224, 0.0278, 0.0119, 0.0117, 0.0289, 0.0237, 0.0339, 0.0218, 0.0218,
         0.0207, 0.0204, 0.0353, 0.0449, 0.0617, 0.0216, 0.0193, 0.0195, 0.0449,
         0.0184, 0.0269, 0.0146, 0.0212, 0.0181, 0.0262, 0.0159, 0.0114, 0.0205,
         0.0281, 0.0380, 0.0157, 0.0186, 0.0403, 0.0301, 0.0160, 0.0373, 0.0286,
         0.0175, 0.0214, 0.0209, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 1
Session Number: 70
images/76
(64, 64, 3)
tensor([[0.0222, 0.0418, 0.0162, 0.0214, 0.0354, 0.0138, 0.0328, 0.0138, 0.0223,
         0.0170, 0.0241, 0.0319, 0.0459, 0.0312, 0.0468, 0.0169, 0.0211, 0.0283,
         0.0139, 0.0230, 0.0212, 0.0242, 0.0198, 0.0205, 0.0188, 0.0190, 0.0264,
         0.0223, 0.0303, 0.0203, 0.0275, 0.0185, 0.0279, 0.0290, 0.0208, 0.0379,
         0.0196, 0.0268, 0.0215, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 71
images/386
(64, 64, 3)
tensor([[0.0179, 0.0225, 0.0243, 0.0202, 0.0296, 0.0184, 0.0357, 0.0174, 0.0154,
         0.0185, 0.0156, 0.0316, 0.0350, 0.0393, 0.0195, 0.0165, 0.0201, 0.0317,
         0.0116, 0.0325, 0.0154, 0.0288, 0.0216, 0.0157, 0.0232, 0.0254, 0.0240,
         0.0370, 0.0407, 0.0170, 0.0172, 0.0320, 0.0339, 0.0215, 0.0189, 0.0217,
         0.0461, 0.0295, 0.0241, 0.0330]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 72
images/113
(64, 64, 3)
tensor([[0.0265, 0.0308, 0.0180, 0.0166, 0.0391, 0.0139, 0.0219, 0.0199, 0.0249,
         0.0216, 0.0186, 0.0323, 0.0418, 0.0365, 0.0313, 0.0180, 0.0168, 0.0410,
         0.0215, 0.0142, 0.0244, 0.0182, 0.0250, 0.0174, 0.0261, 0.0161, 0.0241,
         0.0246, 0.0379, 0.0266, 0.0144, 0.0272, 0.0219, 0.0326, 0.0260, 0.0422,
         0.0346, 0.0173, 0.0186, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Session Number: 73
images/526
(64, 64, 3)
tensor([[0.0352, 0.0290, 0.0227, 0.0156, 0.0278, 0.0278, 0.0312, 0.0138, 0.0199,
         0.0278, 0.0160, 0.0183, 0.0314, 0.0260, 0.0195, 0.0178, 0.0313, 0.0557,
         0.0159, 0.0166, 0.0166, 0.0289, 0.0259, 0.0155, 0.0198, 0.0187, 0.0199,
         0.0223, 0.0420, 0.0253, 0.0255, 0.0213, 0.0289, 0.0275, 0.0194, 0.0476,
         0.0306, 0.0168, 0.0205, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 74
images/474
(64, 64, 3)
tensor([[0.0357, 0.0235, 0.0139, 0.0094, 0.0327, 0.0320, 0.0234, 0.0136, 0.0119,
         0.0156, 0.0193, 0.0319, 0.0771, 0.0357, 0.0180, 0.0132, 0.0306, 0.0442,
         0.0187, 0.0176, 0.0149, 0.0175, 0.0224, 0.0205, 0.0206, 0.0219, 0.0233,
         0.0362, 0.0410, 0.0179, 0.0157, 0.0301, 0.0204, 0.0239, 0.0240, 0.0396,
         0.0209, 0.0149, 0.0339, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 75
images/221
(64, 64, 3)
tensor([[0.0205, 0.0375, 0.0123, 0.0173, 0.0361, 0.0212, 0.0366, 0.0237, 0.0213,
         0.0289, 0.0188, 0.0179, 0.0214, 0.0343, 0.0314, 0.0287, 0.0213, 0.0307,
         0.0330, 0.0110, 0.0167, 0.0337, 0.0151, 0.0266, 0.0337, 0.0109, 0.0251,
         0.0315, 0.0438, 0.0227, 0.0127, 0.0260, 0.0273, 0.0283, 0.0193, 0.0322,
         0.0223, 0.0200, 0.0281, 0.0200]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 76
images/439
(64, 64, 3)
tensor([[0.0213, 0.0220, 0.0199, 0.0188, 0.0292, 0.0221, 0.0436, 0.0129, 0.0190,
         0.0166, 0.0179, 0.0418, 0.0429, 0.0380, 0.0314, 0.0212, 0.0158, 0.0239,
         0.0181, 0.0214, 0.0181, 0.0273, 0.0166, 0.0185, 0.0214, 0.0157, 0.0138,
         0.0314, 0.0419, 0.0313, 0.0173, 0.0324, 0.0247, 0.0218, 0.0202, 0.0465,
         0.0360, 0.0232, 0.0168, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 77
images/197
(64, 64, 3)
tensor([[0.0210, 0.0251, 0.0291, 0.0178, 0.0457, 0.0208, 0.0338, 0.0138, 0.0182,
         0.0161, 0.0140, 0.0285, 0.0348, 0.0389, 0.0211, 0.0136, 0.0209, 0.0434,
         0.0175, 0.0212, 0.0213, 0.0190, 0.0176, 0.0155, 0.0281, 0.0192, 0.0244,
         0.0269, 0.0362, 0.0241, 0.0136, 0.0397, 0.0323, 0.0283, 0.0178, 0.0276,
         0.0457, 0.0144, 0.0150, 0.0383]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 78
images/152
(64, 64, 3)
tensor([[0.0399, 0.0295, 0.0142, 0.0238, 0.0357, 0.0248, 0.0365, 0.0171, 0.0191,
         0.0291, 0.0158, 0.0426, 0.0402, 0.0222, 0.0228, 0.0219, 0.0200, 0.0249,
         0.0211, 0.0190, 0.0208, 0.0280, 0.0137, 0.0233, 0.0183, 0.0243, 0.0392,
         0.0223, 0.0314, 0.0261, 0.0135, 0.0211, 0.0196, 0.0133, 0.0156, 0.0287,
         0.0388, 0.0215, 0.0281, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/336
(64, 64, 3)
tensor([[0.0222, 0.0279, 0.0171, 0.0136, 0.0445, 0.0208, 0.0260, 0.0177, 0.0168,
         0.0285, 0.0228, 0.0329, 0.0427, 0.0218, 0.0257, 0.0190, 0.0252, 0.0315,
         0.0221, 0.0265, 0.0145, 0.0324, 0.0194, 0.0199, 0.0240, 0.0193, 0.0238,
         0.0435, 0.0270, 0.0260, 0.0207, 0.0252, 0.0199, 0.0271, 0.0259, 0.0355,
         0.0211, 0.0212, 0.0180, 0.0301]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 80
images/337
(64, 64, 3)
tensor([[0.0222, 0.0243, 0.0309, 0.0238, 0.0364, 0.0154, 0.0285, 0.0113, 0.0183,
         0.0246, 0.0176, 0.0301, 0.0287, 0.0213, 0.0402, 0.0217, 0.0206, 0.0350,
         0.0198, 0.0206, 0.0198, 0.0232, 0.0259, 0.0237, 0.0235, 0.0225, 0.0264,
         0.0438, 0.0284, 0.0262, 0.0180, 0.0330, 0.0260, 0.0247, 0.0233, 0.0263,
         0.0218, 0.0182, 0.0288, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 81
images/447
(64, 64, 3)
tensor([[0.0207, 0.0232, 0.0213, 0.0135, 0.0363, 0.0147, 0.0343, 0.0227, 0.0199,
         0.0234, 0.0119, 0.0283, 0.0234, 0.0206, 0.0252, 0.0301, 0.0205, 0.0505,
         0.0196, 0.0234, 0.0202, 0.0346, 0.0197, 0.0205, 0.0183, 0.0251, 0.0239,
         0.0297, 0.0414, 0.0210, 0.0196, 0.0546, 0.0309, 0.0122, 0.0413, 0.0199,
         0.0282, 0.0236, 0.0148, 0.0169]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 82
images/375
(64, 64, 3)
tensor([[0.0298, 0.0287, 0.0263, 0.0191, 0.0380, 0.0276, 0.0313, 0.0171, 0.0125,
         0.0196, 0.0204, 0.0257, 0.0497, 0.0279, 0.0227, 0.0228, 0.0219, 0.0358,
         0.0164, 0.0187, 0.0186, 0.0282, 0.0309, 0.0244, 0.0196, 0.0198, 0.0216,
         0.0276, 0.0384, 0.0182, 0.0201, 0.0279, 0.0245, 0.0224, 0.0202, 0.0247,
         0.0466, 0.0163, 0.0200, 0.0181]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 83
images/591
(64, 64, 3)
tensor([[0.0311, 0.0348, 0.0142, 0.0170, 0.0343, 0.0114, 0.0305, 0.0165, 0.0188,
         0.0151, 0.0221, 0.0322, 0.0537, 0.0229, 0.0338, 0.0259, 0.0178, 0.0287,
         0.0197, 0.0314, 0.0125, 0.0226, 0.0173, 0.0221, 0.0163, 0.0204, 0.0231,
         0.0404, 0.0244, 0.0343, 0.0155, 0.0312, 0.0263, 0.0239, 0.0284, 0.0379,
         0.0278, 0.0209, 0.0197, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 84
images/450
(64, 64, 3)
tensor([[0.0352, 0.0251, 0.0170, 0.0170, 0.0263, 0.0329, 0.0253, 0.0197, 0.0249,
         0.0258, 0.0275, 0.0405, 0.0278, 0.0242, 0.0178, 0.0273, 0.0248, 0.0302,
         0.0190, 0.0133, 0.0236, 0.0248, 0.0200, 0.0191, 0.0183, 0.0160, 0.0259,
         0.0382, 0.0429, 0.0137, 0.0145, 0.0309, 0.0247, 0.0454, 0.0212, 0.0305,
         0.0378, 0.0097, 0.0204, 0.0204]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 85
images/4
(64, 64, 3)
tensor([[0.0286, 0.0292, 0.0172, 0.0281, 0.0447, 0.0205, 0.0268, 0.0109, 0.0256,
         0.0188, 0.0178, 0.0258, 0.0340, 0.0340, 0.0273, 0.0240, 0.0226, 0.0348,
         0.0159, 0.0183, 0.0232, 0.0261, 0.0148, 0.0266, 0.0184, 0.0191, 0.0225,
         0.0430, 0.0261, 0.0230, 0.0210, 0.0393, 0.0247, 0.0247, 0.0334, 0.0241,
         0.0220, 0.0142, 0.0171, 0.0317]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 1
Session Number: 86
images/226
(64, 64, 3)
tensor([[0.0308, 0.0255, 0.0107, 0.0155, 0.0181, 0.0197, 0.0263, 0.0185, 0.0169,
         0.0164, 0.0342, 0.0214, 0.0484, 0.0457, 0.0311, 0.0220, 0.0315, 0.0334,
         0.0143, 0.0143, 0.0164, 0.0339, 0.0159, 0.0206, 0.0193, 0.0232, 0.0332,
         0.0346, 0.0331, 0.0220, 0.0138, 0.0252, 0.0411, 0.0214, 0.0367, 0.0174,
         0.0351, 0.0162, 0.0313, 0.0147]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 87
images/154
(64, 64, 3)
tensor([[0.0252, 0.0236, 0.0190, 0.0188, 0.0280, 0.0210, 0.0353, 0.0192, 0.0170,
         0.0129, 0.0167, 0.0427, 0.0515, 0.0220, 0.0223, 0.0249, 0.0195, 0.0248,
         0.0159, 0.0221, 0.0175, 0.0337, 0.0264, 0.0210, 0.0179, 0.0193, 0.0208,
         0.0280, 0.0484, 0.0307, 0.0163, 0.0304, 0.0256, 0.0215, 0.0237, 0.0336,
         0.0219, 0.0335, 0.0219, 0.0257]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 88
images/524
(64, 64, 3)
tensor([[0.0341, 0.0223, 0.0214, 0.0176, 0.0348, 0.0164, 0.0358, 0.0183, 0.0237,
         0.0236, 0.0294, 0.0324, 0.0472, 0.0404, 0.0287, 0.0155, 0.0216, 0.0257,
         0.0294, 0.0253, 0.0129, 0.0180, 0.0223, 0.0166, 0.0133, 0.0204, 0.0207,
         0.0314, 0.0319, 0.0274, 0.0199, 0.0299, 0.0217, 0.0271, 0.0213, 0.0352,
         0.0265, 0.0166, 0.0210, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/462
(64, 64, 3)
tensor([[0.0165, 0.0249, 0.0226, 0.0177, 0.0336, 0.0250, 0.0326, 0.0248, 0.0227,
         0.0160, 0.0143, 0.0294, 0.0613, 0.0338, 0.0245, 0.0260, 0.0129, 0.0419,
         0.0195, 0.0231, 0.0131, 0.0154, 0.0223, 0.0220, 0.0232, 0.0236, 0.0312,
         0.0423, 0.0183, 0.0231, 0.0197, 0.0330, 0.0212, 0.0272, 0.0210, 0.0318,
         0.0218, 0.0191, 0.0233, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 90
images/266
(64, 64, 3)
tensor([[0.0202, 0.0264, 0.0239, 0.0164, 0.0244, 0.0340, 0.0263, 0.0129, 0.0261,
         0.0188, 0.0175, 0.0392, 0.0284, 0.0340, 0.0236, 0.0195, 0.0183, 0.0239,
         0.0204, 0.0245, 0.0197, 0.0328, 0.0233, 0.0371, 0.0290, 0.0239, 0.0253,
         0.0338, 0.0279, 0.0261, 0.0215, 0.0201, 0.0251, 0.0137, 0.0230, 0.0376,
         0.0345, 0.0145, 0.0258, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 0
Session Number: 91
images/539
(64, 64, 3)
tensor([[0.0171, 0.0254, 0.0176, 0.0140, 0.0234, 0.0244, 0.0418, 0.0322, 0.0227,
         0.0152, 0.0223, 0.0550, 0.0401, 0.0289, 0.0278, 0.0205, 0.0171, 0.0203,
         0.0257, 0.0301, 0.0147, 0.0215, 0.0218, 0.0245, 0.0297, 0.0159, 0.0204,
         0.0401, 0.0331, 0.0181, 0.0234, 0.0406, 0.0284, 0.0197, 0.0176, 0.0243,
         0.0144, 0.0201, 0.0162, 0.0339]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 92
images/211
(64, 64, 3)
tensor([[0.0290, 0.0185, 0.0223, 0.0133, 0.0255, 0.0268, 0.0235, 0.0333, 0.0261,
         0.0254, 0.0179, 0.0239, 0.0334, 0.0286, 0.0210, 0.0213, 0.0206, 0.0377,
         0.0169, 0.0185, 0.0170, 0.0255, 0.0259, 0.0233, 0.0237, 0.0131, 0.0226,
         0.0335, 0.0386, 0.0251, 0.0254, 0.0314, 0.0288, 0.0291, 0.0357, 0.0330,
         0.0143, 0.0252, 0.0237, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 93
images/511
(64, 64, 3)
tensor([[0.0337, 0.0217, 0.0168, 0.0251, 0.0291, 0.0275, 0.0288, 0.0136, 0.0176,
         0.0193, 0.0229, 0.0239, 0.0417, 0.0267, 0.0284, 0.0209, 0.0168, 0.0406,
         0.0191, 0.0202, 0.0137, 0.0229, 0.0286, 0.0164, 0.0192, 0.0194, 0.0344,
         0.0266, 0.0377, 0.0237, 0.0330, 0.0239, 0.0224, 0.0262, 0.0274, 0.0252,
         0.0471, 0.0152, 0.0254, 0.0171]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 94
images/535
(64, 64, 3)
tensor([[0.0332, 0.0306, 0.0223, 0.0277, 0.0324, 0.0254, 0.0357, 0.0117, 0.0177,
         0.0257, 0.0185, 0.0257, 0.0553, 0.0266, 0.0198, 0.0179, 0.0184, 0.0254,
         0.0182, 0.0352, 0.0176, 0.0245, 0.0162, 0.0170, 0.0181, 0.0234, 0.0308,
         0.0321, 0.0303, 0.0222, 0.0208, 0.0246, 0.0244, 0.0146, 0.0244, 0.0327,
         0.0243, 0.0258, 0.0254, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 95
images/595
(64, 64, 3)
tensor([[0.0311, 0.0336, 0.0315, 0.0195, 0.0348, 0.0193, 0.0277, 0.0174, 0.0128,
         0.0223, 0.0249, 0.0365, 0.0469, 0.0343, 0.0208, 0.0122, 0.0246, 0.0192,
         0.0317, 0.0223, 0.0196, 0.0258, 0.0223, 0.0243, 0.0256, 0.0172, 0.0245,
         0.0224, 0.0351, 0.0209, 0.0141, 0.0256, 0.0346, 0.0185, 0.0173, 0.0349,
         0.0236, 0.0208, 0.0271, 0.0223]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 96
images/409
(64, 64, 3)
tensor([[0.0158, 0.0234, 0.0169, 0.0121, 0.0382, 0.0242, 0.0440, 0.0212, 0.0145,
         0.0274, 0.0215, 0.0362, 0.0496, 0.0234, 0.0267, 0.0130, 0.0123, 0.0511,
         0.0194, 0.0201, 0.0130, 0.0225, 0.0113, 0.0294, 0.0163, 0.0211, 0.0280,
         0.0600, 0.0247, 0.0234, 0.0195, 0.0293, 0.0195, 0.0274, 0.0216, 0.0192,
         0.0242, 0.0188, 0.0186, 0.0410]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 97
images/36
(64, 64, 3)
tensor([[0.0254, 0.0175, 0.0157, 0.0212, 0.0608, 0.0250, 0.0351, 0.0165, 0.0199,
         0.0192, 0.0231, 0.0359, 0.0405, 0.0340, 0.0215, 0.0121, 0.0177, 0.0306,
         0.0455, 0.0207, 0.0141, 0.0132, 0.0224, 0.0181, 0.0164, 0.0206, 0.0208,
         0.0286, 0.0299, 0.0251, 0.0115, 0.0213, 0.0350, 0.0355, 0.0245, 0.0320,
         0.0383, 0.0181, 0.0167, 0.0201]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 98
images/373
(64, 64, 3)
tensor([[0.0302, 0.0223, 0.0207, 0.0148, 0.0275, 0.0224, 0.0252, 0.0154, 0.0204,
         0.0235, 0.0238, 0.0287, 0.0411, 0.0371, 0.0274, 0.0149, 0.0179, 0.0342,
         0.0249, 0.0194, 0.0244, 0.0243, 0.0206, 0.0183, 0.0239, 0.0229, 0.0315,
         0.0338, 0.0363, 0.0181, 0.0146, 0.0311, 0.0269, 0.0342, 0.0211, 0.0403,
         0.0222, 0.0164, 0.0154, 0.0318]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 99
images/181
(64, 64, 3)
tensor([[0.0252, 0.0312, 0.0158, 0.0239, 0.0320, 0.0277, 0.0363, 0.0144, 0.0222,
         0.0134, 0.0131, 0.0317, 0.0490, 0.0248, 0.0160, 0.0152, 0.0207, 0.0384,
         0.0204, 0.0181, 0.0197, 0.0205, 0.0189, 0.0267, 0.0225, 0.0202, 0.0367,
         0.0336, 0.0258, 0.0197, 0.0216, 0.0313, 0.0348, 0.0275, 0.0185, 0.0505,
         0.0201, 0.0145, 0.0254, 0.0218]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Saving the weights
43 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/347
(64, 64, 3)
2018-10-13 00:00:22.327 Python[7916:15683772] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0296, 0.0304, 0.0155, 0.0245, 0.0213, 0.0169, 0.0312, 0.0160, 0.0130,
         0.0208, 0.0167, 0.0247, 0.0253, 0.0299, 0.0514, 0.0202, 0.0207, 0.0207,
         0.0178, 0.0242, 0.0144, 0.0253, 0.0327, 0.0207, 0.0254, 0.0208, 0.0205,
         0.0287, 0.0316, 0.0130, 0.0221, 0.0310, 0.0238, 0.0238, 0.0230, 0.0425,
         0.0435, 0.0431, 0.0207, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/72
(64, 64, 3)
tensor([[0.0352, 0.0172, 0.0183, 0.0242, 0.0413, 0.0216, 0.0268, 0.0194, 0.0126,
         0.0180, 0.0143, 0.0337, 0.0321, 0.0319, 0.0282, 0.0290, 0.0231, 0.0309,
         0.0135, 0.0260, 0.0148, 0.0248, 0.0199, 0.0215, 0.0198, 0.0242, 0.0191,
         0.0415, 0.0327, 0.0209, 0.0115, 0.0374, 0.0163, 0.0361, 0.0233, 0.0274,
         0.0413, 0.0247, 0.0204, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/505
(64, 64, 3)
tensor([[0.0368, 0.0340, 0.0155, 0.0147, 0.0346, 0.0279, 0.0391, 0.0147, 0.0149,
         0.0154, 0.0246, 0.0353, 0.0296, 0.0363, 0.0160, 0.0168, 0.0316, 0.0354,
         0.0232, 0.0123, 0.0168, 0.0177, 0.0205, 0.0276, 0.0170, 0.0208, 0.0321,
         0.0260, 0.0418, 0.0215, 0.0214, 0.0300, 0.0341, 0.0303, 0.0172, 0.0326,
         0.0262, 0.0207, 0.0174, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 3
images/345
(64, 64, 3)
tensor([[0.0313, 0.0283, 0.0165, 0.0194, 0.0331, 0.0196, 0.0388, 0.0240, 0.0206,
         0.0135, 0.0352, 0.0318, 0.0271, 0.0389, 0.0252, 0.0224, 0.0162, 0.0420,
         0.0171, 0.0266, 0.0185, 0.0226, 0.0161, 0.0199, 0.0229, 0.0176, 0.0266,
         0.0354, 0.0344, 0.0197, 0.0228, 0.0211, 0.0316, 0.0303, 0.0242, 0.0237,
         0.0215, 0.0168, 0.0226, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 4
images/328
(64, 64, 3)
tensor([[0.0330, 0.0250, 0.0281, 0.0152, 0.0456, 0.0215, 0.0279, 0.0166, 0.0182,
         0.0219, 0.0193, 0.0455, 0.0201, 0.0317, 0.0309, 0.0219, 0.0178, 0.0278,
         0.0165, 0.0134, 0.0164, 0.0185, 0.0204, 0.0199, 0.0255, 0.0265, 0.0314,
         0.0417, 0.0390, 0.0210, 0.0149, 0.0281, 0.0273, 0.0252, 0.0310, 0.0159,
         0.0222, 0.0208, 0.0232, 0.0331]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 5
images/136
(64, 64, 3)
tensor([[0.0116, 0.0340, 0.0170, 0.0133, 0.0260, 0.0195, 0.0396, 0.0330, 0.0213,
         0.0181, 0.0205, 0.0293, 0.0433, 0.0375, 0.0262, 0.0286, 0.0295, 0.0338,
         0.0173, 0.0356, 0.0161, 0.0200, 0.0203, 0.0364, 0.0135, 0.0146, 0.0216,
         0.0287, 0.0248, 0.0299, 0.0170, 0.0281, 0.0274, 0.0294, 0.0253, 0.0373,
         0.0168, 0.0148, 0.0193, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 6
images/396
(64, 64, 3)
tensor([[0.0413, 0.0246, 0.0217, 0.0198, 0.0345, 0.0221, 0.0263, 0.0192, 0.0242,
         0.0299, 0.0160, 0.0266, 0.0349, 0.0221, 0.0294, 0.0207, 0.0150, 0.0307,
         0.0273, 0.0239, 0.0126, 0.0245, 0.0173, 0.0280, 0.0175, 0.0179, 0.0249,
         0.0326, 0.0291, 0.0183, 0.0257, 0.0187, 0.0182, 0.0304, 0.0186, 0.0458,
         0.0245, 0.0239, 0.0258, 0.0354]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 7
images/488
(64, 64, 3)
tensor([[0.0429, 0.0230, 0.0265, 0.0156, 0.0169, 0.0157, 0.0227, 0.0120, 0.0132,
         0.0158, 0.0165, 0.0426, 0.0320, 0.0377, 0.0226, 0.0238, 0.0238, 0.0266,
         0.0167, 0.0273, 0.0149, 0.0263, 0.0215, 0.0274, 0.0154, 0.0232, 0.0400,
         0.0461, 0.0377, 0.0185, 0.0252, 0.0290, 0.0212, 0.0304, 0.0201, 0.0333,
         0.0335, 0.0228, 0.0154, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/353
(64, 64, 3)
tensor([[0.0194, 0.0258, 0.0130, 0.0171, 0.0263, 0.0215, 0.0238, 0.0265, 0.0181,
         0.0227, 0.0165, 0.0277, 0.0547, 0.0319, 0.0307, 0.0173, 0.0258, 0.0442,
         0.0281, 0.0173, 0.0084, 0.0206, 0.0355, 0.0222, 0.0143, 0.0143, 0.0312,
         0.0296, 0.0375, 0.0181, 0.0161, 0.0286, 0.0284, 0.0233, 0.0204, 0.0374,
         0.0220, 0.0221, 0.0160, 0.0453]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 9
images/361
(64, 64, 3)
tensor([[0.0389, 0.0297, 0.0148, 0.0134, 0.0269, 0.0184, 0.0312, 0.0239, 0.0146,
         0.0194, 0.0217, 0.0245, 0.0356, 0.0369, 0.0251, 0.0286, 0.0290, 0.0445,
         0.0182, 0.0099, 0.0161, 0.0193, 0.0162, 0.0195, 0.0266, 0.0155, 0.0304,
         0.0274, 0.0479, 0.0231, 0.0193, 0.0302, 0.0270, 0.0202, 0.0175, 0.0508,
         0.0174, 0.0149, 0.0226, 0.0331]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 10
images/415
(64, 64, 3)
tensor([[0.0196, 0.0209, 0.0120, 0.0170, 0.0434, 0.0279, 0.0267, 0.0164, 0.0247,
         0.0275, 0.0203, 0.0341, 0.0463, 0.0254, 0.0396, 0.0131, 0.0181, 0.0246,
         0.0187, 0.0262, 0.0131, 0.0246, 0.0227, 0.0194, 0.0157, 0.0164, 0.0401,
         0.0299, 0.0299, 0.0182, 0.0206, 0.0265, 0.0266, 0.0268, 0.0283, 0.0357,
         0.0260, 0.0231, 0.0186, 0.0356]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/344
(64, 64, 3)
tensor([[0.0200, 0.0275, 0.0377, 0.0217, 0.0291, 0.0221, 0.0356, 0.0195, 0.0301,
         0.0269, 0.0107, 0.0299, 0.0310, 0.0279, 0.0202, 0.0185, 0.0156, 0.0458,
         0.0122, 0.0195, 0.0133, 0.0228, 0.0173, 0.0375, 0.0214, 0.0235, 0.0242,
         0.0370, 0.0455, 0.0415, 0.0197, 0.0212, 0.0245, 0.0180, 0.0214, 0.0166,
         0.0293, 0.0256, 0.0149, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 12
images/469
(64, 64, 3)
tensor([[0.0358, 0.0234, 0.0130, 0.0183, 0.0270, 0.0227, 0.0314, 0.0179, 0.0251,
         0.0157, 0.0185, 0.0307, 0.0472, 0.0338, 0.0293, 0.0199, 0.0168, 0.0392,
         0.0173, 0.0191, 0.0199, 0.0271, 0.0194, 0.0276, 0.0205, 0.0263, 0.0203,
         0.0314, 0.0368, 0.0170, 0.0148, 0.0411, 0.0175, 0.0179, 0.0246, 0.0300,
         0.0268, 0.0271, 0.0283, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 13
images/108
(64, 64, 3)
tensor([[0.0181, 0.0243, 0.0259, 0.0151, 0.0265, 0.0321, 0.0334, 0.0201, 0.0136,
         0.0268, 0.0266, 0.0276, 0.0361, 0.0432, 0.0217, 0.0178, 0.0267, 0.0221,
         0.0132, 0.0284, 0.0196, 0.0244, 0.0188, 0.0254, 0.0233, 0.0192, 0.0235,
         0.0440, 0.0317, 0.0160, 0.0220, 0.0376, 0.0306, 0.0188, 0.0346, 0.0213,
         0.0245, 0.0145, 0.0274, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 1
Session Number: 14
images/134
(64, 64, 3)
tensor([[0.0486, 0.0209, 0.0191, 0.0149, 0.0255, 0.0240, 0.0271, 0.0174, 0.0181,
         0.0146, 0.0251, 0.0299, 0.0438, 0.0252, 0.0371, 0.0150, 0.0214, 0.0365,
         0.0170, 0.0185, 0.0170, 0.0190, 0.0464, 0.0160, 0.0227, 0.0186, 0.0223,
         0.0315, 0.0338, 0.0225, 0.0230, 0.0338, 0.0253, 0.0273, 0.0154, 0.0210,
         0.0262, 0.0180, 0.0341, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 15
images/254
(64, 64, 3)
tensor([[0.0246, 0.0244, 0.0141, 0.0200, 0.0463, 0.0163, 0.0295, 0.0153, 0.0186,
         0.0188, 0.0225, 0.0309, 0.0311, 0.0500, 0.0291, 0.0236, 0.0147, 0.0403,
         0.0191, 0.0317, 0.0169, 0.0190, 0.0255, 0.0142, 0.0247, 0.0138, 0.0166,
         0.0292, 0.0231, 0.0344, 0.0186, 0.0369, 0.0338, 0.0122, 0.0195, 0.0381,
         0.0407, 0.0116, 0.0280, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/172
(64, 64, 3)
tensor([[0.0337, 0.0296, 0.0127, 0.0185, 0.0399, 0.0202, 0.0344, 0.0178, 0.0215,
         0.0210, 0.0198, 0.0194, 0.0467, 0.0415, 0.0238, 0.0117, 0.0221, 0.0353,
         0.0202, 0.0219, 0.0156, 0.0196, 0.0205, 0.0184, 0.0203, 0.0228, 0.0221,
         0.0330, 0.0320, 0.0287, 0.0146, 0.0415, 0.0279, 0.0314, 0.0353, 0.0315,
         0.0202, 0.0205, 0.0175, 0.0150]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 17
images/490
(64, 64, 3)
tensor([[0.0192, 0.0290, 0.0273, 0.0201, 0.0416, 0.0137, 0.0306, 0.0201, 0.0202,
         0.0196, 0.0144, 0.0254, 0.0303, 0.0295, 0.0233, 0.0171, 0.0184, 0.0485,
         0.0192, 0.0179, 0.0165, 0.0191, 0.0327, 0.0210, 0.0251, 0.0187, 0.0224,
         0.0244, 0.0309, 0.0443, 0.0222, 0.0355, 0.0224, 0.0260, 0.0221, 0.0406,
         0.0222, 0.0200, 0.0206, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 18
images/446
(64, 64, 3)
tensor([[0.0222, 0.0241, 0.0237, 0.0191, 0.0370, 0.0195, 0.0360, 0.0131, 0.0147,
         0.0198, 0.0143, 0.0216, 0.0588, 0.0315, 0.0174, 0.0229, 0.0156, 0.0272,
         0.0190, 0.0241, 0.0186, 0.0230, 0.0171, 0.0165, 0.0188, 0.0162, 0.0272,
         0.0285, 0.0398, 0.0233, 0.0223, 0.0234, 0.0292, 0.0219, 0.0291, 0.0318,
         0.0479, 0.0168, 0.0274, 0.0396]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 19
images/453
(64, 64, 3)
tensor([[0.0314, 0.0197, 0.0192, 0.0216, 0.0396, 0.0254, 0.0320, 0.0173, 0.0240,
         0.0198, 0.0173, 0.0371, 0.0342, 0.0345, 0.0261, 0.0191, 0.0244, 0.0399,
         0.0276, 0.0190, 0.0267, 0.0178, 0.0142, 0.0163, 0.0178, 0.0160, 0.0260,
         0.0310, 0.0360, 0.0219, 0.0139, 0.0252, 0.0333, 0.0308, 0.0221, 0.0221,
         0.0353, 0.0174, 0.0193, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 20
images/224
(64, 64, 3)
tensor([[0.0314, 0.0196, 0.0215, 0.0174, 0.0425, 0.0276, 0.0359, 0.0209, 0.0153,
         0.0183, 0.0188, 0.0270, 0.0434, 0.0223, 0.0236, 0.0279, 0.0162, 0.0307,
         0.0167, 0.0204, 0.0139, 0.0242, 0.0196, 0.0208, 0.0260, 0.0270, 0.0263,
         0.0386, 0.0204, 0.0300, 0.0225, 0.0304, 0.0308, 0.0177, 0.0222, 0.0333,
         0.0187, 0.0287, 0.0239, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 21
images/305
(64, 64, 3)
tensor([[0.0229, 0.0338, 0.0219, 0.0159, 0.0180, 0.0212, 0.0302, 0.0154, 0.0180,
         0.0170, 0.0185, 0.0305, 0.0693, 0.0214, 0.0169, 0.0152, 0.0279, 0.0258,
         0.0257, 0.0145, 0.0152, 0.0193, 0.0186, 0.0216, 0.0171, 0.0272, 0.0294,
         0.0305, 0.0436, 0.0176, 0.0259, 0.0290, 0.0272, 0.0249, 0.0227, 0.0406,
         0.0383, 0.0201, 0.0291, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/245
(64, 64, 3)
tensor([[0.0270, 0.0257, 0.0153, 0.0222, 0.0297, 0.0192, 0.0264, 0.0220, 0.0231,
         0.0224, 0.0126, 0.0282, 0.0379, 0.0363, 0.0201, 0.0206, 0.0391, 0.0620,
         0.0141, 0.0179, 0.0162, 0.0240, 0.0238, 0.0271, 0.0241, 0.0212, 0.0196,
         0.0226, 0.0269, 0.0226, 0.0143, 0.0397, 0.0242, 0.0216, 0.0266, 0.0382,
         0.0218, 0.0183, 0.0201, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 23
images/488
(64, 64, 3)
tensor([[0.0179, 0.0221, 0.0174, 0.0170, 0.0353, 0.0241, 0.0325, 0.0204, 0.0190,
         0.0293, 0.0182, 0.0331, 0.0352, 0.0381, 0.0278, 0.0136, 0.0227, 0.0199,
         0.0226, 0.0247, 0.0185, 0.0304, 0.0243, 0.0295, 0.0133, 0.0216, 0.0318,
         0.0337, 0.0279, 0.0172, 0.0171, 0.0330, 0.0252, 0.0278, 0.0241, 0.0263,
         0.0330, 0.0245, 0.0234, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 24
images/39
(64, 64, 3)
tensor([[0.0214, 0.0172, 0.0158, 0.0174, 0.0386, 0.0176, 0.0239, 0.0208, 0.0228,
         0.0202, 0.0154, 0.0385, 0.0227, 0.0289, 0.0267, 0.0165, 0.0255, 0.0281,
         0.0192, 0.0221, 0.0198, 0.0220, 0.0272, 0.0242, 0.0249, 0.0302, 0.0251,
         0.0477, 0.0320, 0.0180, 0.0334, 0.0303, 0.0227, 0.0226, 0.0298, 0.0474,
         0.0200, 0.0212, 0.0186, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 25
images/74
(64, 64, 3)
tensor([[0.0275, 0.0240, 0.0235, 0.0173, 0.0283, 0.0180, 0.0266, 0.0203, 0.0126,
         0.0229, 0.0182, 0.0238, 0.0516, 0.0375, 0.0209, 0.0266, 0.0169, 0.0408,
         0.0118, 0.0267, 0.0181, 0.0270, 0.0350, 0.0370, 0.0203, 0.0237, 0.0183,
         0.0352, 0.0243, 0.0399, 0.0110, 0.0310, 0.0232, 0.0117, 0.0213, 0.0311,
         0.0338, 0.0211, 0.0189, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 1
Session Number: 26
images/417
(64, 64, 3)
tensor([[0.0274, 0.0235, 0.0209, 0.0172, 0.0385, 0.0164, 0.0230, 0.0131, 0.0173,
         0.0228, 0.0130, 0.0421, 0.0238, 0.0401, 0.0304, 0.0182, 0.0217, 0.0425,
         0.0171, 0.0254, 0.0258, 0.0283, 0.0332, 0.0183, 0.0222, 0.0191, 0.0213,
         0.0365, 0.0335, 0.0294, 0.0183, 0.0236, 0.0313, 0.0237, 0.0191, 0.0363,
         0.0320, 0.0178, 0.0144, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 27
images/251
(64, 64, 3)
tensor([[0.0273, 0.0259, 0.0182, 0.0149, 0.0224, 0.0206, 0.0360, 0.0155, 0.0281,
         0.0146, 0.0332, 0.0331, 0.0533, 0.0218, 0.0242, 0.0207, 0.0296, 0.0238,
         0.0263, 0.0190, 0.0169, 0.0221, 0.0190, 0.0120, 0.0146, 0.0247, 0.0359,
         0.0296, 0.0243, 0.0228, 0.0172, 0.0278, 0.0243, 0.0242, 0.0406, 0.0293,
         0.0284, 0.0244, 0.0305, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 28
images/527
(64, 64, 3)
tensor([[0.0318, 0.0198, 0.0188, 0.0178, 0.0412, 0.0218, 0.0319, 0.0235, 0.0182,
         0.0171, 0.0247, 0.0280, 0.0795, 0.0321, 0.0211, 0.0133, 0.0242, 0.0421,
         0.0265, 0.0157, 0.0147, 0.0161, 0.0285, 0.0152, 0.0141, 0.0124, 0.0256,
         0.0194, 0.0160, 0.0269, 0.0154, 0.0251, 0.0241, 0.0287, 0.0351, 0.0396,
         0.0364, 0.0217, 0.0176, 0.0182]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Session Number: 29
images/373
(64, 64, 3)
tensor([[0.0267, 0.0174, 0.0314, 0.0334, 0.0315, 0.0275, 0.0256, 0.0124, 0.0199,
         0.0273, 0.0208, 0.0253, 0.0374, 0.0312, 0.0215, 0.0210, 0.0167, 0.0360,
         0.0180, 0.0277, 0.0253, 0.0239, 0.0249, 0.0223, 0.0233, 0.0165, 0.0243,
         0.0306, 0.0290, 0.0160, 0.0197, 0.0271, 0.0330, 0.0329, 0.0193, 0.0327,
         0.0327, 0.0136, 0.0152, 0.0290]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 30
images/62
(64, 64, 3)
tensor([[0.0221, 0.0229, 0.0193, 0.0126, 0.0314, 0.0160, 0.0304, 0.0206, 0.0203,
         0.0178, 0.0183, 0.0281, 0.0356, 0.0422, 0.0137, 0.0175, 0.0152, 0.0483,
         0.0217, 0.0316, 0.0176, 0.0341, 0.0214, 0.0160, 0.0409, 0.0144, 0.0216,
         0.0427, 0.0352, 0.0203, 0.0224, 0.0334, 0.0197, 0.0432, 0.0211, 0.0248,
         0.0269, 0.0184, 0.0170, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 31
images/533
(64, 64, 3)
tensor([[0.0254, 0.0177, 0.0225, 0.0119, 0.0354, 0.0154, 0.0227, 0.0199, 0.0217,
         0.0245, 0.0166, 0.0804, 0.0288, 0.0242, 0.0153, 0.0136, 0.0272, 0.0353,
         0.0163, 0.0195, 0.0225, 0.0201, 0.0215, 0.0174, 0.0264, 0.0217, 0.0180,
         0.0290, 0.0455, 0.0239, 0.0127, 0.0328, 0.0288, 0.0210, 0.0238, 0.0228,
         0.0438, 0.0266, 0.0153, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 32
images/42
(64, 64, 3)
tensor([[0.0346, 0.0297, 0.0140, 0.0163, 0.0257, 0.0319, 0.0369, 0.0187, 0.0165,
         0.0180, 0.0180, 0.0288, 0.0357, 0.0180, 0.0289, 0.0204, 0.0272, 0.0303,
         0.0225, 0.0170, 0.0104, 0.0256, 0.0175, 0.0327, 0.0282, 0.0264, 0.0337,
         0.0349, 0.0189, 0.0349, 0.0236, 0.0177, 0.0296, 0.0188, 0.0300, 0.0268,
         0.0263, 0.0261, 0.0258, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 33
images/384
(64, 64, 3)
tensor([[0.0314, 0.0245, 0.0137, 0.0222, 0.0328, 0.0270, 0.0413, 0.0176, 0.0156,
         0.0191, 0.0152, 0.0447, 0.0392, 0.0236, 0.0233, 0.0135, 0.0170, 0.0367,
         0.0378, 0.0162, 0.0199, 0.0164, 0.0267, 0.0173, 0.0299, 0.0187, 0.0199,
         0.0231, 0.0335, 0.0237, 0.0193, 0.0418, 0.0324, 0.0277, 0.0140, 0.0269,
         0.0326, 0.0146, 0.0181, 0.0313]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 34
images/170
(64, 64, 3)
tensor([[0.0344, 0.0288, 0.0243, 0.0157, 0.0241, 0.0175, 0.0299, 0.0135, 0.0125,
         0.0277, 0.0210, 0.0238, 0.0388, 0.0233, 0.0312, 0.0146, 0.0192, 0.0413,
         0.0174, 0.0211, 0.0193, 0.0249, 0.0162, 0.0241, 0.0311, 0.0229, 0.0272,
         0.0434, 0.0260, 0.0336, 0.0172, 0.0294, 0.0304, 0.0248, 0.0169, 0.0366,
         0.0304, 0.0207, 0.0186, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 35
images/323
(64, 64, 3)
tensor([[0.0374, 0.0188, 0.0265, 0.0137, 0.0222, 0.0269, 0.0307, 0.0273, 0.0237,
         0.0197, 0.0218, 0.0270, 0.0478, 0.0308, 0.0257, 0.0166, 0.0172, 0.0272,
         0.0171, 0.0156, 0.0163, 0.0229, 0.0246, 0.0256, 0.0156, 0.0164, 0.0202,
         0.0257, 0.0507, 0.0392, 0.0196, 0.0201, 0.0337, 0.0289, 0.0259, 0.0258,
         0.0228, 0.0249, 0.0222, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 36
images/269
(64, 64, 3)
tensor([[0.0249, 0.0226, 0.0193, 0.0228, 0.0372, 0.0150, 0.0349, 0.0204, 0.0233,
         0.0170, 0.0129, 0.0223, 0.0247, 0.0438, 0.0379, 0.0178, 0.0214, 0.0363,
         0.0118, 0.0253, 0.0155, 0.0227, 0.0172, 0.0154, 0.0268, 0.0215, 0.0191,
         0.0244, 0.0290, 0.0303, 0.0240, 0.0274, 0.0211, 0.0269, 0.0431, 0.0298,
         0.0326, 0.0327, 0.0207, 0.0282]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 37
images/397
(64, 64, 3)
tensor([[0.0227, 0.0338, 0.0209, 0.0150, 0.0420, 0.0186, 0.0377, 0.0156, 0.0184,
         0.0144, 0.0182, 0.0279, 0.0391, 0.0404, 0.0271, 0.0264, 0.0189, 0.0338,
         0.0168, 0.0169, 0.0220, 0.0307, 0.0217, 0.0211, 0.0233, 0.0197, 0.0200,
         0.0328, 0.0351, 0.0328, 0.0214, 0.0208, 0.0227, 0.0217, 0.0246, 0.0340,
         0.0332, 0.0192, 0.0207, 0.0181]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 38
images/239
(64, 64, 3)
tensor([[0.0290, 0.0341, 0.0275, 0.0122, 0.0287, 0.0179, 0.0364, 0.0187, 0.0174,
         0.0149, 0.0184, 0.0460, 0.0285, 0.0278, 0.0350, 0.0194, 0.0133, 0.0307,
         0.0223, 0.0182, 0.0172, 0.0246, 0.0241, 0.0236, 0.0215, 0.0184, 0.0206,
         0.0344, 0.0386, 0.0282, 0.0236, 0.0279, 0.0262, 0.0236, 0.0397, 0.0293,
         0.0255, 0.0183, 0.0181, 0.0203]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 39
images/385
(64, 64, 3)
tensor([[0.0402, 0.0226, 0.0225, 0.0139, 0.0428, 0.0308, 0.0389, 0.0161, 0.0174,
         0.0282, 0.0202, 0.0259, 0.0417, 0.0344, 0.0224, 0.0186, 0.0230, 0.0372,
         0.0153, 0.0188, 0.0214, 0.0292, 0.0194, 0.0239, 0.0273, 0.0172, 0.0238,
         0.0368, 0.0401, 0.0244, 0.0195, 0.0215, 0.0325, 0.0215, 0.0173, 0.0237,
         0.0230, 0.0109, 0.0181, 0.0176]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 40
images/404
(64, 64, 3)
tensor([[0.0291, 0.0259, 0.0136, 0.0187, 0.0250, 0.0257, 0.0361, 0.0236, 0.0132,
         0.0169, 0.0139, 0.0271, 0.0316, 0.0431, 0.0205, 0.0241, 0.0341, 0.0235,
         0.0179, 0.0191, 0.0194, 0.0254, 0.0298, 0.0263, 0.0232, 0.0238, 0.0243,
         0.0332, 0.0417, 0.0222, 0.0127, 0.0339, 0.0319, 0.0325, 0.0308, 0.0237,
         0.0275, 0.0161, 0.0150, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 41
images/197
(64, 64, 3)
tensor([[0.0234, 0.0219, 0.0131, 0.0227, 0.0285, 0.0201, 0.0392, 0.0142, 0.0253,
         0.0110, 0.0215, 0.0292, 0.0375, 0.0495, 0.0266, 0.0241, 0.0293, 0.0561,
         0.0214, 0.0105, 0.0254, 0.0154, 0.0174, 0.0155, 0.0191, 0.0229, 0.0261,
         0.0295, 0.0355, 0.0209, 0.0198, 0.0266, 0.0273, 0.0244, 0.0215, 0.0317,
         0.0317, 0.0151, 0.0195, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1 
Session Number: 42
images/319
(64, 64, 3)
tensor([[0.0261, 0.0326, 0.0181, 0.0182, 0.0290, 0.0259, 0.0290, 0.0123, 0.0273,
         0.0277, 0.0169, 0.0390, 0.0436, 0.0402, 0.0200, 0.0266, 0.0128, 0.0373,
         0.0164, 0.0219, 0.0232, 0.0288, 0.0248, 0.0151, 0.0169, 0.0147, 0.0263,
         0.0374, 0.0175, 0.0298, 0.0185, 0.0365, 0.0280, 0.0202, 0.0268, 0.0292,
         0.0321, 0.0150, 0.0161, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/253
(64, 64, 3)
tensor([[0.0381, 0.0226, 0.0153, 0.0143, 0.0432, 0.0211, 0.0296, 0.0129, 0.0160,
         0.0230, 0.0222, 0.0254, 0.0403, 0.0421, 0.0240, 0.0123, 0.0184, 0.0474,
         0.0195, 0.0271, 0.0151, 0.0384, 0.0200, 0.0198, 0.0155, 0.0169, 0.0233,
         0.0387, 0.0326, 0.0244, 0.0173, 0.0306, 0.0177, 0.0367, 0.0205, 0.0262,
         0.0181, 0.0220, 0.0247, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/77
(64, 64, 3)
tensor([[0.0241, 0.0260, 0.0159, 0.0243, 0.0373, 0.0205, 0.0361, 0.0178, 0.0194,
         0.0169, 0.0152, 0.0344, 0.0383, 0.0264, 0.0306, 0.0195, 0.0262, 0.0357,
         0.0172, 0.0307, 0.0172, 0.0245, 0.0191, 0.0234, 0.0244, 0.0223, 0.0296,
         0.0354, 0.0340, 0.0181, 0.0229, 0.0272, 0.0263, 0.0324, 0.0207, 0.0228,
         0.0193, 0.0234, 0.0243, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 45
images/455
(64, 64, 3)
tensor([[0.0381, 0.0290, 0.0161, 0.0194, 0.0296, 0.0197, 0.0194, 0.0279, 0.0200,
         0.0124, 0.0183, 0.0411, 0.0546, 0.0400, 0.0316, 0.0260, 0.0210, 0.0340,
         0.0233, 0.0236, 0.0169, 0.0176, 0.0194, 0.0256, 0.0175, 0.0123, 0.0224,
         0.0228, 0.0341, 0.0293, 0.0177, 0.0310, 0.0199, 0.0412, 0.0181, 0.0324,
         0.0177, 0.0206, 0.0137, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 46
images/537
(64, 64, 3)
tensor([[0.0183, 0.0326, 0.0179, 0.0183, 0.0305, 0.0208, 0.0543, 0.0226, 0.0148,
         0.0228, 0.0259, 0.0216, 0.0520, 0.0245, 0.0193, 0.0164, 0.0186, 0.0210,
         0.0197, 0.0254, 0.0193, 0.0213, 0.0261, 0.0169, 0.0165, 0.0115, 0.0283,
         0.0475, 0.0257, 0.0202, 0.0180, 0.0258, 0.0314, 0.0403, 0.0249, 0.0307,
         0.0273, 0.0199, 0.0269, 0.0240]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 47
images/28
(64, 64, 3)
tensor([[0.0249, 0.0221, 0.0167, 0.0104, 0.0217, 0.0218, 0.0270, 0.0174, 0.0208,
         0.0197, 0.0178, 0.0244, 0.0439, 0.0367, 0.0150, 0.0228, 0.0166, 0.0293,
         0.0182, 0.0221, 0.0130, 0.0340, 0.0197, 0.0208, 0.0207, 0.0202, 0.0259,
         0.0334, 0.0313, 0.0195, 0.0158, 0.0341, 0.0401, 0.0277, 0.0266, 0.0408,
         0.0403, 0.0164, 0.0191, 0.0512]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 48
images/547
(64, 64, 3)
tensor([[0.0256, 0.0194, 0.0207, 0.0169, 0.0405, 0.0205, 0.0321, 0.0182, 0.0218,
         0.0162, 0.0286, 0.0372, 0.0275, 0.0325, 0.0207, 0.0182, 0.0262, 0.0410,
         0.0216, 0.0249, 0.0196, 0.0181, 0.0155, 0.0212, 0.0206, 0.0196, 0.0276,
         0.0309, 0.0340, 0.0207, 0.0176, 0.0311, 0.0158, 0.0298, 0.0227, 0.0421,
         0.0334, 0.0183, 0.0239, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 1
Session Number: 49
images/61
(64, 64, 3)
tensor([[0.0264, 0.0245, 0.0134, 0.0171, 0.0268, 0.0237, 0.0345, 0.0185, 0.0183,
         0.0233, 0.0156, 0.0329, 0.0574, 0.0438, 0.0237, 0.0240, 0.0172, 0.0373,
         0.0184, 0.0235, 0.0205, 0.0246, 0.0204, 0.0152, 0.0200, 0.0216, 0.0200,
         0.0431, 0.0356, 0.0185, 0.0202, 0.0198, 0.0331, 0.0218, 0.0290, 0.0240,
         0.0246, 0.0170, 0.0281, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 50
images/476
(64, 64, 3)
tensor([[0.0335, 0.0262, 0.0218, 0.0084, 0.0295, 0.0143, 0.0329, 0.0163, 0.0160,
         0.0163, 0.0208, 0.0273, 0.0403, 0.0390, 0.0243, 0.0206, 0.0203, 0.0290,
         0.0187, 0.0164, 0.0149, 0.0436, 0.0259, 0.0187, 0.0202, 0.0142, 0.0214,
         0.0462, 0.0366, 0.0278, 0.0149, 0.0245, 0.0399, 0.0190, 0.0237, 0.0331,
         0.0203, 0.0203, 0.0330, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 51
images/585
(64, 64, 3)
tensor([[0.0318, 0.0299, 0.0227, 0.0261, 0.0360, 0.0177, 0.0260, 0.0151, 0.0203,
         0.0176, 0.0210, 0.0244, 0.0299, 0.0362, 0.0192, 0.0178, 0.0254, 0.0404,
         0.0190, 0.0190, 0.0158, 0.0325, 0.0223, 0.0200, 0.0113, 0.0153, 0.0363,
         0.0387, 0.0438, 0.0166, 0.0150, 0.0171, 0.0383, 0.0383, 0.0223, 0.0155,
         0.0329, 0.0170, 0.0216, 0.0339]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/364
(64, 64, 3)
tensor([[0.0332, 0.0162, 0.0258, 0.0217, 0.0360, 0.0233, 0.0223, 0.0158, 0.0189,
         0.0158, 0.0199, 0.0192, 0.0341, 0.0308, 0.0163, 0.0240, 0.0201, 0.0414,
         0.0280, 0.0152, 0.0197, 0.0252, 0.0260, 0.0121, 0.0210, 0.0252, 0.0210,
         0.0338, 0.0408, 0.0241, 0.0214, 0.0303, 0.0314, 0.0271, 0.0276, 0.0296,
         0.0431, 0.0151, 0.0205, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 53
images/358
(64, 64, 3)
tensor([[0.0294, 0.0367, 0.0146, 0.0196, 0.0232, 0.0137, 0.0413, 0.0173, 0.0254,
         0.0282, 0.0200, 0.0250, 0.0293, 0.0362, 0.0246, 0.0202, 0.0195, 0.0427,
         0.0168, 0.0131, 0.0196, 0.0306, 0.0200, 0.0231, 0.0269, 0.0130, 0.0216,
         0.0303, 0.0275, 0.0261, 0.0131, 0.0245, 0.0392, 0.0300, 0.0241, 0.0230,
         0.0308, 0.0146, 0.0205, 0.0445]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 54
images/15
(64, 64, 3)
tensor([[0.0287, 0.0208, 0.0236, 0.0223, 0.0335, 0.0155, 0.0306, 0.0178, 0.0289,
         0.0155, 0.0251, 0.0209, 0.0531, 0.0309, 0.0271, 0.0211, 0.0127, 0.0377,
         0.0204, 0.0178, 0.0161, 0.0312, 0.0134, 0.0155, 0.0192, 0.0157, 0.0272,
         0.0429, 0.0296, 0.0290, 0.0276, 0.0246, 0.0262, 0.0178, 0.0177, 0.0270,
         0.0263, 0.0205, 0.0308, 0.0375]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 55
images/256
(64, 64, 3)
tensor([[0.0288, 0.0202, 0.0232, 0.0211, 0.0401, 0.0168, 0.0469, 0.0205, 0.0165,
         0.0195, 0.0188, 0.0267, 0.0531, 0.0305, 0.0333, 0.0164, 0.0196, 0.0427,
         0.0286, 0.0256, 0.0318, 0.0199, 0.0138, 0.0109, 0.0125, 0.0124, 0.0342,
         0.0325, 0.0245, 0.0377, 0.0227, 0.0213, 0.0298, 0.0186, 0.0223, 0.0210,
         0.0257, 0.0244, 0.0170, 0.0181]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 56
images/454
(64, 64, 3)
tensor([[0.0253, 0.0350, 0.0120, 0.0265, 0.0451, 0.0171, 0.0274, 0.0127, 0.0152,
         0.0224, 0.0267, 0.0170, 0.0359, 0.0413, 0.0271, 0.0144, 0.0212, 0.0306,
         0.0234, 0.0187, 0.0171, 0.0316, 0.0232, 0.0252, 0.0217, 0.0177, 0.0367,
         0.0278, 0.0279, 0.0252, 0.0176, 0.0330, 0.0304, 0.0202, 0.0204, 0.0233,
         0.0284, 0.0166, 0.0335, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 57
images/435
(64, 64, 3)
tensor([[0.0250, 0.0340, 0.0203, 0.0209, 0.0288, 0.0304, 0.0353, 0.0171, 0.0143,
         0.0266, 0.0303, 0.0291, 0.0444, 0.0233, 0.0273, 0.0182, 0.0199, 0.0290,
         0.0255, 0.0267, 0.0206, 0.0160, 0.0185, 0.0246, 0.0161, 0.0160, 0.0276,
         0.0331, 0.0321, 0.0263, 0.0168, 0.0215, 0.0247, 0.0309, 0.0277, 0.0356,
         0.0299, 0.0175, 0.0195, 0.0187]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 58
images/363
(64, 64, 3)
tensor([[0.0351, 0.0220, 0.0273, 0.0171, 0.0495, 0.0144, 0.0375, 0.0145, 0.0166,
         0.0198, 0.0173, 0.0387, 0.0336, 0.0291, 0.0269, 0.0184, 0.0148, 0.0581,
         0.0200, 0.0255, 0.0165, 0.0180, 0.0196, 0.0188, 0.0168, 0.0278, 0.0235,
         0.0308, 0.0357, 0.0233, 0.0245, 0.0166, 0.0234, 0.0127, 0.0325, 0.0219,
         0.0380, 0.0194, 0.0233, 0.0207]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 1
Session Number: 59
images/508
(64, 64, 3)
tensor([[0.0285, 0.0319, 0.0127, 0.0251, 0.0368, 0.0120, 0.0171, 0.0175, 0.0208,
         0.0159, 0.0219, 0.0359, 0.0302, 0.0336, 0.0225, 0.0172, 0.0195, 0.0358,
         0.0153, 0.0281, 0.0171, 0.0273, 0.0272, 0.0296, 0.0202, 0.0245, 0.0234,
         0.0363, 0.0327, 0.0246, 0.0169, 0.0270, 0.0256, 0.0265, 0.0150, 0.0339,
         0.0199, 0.0187, 0.0437, 0.0315]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 60
images/583
(64, 64, 3)
tensor([[0.0375, 0.0190, 0.0226, 0.0238, 0.0257, 0.0216, 0.0339, 0.0220, 0.0157,
         0.0190, 0.0203, 0.0401, 0.0254, 0.0301, 0.0240, 0.0134, 0.0184, 0.0262,
         0.0220, 0.0155, 0.0147, 0.0373, 0.0270, 0.0250, 0.0270, 0.0241, 0.0168,
         0.0409, 0.0400, 0.0203, 0.0187, 0.0267, 0.0307, 0.0290, 0.0180, 0.0171,
         0.0295, 0.0234, 0.0228, 0.0349]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 61
images/404
(64, 64, 3)
tensor([[0.0295, 0.0258, 0.0233, 0.0158, 0.0378, 0.0144, 0.0368, 0.0340, 0.0251,
         0.0245, 0.0188, 0.0395, 0.0353, 0.0227, 0.0276, 0.0159, 0.0298, 0.0265,
         0.0171, 0.0145, 0.0194, 0.0236, 0.0181, 0.0220, 0.0217, 0.0162, 0.0168,
         0.0206, 0.0340, 0.0207, 0.0119, 0.0484, 0.0335, 0.0241, 0.0187, 0.0359,
         0.0294, 0.0168, 0.0250, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 62
images/277
(64, 64, 3)
tensor([[0.0368, 0.0254, 0.0182, 0.0178, 0.0332, 0.0183, 0.0323, 0.0112, 0.0233,
         0.0205, 0.0208, 0.0403, 0.0364, 0.0262, 0.0238, 0.0145, 0.0234, 0.0311,
         0.0232, 0.0368, 0.0138, 0.0305, 0.0208, 0.0205, 0.0260, 0.0167, 0.0244,
         0.0346, 0.0324, 0.0187, 0.0113, 0.0180, 0.0312, 0.0256, 0.0169, 0.0405,
         0.0337, 0.0169, 0.0214, 0.0323]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 63
images/87
(64, 64, 3)
tensor([[0.0240, 0.0324, 0.0130, 0.0213, 0.0277, 0.0164, 0.0337, 0.0144, 0.0304,
         0.0213, 0.0127, 0.0386, 0.0350, 0.0458, 0.0311, 0.0189, 0.0125, 0.0479,
         0.0199, 0.0269, 0.0166, 0.0319, 0.0153, 0.0204, 0.0265, 0.0125, 0.0206,
         0.0423, 0.0304, 0.0241, 0.0308, 0.0214, 0.0209, 0.0240, 0.0294, 0.0177,
         0.0167, 0.0227, 0.0191, 0.0328]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 64
images/480
(64, 64, 3)
tensor([[0.0225, 0.0278, 0.0140, 0.0100, 0.0252, 0.0255, 0.0338, 0.0175, 0.0217,
         0.0247, 0.0232, 0.0392, 0.0407, 0.0312, 0.0306, 0.0161, 0.0289, 0.0373,
         0.0263, 0.0191, 0.0187, 0.0269, 0.0192, 0.0178, 0.0217, 0.0171, 0.0219,
         0.0412, 0.0359, 0.0269, 0.0176, 0.0311, 0.0285, 0.0213, 0.0235, 0.0318,
         0.0173, 0.0175, 0.0183, 0.0306]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 65
images/329
(64, 64, 3)
tensor([[0.0299, 0.0278, 0.0154, 0.0198, 0.0511, 0.0344, 0.0253, 0.0121, 0.0130,
         0.0208, 0.0170, 0.0403, 0.0420, 0.0245, 0.0266, 0.0189, 0.0224, 0.0248,
         0.0302, 0.0287, 0.0324, 0.0345, 0.0161, 0.0258, 0.0221, 0.0192, 0.0300,
         0.0329, 0.0297, 0.0181, 0.0168, 0.0315, 0.0176, 0.0179, 0.0238, 0.0224,
         0.0251, 0.0218, 0.0163, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 66
images/324
(64, 64, 3)
tensor([[0.0252, 0.0297, 0.0238, 0.0207, 0.0350, 0.0174, 0.0362, 0.0123, 0.0210,
         0.0174, 0.0157, 0.0295, 0.0265, 0.0298, 0.0380, 0.0154, 0.0239, 0.0419,
         0.0197, 0.0254, 0.0228, 0.0275, 0.0182, 0.0150, 0.0163, 0.0215, 0.0271,
         0.0245, 0.0349, 0.0228, 0.0142, 0.0355, 0.0406, 0.0234, 0.0146, 0.0493,
         0.0307, 0.0149, 0.0211, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 67
images/73
(64, 64, 3)
tensor([[0.0305, 0.0240, 0.0225, 0.0145, 0.0361, 0.0266, 0.0399, 0.0258, 0.0121,
         0.0277, 0.0189, 0.0261, 0.0396, 0.0406, 0.0201, 0.0140, 0.0149, 0.0276,
         0.0184, 0.0223, 0.0153, 0.0213, 0.0240, 0.0254, 0.0304, 0.0182, 0.0268,
         0.0225, 0.0408, 0.0276, 0.0228, 0.0303, 0.0223, 0.0223, 0.0238, 0.0316,
         0.0285, 0.0188, 0.0163, 0.0288]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/268
(64, 64, 3)
tensor([[0.0174, 0.0237, 0.0253, 0.0191, 0.0290, 0.0120, 0.0446, 0.0268, 0.0217,
         0.0283, 0.0251, 0.0258, 0.0388, 0.0265, 0.0219, 0.0141, 0.0257, 0.0326,
         0.0187, 0.0137, 0.0168, 0.0157, 0.0218, 0.0130, 0.0230, 0.0195, 0.0292,
         0.0303, 0.0529, 0.0342, 0.0194, 0.0226, 0.0345, 0.0236, 0.0182, 0.0217,
         0.0267, 0.0192, 0.0209, 0.0461]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 69
images/462
(64, 64, 3)
tensor([[0.0211, 0.0273, 0.0190, 0.0132, 0.0248, 0.0253, 0.0423, 0.0180, 0.0195,
         0.0197, 0.0255, 0.0309, 0.0449, 0.0436, 0.0254, 0.0222, 0.0162, 0.0343,
         0.0192, 0.0180, 0.0183, 0.0176, 0.0190, 0.0197, 0.0289, 0.0183, 0.0254,
         0.0255, 0.0292, 0.0265, 0.0255, 0.0445, 0.0372, 0.0157, 0.0278, 0.0305,
         0.0185, 0.0179, 0.0203, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 70
images/336
(64, 64, 3)
tensor([[0.0193, 0.0374, 0.0179, 0.0239, 0.0402, 0.0216, 0.0377, 0.0130, 0.0226,
         0.0188, 0.0218, 0.0287, 0.0474, 0.0328, 0.0285, 0.0229, 0.0177, 0.0230,
         0.0191, 0.0323, 0.0227, 0.0347, 0.0234, 0.0207, 0.0209, 0.0175, 0.0230,
         0.0247, 0.0269, 0.0302, 0.0200, 0.0196, 0.0279, 0.0228, 0.0151, 0.0312,
         0.0214, 0.0199, 0.0248, 0.0258]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 71
images/57
(64, 64, 3)
tensor([[0.0289, 0.0187, 0.0250, 0.0178, 0.0321, 0.0182, 0.0368, 0.0217, 0.0171,
         0.0273, 0.0172, 0.0357, 0.0378, 0.0328, 0.0195, 0.0141, 0.0209, 0.0224,
         0.0156, 0.0266, 0.0176, 0.0169, 0.0221, 0.0190, 0.0227, 0.0248, 0.0205,
         0.0425, 0.0428, 0.0227, 0.0180, 0.0262, 0.0340, 0.0253, 0.0233, 0.0272,
         0.0358, 0.0165, 0.0346, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 72
images/199
(64, 64, 3)
tensor([[0.0280, 0.0271, 0.0259, 0.0189, 0.0310, 0.0174, 0.0308, 0.0244, 0.0219,
         0.0186, 0.0215, 0.0323, 0.0384, 0.0240, 0.0221, 0.0178, 0.0175, 0.0194,
         0.0293, 0.0144, 0.0209, 0.0209, 0.0226, 0.0242, 0.0231, 0.0202, 0.0203,
         0.0449, 0.0306, 0.0259, 0.0161, 0.0238, 0.0206, 0.0311, 0.0303, 0.0360,
         0.0335, 0.0218, 0.0278, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 73
images/324
(64, 64, 3)
tensor([[0.0245, 0.0234, 0.0186, 0.0170, 0.0359, 0.0189, 0.0356, 0.0150, 0.0199,
         0.0180, 0.0223, 0.0287, 0.0256, 0.0224, 0.0225, 0.0194, 0.0201, 0.0359,
         0.0247, 0.0150, 0.0127, 0.0213, 0.0219, 0.0131, 0.0239, 0.0298, 0.0234,
         0.0341, 0.0351, 0.0312, 0.0142, 0.0336, 0.0502, 0.0260, 0.0249, 0.0509,
         0.0303, 0.0180, 0.0202, 0.0218]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 74
images/415
(64, 64, 3)
tensor([[0.0452, 0.0316, 0.0105, 0.0215, 0.0292, 0.0331, 0.0256, 0.0108, 0.0159,
         0.0180, 0.0214, 0.0302, 0.0457, 0.0271, 0.0369, 0.0313, 0.0196, 0.0439,
         0.0192, 0.0241, 0.0162, 0.0152, 0.0158, 0.0191, 0.0221, 0.0158, 0.0247,
         0.0291, 0.0321, 0.0117, 0.0177, 0.0229, 0.0229, 0.0194, 0.0258, 0.0333,
         0.0235, 0.0228, 0.0369, 0.0325]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 75
images/89
(64, 64, 3)
tensor([[0.0187, 0.0353, 0.0137, 0.0290, 0.0343, 0.0192, 0.0252, 0.0146, 0.0207,
         0.0254, 0.0131, 0.0190, 0.0360, 0.0311, 0.0191, 0.0259, 0.0181, 0.0229,
         0.0338, 0.0193, 0.0156, 0.0274, 0.0179, 0.0251, 0.0301, 0.0192, 0.0308,
         0.0410, 0.0578, 0.0358, 0.0188, 0.0312, 0.0250, 0.0234, 0.0154, 0.0243,
         0.0239, 0.0166, 0.0200, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 76
images/194
(64, 64, 3)
tensor([[0.0294, 0.0234, 0.0209, 0.0089, 0.0260, 0.0239, 0.0314, 0.0178, 0.0266,
         0.0226, 0.0257, 0.0424, 0.0380, 0.0349, 0.0371, 0.0208, 0.0205, 0.0231,
         0.0267, 0.0143, 0.0174, 0.0246, 0.0257, 0.0211, 0.0175, 0.0175, 0.0172,
         0.0397, 0.0445, 0.0293, 0.0181, 0.0341, 0.0200, 0.0189, 0.0201, 0.0298,
         0.0283, 0.0198, 0.0161, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 77
images/259
(64, 64, 3)
tensor([[0.0230, 0.0245, 0.0265, 0.0208, 0.0462, 0.0245, 0.0211, 0.0193, 0.0286,
         0.0140, 0.0176, 0.0277, 0.0452, 0.0281, 0.0187, 0.0164, 0.0277, 0.0331,
         0.0240, 0.0169, 0.0229, 0.0227, 0.0195, 0.0226, 0.0203, 0.0143, 0.0162,
         0.0370, 0.0253, 0.0273, 0.0154, 0.0382, 0.0284, 0.0239, 0.0190, 0.0367,
         0.0423, 0.0156, 0.0146, 0.0336]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 78
images/8
(64, 64, 3)
tensor([[0.0301, 0.0337, 0.0197, 0.0231, 0.0241, 0.0188, 0.0398, 0.0172, 0.0284,
         0.0253, 0.0208, 0.0486, 0.0362, 0.0263, 0.0199, 0.0248, 0.0218, 0.0207,
         0.0196, 0.0246, 0.0202, 0.0251, 0.0130, 0.0179, 0.0203, 0.0196, 0.0324,
         0.0174, 0.0316, 0.0324, 0.0123, 0.0196, 0.0241, 0.0173, 0.0242, 0.0260,
         0.0382, 0.0234, 0.0314, 0.0302]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/442
(64, 64, 3)
tensor([[0.0234, 0.0171, 0.0175, 0.0197, 0.0435, 0.0279, 0.0238, 0.0233, 0.0201,
         0.0275, 0.0199, 0.0326, 0.0383, 0.0234, 0.0284, 0.0218, 0.0199, 0.0375,
         0.0294, 0.0245, 0.0130, 0.0365, 0.0222, 0.0215, 0.0206, 0.0224, 0.0206,
         0.0452, 0.0245, 0.0242, 0.0160, 0.0186, 0.0206, 0.0225, 0.0318, 0.0234,
         0.0234, 0.0303, 0.0222, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 80
images/80
(64, 64, 3)
tensor([[0.0299, 0.0262, 0.0135, 0.0251, 0.0326, 0.0172, 0.0389, 0.0162, 0.0149,
         0.0174, 0.0136, 0.0415, 0.0373, 0.0216, 0.0329, 0.0240, 0.0241, 0.0393,
         0.0197, 0.0207, 0.0220, 0.0260, 0.0263, 0.0149, 0.0251, 0.0184, 0.0298,
         0.0267, 0.0352, 0.0212, 0.0176, 0.0287, 0.0219, 0.0284, 0.0212, 0.0281,
         0.0240, 0.0187, 0.0281, 0.0311]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 81
images/399
(64, 64, 3)
tensor([[0.0317, 0.0263, 0.0176, 0.0180, 0.0273, 0.0215, 0.0258, 0.0213, 0.0213,
         0.0261, 0.0132, 0.0312, 0.0317, 0.0315, 0.0326, 0.0187, 0.0123, 0.0468,
         0.0145, 0.0305, 0.0132, 0.0300, 0.0258, 0.0217, 0.0192, 0.0277, 0.0251,
         0.0264, 0.0234, 0.0276, 0.0185, 0.0393, 0.0321, 0.0139, 0.0281, 0.0193,
         0.0334, 0.0336, 0.0176, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 82
images/20
(64, 64, 3)
tensor([[0.0249, 0.0309, 0.0296, 0.0166, 0.0425, 0.0178, 0.0295, 0.0153, 0.0147,
         0.0230, 0.0187, 0.0333, 0.0501, 0.0305, 0.0267, 0.0149, 0.0212, 0.0366,
         0.0208, 0.0189, 0.0190, 0.0409, 0.0203, 0.0235, 0.0191, 0.0239, 0.0260,
         0.0267, 0.0344, 0.0232, 0.0163, 0.0203, 0.0245, 0.0271, 0.0253, 0.0163,
         0.0340, 0.0293, 0.0131, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 83
images/547
(64, 64, 3)
tensor([[0.0280, 0.0294, 0.0190, 0.0170, 0.0487, 0.0194, 0.0304, 0.0151, 0.0187,
         0.0173, 0.0243, 0.0337, 0.0468, 0.0259, 0.0299, 0.0231, 0.0212, 0.0290,
         0.0121, 0.0197, 0.0176, 0.0206, 0.0179, 0.0260, 0.0143, 0.0214, 0.0224,
         0.0337, 0.0301, 0.0239, 0.0140, 0.0399, 0.0314, 0.0254, 0.0241, 0.0431,
         0.0284, 0.0195, 0.0155, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 84
images/159
(64, 64, 3)
tensor([[0.0321, 0.0284, 0.0208, 0.0200, 0.0336, 0.0255, 0.0298, 0.0201, 0.0196,
         0.0250, 0.0203, 0.0314, 0.0247, 0.0278, 0.0251, 0.0167, 0.0377, 0.0243,
         0.0184, 0.0186, 0.0243, 0.0312, 0.0219, 0.0213, 0.0221, 0.0160, 0.0240,
         0.0434, 0.0377, 0.0177, 0.0195, 0.0206, 0.0209, 0.0393, 0.0205, 0.0329,
         0.0259, 0.0121, 0.0216, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 85
images/389
(64, 64, 3)
tensor([[0.0237, 0.0258, 0.0197, 0.0286, 0.0268, 0.0241, 0.0287, 0.0206, 0.0178,
         0.0201, 0.0226, 0.0294, 0.0244, 0.0375, 0.0243, 0.0365, 0.0154, 0.0330,
         0.0183, 0.0197, 0.0211, 0.0253, 0.0177, 0.0193, 0.0208, 0.0194, 0.0233,
         0.0394, 0.0279, 0.0340, 0.0159, 0.0259, 0.0292, 0.0172, 0.0271, 0.0307,
         0.0226, 0.0181, 0.0335, 0.0344]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 1
Session Number: 86
images/436
(64, 64, 3)
tensor([[0.0275, 0.0256, 0.0129, 0.0200, 0.0211, 0.0138, 0.0332, 0.0266, 0.0174,
         0.0180, 0.0228, 0.0306, 0.0414, 0.0351, 0.0305, 0.0168, 0.0323, 0.0246,
         0.0147, 0.0166, 0.0177, 0.0176, 0.0200, 0.0336, 0.0207, 0.0187, 0.0310,
         0.0338, 0.0346, 0.0215, 0.0190, 0.0339, 0.0294, 0.0210, 0.0389, 0.0188,
         0.0308, 0.0206, 0.0298, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 87
images/440
(64, 64, 3)
tensor([[0.0262, 0.0228, 0.0198, 0.0182, 0.0256, 0.0193, 0.0406, 0.0232, 0.0199,
         0.0161, 0.0259, 0.0462, 0.0509, 0.0396, 0.0302, 0.0264, 0.0168, 0.0272,
         0.0192, 0.0209, 0.0189, 0.0263, 0.0259, 0.0164, 0.0199, 0.0158, 0.0243,
         0.0189, 0.0269, 0.0282, 0.0153, 0.0319, 0.0241, 0.0216, 0.0297, 0.0342,
         0.0188, 0.0209, 0.0244, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 88
images/456
(64, 64, 3)
tensor([[0.0370, 0.0254, 0.0168, 0.0152, 0.0299, 0.0227, 0.0434, 0.0336, 0.0255,
         0.0140, 0.0256, 0.0348, 0.0427, 0.0267, 0.0226, 0.0163, 0.0139, 0.0306,
         0.0188, 0.0171, 0.0117, 0.0161, 0.0219, 0.0223, 0.0208, 0.0179, 0.0190,
         0.0210, 0.0386, 0.0317, 0.0223, 0.0300, 0.0286, 0.0258, 0.0245, 0.0316,
         0.0397, 0.0147, 0.0209, 0.0282]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 1
Session Number: 89
images/114
(64, 64, 3)
tensor([[0.0255, 0.0302, 0.0183, 0.0147, 0.0386, 0.0197, 0.0286, 0.0207, 0.0166,
         0.0224, 0.0119, 0.0263, 0.0610, 0.0341, 0.0307, 0.0212, 0.0174, 0.0454,
         0.0232, 0.0248, 0.0233, 0.0146, 0.0209, 0.0195, 0.0272, 0.0196, 0.0245,
         0.0322, 0.0211, 0.0256, 0.0161, 0.0293, 0.0245, 0.0257, 0.0253, 0.0339,
         0.0260, 0.0235, 0.0166, 0.0190]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 90
images/152
(64, 64, 3)
tensor([[0.0308, 0.0217, 0.0253, 0.0214, 0.0289, 0.0341, 0.0309, 0.0186, 0.0129,
         0.0227, 0.0133, 0.0488, 0.0271, 0.0347, 0.0253, 0.0268, 0.0194, 0.0196,
         0.0200, 0.0169, 0.0180, 0.0235, 0.0278, 0.0272, 0.0275, 0.0289, 0.0253,
         0.0418, 0.0304, 0.0298, 0.0160, 0.0171, 0.0223, 0.0153, 0.0214, 0.0268,
         0.0300, 0.0192, 0.0237, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 91
images/295
(64, 64, 3)
tensor([[0.0318, 0.0363, 0.0247, 0.0186, 0.0207, 0.0358, 0.0300, 0.0159, 0.0188,
         0.0297, 0.0222, 0.0378, 0.0488, 0.0307, 0.0257, 0.0187, 0.0122, 0.0290,
         0.0246, 0.0223, 0.0153, 0.0207, 0.0244, 0.0255, 0.0216, 0.0231, 0.0172,
         0.0310, 0.0248, 0.0392, 0.0151, 0.0490, 0.0193, 0.0210, 0.0219, 0.0224,
         0.0188, 0.0169, 0.0209, 0.0178]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 92
images/103
(64, 64, 3)
tensor([[0.0224, 0.0220, 0.0188, 0.0138, 0.0288, 0.0208, 0.0282, 0.0329, 0.0232,
         0.0362, 0.0145, 0.0282, 0.0509, 0.0168, 0.0219, 0.0192, 0.0198, 0.0447,
         0.0238, 0.0201, 0.0172, 0.0235, 0.0231, 0.0238, 0.0247, 0.0151, 0.0348,
         0.0286, 0.0391, 0.0255, 0.0280, 0.0337, 0.0235, 0.0228, 0.0288, 0.0257,
         0.0150, 0.0262, 0.0188, 0.0152]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 93
images/533
(64, 64, 3)
tensor([[0.0243, 0.0254, 0.0113, 0.0187, 0.0407, 0.0230, 0.0269, 0.0167, 0.0181,
         0.0222, 0.0189, 0.0244, 0.0549, 0.0345, 0.0222, 0.0212, 0.0180, 0.0476,
         0.0238, 0.0223, 0.0177, 0.0186, 0.0256, 0.0124, 0.0265, 0.0208, 0.0361,
         0.0224, 0.0270, 0.0272, 0.0273, 0.0231, 0.0262, 0.0290, 0.0286, 0.0258,
         0.0380, 0.0181, 0.0191, 0.0152]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 94
images/549
(64, 64, 3)
tensor([[0.0343, 0.0332, 0.0182, 0.0229, 0.0405, 0.0233, 0.0340, 0.0124, 0.0185,
         0.0210, 0.0239, 0.0253, 0.0513, 0.0256, 0.0211, 0.0194, 0.0189, 0.0276,
         0.0174, 0.0231, 0.0150, 0.0258, 0.0141, 0.0184, 0.0226, 0.0254, 0.0359,
         0.0391, 0.0259, 0.0206, 0.0208, 0.0236, 0.0313, 0.0136, 0.0218, 0.0336,
         0.0341, 0.0225, 0.0222, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 95
images/196
(64, 64, 3)
tensor([[0.0332, 0.0326, 0.0222, 0.0251, 0.0359, 0.0177, 0.0276, 0.0186, 0.0229,
         0.0182, 0.0213, 0.0210, 0.0428, 0.0377, 0.0252, 0.0152, 0.0218, 0.0228,
         0.0177, 0.0160, 0.0296, 0.0241, 0.0206, 0.0186, 0.0325, 0.0199, 0.0263,
         0.0246, 0.0216, 0.0163, 0.0183, 0.0328, 0.0260, 0.0286, 0.0151, 0.0486,
         0.0192, 0.0173, 0.0312, 0.0334]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 96
images/253
(64, 64, 3)
tensor([[0.0279, 0.0343, 0.0113, 0.0115, 0.0521, 0.0240, 0.0289, 0.0202, 0.0167,
         0.0162, 0.0220, 0.0317, 0.0545, 0.0391, 0.0251, 0.0130, 0.0201, 0.0385,
         0.0192, 0.0220, 0.0201, 0.0231, 0.0148, 0.0311, 0.0131, 0.0176, 0.0252,
         0.0425, 0.0241, 0.0161, 0.0160, 0.0304, 0.0174, 0.0235, 0.0295, 0.0398,
         0.0222, 0.0165, 0.0167, 0.0320]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 97
images/462
(64, 64, 3)
tensor([[0.0203, 0.0161, 0.0194, 0.0277, 0.0405, 0.0237, 0.0426, 0.0184, 0.0180,
         0.0187, 0.0267, 0.0421, 0.0281, 0.0319, 0.0294, 0.0161, 0.0133, 0.0290,
         0.0267, 0.0216, 0.0150, 0.0132, 0.0325, 0.0157, 0.0247, 0.0240, 0.0208,
         0.0347, 0.0235, 0.0228, 0.0197, 0.0283, 0.0317, 0.0252, 0.0204, 0.0283,
         0.0380, 0.0189, 0.0198, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 98
images/149
(64, 64, 3)
tensor([[0.0311, 0.0263, 0.0184, 0.0093, 0.0376, 0.0180, 0.0295, 0.0149, 0.0196,
         0.0167, 0.0208, 0.0323, 0.0330, 0.0258, 0.0261, 0.0231, 0.0216, 0.0326,
         0.0214, 0.0145, 0.0159, 0.0256, 0.0230, 0.0153, 0.0195, 0.0210, 0.0282,
         0.0490, 0.0267, 0.0229, 0.0132, 0.0316, 0.0258, 0.0327, 0.0294, 0.0407,
         0.0387, 0.0155, 0.0194, 0.0332]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 99
images/537
(64, 64, 3)
tensor([[0.0207, 0.0269, 0.0151, 0.0162, 0.0289, 0.0287, 0.0476, 0.0208, 0.0161,
         0.0182, 0.0256, 0.0210, 0.0367, 0.0248, 0.0130, 0.0145, 0.0248, 0.0330,
         0.0244, 0.0230, 0.0184, 0.0166, 0.0200, 0.0221, 0.0208, 0.0216, 0.0228,
         0.0339, 0.0292, 0.0189, 0.0158, 0.0372, 0.0405, 0.0293, 0.0174, 0.0541,
         0.0259, 0.0168, 0.0327, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Saving the weights
31 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/44
(64, 64, 3)
2018-10-13 00:12:19.724 Python[8194:15689033] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0295, 0.0150, 0.0196, 0.0220, 0.0350, 0.0132, 0.0234, 0.0170, 0.0146,
         0.0159, 0.0155, 0.0264, 0.0228, 0.0313, 0.0350, 0.0273, 0.0230, 0.0417,
         0.0141, 0.0194, 0.0139, 0.0250, 0.0448, 0.0206, 0.0269, 0.0254, 0.0232,
         0.0364, 0.0362, 0.0181, 0.0145, 0.0393, 0.0228, 0.0229, 0.0183, 0.0282,
         0.0397, 0.0340, 0.0237, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 1
images/122
(64, 64, 3)
tensor([[0.0308, 0.0237, 0.0197, 0.0193, 0.0324, 0.0171, 0.0291, 0.0201, 0.0179,
         0.0195, 0.0202, 0.0251, 0.0302, 0.0276, 0.0219, 0.0185, 0.0168, 0.0430,
         0.0200, 0.0238, 0.0164, 0.0275, 0.0221, 0.0296, 0.0284, 0.0194, 0.0206,
         0.0414, 0.0336, 0.0188, 0.0136, 0.0434, 0.0238, 0.0234, 0.0170, 0.0290,
         0.0341, 0.0220, 0.0210, 0.0381]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/574
(64, 64, 3)
tensor([[0.0269, 0.0316, 0.0175, 0.0190, 0.0348, 0.0237, 0.0307, 0.0189, 0.0148,
         0.0222, 0.0218, 0.0365, 0.0351, 0.0350, 0.0314, 0.0202, 0.0237, 0.0618,
         0.0135, 0.0152, 0.0194, 0.0223, 0.0212, 0.0288, 0.0257, 0.0192, 0.0252,
         0.0263, 0.0266, 0.0232, 0.0257, 0.0313, 0.0250, 0.0200, 0.0240, 0.0287,
         0.0162, 0.0214, 0.0177, 0.0176]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 3
images/272
(64, 64, 3)
tensor([[0.0307, 0.0265, 0.0164, 0.0244, 0.0256, 0.0176, 0.0295, 0.0174, 0.0245,
         0.0170, 0.0306, 0.0357, 0.0317, 0.0391, 0.0231, 0.0184, 0.0165, 0.0446,
         0.0175, 0.0266, 0.0138, 0.0170, 0.0226, 0.0203, 0.0174, 0.0186, 0.0212,
         0.0530, 0.0333, 0.0232, 0.0187, 0.0272, 0.0249, 0.0252, 0.0306, 0.0313,
         0.0237, 0.0217, 0.0237, 0.0190]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 4
images/78
(64, 64, 3)
tensor([[0.0246, 0.0299, 0.0203, 0.0171, 0.0440, 0.0244, 0.0372, 0.0162, 0.0214,
         0.0194, 0.0122, 0.0300, 0.0239, 0.0434, 0.0381, 0.0229, 0.0235, 0.0420,
         0.0124, 0.0150, 0.0188, 0.0186, 0.0193, 0.0190, 0.0231, 0.0200, 0.0387,
         0.0162, 0.0263, 0.0251, 0.0204, 0.0321, 0.0263, 0.0329, 0.0360, 0.0233,
         0.0177, 0.0230, 0.0206, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 5
images/103
(64, 64, 3)
tensor([[0.0190, 0.0291, 0.0172, 0.0162, 0.0246, 0.0248, 0.0345, 0.0333, 0.0142,
         0.0273, 0.0244, 0.0359, 0.0416, 0.0287, 0.0261, 0.0332, 0.0197, 0.0489,
         0.0166, 0.0224, 0.0132, 0.0171, 0.0235, 0.0314, 0.0145, 0.0198, 0.0238,
         0.0256, 0.0293, 0.0247, 0.0257, 0.0317, 0.0214, 0.0226, 0.0231, 0.0289,
         0.0194, 0.0159, 0.0247, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 6
images/255
(64, 64, 3)
tensor([[0.0339, 0.0372, 0.0191, 0.0155, 0.0273, 0.0226, 0.0277, 0.0170, 0.0198,
         0.0276, 0.0152, 0.0395, 0.0268, 0.0261, 0.0354, 0.0169, 0.0220, 0.0350,
         0.0179, 0.0241, 0.0155, 0.0298, 0.0282, 0.0239, 0.0200, 0.0207, 0.0240,
         0.0359, 0.0397, 0.0307, 0.0235, 0.0276, 0.0236, 0.0259, 0.0143, 0.0249,
         0.0178, 0.0206, 0.0188, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 7
images/563
(64, 64, 3)
tensor([[0.0399, 0.0208, 0.0231, 0.0206, 0.0242, 0.0171, 0.0289, 0.0091, 0.0148,
         0.0144, 0.0156, 0.0371, 0.0384, 0.0374, 0.0199, 0.0332, 0.0211, 0.0336,
         0.0200, 0.0192, 0.0165, 0.0205, 0.0196, 0.0234, 0.0151, 0.0186, 0.0338,
         0.0451, 0.0462, 0.0216, 0.0218, 0.0320, 0.0201, 0.0327, 0.0177, 0.0363,
         0.0266, 0.0240, 0.0151, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 1
Session Number: 8
images/589
(64, 64, 3)
tensor([[0.0287, 0.0327, 0.0102, 0.0186, 0.0259, 0.0216, 0.0312, 0.0200, 0.0206,
         0.0190, 0.0156, 0.0388, 0.0434, 0.0210, 0.0267, 0.0214, 0.0180, 0.0387,
         0.0212, 0.0199, 0.0133, 0.0287, 0.0281, 0.0208, 0.0144, 0.0194, 0.0252,
         0.0275, 0.0371, 0.0279, 0.0118, 0.0317, 0.0252, 0.0215, 0.0310, 0.0292,
         0.0293, 0.0291, 0.0193, 0.0364]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 9
images/38
(64, 64, 3)
tensor([[0.0326, 0.0387, 0.0154, 0.0220, 0.0278, 0.0140, 0.0299, 0.0153, 0.0136,
         0.0245, 0.0198, 0.0137, 0.0225, 0.0325, 0.0196, 0.0174, 0.0223, 0.0271,
         0.0149, 0.0148, 0.0178, 0.0258, 0.0244, 0.0197, 0.0243, 0.0272, 0.0365,
         0.0347, 0.0572, 0.0252, 0.0207, 0.0304, 0.0301, 0.0234, 0.0110, 0.0598,
         0.0273, 0.0166, 0.0219, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 10
images/355
(64, 64, 3)
tensor([[0.0218, 0.0245, 0.0189, 0.0183, 0.0502, 0.0215, 0.0290, 0.0143, 0.0198,
         0.0278, 0.0162, 0.0303, 0.0387, 0.0262, 0.0285, 0.0123, 0.0190, 0.0320,
         0.0225, 0.0221, 0.0141, 0.0222, 0.0200, 0.0309, 0.0149, 0.0196, 0.0481,
         0.0239, 0.0248, 0.0187, 0.0166, 0.0298, 0.0382, 0.0242, 0.0241, 0.0209,
         0.0289, 0.0284, 0.0242, 0.0336]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/553
(64, 64, 3)
tensor([[0.0205, 0.0271, 0.0387, 0.0162, 0.0426, 0.0306, 0.0267, 0.0185, 0.0257,
         0.0225, 0.0151, 0.0462, 0.0190, 0.0248, 0.0224, 0.0262, 0.0181, 0.0436,
         0.0161, 0.0218, 0.0178, 0.0263, 0.0152, 0.0294, 0.0230, 0.0184, 0.0221,
         0.0224, 0.0513, 0.0332, 0.0152, 0.0256, 0.0237, 0.0200, 0.0292, 0.0237,
         0.0216, 0.0227, 0.0140, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 12
images/44
(64, 64, 3)
tensor([[0.0388, 0.0210, 0.0140, 0.0177, 0.0285, 0.0176, 0.0303, 0.0170, 0.0188,
         0.0123, 0.0236, 0.0256, 0.0358, 0.0609, 0.0130, 0.0273, 0.0265, 0.0430,
         0.0130, 0.0165, 0.0161, 0.0277, 0.0287, 0.0221, 0.0222, 0.0232, 0.0206,
         0.0324, 0.0525, 0.0179, 0.0138, 0.0342, 0.0234, 0.0121, 0.0189, 0.0261,
         0.0288, 0.0250, 0.0250, 0.0282]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 13
images/42
(64, 64, 3)
tensor([[0.0241, 0.0275, 0.0137, 0.0149, 0.0179, 0.0367, 0.0317, 0.0254, 0.0132,
         0.0249, 0.0337, 0.0292, 0.0496, 0.0228, 0.0199, 0.0236, 0.0112, 0.0234,
         0.0208, 0.0134, 0.0178, 0.0247, 0.0161, 0.0215, 0.0217, 0.0193, 0.0275,
         0.0509, 0.0261, 0.0166, 0.0188, 0.0308, 0.0332, 0.0117, 0.0333, 0.0264,
         0.0445, 0.0191, 0.0346, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 14
images/314
(64, 64, 3)
tensor([[0.0277, 0.0178, 0.0154, 0.0123, 0.0286, 0.0222, 0.0301, 0.0230, 0.0190,
         0.0171, 0.0170, 0.0291, 0.0373, 0.0281, 0.0338, 0.0183, 0.0171, 0.0405,
         0.0200, 0.0184, 0.0216, 0.0280, 0.0268, 0.0197, 0.0266, 0.0222, 0.0223,
         0.0382, 0.0372, 0.0194, 0.0126, 0.0709, 0.0297, 0.0237, 0.0229, 0.0161,
         0.0205, 0.0159, 0.0241, 0.0292]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 15
images/382
(64, 64, 3)
tensor([[0.0289, 0.0283, 0.0212, 0.0283, 0.0228, 0.0221, 0.0246, 0.0182, 0.0183,
         0.0297, 0.0260, 0.0285, 0.0255, 0.0432, 0.0352, 0.0213, 0.0172, 0.0259,
         0.0182, 0.0273, 0.0261, 0.0205, 0.0254, 0.0206, 0.0205, 0.0175, 0.0153,
         0.0324, 0.0262, 0.0250, 0.0185, 0.0402, 0.0361, 0.0139, 0.0169, 0.0338,
         0.0372, 0.0127, 0.0269, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 16
images/285
(64, 64, 3)
tensor([[0.0302, 0.0274, 0.0091, 0.0135, 0.0232, 0.0163, 0.0484, 0.0192, 0.0180,
         0.0249, 0.0188, 0.0266, 0.0297, 0.0311, 0.0270, 0.0191, 0.0231, 0.0455,
         0.0166, 0.0240, 0.0169, 0.0310, 0.0212, 0.0201, 0.0289, 0.0252, 0.0243,
         0.0307, 0.0394, 0.0271, 0.0223, 0.0390, 0.0195, 0.0234, 0.0272, 0.0359,
         0.0196, 0.0174, 0.0188, 0.0201]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 17
images/250
(64, 64, 3)
tensor([[0.0177, 0.0349, 0.0200, 0.0193, 0.0388, 0.0150, 0.0266, 0.0271, 0.0182,
         0.0231, 0.0199, 0.0214, 0.0458, 0.0427, 0.0210, 0.0129, 0.0238, 0.0483,
         0.0220, 0.0156, 0.0158, 0.0149, 0.0277, 0.0153, 0.0204, 0.0166, 0.0164,
         0.0313, 0.0342, 0.0297, 0.0126, 0.0470, 0.0224, 0.0336, 0.0244, 0.0321,
         0.0356, 0.0189, 0.0167, 0.0201]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 18
images/428
(64, 64, 3)
tensor([[0.0191, 0.0277, 0.0239, 0.0199, 0.0220, 0.0163, 0.0330, 0.0181, 0.0149,
         0.0153, 0.0123, 0.0286, 0.0518, 0.0336, 0.0181, 0.0268, 0.0162, 0.0281,
         0.0144, 0.0240, 0.0205, 0.0274, 0.0284, 0.0244, 0.0182, 0.0159, 0.0386,
         0.0370, 0.0347, 0.0166, 0.0169, 0.0288, 0.0309, 0.0217, 0.0424, 0.0315,
         0.0272, 0.0177, 0.0180, 0.0392]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 19
images/149
(64, 64, 3)
tensor([[0.0388, 0.0194, 0.0172, 0.0213, 0.0420, 0.0235, 0.0384, 0.0150, 0.0176,
         0.0198, 0.0173, 0.0256, 0.0266, 0.0306, 0.0219, 0.0175, 0.0310, 0.0487,
         0.0226, 0.0156, 0.0127, 0.0161, 0.0158, 0.0152, 0.0176, 0.0152, 0.0178,
         0.0398, 0.0454, 0.0268, 0.0153, 0.0318, 0.0318, 0.0263, 0.0218, 0.0311,
         0.0355, 0.0191, 0.0243, 0.0302]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 20
images/35
(64, 64, 3)
tensor([[0.0172, 0.0203, 0.0189, 0.0179, 0.0551, 0.0141, 0.0285, 0.0175, 0.0162,
         0.0185, 0.0208, 0.0329, 0.0551, 0.0210, 0.0282, 0.0173, 0.0165, 0.0406,
         0.0148, 0.0244, 0.0143, 0.0217, 0.0207, 0.0180, 0.0290, 0.0283, 0.0208,
         0.0349, 0.0247, 0.0232, 0.0290, 0.0238, 0.0270, 0.0257, 0.0196, 0.0480,
         0.0322, 0.0248, 0.0150, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 21
images/340
(64, 64, 3)
tensor([[0.0369, 0.0297, 0.0151, 0.0150, 0.0193, 0.0178, 0.0345, 0.0140, 0.0166,
         0.0173, 0.0200, 0.0318, 0.0463, 0.0300, 0.0212, 0.0171, 0.0208, 0.0272,
         0.0193, 0.0220, 0.0162, 0.0224, 0.0169, 0.0218, 0.0178, 0.0298, 0.0261,
         0.0307, 0.0402, 0.0168, 0.0194, 0.0331, 0.0258, 0.0216, 0.0196, 0.0514,
         0.0381, 0.0183, 0.0330, 0.0291]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 22
images/470
(64, 64, 3)
tensor([[0.0364, 0.0268, 0.0140, 0.0162, 0.0308, 0.0188, 0.0340, 0.0201, 0.0158,
         0.0217, 0.0136, 0.0257, 0.0572, 0.0365, 0.0182, 0.0147, 0.0300, 0.0520,
         0.0139, 0.0158, 0.0209, 0.0183, 0.0235, 0.0237, 0.0197, 0.0140, 0.0249,
         0.0293, 0.0537, 0.0172, 0.0161, 0.0210, 0.0227, 0.0334, 0.0318, 0.0352,
         0.0191, 0.0172, 0.0190, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 23
images/302
(64, 64, 3)
tensor([[0.0225, 0.0269, 0.0153, 0.0147, 0.0284, 0.0181, 0.0439, 0.0210, 0.0220,
         0.0296, 0.0239, 0.0255, 0.0425, 0.0327, 0.0333, 0.0200, 0.0317, 0.0238,
         0.0200, 0.0248, 0.0203, 0.0186, 0.0218, 0.0258, 0.0166, 0.0210, 0.0282,
         0.0219, 0.0238, 0.0305, 0.0192, 0.0419, 0.0197, 0.0278, 0.0313, 0.0299,
         0.0220, 0.0195, 0.0208, 0.0188]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 1
Session Number: 24
images/255
(64, 64, 3)
tensor([[0.0269, 0.0256, 0.0102, 0.0152, 0.0459, 0.0203, 0.0301, 0.0124, 0.0237,
         0.0214, 0.0166, 0.0346, 0.0351, 0.0269, 0.0239, 0.0179, 0.0198, 0.0328,
         0.0196, 0.0170, 0.0201, 0.0249, 0.0194, 0.0274, 0.0224, 0.0381, 0.0337,
         0.0497, 0.0345, 0.0295, 0.0214, 0.0428, 0.0210, 0.0187, 0.0272, 0.0257,
         0.0167, 0.0158, 0.0148, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/552
(64, 64, 3)
tensor([[0.0269, 0.0303, 0.0132, 0.0180, 0.0254, 0.0139, 0.0335, 0.0215, 0.0178,
         0.0214, 0.0228, 0.0286, 0.0719, 0.0246, 0.0197, 0.0231, 0.0191, 0.0465,
         0.0156, 0.0150, 0.0188, 0.0222, 0.0349, 0.0243, 0.0220, 0.0198, 0.0219,
         0.0403, 0.0201, 0.0394, 0.0161, 0.0303, 0.0220, 0.0152, 0.0193, 0.0329,
         0.0334, 0.0165, 0.0219, 0.0198]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 26
images/359
(64, 64, 3)
tensor([[0.0265, 0.0312, 0.0167, 0.0155, 0.0335, 0.0129, 0.0291, 0.0174, 0.0160,
         0.0249, 0.0098, 0.0335, 0.0217, 0.0462, 0.0277, 0.0146, 0.0141, 0.0431,
         0.0190, 0.0237, 0.0286, 0.0444, 0.0244, 0.0261, 0.0186, 0.0139, 0.0274,
         0.0438, 0.0398, 0.0235, 0.0183, 0.0225, 0.0265, 0.0248, 0.0238, 0.0226,
         0.0288, 0.0161, 0.0217, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 27
images/362
(64, 64, 3)
tensor([[0.0362, 0.0337, 0.0117, 0.0222, 0.0246, 0.0128, 0.0422, 0.0146, 0.0216,
         0.0207, 0.0209, 0.0257, 0.0442, 0.0292, 0.0245, 0.0280, 0.0374, 0.0330,
         0.0268, 0.0297, 0.0141, 0.0185, 0.0195, 0.0144, 0.0170, 0.0167, 0.0360,
         0.0236, 0.0253, 0.0239, 0.0145, 0.0308, 0.0212, 0.0320, 0.0249, 0.0280,
         0.0262, 0.0201, 0.0264, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 28
images/593
(64, 64, 3)
tensor([[0.0416, 0.0206, 0.0194, 0.0158, 0.0274, 0.0180, 0.0330, 0.0220, 0.0161,
         0.0200, 0.0251, 0.0260, 0.0562, 0.0319, 0.0209, 0.0077, 0.0189, 0.0381,
         0.0275, 0.0228, 0.0112, 0.0183, 0.0282, 0.0268, 0.0112, 0.0161, 0.0245,
         0.0244, 0.0160, 0.0223, 0.0259, 0.0291, 0.0246, 0.0277, 0.0379, 0.0490,
         0.0378, 0.0231, 0.0213, 0.0154]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Session Number: 29
images/547
(64, 64, 3)
tensor([[0.0259, 0.0172, 0.0216, 0.0216, 0.0365, 0.0237, 0.0280, 0.0233, 0.0197,
         0.0258, 0.0230, 0.0270, 0.0347, 0.0278, 0.0218, 0.0208, 0.0177, 0.0415,
         0.0165, 0.0265, 0.0194, 0.0243, 0.0335, 0.0211, 0.0185, 0.0113, 0.0233,
         0.0336, 0.0297, 0.0199, 0.0232, 0.0326, 0.0302, 0.0311, 0.0244, 0.0339,
         0.0307, 0.0194, 0.0173, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 30
images/534
(64, 64, 3)
tensor([[0.0272, 0.0247, 0.0179, 0.0199, 0.0296, 0.0145, 0.0285, 0.0201, 0.0238,
         0.0228, 0.0228, 0.0275, 0.0261, 0.0353, 0.0255, 0.0222, 0.0191, 0.0350,
         0.0220, 0.0213, 0.0284, 0.0292, 0.0176, 0.0179, 0.0259, 0.0254, 0.0208,
         0.0368, 0.0332, 0.0310, 0.0311, 0.0287, 0.0245, 0.0376, 0.0199, 0.0233,
         0.0199, 0.0213, 0.0189, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 31
images/503
(64, 64, 3)
tensor([[0.0319, 0.0227, 0.0245, 0.0166, 0.0229, 0.0191, 0.0273, 0.0212, 0.0183,
         0.0220, 0.0219, 0.0447, 0.0230, 0.0282, 0.0156, 0.0253, 0.0244, 0.0609,
         0.0127, 0.0213, 0.0215, 0.0196, 0.0159, 0.0197, 0.0210, 0.0244, 0.0145,
         0.0365, 0.0396, 0.0298, 0.0144, 0.0296, 0.0281, 0.0191, 0.0194, 0.0252,
         0.0367, 0.0255, 0.0235, 0.0315]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 32
images/17
(64, 64, 3)
tensor([[0.0360, 0.0380, 0.0106, 0.0164, 0.0220, 0.0260, 0.0385, 0.0168, 0.0161,
         0.0161, 0.0255, 0.0269, 0.0336, 0.0258, 0.0370, 0.0206, 0.0277, 0.0260,
         0.0245, 0.0287, 0.0119, 0.0434, 0.0220, 0.0200, 0.0239, 0.0169, 0.0323,
         0.0265, 0.0232, 0.0242, 0.0228, 0.0263, 0.0314, 0.0245, 0.0187, 0.0250,
         0.0205, 0.0252, 0.0264, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 33
images/22
(64, 64, 3)
tensor([[0.0241, 0.0245, 0.0154, 0.0224, 0.0368, 0.0299, 0.0490, 0.0213, 0.0127,
         0.0203, 0.0173, 0.0324, 0.0460, 0.0301, 0.0164, 0.0099, 0.0150, 0.0322,
         0.0264, 0.0185, 0.0220, 0.0269, 0.0216, 0.0148, 0.0340, 0.0194, 0.0228,
         0.0256, 0.0354, 0.0258, 0.0199, 0.0327, 0.0368, 0.0189, 0.0150, 0.0274,
         0.0342, 0.0143, 0.0260, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 34
images/496
(64, 64, 3)
tensor([[0.0321, 0.0270, 0.0219, 0.0180, 0.0277, 0.0153, 0.0304, 0.0169, 0.0183,
         0.0178, 0.0191, 0.0274, 0.0277, 0.0277, 0.0230, 0.0178, 0.0305, 0.0531,
         0.0153, 0.0172, 0.0177, 0.0293, 0.0170, 0.0238, 0.0324, 0.0174, 0.0336,
         0.0302, 0.0255, 0.0321, 0.0133, 0.0276, 0.0339, 0.0275, 0.0195, 0.0503,
         0.0167, 0.0169, 0.0281, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 35
images/165
(64, 64, 3)
tensor([[0.0310, 0.0319, 0.0205, 0.0171, 0.0171, 0.0206, 0.0231, 0.0240, 0.0201,
         0.0195, 0.0154, 0.0305, 0.0501, 0.0423, 0.0337, 0.0230, 0.0146, 0.0327,
         0.0183, 0.0200, 0.0189, 0.0211, 0.0152, 0.0233, 0.0223, 0.0136, 0.0277,
         0.0239, 0.0379, 0.0312, 0.0176, 0.0253, 0.0265, 0.0214, 0.0240, 0.0339,
         0.0271, 0.0268, 0.0211, 0.0357]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 36
images/443
(64, 64, 3)
tensor([[0.0324, 0.0205, 0.0198, 0.0231, 0.0274, 0.0187, 0.0437, 0.0258, 0.0187,
         0.0114, 0.0151, 0.0249, 0.0321, 0.0375, 0.0283, 0.0150, 0.0182, 0.0389,
         0.0187, 0.0201, 0.0182, 0.0195, 0.0173, 0.0175, 0.0274, 0.0187, 0.0178,
         0.0237, 0.0302, 0.0219, 0.0257, 0.0373, 0.0227, 0.0206, 0.0248, 0.0361,
         0.0406, 0.0213, 0.0303, 0.0381]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 37
images/377
(64, 64, 3)
tensor([[0.0197, 0.0410, 0.0199, 0.0189, 0.0349, 0.0215, 0.0315, 0.0108, 0.0138,
         0.0249, 0.0155, 0.0445, 0.0447, 0.0357, 0.0266, 0.0209, 0.0237, 0.0355,
         0.0286, 0.0202, 0.0273, 0.0185, 0.0164, 0.0210, 0.0181, 0.0220, 0.0246,
         0.0338, 0.0295, 0.0351, 0.0142, 0.0216, 0.0220, 0.0238, 0.0240, 0.0324,
         0.0279, 0.0166, 0.0135, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 38
images/253
(64, 64, 3)
tensor([[0.0269, 0.0254, 0.0198, 0.0120, 0.0387, 0.0160, 0.0288, 0.0191, 0.0114,
         0.0155, 0.0160, 0.0396, 0.0290, 0.0260, 0.0289, 0.0148, 0.0205, 0.0449,
         0.0204, 0.0205, 0.0193, 0.0294, 0.0193, 0.0333, 0.0173, 0.0194, 0.0229,
         0.0410, 0.0384, 0.0172, 0.0256, 0.0418, 0.0246, 0.0171, 0.0275, 0.0542,
         0.0246, 0.0169, 0.0148, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 39
images/436
(64, 64, 3)
tensor([[0.0316, 0.0189, 0.0189, 0.0212, 0.0397, 0.0248, 0.0307, 0.0242, 0.0153,
         0.0244, 0.0150, 0.0253, 0.0508, 0.0510, 0.0221, 0.0149, 0.0167, 0.0449,
         0.0183, 0.0202, 0.0197, 0.0220, 0.0178, 0.0211, 0.0231, 0.0190, 0.0210,
         0.0474, 0.0310, 0.0277, 0.0173, 0.0302, 0.0259, 0.0162, 0.0238, 0.0209,
         0.0228, 0.0182, 0.0225, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 40
images/56
(64, 64, 3)
tensor([[0.0372, 0.0273, 0.0151, 0.0206, 0.0356, 0.0289, 0.0299, 0.0180, 0.0159,
         0.0184, 0.0174, 0.0200, 0.0357, 0.0272, 0.0218, 0.0235, 0.0233, 0.0429,
         0.0166, 0.0214, 0.0211, 0.0365, 0.0235, 0.0231, 0.0272, 0.0305, 0.0216,
         0.0232, 0.0265, 0.0239, 0.0209, 0.0349, 0.0320, 0.0153, 0.0165, 0.0255,
         0.0298, 0.0201, 0.0281, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 41
images/115
(64, 64, 3)
tensor([[0.0266, 0.0220, 0.0159, 0.0226, 0.0207, 0.0268, 0.0290, 0.0184, 0.0258,
         0.0154, 0.0166, 0.0353, 0.0395, 0.0308, 0.0227, 0.0312, 0.0203, 0.0419,
         0.0229, 0.0086, 0.0167, 0.0292, 0.0212, 0.0195, 0.0185, 0.0241, 0.0198,
         0.0233, 0.0358, 0.0363, 0.0223, 0.0219, 0.0252, 0.0192, 0.0204, 0.0403,
         0.0366, 0.0242, 0.0282, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 42
images/531
(64, 64, 3)
tensor([[0.0286, 0.0285, 0.0240, 0.0165, 0.0341, 0.0170, 0.0227, 0.0236, 0.0242,
         0.0217, 0.0156, 0.0372, 0.0414, 0.0224, 0.0237, 0.0280, 0.0157, 0.0374,
         0.0200, 0.0181, 0.0221, 0.0211, 0.0250, 0.0190, 0.0180, 0.0163, 0.0412,
         0.0419, 0.0190, 0.0221, 0.0190, 0.0303, 0.0216, 0.0301, 0.0253, 0.0299,
         0.0275, 0.0174, 0.0203, 0.0324]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/57
(64, 64, 3)
tensor([[0.0360, 0.0157, 0.0192, 0.0155, 0.0359, 0.0225, 0.0374, 0.0205, 0.0147,
         0.0360, 0.0271, 0.0247, 0.0391, 0.0316, 0.0226, 0.0149, 0.0178, 0.0559,
         0.0221, 0.0276, 0.0116, 0.0234, 0.0232, 0.0172, 0.0163, 0.0212, 0.0213,
         0.0331, 0.0272, 0.0208, 0.0257, 0.0258, 0.0177, 0.0238, 0.0208, 0.0256,
         0.0281, 0.0146, 0.0426, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/62
(64, 64, 3)
tensor([[0.0188, 0.0407, 0.0156, 0.0204, 0.0299, 0.0330, 0.0338, 0.0173, 0.0206,
         0.0185, 0.0168, 0.0246, 0.0467, 0.0299, 0.0325, 0.0213, 0.0184, 0.0452,
         0.0185, 0.0219, 0.0163, 0.0244, 0.0238, 0.0207, 0.0256, 0.0129, 0.0313,
         0.0319, 0.0330, 0.0167, 0.0201, 0.0291, 0.0216, 0.0330, 0.0261, 0.0204,
         0.0149, 0.0286, 0.0169, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 45
images/282
(64, 64, 3)
tensor([[0.0370, 0.0207, 0.0160, 0.0175, 0.0208, 0.0164, 0.0176, 0.0240, 0.0186,
         0.0135, 0.0166, 0.0592, 0.0394, 0.0290, 0.0319, 0.0238, 0.0201, 0.0447,
         0.0193, 0.0163, 0.0208, 0.0187, 0.0168, 0.0234, 0.0231, 0.0168, 0.0395,
         0.0242, 0.0481, 0.0190, 0.0182, 0.0287, 0.0268, 0.0322, 0.0147, 0.0416,
         0.0198, 0.0178, 0.0240, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 46
images/387
(64, 64, 3)
tensor([[0.0280, 0.0241, 0.0239, 0.0116, 0.0217, 0.0141, 0.0414, 0.0207, 0.0152,
         0.0180, 0.0204, 0.0310, 0.0489, 0.0282, 0.0306, 0.0138, 0.0183, 0.0238,
         0.0206, 0.0377, 0.0257, 0.0257, 0.0236, 0.0239, 0.0185, 0.0164, 0.0280,
         0.0353, 0.0320, 0.0208, 0.0176, 0.0277, 0.0472, 0.0295, 0.0199, 0.0273,
         0.0244, 0.0229, 0.0167, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 1
Session Number: 47
images/161
(64, 64, 3)
tensor([[0.0353, 0.0328, 0.0214, 0.0118, 0.0245, 0.0240, 0.0286, 0.0194, 0.0195,
         0.0258, 0.0195, 0.0279, 0.0405, 0.0366, 0.0182, 0.0219, 0.0207, 0.0406,
         0.0113, 0.0137, 0.0149, 0.0222, 0.0205, 0.0175, 0.0220, 0.0236, 0.0168,
         0.0345, 0.0354, 0.0234, 0.0150, 0.0269, 0.0386, 0.0252, 0.0249, 0.0382,
         0.0309, 0.0222, 0.0160, 0.0377]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 1
Session Number: 48
images/66
(64, 64, 3)
tensor([[0.0337, 0.0241, 0.0235, 0.0127, 0.0375, 0.0220, 0.0224, 0.0173, 0.0210,
         0.0152, 0.0159, 0.0440, 0.0290, 0.0318, 0.0259, 0.0271, 0.0187, 0.0399,
         0.0159, 0.0241, 0.0130, 0.0304, 0.0173, 0.0274, 0.0188, 0.0216, 0.0248,
         0.0302, 0.0373, 0.0270, 0.0281, 0.0260, 0.0173, 0.0241, 0.0303, 0.0283,
         0.0329, 0.0137, 0.0208, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 49
images/159
(64, 64, 3)
tensor([[0.0222, 0.0217, 0.0182, 0.0187, 0.0325, 0.0250, 0.0447, 0.0189, 0.0187,
         0.0228, 0.0133, 0.0356, 0.0570, 0.0428, 0.0204, 0.0219, 0.0214, 0.0338,
         0.0318, 0.0273, 0.0226, 0.0236, 0.0212, 0.0148, 0.0209, 0.0140, 0.0280,
         0.0330, 0.0341, 0.0141, 0.0143, 0.0169, 0.0297, 0.0231, 0.0316, 0.0296,
         0.0202, 0.0205, 0.0188, 0.0204]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 50
images/480
(64, 64, 3)
tensor([[0.0293, 0.0275, 0.0223, 0.0100, 0.0357, 0.0140, 0.0343, 0.0160, 0.0194,
         0.0161, 0.0193, 0.0279, 0.0396, 0.0343, 0.0364, 0.0169, 0.0276, 0.0462,
         0.0199, 0.0147, 0.0163, 0.0355, 0.0181, 0.0159, 0.0172, 0.0139, 0.0233,
         0.0262, 0.0382, 0.0256, 0.0137, 0.0377, 0.0398, 0.0267, 0.0191, 0.0230,
         0.0233, 0.0201, 0.0316, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 51
images/223
(64, 64, 3)
tensor([[0.0364, 0.0340, 0.0224, 0.0199, 0.0281, 0.0141, 0.0262, 0.0144, 0.0312,
         0.0169, 0.0156, 0.0328, 0.0318, 0.0323, 0.0242, 0.0147, 0.0189, 0.0310,
         0.0158, 0.0203, 0.0219, 0.0336, 0.0168, 0.0219, 0.0121, 0.0200, 0.0334,
         0.0232, 0.0423, 0.0162, 0.0184, 0.0252, 0.0301, 0.0459, 0.0226, 0.0238,
         0.0330, 0.0203, 0.0220, 0.0364]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 1
Session Number: 52
images/296
(64, 64, 3)
tensor([[0.0356, 0.0179, 0.0311, 0.0137, 0.0465, 0.0224, 0.0251, 0.0266, 0.0155,
         0.0142, 0.0144, 0.0188, 0.0413, 0.0317, 0.0226, 0.0205, 0.0195, 0.0336,
         0.0217, 0.0165, 0.0198, 0.0232, 0.0308, 0.0161, 0.0277, 0.0213, 0.0181,
         0.0237, 0.0335, 0.0295, 0.0309, 0.0242, 0.0199, 0.0281, 0.0330, 0.0241,
         0.0289, 0.0191, 0.0336, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 53
images/573
(64, 64, 3)
tensor([[0.0347, 0.0347, 0.0110, 0.0134, 0.0324, 0.0177, 0.0279, 0.0142, 0.0229,
         0.0354, 0.0175, 0.0340, 0.0260, 0.0368, 0.0254, 0.0189, 0.0233, 0.0376,
         0.0155, 0.0173, 0.0178, 0.0367, 0.0185, 0.0243, 0.0204, 0.0171, 0.0250,
         0.0288, 0.0308, 0.0256, 0.0092, 0.0284, 0.0353, 0.0366, 0.0251, 0.0209,
         0.0339, 0.0169, 0.0153, 0.0371]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 54
images/106
(64, 64, 3)
tensor([[0.0202, 0.0265, 0.0248, 0.0207, 0.0309, 0.0104, 0.0449, 0.0323, 0.0217,
         0.0104, 0.0232, 0.0206, 0.0381, 0.0321, 0.0293, 0.0185, 0.0190, 0.0432,
         0.0233, 0.0171, 0.0115, 0.0273, 0.0171, 0.0142, 0.0260, 0.0172, 0.0232,
         0.0322, 0.0300, 0.0315, 0.0270, 0.0252, 0.0332, 0.0187, 0.0228, 0.0372,
         0.0231, 0.0176, 0.0280, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 55
images/379
(64, 64, 3)
tensor([[0.0206, 0.0231, 0.0219, 0.0203, 0.0396, 0.0160, 0.0462, 0.0179, 0.0191,
         0.0194, 0.0146, 0.0376, 0.0678, 0.0244, 0.0236, 0.0149, 0.0236, 0.0504,
         0.0233, 0.0225, 0.0191, 0.0219, 0.0192, 0.0150, 0.0213, 0.0153, 0.0355,
         0.0213, 0.0302, 0.0204, 0.0226, 0.0202, 0.0378, 0.0180, 0.0288, 0.0225,
         0.0246, 0.0284, 0.0131, 0.0178]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 56
images/88
(64, 64, 3)
tensor([[0.0279, 0.0421, 0.0158, 0.0228, 0.0287, 0.0190, 0.0369, 0.0108, 0.0162,
         0.0271, 0.0160, 0.0284, 0.0574, 0.0416, 0.0296, 0.0202, 0.0260, 0.0456,
         0.0172, 0.0177, 0.0158, 0.0312, 0.0220, 0.0203, 0.0167, 0.0170, 0.0289,
         0.0317, 0.0322, 0.0219, 0.0119, 0.0258, 0.0237, 0.0165, 0.0239, 0.0252,
         0.0346, 0.0174, 0.0146, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 57
images/381
(64, 64, 3)
tensor([[0.0218, 0.0372, 0.0285, 0.0166, 0.0227, 0.0221, 0.0288, 0.0247, 0.0123,
         0.0245, 0.0304, 0.0214, 0.0458, 0.0195, 0.0276, 0.0183, 0.0279, 0.0479,
         0.0219, 0.0214, 0.0169, 0.0208, 0.0227, 0.0217, 0.0265, 0.0183, 0.0215,
         0.0237, 0.0415, 0.0189, 0.0183, 0.0238, 0.0326, 0.0314, 0.0196, 0.0365,
         0.0271, 0.0190, 0.0155, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 58
images/571
(64, 64, 3)
tensor([[0.0395, 0.0260, 0.0160, 0.0155, 0.0453, 0.0183, 0.0471, 0.0138, 0.0129,
         0.0159, 0.0139, 0.0332, 0.0512, 0.0301, 0.0252, 0.0145, 0.0191, 0.0640,
         0.0169, 0.0223, 0.0174, 0.0192, 0.0280, 0.0173, 0.0175, 0.0299, 0.0295,
         0.0347, 0.0376, 0.0272, 0.0205, 0.0192, 0.0186, 0.0123, 0.0270, 0.0172,
         0.0229, 0.0183, 0.0232, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 59
images/123
(64, 64, 3)
tensor([[0.0273, 0.0204, 0.0214, 0.0250, 0.0241, 0.0142, 0.0347, 0.0207, 0.0158,
         0.0155, 0.0215, 0.0259, 0.0251, 0.0353, 0.0286, 0.0170, 0.0182, 0.0440,
         0.0221, 0.0238, 0.0191, 0.0297, 0.0168, 0.0294, 0.0220, 0.0228, 0.0171,
         0.0267, 0.0424, 0.0248, 0.0219, 0.0241, 0.0315, 0.0281, 0.0314, 0.0260,
         0.0235, 0.0168, 0.0418, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 60
images/287
(64, 64, 3)
tensor([[0.0281, 0.0256, 0.0192, 0.0301, 0.0212, 0.0238, 0.0267, 0.0216, 0.0205,
         0.0206, 0.0230, 0.0302, 0.0431, 0.0325, 0.0254, 0.0149, 0.0124, 0.0284,
         0.0183, 0.0182, 0.0195, 0.0336, 0.0231, 0.0265, 0.0221, 0.0191, 0.0183,
         0.0495, 0.0331, 0.0210, 0.0153, 0.0311, 0.0242, 0.0272, 0.0234, 0.0196,
         0.0326, 0.0153, 0.0272, 0.0342]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 61
images/238
(64, 64, 3)
tensor([[0.0319, 0.0287, 0.0193, 0.0171, 0.0429, 0.0143, 0.0343, 0.0313, 0.0265,
         0.0339, 0.0248, 0.0292, 0.0374, 0.0229, 0.0250, 0.0158, 0.0295, 0.0406,
         0.0186, 0.0165, 0.0147, 0.0208, 0.0175, 0.0218, 0.0282, 0.0142, 0.0190,
         0.0195, 0.0311, 0.0208, 0.0154, 0.0298, 0.0383, 0.0205, 0.0223, 0.0245,
         0.0292, 0.0165, 0.0313, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 62
images/382
(64, 64, 3)
tensor([[0.0301, 0.0304, 0.0223, 0.0185, 0.0277, 0.0198, 0.0294, 0.0127, 0.0156,
         0.0237, 0.0219, 0.0297, 0.0372, 0.0321, 0.0331, 0.0176, 0.0209, 0.0309,
         0.0200, 0.0267, 0.0232, 0.0234, 0.0239, 0.0221, 0.0311, 0.0206, 0.0197,
         0.0300, 0.0261, 0.0199, 0.0134, 0.0251, 0.0268, 0.0227, 0.0226, 0.0532,
         0.0279, 0.0228, 0.0208, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 63
images/319
(64, 64, 3)
tensor([[0.0256, 0.0348, 0.0135, 0.0189, 0.0249, 0.0224, 0.0374, 0.0116, 0.0245,
         0.0173, 0.0176, 0.0358, 0.0370, 0.0357, 0.0248, 0.0199, 0.0144, 0.0361,
         0.0249, 0.0252, 0.0133, 0.0360, 0.0180, 0.0207, 0.0312, 0.0155, 0.0293,
         0.0497, 0.0300, 0.0217, 0.0229, 0.0235, 0.0214, 0.0167, 0.0315, 0.0242,
         0.0174, 0.0198, 0.0195, 0.0354]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 64
images/267
(64, 64, 3)
tensor([[0.0226, 0.0304, 0.0212, 0.0138, 0.0305, 0.0209, 0.0311, 0.0212, 0.0190,
         0.0241, 0.0212, 0.0290, 0.0349, 0.0234, 0.0234, 0.0166, 0.0282, 0.0286,
         0.0212, 0.0192, 0.0110, 0.0325, 0.0266, 0.0205, 0.0274, 0.0197, 0.0219,
         0.0296, 0.0344, 0.0428, 0.0123, 0.0354, 0.0296, 0.0197, 0.0233, 0.0398,
         0.0216, 0.0192, 0.0177, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 65
images/594
(64, 64, 3)
tensor([[0.0255, 0.0260, 0.0139, 0.0119, 0.0374, 0.0387, 0.0263, 0.0194, 0.0112,
         0.0194, 0.0209, 0.0303, 0.0433, 0.0282, 0.0263, 0.0184, 0.0291, 0.0263,
         0.0254, 0.0198, 0.0226, 0.0329, 0.0169, 0.0345, 0.0210, 0.0182, 0.0361,
         0.0290, 0.0253, 0.0229, 0.0232, 0.0285, 0.0266, 0.0219, 0.0224, 0.0295,
         0.0297, 0.0241, 0.0171, 0.0195]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 66
images/38
(64, 64, 3)
tensor([[0.0245, 0.0402, 0.0203, 0.0272, 0.0265, 0.0114, 0.0219, 0.0106, 0.0203,
         0.0278, 0.0170, 0.0235, 0.0260, 0.0238, 0.0291, 0.0193, 0.0176, 0.0410,
         0.0170, 0.0301, 0.0232, 0.0292, 0.0222, 0.0163, 0.0197, 0.0223, 0.0327,
         0.0304, 0.0376, 0.0264, 0.0246, 0.0335, 0.0287, 0.0268, 0.0117, 0.0409,
         0.0309, 0.0181, 0.0214, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 67
images/584
(64, 64, 3)
tensor([[0.0285, 0.0253, 0.0199, 0.0166, 0.0231, 0.0295, 0.0535, 0.0226, 0.0132,
         0.0235, 0.0215, 0.0243, 0.0512, 0.0330, 0.0234, 0.0128, 0.0168, 0.0331,
         0.0164, 0.0208, 0.0202, 0.0269, 0.0226, 0.0310, 0.0233, 0.0209, 0.0197,
         0.0245, 0.0291, 0.0226, 0.0234, 0.0436, 0.0218, 0.0193, 0.0228, 0.0279,
         0.0268, 0.0180, 0.0185, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/475
(64, 64, 3)
tensor([[0.0168, 0.0239, 0.0180, 0.0195, 0.0394, 0.0175, 0.0480, 0.0271, 0.0234,
         0.0238, 0.0136, 0.0209, 0.0501, 0.0330, 0.0187, 0.0201, 0.0260, 0.0326,
         0.0238, 0.0182, 0.0184, 0.0204, 0.0176, 0.0170, 0.0250, 0.0154, 0.0244,
         0.0325, 0.0415, 0.0258, 0.0153, 0.0265, 0.0287, 0.0193, 0.0187, 0.0183,
         0.0398, 0.0192, 0.0237, 0.0377]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 69
images/109
(64, 64, 3)
tensor([[0.0229, 0.0218, 0.0150, 0.0117, 0.0338, 0.0179, 0.0383, 0.0176, 0.0322,
         0.0258, 0.0316, 0.0335, 0.0274, 0.0480, 0.0302, 0.0181, 0.0237, 0.0351,
         0.0183, 0.0188, 0.0139, 0.0276, 0.0169, 0.0271, 0.0238, 0.0156, 0.0218,
         0.0286, 0.0372, 0.0282, 0.0192, 0.0383, 0.0369, 0.0139, 0.0250, 0.0315,
         0.0172, 0.0162, 0.0226, 0.0166]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 70
images/164
(64, 64, 3)
tensor([[0.0258, 0.0474, 0.0165, 0.0300, 0.0511, 0.0131, 0.0401, 0.0120, 0.0205,
         0.0155, 0.0225, 0.0373, 0.0480, 0.0365, 0.0308, 0.0171, 0.0165, 0.0259,
         0.0165, 0.0231, 0.0203, 0.0260, 0.0217, 0.0196, 0.0194, 0.0192, 0.0284,
         0.0221, 0.0195, 0.0319, 0.0221, 0.0169, 0.0248, 0.0178, 0.0206, 0.0392,
         0.0206, 0.0247, 0.0194, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 71
images/468
(64, 64, 3)
tensor([[0.0252, 0.0257, 0.0272, 0.0174, 0.0376, 0.0228, 0.0291, 0.0226, 0.0159,
         0.0269, 0.0163, 0.0292, 0.0331, 0.0331, 0.0212, 0.0134, 0.0298, 0.0230,
         0.0144, 0.0203, 0.0162, 0.0263, 0.0165, 0.0225, 0.0205, 0.0198, 0.0214,
         0.0522, 0.0377, 0.0182, 0.0155, 0.0283, 0.0398, 0.0268, 0.0219, 0.0257,
         0.0329, 0.0212, 0.0310, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 72
images/291
(64, 64, 3)
tensor([[0.0295, 0.0291, 0.0240, 0.0171, 0.0425, 0.0222, 0.0304, 0.0241, 0.0203,
         0.0177, 0.0202, 0.0312, 0.0409, 0.0316, 0.0218, 0.0154, 0.0193, 0.0302,
         0.0195, 0.0174, 0.0233, 0.0184, 0.0191, 0.0233, 0.0343, 0.0146, 0.0252,
         0.0370, 0.0349, 0.0308, 0.0154, 0.0244, 0.0255, 0.0319, 0.0265, 0.0328,
         0.0260, 0.0166, 0.0133, 0.0223]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 73
images/591
(64, 64, 3)
tensor([[0.0278, 0.0274, 0.0207, 0.0189, 0.0349, 0.0144, 0.0367, 0.0185, 0.0164,
         0.0222, 0.0290, 0.0272, 0.0276, 0.0186, 0.0288, 0.0194, 0.0162, 0.0410,
         0.0274, 0.0209, 0.0137, 0.0212, 0.0203, 0.0148, 0.0202, 0.0236, 0.0191,
         0.0336, 0.0362, 0.0312, 0.0156, 0.0328, 0.0380, 0.0279, 0.0219, 0.0320,
         0.0353, 0.0236, 0.0239, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 74
images/15
(64, 64, 3)
tensor([[0.0391, 0.0251, 0.0120, 0.0198, 0.0309, 0.0270, 0.0314, 0.0126, 0.0153,
         0.0237, 0.0216, 0.0248, 0.0489, 0.0392, 0.0293, 0.0187, 0.0224, 0.0490,
         0.0191, 0.0156, 0.0153, 0.0173, 0.0133, 0.0198, 0.0245, 0.0209, 0.0266,
         0.0296, 0.0392, 0.0190, 0.0171, 0.0298, 0.0270, 0.0245, 0.0249, 0.0236,
         0.0249, 0.0190, 0.0244, 0.0338]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 75
images/537
(64, 64, 3)
tensor([[0.0211, 0.0365, 0.0141, 0.0262, 0.0348, 0.0211, 0.0415, 0.0189, 0.0157,
         0.0308, 0.0193, 0.0187, 0.0293, 0.0317, 0.0194, 0.0244, 0.0234, 0.0186,
         0.0292, 0.0142, 0.0213, 0.0324, 0.0143, 0.0265, 0.0320, 0.0153, 0.0317,
         0.0280, 0.0408, 0.0274, 0.0150, 0.0333, 0.0294, 0.0244, 0.0159, 0.0282,
         0.0232, 0.0214, 0.0290, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 76
images/106
(64, 64, 3)
tensor([[0.0178, 0.0226, 0.0223, 0.0136, 0.0422, 0.0183, 0.0328, 0.0198, 0.0233,
         0.0160, 0.0218, 0.0435, 0.0372, 0.0277, 0.0395, 0.0253, 0.0239, 0.0265,
         0.0248, 0.0176, 0.0157, 0.0245, 0.0209, 0.0206, 0.0239, 0.0166, 0.0178,
         0.0340, 0.0420, 0.0298, 0.0172, 0.0276, 0.0233, 0.0210, 0.0266, 0.0365,
         0.0200, 0.0179, 0.0209, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 77
images/193
(64, 64, 3)
tensor([[0.0236, 0.0205, 0.0284, 0.0220, 0.0365, 0.0203, 0.0275, 0.0172, 0.0208,
         0.0120, 0.0144, 0.0263, 0.0271, 0.0420, 0.0236, 0.0151, 0.0257, 0.0595,
         0.0210, 0.0292, 0.0260, 0.0223, 0.0239, 0.0163, 0.0293, 0.0173, 0.0234,
         0.0192, 0.0367, 0.0358, 0.0183, 0.0253, 0.0228, 0.0341, 0.0173, 0.0362,
         0.0181, 0.0169, 0.0194, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 78
images/551
(64, 64, 3)
tensor([[0.0306, 0.0430, 0.0125, 0.0245, 0.0202, 0.0240, 0.0367, 0.0153, 0.0188,
         0.0261, 0.0222, 0.0416, 0.0494, 0.0238, 0.0248, 0.0164, 0.0255, 0.0275,
         0.0210, 0.0173, 0.0140, 0.0156, 0.0185, 0.0225, 0.0145, 0.0197, 0.0270,
         0.0246, 0.0374, 0.0219, 0.0137, 0.0212, 0.0178, 0.0153, 0.0232, 0.0444,
         0.0454, 0.0230, 0.0255, 0.0331]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/18
(64, 64, 3)
tensor([[0.0358, 0.0227, 0.0183, 0.0232, 0.0404, 0.0193, 0.0399, 0.0257, 0.0166,
         0.0238, 0.0209, 0.0391, 0.0358, 0.0323, 0.0204, 0.0222, 0.0169, 0.0277,
         0.0219, 0.0203, 0.0149, 0.0267, 0.0197, 0.0252, 0.0272, 0.0159, 0.0254,
         0.0443, 0.0218, 0.0186, 0.0166, 0.0192, 0.0229, 0.0219, 0.0290, 0.0298,
         0.0185, 0.0290, 0.0238, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 80
images/121
(64, 64, 3)
tensor([[0.0283, 0.0281, 0.0166, 0.0187, 0.0347, 0.0163, 0.0315, 0.0194, 0.0227,
         0.0193, 0.0190, 0.0291, 0.0320, 0.0218, 0.0340, 0.0260, 0.0275, 0.0294,
         0.0309, 0.0177, 0.0167, 0.0230, 0.0185, 0.0195, 0.0194, 0.0232, 0.0219,
         0.0334, 0.0334, 0.0224, 0.0172, 0.0304, 0.0271, 0.0338, 0.0272, 0.0256,
         0.0224, 0.0234, 0.0230, 0.0354]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 81
images/338
(64, 64, 3)
tensor([[0.0272, 0.0150, 0.0247, 0.0208, 0.0232, 0.0201, 0.0316, 0.0210, 0.0243,
         0.0179, 0.0172, 0.0390, 0.0305, 0.0200, 0.0266, 0.0235, 0.0106, 0.0488,
         0.0228, 0.0323, 0.0148, 0.0311, 0.0215, 0.0264, 0.0164, 0.0266, 0.0318,
         0.0324, 0.0295, 0.0232, 0.0255, 0.0481, 0.0252, 0.0144, 0.0196, 0.0221,
         0.0254, 0.0233, 0.0220, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 82
images/399
(64, 64, 3)
tensor([[0.0359, 0.0272, 0.0257, 0.0169, 0.0301, 0.0248, 0.0220, 0.0174, 0.0128,
         0.0216, 0.0219, 0.0335, 0.0380, 0.0289, 0.0218, 0.0181, 0.0207, 0.0342,
         0.0188, 0.0156, 0.0130, 0.0273, 0.0341, 0.0250, 0.0162, 0.0304, 0.0229,
         0.0270, 0.0392, 0.0340, 0.0149, 0.0261, 0.0272, 0.0213, 0.0242, 0.0244,
         0.0484, 0.0246, 0.0105, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 1
Session Number: 83
images/385
(64, 64, 3)
tensor([[0.0285, 0.0378, 0.0188, 0.0169, 0.0365, 0.0196, 0.0275, 0.0111, 0.0170,
         0.0180, 0.0189, 0.0330, 0.0763, 0.0174, 0.0349, 0.0208, 0.0268, 0.0229,
         0.0133, 0.0211, 0.0162, 0.0216, 0.0133, 0.0225, 0.0227, 0.0251, 0.0265,
         0.0379, 0.0307, 0.0292, 0.0164, 0.0208, 0.0217, 0.0339, 0.0304, 0.0263,
         0.0318, 0.0153, 0.0193, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 84
images/423
(64, 64, 3)
tensor([[0.0374, 0.0210, 0.0185, 0.0215, 0.0293, 0.0288, 0.0321, 0.0182, 0.0186,
         0.0212, 0.0263, 0.0322, 0.0189, 0.0238, 0.0233, 0.0250, 0.0212, 0.0296,
         0.0239, 0.0205, 0.0225, 0.0286, 0.0272, 0.0201, 0.0230, 0.0291, 0.0185,
         0.0281, 0.0322, 0.0252, 0.0192, 0.0290, 0.0191, 0.0315, 0.0196, 0.0351,
         0.0311, 0.0151, 0.0295, 0.0249]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 85
images/470
(64, 64, 3)
tensor([[0.0213, 0.0324, 0.0115, 0.0244, 0.0267, 0.0229, 0.0229, 0.0151, 0.0212,
         0.0202, 0.0290, 0.0212, 0.0451, 0.0360, 0.0274, 0.0322, 0.0236, 0.0443,
         0.0236, 0.0186, 0.0202, 0.0158, 0.0170, 0.0127, 0.0153, 0.0161, 0.0288,
         0.0450, 0.0320, 0.0214, 0.0139, 0.0224, 0.0299, 0.0260, 0.0311, 0.0305,
         0.0191, 0.0190, 0.0160, 0.0482]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 86
images/322
(64, 64, 3)
tensor([[0.0304, 0.0335, 0.0122, 0.0185, 0.0182, 0.0160, 0.0296, 0.0211, 0.0147,
         0.0198, 0.0156, 0.0294, 0.0446, 0.0307, 0.0223, 0.0192, 0.0235, 0.0344,
         0.0150, 0.0145, 0.0209, 0.0374, 0.0191, 0.0213, 0.0195, 0.0186, 0.0304,
         0.0426, 0.0408, 0.0182, 0.0170, 0.0292, 0.0420, 0.0319, 0.0308, 0.0279,
         0.0326, 0.0193, 0.0159, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 87
images/548
(64, 64, 3)
tensor([[0.0265, 0.0302, 0.0148, 0.0200, 0.0252, 0.0189, 0.0470, 0.0186, 0.0183,
         0.0167, 0.0227, 0.0423, 0.0313, 0.0262, 0.0223, 0.0279, 0.0152, 0.0389,
         0.0178, 0.0287, 0.0136, 0.0391, 0.0185, 0.0227, 0.0188, 0.0215, 0.0220,
         0.0277, 0.0368, 0.0319, 0.0177, 0.0309, 0.0221, 0.0216, 0.0171, 0.0216,
         0.0243, 0.0308, 0.0330, 0.0188]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 88
images/64
(64, 64, 3)
tensor([[0.0301, 0.0251, 0.0222, 0.0220, 0.0384, 0.0228, 0.0400, 0.0189, 0.0169,
         0.0206, 0.0353, 0.0254, 0.0379, 0.0371, 0.0213, 0.0173, 0.0168, 0.0408,
         0.0193, 0.0249, 0.0187, 0.0187, 0.0199, 0.0177, 0.0188, 0.0230, 0.0170,
         0.0192, 0.0359, 0.0227, 0.0246, 0.0330, 0.0169, 0.0201, 0.0229, 0.0387,
         0.0243, 0.0234, 0.0237, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 89
images/545
(64, 64, 3)
tensor([[0.0184, 0.0277, 0.0182, 0.0130, 0.0425, 0.0219, 0.0273, 0.0201, 0.0183,
         0.0165, 0.0132, 0.0293, 0.0578, 0.0264, 0.0270, 0.0184, 0.0220, 0.0705,
         0.0253, 0.0170, 0.0157, 0.0116, 0.0201, 0.0219, 0.0253, 0.0210, 0.0257,
         0.0359, 0.0200, 0.0199, 0.0134, 0.0351, 0.0211, 0.0254, 0.0210, 0.0388,
         0.0305, 0.0205, 0.0235, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 90
images/65
(64, 64, 3)
tensor([[0.0250, 0.0196, 0.0280, 0.0219, 0.0352, 0.0288, 0.0300, 0.0181, 0.0182,
         0.0236, 0.0188, 0.0298, 0.0336, 0.0295, 0.0237, 0.0233, 0.0198, 0.0287,
         0.0176, 0.0173, 0.0159, 0.0308, 0.0310, 0.0265, 0.0244, 0.0201, 0.0249,
         0.0333, 0.0374, 0.0331, 0.0158, 0.0190, 0.0226, 0.0206, 0.0272, 0.0224,
         0.0313, 0.0236, 0.0271, 0.0223]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 91
images/209
(64, 64, 3)
tensor([[0.0264, 0.0309, 0.0245, 0.0183, 0.0191, 0.0259, 0.0336, 0.0178, 0.0137,
         0.0241, 0.0216, 0.0452, 0.0431, 0.0273, 0.0189, 0.0136, 0.0202, 0.0279,
         0.0191, 0.0261, 0.0158, 0.0229, 0.0280, 0.0184, 0.0198, 0.0185, 0.0240,
         0.0377, 0.0317, 0.0231, 0.0202, 0.0490, 0.0242, 0.0309, 0.0206, 0.0414,
         0.0166, 0.0128, 0.0177, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 92
images/362
(64, 64, 3)
tensor([[0.0343, 0.0284, 0.0142, 0.0171, 0.0283, 0.0199, 0.0289, 0.0246, 0.0227,
         0.0263, 0.0184, 0.0303, 0.0354, 0.0231, 0.0224, 0.0179, 0.0257, 0.0242,
         0.0144, 0.0262, 0.0147, 0.0246, 0.0202, 0.0236, 0.0200, 0.0147, 0.0215,
         0.0339, 0.0570, 0.0227, 0.0230, 0.0397, 0.0262, 0.0348, 0.0227, 0.0200,
         0.0198, 0.0226, 0.0332, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 93
images/205
(64, 64, 3)
tensor([[0.0252, 0.0278, 0.0128, 0.0235, 0.0363, 0.0236, 0.0286, 0.0173, 0.0253,
         0.0209, 0.0201, 0.0327, 0.0352, 0.0304, 0.0312, 0.0206, 0.0181, 0.0403,
         0.0190, 0.0199, 0.0131, 0.0256, 0.0215, 0.0146, 0.0188, 0.0180, 0.0451,
         0.0202, 0.0228, 0.0259, 0.0240, 0.0233, 0.0221, 0.0344, 0.0302, 0.0327,
         0.0399, 0.0222, 0.0166, 0.0200]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 94
images/338
(64, 64, 3)
tensor([[0.0372, 0.0314, 0.0250, 0.0276, 0.0275, 0.0249, 0.0355, 0.0112, 0.0195,
         0.0246, 0.0204, 0.0251, 0.0407, 0.0346, 0.0261, 0.0182, 0.0112, 0.0256,
         0.0234, 0.0295, 0.0151, 0.0251, 0.0178, 0.0214, 0.0150, 0.0233, 0.0235,
         0.0403, 0.0245, 0.0220, 0.0220, 0.0227, 0.0252, 0.0178, 0.0201, 0.0384,
         0.0281, 0.0311, 0.0274, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 95
images/498
(64, 64, 3)
tensor([[0.0339, 0.0308, 0.0245, 0.0144, 0.0311, 0.0167, 0.0409, 0.0210, 0.0152,
         0.0165, 0.0200, 0.0321, 0.0429, 0.0361, 0.0252, 0.0156, 0.0231, 0.0221,
         0.0200, 0.0184, 0.0216, 0.0323, 0.0183, 0.0256, 0.0247, 0.0170, 0.0231,
         0.0221, 0.0278, 0.0213, 0.0122, 0.0256, 0.0342, 0.0222, 0.0151, 0.0384,
         0.0253, 0.0252, 0.0328, 0.0351]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 96
images/462
(64, 64, 3)
tensor([[0.0214, 0.0260, 0.0245, 0.0159, 0.0353, 0.0325, 0.0329, 0.0288, 0.0204,
         0.0178, 0.0194, 0.0373, 0.0435, 0.0321, 0.0302, 0.0208, 0.0132, 0.0510,
         0.0223, 0.0211, 0.0154, 0.0183, 0.0144, 0.0224, 0.0179, 0.0197, 0.0231,
         0.0372, 0.0250, 0.0215, 0.0240, 0.0309, 0.0200, 0.0217, 0.0263, 0.0294,
         0.0194, 0.0136, 0.0222, 0.0312]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 97
images/576
(64, 64, 3)
tensor([[0.0224, 0.0209, 0.0133, 0.0292, 0.0338, 0.0213, 0.0451, 0.0180, 0.0160,
         0.0172, 0.0248, 0.0385, 0.0326, 0.0286, 0.0270, 0.0112, 0.0149, 0.0248,
         0.0256, 0.0209, 0.0205, 0.0246, 0.0294, 0.0214, 0.0215, 0.0270, 0.0219,
         0.0420, 0.0269, 0.0211, 0.0207, 0.0278, 0.0279, 0.0268, 0.0268, 0.0219,
         0.0361, 0.0232, 0.0224, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 98
images/75
(64, 64, 3)
tensor([[0.0316, 0.0322, 0.0176, 0.0113, 0.0214, 0.0225, 0.0283, 0.0171, 0.0169,
         0.0217, 0.0172, 0.0317, 0.0374, 0.0326, 0.0296, 0.0180, 0.0187, 0.0300,
         0.0238, 0.0213, 0.0190, 0.0244, 0.0154, 0.0194, 0.0229, 0.0209, 0.0220,
         0.0501, 0.0448, 0.0175, 0.0200, 0.0285, 0.0289, 0.0313, 0.0246, 0.0362,
         0.0276, 0.0171, 0.0187, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 99
images/558
(64, 64, 3)
tensor([[0.0299, 0.0309, 0.0107, 0.0139, 0.0396, 0.0236, 0.0258, 0.0303, 0.0190,
         0.0179, 0.0237, 0.0269, 0.0436, 0.0308, 0.0224, 0.0187, 0.0331, 0.0295,
         0.0318, 0.0223, 0.0163, 0.0206, 0.0174, 0.0254, 0.0226, 0.0194, 0.0320,
         0.0319, 0.0266, 0.0291, 0.0150, 0.0258, 0.0274, 0.0301, 0.0206, 0.0190,
         0.0242, 0.0212, 0.0256, 0.0251]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Saving the weights
37 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/8
(64, 64, 3)
2018-10-13 01:20:20.835 Python[9586:15724994] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0278, 0.0295, 0.0258, 0.0252, 0.0296, 0.0217, 0.0333, 0.0161, 0.0150,
         0.0185, 0.0165, 0.0280, 0.0262, 0.0278, 0.0306, 0.0250, 0.0208, 0.0281,
         0.0127, 0.0205, 0.0181, 0.0229, 0.0257, 0.0217, 0.0414, 0.0236, 0.0226,
         0.0244, 0.0368, 0.0188, 0.0168, 0.0379, 0.0203, 0.0217, 0.0179, 0.0237,
         0.0398, 0.0327, 0.0311, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 1
images/5
(64, 64, 3)
tensor([[0.0272, 0.0335, 0.0219, 0.0123, 0.0383, 0.0140, 0.0343, 0.0158, 0.0208,
         0.0170, 0.0208, 0.0557, 0.0263, 0.0333, 0.0395, 0.0147, 0.0187, 0.0346,
         0.0116, 0.0206, 0.0198, 0.0305, 0.0201, 0.0219, 0.0272, 0.0137, 0.0185,
         0.0441, 0.0227, 0.0212, 0.0179, 0.0410, 0.0198, 0.0270, 0.0214, 0.0265,
         0.0384, 0.0230, 0.0164, 0.0181]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/76
(64, 64, 3)
tensor([[0.0354, 0.0303, 0.0136, 0.0166, 0.0300, 0.0173, 0.0244, 0.0169, 0.0156,
         0.0191, 0.0293, 0.0403, 0.0361, 0.0312, 0.0305, 0.0183, 0.0399, 0.0453,
         0.0180, 0.0126, 0.0165, 0.0186, 0.0253, 0.0270, 0.0168, 0.0146, 0.0252,
         0.0243, 0.0441, 0.0161, 0.0241, 0.0213, 0.0203, 0.0350, 0.0274, 0.0284,
         0.0260, 0.0217, 0.0223, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 3
images/581
(64, 64, 3)
tensor([[0.0313, 0.0255, 0.0190, 0.0177, 0.0342, 0.0173, 0.0306, 0.0170, 0.0210,
         0.0148, 0.0295, 0.0244, 0.0241, 0.0354, 0.0298, 0.0248, 0.0195, 0.0414,
         0.0178, 0.0226, 0.0133, 0.0218, 0.0152, 0.0227, 0.0285, 0.0230, 0.0215,
         0.0350, 0.0378, 0.0171, 0.0276, 0.0271, 0.0267, 0.0337, 0.0234, 0.0321,
         0.0277, 0.0169, 0.0261, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 4
images/321
(64, 64, 3)
tensor([[0.0184, 0.0260, 0.0239, 0.0163, 0.0427, 0.0199, 0.0157, 0.0168, 0.0153,
         0.0275, 0.0154, 0.0400, 0.0300, 0.0281, 0.0280, 0.0214, 0.0285, 0.0483,
         0.0160, 0.0174, 0.0168, 0.0280, 0.0235, 0.0246, 0.0168, 0.0271, 0.0297,
         0.0396, 0.0259, 0.0243, 0.0131, 0.0323, 0.0178, 0.0244, 0.0284, 0.0246,
         0.0228, 0.0238, 0.0170, 0.0436]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 5
images/549
(64, 64, 3)
tensor([[0.0178, 0.0311, 0.0170, 0.0155, 0.0414, 0.0223, 0.0332, 0.0229, 0.0147,
         0.0210, 0.0313, 0.0328, 0.0382, 0.0248, 0.0213, 0.0360, 0.0201, 0.0292,
         0.0132, 0.0193, 0.0160, 0.0241, 0.0193, 0.0262, 0.0212, 0.0225, 0.0312,
         0.0275, 0.0354, 0.0421, 0.0204, 0.0219, 0.0270, 0.0188, 0.0208, 0.0339,
         0.0267, 0.0163, 0.0209, 0.0247]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 6
images/25
(64, 64, 3)
tensor([[0.0417, 0.0267, 0.0229, 0.0177, 0.0237, 0.0262, 0.0254, 0.0159, 0.0161,
         0.0320, 0.0189, 0.0197, 0.0314, 0.0317, 0.0303, 0.0184, 0.0231, 0.0491,
         0.0270, 0.0253, 0.0180, 0.0213, 0.0219, 0.0255, 0.0220, 0.0171, 0.0225,
         0.0346, 0.0275, 0.0215, 0.0283, 0.0210, 0.0242, 0.0246, 0.0196, 0.0303,
         0.0248, 0.0176, 0.0219, 0.0326]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 7
images/366
(64, 64, 3)
tensor([[0.0339, 0.0317, 0.0219, 0.0143, 0.0231, 0.0243, 0.0305, 0.0112, 0.0106,
         0.0174, 0.0183, 0.0257, 0.0460, 0.0312, 0.0200, 0.0311, 0.0233, 0.0265,
         0.0237, 0.0201, 0.0162, 0.0283, 0.0173, 0.0267, 0.0201, 0.0204, 0.0316,
         0.0420, 0.0341, 0.0268, 0.0300, 0.0391, 0.0246, 0.0267, 0.0158, 0.0248,
         0.0340, 0.0201, 0.0116, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/384
(64, 64, 3)
tensor([[0.0271, 0.0207, 0.0098, 0.0205, 0.0379, 0.0253, 0.0307, 0.0205, 0.0182,
         0.0263, 0.0157, 0.0285, 0.0496, 0.0187, 0.0249, 0.0186, 0.0302, 0.0468,
         0.0295, 0.0153, 0.0083, 0.0179, 0.0328, 0.0243, 0.0162, 0.0154, 0.0277,
         0.0265, 0.0280, 0.0212, 0.0119, 0.0455, 0.0251, 0.0234, 0.0196, 0.0342,
         0.0283, 0.0173, 0.0197, 0.0419]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 9
images/477
(64, 64, 3)
tensor([[0.0253, 0.0370, 0.0164, 0.0213, 0.0247, 0.0168, 0.0336, 0.0213, 0.0179,
         0.0285, 0.0243, 0.0225, 0.0385, 0.0410, 0.0222, 0.0200, 0.0213, 0.0337,
         0.0193, 0.0177, 0.0166, 0.0195, 0.0199, 0.0226, 0.0213, 0.0208, 0.0259,
         0.0359, 0.0375, 0.0302, 0.0156, 0.0311, 0.0226, 0.0184, 0.0175, 0.0474,
         0.0217, 0.0216, 0.0264, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 10
images/494
(64, 64, 3)
tensor([[0.0272, 0.0246, 0.0147, 0.0154, 0.0361, 0.0294, 0.0303, 0.0130, 0.0257,
         0.0192, 0.0239, 0.0236, 0.0441, 0.0320, 0.0319, 0.0113, 0.0220, 0.0342,
         0.0280, 0.0217, 0.0132, 0.0239, 0.0259, 0.0270, 0.0138, 0.0145, 0.0273,
         0.0229, 0.0214, 0.0228, 0.0172, 0.0270, 0.0353, 0.0261, 0.0236, 0.0301,
         0.0349, 0.0259, 0.0354, 0.0236]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 11
images/427
(64, 64, 3)
tensor([[0.0226, 0.0356, 0.0339, 0.0122, 0.0295, 0.0302, 0.0293, 0.0184, 0.0158,
         0.0251, 0.0158, 0.0349, 0.0254, 0.0292, 0.0226, 0.0149, 0.0127, 0.0524,
         0.0237, 0.0180, 0.0146, 0.0257, 0.0210, 0.0331, 0.0262, 0.0196, 0.0188,
         0.0338, 0.0466, 0.0396, 0.0172, 0.0242, 0.0222, 0.0143, 0.0281, 0.0167,
         0.0264, 0.0313, 0.0180, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/219
(64, 64, 3)
tensor([[0.0361, 0.0334, 0.0168, 0.0205, 0.0286, 0.0195, 0.0323, 0.0177, 0.0232,
         0.0159, 0.0220, 0.0246, 0.0401, 0.0418, 0.0196, 0.0189, 0.0233, 0.0383,
         0.0144, 0.0189, 0.0164, 0.0201, 0.0224, 0.0237, 0.0186, 0.0312, 0.0213,
         0.0284, 0.0384, 0.0242, 0.0148, 0.0319, 0.0264, 0.0145, 0.0344, 0.0234,
         0.0363, 0.0205, 0.0228, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 1
Session Number: 13
images/348
(64, 64, 3)
tensor([[0.0204, 0.0249, 0.0201, 0.0130, 0.0288, 0.0336, 0.0416, 0.0196, 0.0124,
         0.0238, 0.0289, 0.0367, 0.0564, 0.0330, 0.0139, 0.0243, 0.0173, 0.0233,
         0.0151, 0.0227, 0.0240, 0.0197, 0.0161, 0.0207, 0.0199, 0.0142, 0.0216,
         0.0356, 0.0286, 0.0191, 0.0151, 0.0251, 0.0471, 0.0125, 0.0372, 0.0270,
         0.0303, 0.0175, 0.0355, 0.0232]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 14
images/513
(64, 64, 3)
tensor([[0.0337, 0.0298, 0.0132, 0.0122, 0.0256, 0.0267, 0.0277, 0.0222, 0.0190,
         0.0196, 0.0189, 0.0320, 0.0360, 0.0309, 0.0487, 0.0179, 0.0261, 0.0438,
         0.0174, 0.0160, 0.0181, 0.0176, 0.0239, 0.0199, 0.0239, 0.0228, 0.0286,
         0.0223, 0.0320, 0.0244, 0.0217, 0.0497, 0.0259, 0.0153, 0.0185, 0.0163,
         0.0174, 0.0159, 0.0379, 0.0304]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 174, in <module>
    main()
  File "Torch_reinforce01.py", line 144, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: ''
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/445
(64, 64, 3)
2018-10-13 01:21:17.831 Python[9641:15725538] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0367, 0.0220, 0.0174, 0.0222, 0.0309, 0.0165, 0.0339, 0.0153, 0.0120,
         0.0193, 0.0183, 0.0237, 0.0263, 0.0335, 0.0347, 0.0217, 0.0321, 0.0276,
         0.0145, 0.0219, 0.0127, 0.0272, 0.0393, 0.0279, 0.0330, 0.0248, 0.0235,
         0.0208, 0.0328, 0.0184, 0.0185, 0.0314, 0.0247, 0.0210, 0.0210, 0.0348,
         0.0245, 0.0352, 0.0256, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/15
(64, 64, 3)
tensor([[0.0278, 0.0234, 0.0123, 0.0212, 0.0372, 0.0203, 0.0298, 0.0161, 0.0169,
         0.0220, 0.0202, 0.0288, 0.0269, 0.0306, 0.0330, 0.0222, 0.0197, 0.0411,
         0.0196, 0.0277, 0.0184, 0.0320, 0.0188, 0.0228, 0.0178, 0.0199, 0.0246,
         0.0337, 0.0310, 0.0225, 0.0153, 0.0465, 0.0273, 0.0257, 0.0224, 0.0241,
         0.0365, 0.0265, 0.0157, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/557
(64, 64, 3)
tensor([[0.0348, 0.0371, 0.0160, 0.0263, 0.0289, 0.0204, 0.0258, 0.0123, 0.0121,
         0.0243, 0.0209, 0.0205, 0.0363, 0.0450, 0.0232, 0.0253, 0.0342, 0.0390,
         0.0139, 0.0134, 0.0226, 0.0200, 0.0214, 0.0372, 0.0143, 0.0199, 0.0328,
         0.0225, 0.0397, 0.0210, 0.0178, 0.0211, 0.0342, 0.0223, 0.0289, 0.0302,
         0.0258, 0.0231, 0.0191, 0.0162]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 3
images/488
(64, 64, 3)
tensor([[0.0265, 0.0280, 0.0187, 0.0251, 0.0237, 0.0157, 0.0361, 0.0166, 0.0204,
         0.0119, 0.0200, 0.0424, 0.0336, 0.0349, 0.0205, 0.0180, 0.0166, 0.0330,
         0.0159, 0.0293, 0.0126, 0.0235, 0.0195, 0.0230, 0.0204, 0.0176, 0.0207,
         0.0567, 0.0478, 0.0184, 0.0225, 0.0241, 0.0294, 0.0270, 0.0237, 0.0365,
         0.0256, 0.0261, 0.0181, 0.0200]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 4
images/270
(64, 64, 3)
tensor([[0.0194, 0.0338, 0.0196, 0.0176, 0.0404, 0.0191, 0.0262, 0.0211, 0.0202,
         0.0232, 0.0161, 0.0297, 0.0248, 0.0357, 0.0329, 0.0190, 0.0185, 0.0423,
         0.0172, 0.0168, 0.0149, 0.0215, 0.0193, 0.0255, 0.0219, 0.0203, 0.0378,
         0.0284, 0.0336, 0.0274, 0.0228, 0.0357, 0.0251, 0.0236, 0.0258, 0.0194,
         0.0229, 0.0247, 0.0251, 0.0306]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 5
images/303
(64, 64, 3)
tensor([[0.0161, 0.0288, 0.0167, 0.0128, 0.0271, 0.0198, 0.0312, 0.0218, 0.0154,
         0.0284, 0.0245, 0.0277, 0.0326, 0.0313, 0.0312, 0.0266, 0.0244, 0.0502,
         0.0183, 0.0232, 0.0224, 0.0188, 0.0240, 0.0275, 0.0156, 0.0175, 0.0207,
         0.0345, 0.0404, 0.0410, 0.0178, 0.0214, 0.0209, 0.0314, 0.0280, 0.0324,
         0.0211, 0.0172, 0.0184, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 6
images/115
(64, 64, 3)
tensor([[0.0317, 0.0398, 0.0205, 0.0168, 0.0231, 0.0231, 0.0294, 0.0169, 0.0183,
         0.0348, 0.0134, 0.0266, 0.0384, 0.0252, 0.0259, 0.0205, 0.0240, 0.0430,
         0.0169, 0.0167, 0.0146, 0.0331, 0.0278, 0.0301, 0.0155, 0.0161, 0.0213,
         0.0274, 0.0371, 0.0274, 0.0278, 0.0202, 0.0212, 0.0199, 0.0144, 0.0351,
         0.0328, 0.0240, 0.0218, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 7
images/436
(64, 64, 3)
tensor([[0.0384, 0.0242, 0.0163, 0.0202, 0.0215, 0.0177, 0.0265, 0.0156, 0.0128,
         0.0146, 0.0177, 0.0402, 0.0418, 0.0347, 0.0257, 0.0285, 0.0191, 0.0394,
         0.0160, 0.0220, 0.0150, 0.0179, 0.0207, 0.0318, 0.0210, 0.0275, 0.0350,
         0.0418, 0.0391, 0.0253, 0.0256, 0.0259, 0.0219, 0.0260, 0.0205, 0.0209,
         0.0268, 0.0271, 0.0132, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 8
images/107
(64, 64, 3)
tensor([[0.0256, 0.0225, 0.0145, 0.0173, 0.0382, 0.0191, 0.0196, 0.0200, 0.0174,
         0.0267, 0.0184, 0.0232, 0.0364, 0.0229, 0.0292, 0.0195, 0.0272, 0.0434,
         0.0281, 0.0155, 0.0101, 0.0182, 0.0310, 0.0334, 0.0253, 0.0230, 0.0280,
         0.0258, 0.0295, 0.0239, 0.0124, 0.0446, 0.0259, 0.0250, 0.0262, 0.0286,
         0.0276, 0.0210, 0.0203, 0.0355]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 9
images/469
(64, 64, 3)
tensor([[0.0366, 0.0279, 0.0071, 0.0113, 0.0228, 0.0170, 0.0351, 0.0205, 0.0149,
         0.0246, 0.0181, 0.0301, 0.0405, 0.0240, 0.0329, 0.0139, 0.0196, 0.0327,
         0.0211, 0.0204, 0.0189, 0.0202, 0.0183, 0.0262, 0.0181, 0.0203, 0.0266,
         0.0295, 0.0599, 0.0182, 0.0261, 0.0331, 0.0265, 0.0206, 0.0191, 0.0527,
         0.0259, 0.0192, 0.0282, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 10
images/137
(64, 64, 3)
tensor([[0.0220, 0.0220, 0.0196, 0.0223, 0.0426, 0.0180, 0.0336, 0.0121, 0.0180,
         0.0310, 0.0226, 0.0263, 0.0406, 0.0279, 0.0354, 0.0115, 0.0204, 0.0256,
         0.0164, 0.0248, 0.0155, 0.0214, 0.0250, 0.0276, 0.0160, 0.0192, 0.0333,
         0.0194, 0.0225, 0.0179, 0.0263, 0.0308, 0.0377, 0.0273, 0.0266, 0.0347,
         0.0267, 0.0188, 0.0233, 0.0373]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/144
(64, 64, 3)
tensor([[0.0250, 0.0373, 0.0321, 0.0169, 0.0332, 0.0261, 0.0279, 0.0132, 0.0238,
         0.0218, 0.0120, 0.0275, 0.0258, 0.0316, 0.0221, 0.0247, 0.0155, 0.0397,
         0.0172, 0.0179, 0.0168, 0.0188, 0.0307, 0.0528, 0.0178, 0.0229, 0.0211,
         0.0220, 0.0407, 0.0339, 0.0196, 0.0247, 0.0202, 0.0236, 0.0198, 0.0289,
         0.0346, 0.0167, 0.0172, 0.0257]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 12
images/561
(64, 64, 3)
tensor([[0.0338, 0.0276, 0.0148, 0.0189, 0.0346, 0.0158, 0.0348, 0.0199, 0.0236,
         0.0192, 0.0216, 0.0304, 0.0383, 0.0430, 0.0217, 0.0164, 0.0160, 0.0396,
         0.0144, 0.0178, 0.0216, 0.0272, 0.0229, 0.0248, 0.0263, 0.0226, 0.0237,
         0.0308, 0.0446, 0.0169, 0.0096, 0.0300, 0.0220, 0.0188, 0.0232, 0.0234,
         0.0297, 0.0234, 0.0225, 0.0335]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 13
images/505
(64, 64, 3)
tensor([[0.0206, 0.0250, 0.0195, 0.0095, 0.0255, 0.0410, 0.0467, 0.0171, 0.0139,
         0.0169, 0.0268, 0.0367, 0.0354, 0.0241, 0.0125, 0.0195, 0.0180, 0.0216,
         0.0192, 0.0211, 0.0238, 0.0240, 0.0171, 0.0207, 0.0259, 0.0190, 0.0295,
         0.0372, 0.0458, 0.0149, 0.0171, 0.0437, 0.0420, 0.0204, 0.0227, 0.0252,
         0.0342, 0.0153, 0.0222, 0.0285]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 14
images/553
(64, 64, 3)
tensor([[0.0345, 0.0276, 0.0193, 0.0144, 0.0246, 0.0171, 0.0302, 0.0177, 0.0171,
         0.0186, 0.0232, 0.0390, 0.0279, 0.0281, 0.0340, 0.0236, 0.0240, 0.0396,
         0.0227, 0.0250, 0.0179, 0.0234, 0.0209, 0.0128, 0.0328, 0.0172, 0.0330,
         0.0271, 0.0392, 0.0300, 0.0154, 0.0412, 0.0327, 0.0206, 0.0195, 0.0169,
         0.0176, 0.0182, 0.0276, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 15
images/500
(64, 64, 3)
tensor([[0.0256, 0.0282, 0.0152, 0.0204, 0.0395, 0.0194, 0.0347, 0.0136, 0.0164,
         0.0253, 0.0144, 0.0250, 0.0349, 0.0321, 0.0238, 0.0153, 0.0181, 0.0356,
         0.0143, 0.0273, 0.0206, 0.0190, 0.0311, 0.0237, 0.0328, 0.0211, 0.0183,
         0.0296, 0.0196, 0.0448, 0.0250, 0.0466, 0.0282, 0.0131, 0.0138, 0.0291,
         0.0363, 0.0138, 0.0266, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/489
(64, 64, 3)
tensor([[0.0260, 0.0293, 0.0098, 0.0130, 0.0290, 0.0183, 0.0342, 0.0219, 0.0252,
         0.0165, 0.0183, 0.0252, 0.0531, 0.0325, 0.0235, 0.0163, 0.0230, 0.0396,
         0.0216, 0.0287, 0.0208, 0.0219, 0.0201, 0.0162, 0.0179, 0.0326, 0.0257,
         0.0337, 0.0352, 0.0225, 0.0138, 0.0399, 0.0261, 0.0231, 0.0324, 0.0348,
         0.0230, 0.0201, 0.0144, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0 
Session Number: 17
images/582
(64, 64, 3)
tensor([[0.0185, 0.0304, 0.0216, 0.0232, 0.0231, 0.0164, 0.0415, 0.0177, 0.0232,
         0.0318, 0.0165, 0.0213, 0.0593, 0.0453, 0.0213, 0.0165, 0.0169, 0.0560,
         0.0176, 0.0216, 0.0102, 0.0170, 0.0241, 0.0172, 0.0168, 0.0155, 0.0192,
         0.0313, 0.0275, 0.0382, 0.0117, 0.0337, 0.0224, 0.0183, 0.0338, 0.0334,
         0.0286, 0.0179, 0.0215, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 18
images/597
(64, 64, 3)
tensor([[0.0248, 0.0235, 0.0171, 0.0177, 0.0376, 0.0183, 0.0435, 0.0158, 0.0201,
         0.0130, 0.0182, 0.0336, 0.0630, 0.0287, 0.0153, 0.0144, 0.0199, 0.0365,
         0.0210, 0.0252, 0.0242, 0.0308, 0.0181, 0.0173, 0.0166, 0.0179, 0.0250,
         0.0277, 0.0329, 0.0250, 0.0150, 0.0338, 0.0238, 0.0238, 0.0302, 0.0307,
         0.0382, 0.0125, 0.0172, 0.0321]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 19
images/463
(64, 64, 3)
tensor([[0.0336, 0.0290, 0.0203, 0.0220, 0.0297, 0.0212, 0.0278, 0.0134, 0.0145,
         0.0222, 0.0210, 0.0168, 0.0369, 0.0530, 0.0235, 0.0144, 0.0225, 0.0520,
         0.0304, 0.0182, 0.0160, 0.0217, 0.0207, 0.0122, 0.0214, 0.0194, 0.0151,
         0.0275, 0.0398, 0.0245, 0.0148, 0.0240, 0.0285, 0.0276, 0.0215, 0.0281,
         0.0397, 0.0222, 0.0284, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 20
images/454
(64, 64, 3)
tensor([[0.0220, 0.0224, 0.0122, 0.0247, 0.0400, 0.0188, 0.0381, 0.0177, 0.0165,
         0.0131, 0.0261, 0.0223, 0.0410, 0.0338, 0.0252, 0.0171, 0.0199, 0.0322,
         0.0164, 0.0239, 0.0153, 0.0248, 0.0250, 0.0208, 0.0265, 0.0207, 0.0191,
         0.0283, 0.0248, 0.0255, 0.0261, 0.0343, 0.0366, 0.0265, 0.0205, 0.0311,
         0.0225, 0.0342, 0.0216, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 21
images/299
(64, 64, 3)
tensor([[0.0225, 0.0300, 0.0168, 0.0167, 0.0276, 0.0197, 0.0348, 0.0159, 0.0299,
         0.0195, 0.0156, 0.0327, 0.0599, 0.0303, 0.0142, 0.0169, 0.0244, 0.0430,
         0.0245, 0.0213, 0.0121, 0.0218, 0.0151, 0.0274, 0.0106, 0.0192, 0.0298,
         0.0310, 0.0431, 0.0182, 0.0143, 0.0338, 0.0274, 0.0191, 0.0289, 0.0371,
         0.0297, 0.0199, 0.0225, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 22
images/505
(64, 64, 3)
tensor([[0.0371, 0.0252, 0.0186, 0.0145, 0.0275, 0.0215, 0.0487, 0.0225, 0.0147,
         0.0241, 0.0147, 0.0388, 0.0307, 0.0354, 0.0151, 0.0168, 0.0250, 0.0527,
         0.0186, 0.0151, 0.0189, 0.0180, 0.0174, 0.0241, 0.0214, 0.0203, 0.0277,
         0.0283, 0.0485, 0.0182, 0.0127, 0.0418, 0.0263, 0.0274, 0.0226, 0.0218,
         0.0240, 0.0135, 0.0241, 0.0258]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 23
images/227
(64, 64, 3)
tensor([[0.0191, 0.0302, 0.0174, 0.0171, 0.0361, 0.0286, 0.0242, 0.0214, 0.0173,
         0.0316, 0.0157, 0.0372, 0.0421, 0.0319, 0.0268, 0.0165, 0.0239, 0.0252,
         0.0265, 0.0199, 0.0228, 0.0253, 0.0250, 0.0251, 0.0189, 0.0232, 0.0263,
         0.0295, 0.0313, 0.0244, 0.0226, 0.0265, 0.0178, 0.0322, 0.0235, 0.0268,
         0.0278, 0.0173, 0.0215, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: `1
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 174, in <module>
    main()
  File "Torch_reinforce01.py", line 144, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: '`1'
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/187
(64, 64, 3)
2018-10-13 01:22:46.243 Python[9708:15726247] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0378, 0.0208, 0.0197, 0.0212, 0.0307, 0.0239, 0.0257, 0.0193, 0.0192,
         0.0143, 0.0240, 0.0207, 0.0226, 0.0380, 0.0250, 0.0207, 0.0194, 0.0337,
         0.0110, 0.0185, 0.0140, 0.0193, 0.0359, 0.0221, 0.0336, 0.0258, 0.0214,
         0.0369, 0.0229, 0.0177, 0.0227, 0.0337, 0.0243, 0.0227, 0.0237, 0.0477,
         0.0318, 0.0253, 0.0311, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 1
images/251
(64, 64, 3)
tensor([[0.0297, 0.0224, 0.0196, 0.0106, 0.0230, 0.0199, 0.0461, 0.0181, 0.0164,
         0.0133, 0.0259, 0.0429, 0.0249, 0.0326, 0.0266, 0.0176, 0.0200, 0.0433,
         0.0166, 0.0249, 0.0128, 0.0232, 0.0212, 0.0241, 0.0228, 0.0235, 0.0171,
         0.0325, 0.0284, 0.0204, 0.0206, 0.0457, 0.0227, 0.0300, 0.0279, 0.0376,
         0.0351, 0.0207, 0.0178, 0.0216]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/511
(64, 64, 3)
tensor([[0.0359, 0.0211, 0.0154, 0.0238, 0.0263, 0.0244, 0.0269, 0.0121, 0.0131,
         0.0212, 0.0309, 0.0314, 0.0302, 0.0434, 0.0259, 0.0182, 0.0337, 0.0409,
         0.0151, 0.0158, 0.0186, 0.0257, 0.0246, 0.0245, 0.0143, 0.0174, 0.0231,
         0.0226, 0.0458, 0.0193, 0.0233, 0.0323, 0.0249, 0.0279, 0.0254, 0.0266,
         0.0374, 0.0222, 0.0222, 0.0161]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 3
images/374
(64, 64, 3)
tensor([[0.0360, 0.0313, 0.0119, 0.0164, 0.0301, 0.0173, 0.0370, 0.0152, 0.0279,
         0.0147, 0.0252, 0.0428, 0.0289, 0.0374, 0.0252, 0.0221, 0.0244, 0.0419,
         0.0113, 0.0231, 0.0134, 0.0187, 0.0192, 0.0211, 0.0211, 0.0200, 0.0284,
         0.0417, 0.0299, 0.0249, 0.0289, 0.0209, 0.0259, 0.0222, 0.0291, 0.0254,
         0.0259, 0.0220, 0.0228, 0.0185]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 4
images/118
(64, 64, 3)
tensor([[0.0185, 0.0265, 0.0253, 0.0160, 0.0363, 0.0218, 0.0313, 0.0146, 0.0146,
         0.0200, 0.0166, 0.0412, 0.0300, 0.0281, 0.0386, 0.0140, 0.0183, 0.0477,
         0.0172, 0.0146, 0.0157, 0.0214, 0.0213, 0.0206, 0.0166, 0.0136, 0.0386,
         0.0253, 0.0318, 0.0343, 0.0194, 0.0322, 0.0267, 0.0362, 0.0291, 0.0296,
         0.0255, 0.0230, 0.0244, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 5
images/56
(64, 64, 3)
tensor([[0.0195, 0.0303, 0.0210, 0.0191, 0.0228, 0.0285, 0.0300, 0.0275, 0.0117,
         0.0206, 0.0225, 0.0346, 0.0441, 0.0280, 0.0182, 0.0323, 0.0203, 0.0377,
         0.0230, 0.0161, 0.0138, 0.0300, 0.0240, 0.0298, 0.0172, 0.0150, 0.0244,
         0.0282, 0.0292, 0.0234, 0.0204, 0.0308, 0.0264, 0.0218, 0.0228, 0.0346,
         0.0223, 0.0198, 0.0313, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 6
images/375
(64, 64, 3)
tensor([[0.0441, 0.0313, 0.0222, 0.0215, 0.0247, 0.0245, 0.0269, 0.0185, 0.0178,
         0.0295, 0.0126, 0.0262, 0.0345, 0.0217, 0.0314, 0.0236, 0.0171, 0.0469,
         0.0188, 0.0245, 0.0162, 0.0231, 0.0229, 0.0314, 0.0160, 0.0151, 0.0213,
         0.0317, 0.0383, 0.0193, 0.0218, 0.0244, 0.0197, 0.0229, 0.0185, 0.0367,
         0.0329, 0.0181, 0.0282, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 7
images/534
(64, 64, 3)
tensor([[0.0380, 0.0249, 0.0255, 0.0217, 0.0247, 0.0175, 0.0390, 0.0135, 0.0217,
         0.0138, 0.0192, 0.0304, 0.0408, 0.0304, 0.0196, 0.0349, 0.0237, 0.0314,
         0.0118, 0.0181, 0.0216, 0.0218, 0.0147, 0.0268, 0.0171, 0.0214, 0.0369,
         0.0457, 0.0369, 0.0316, 0.0328, 0.0265, 0.0237, 0.0312, 0.0151, 0.0229,
         0.0195, 0.0122, 0.0163, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/260
(64, 64, 3)
tensor([[0.0320, 0.0305, 0.0108, 0.0197, 0.0208, 0.0207, 0.0303, 0.0197, 0.0197,
         0.0212, 0.0153, 0.0280, 0.0448, 0.0259, 0.0244, 0.0271, 0.0346, 0.0347,
         0.0149, 0.0204, 0.0133, 0.0288, 0.0369, 0.0317, 0.0207, 0.0236, 0.0290,
         0.0268, 0.0337, 0.0177, 0.0143, 0.0478, 0.0254, 0.0196, 0.0237, 0.0273,
         0.0191, 0.0226, 0.0161, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 9
images/579
(64, 64, 3)
tensor([[0.0285, 0.0234, 0.0148, 0.0108, 0.0297, 0.0172, 0.0378, 0.0184, 0.0156,
         0.0258, 0.0184, 0.0319, 0.0370, 0.0301, 0.0376, 0.0142, 0.0177, 0.0414,
         0.0174, 0.0149, 0.0177, 0.0244, 0.0164, 0.0246, 0.0191, 0.0171, 0.0290,
         0.0329, 0.0622, 0.0231, 0.0245, 0.0285, 0.0286, 0.0238, 0.0157, 0.0380,
         0.0214, 0.0152, 0.0269, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 10
images/157
(64, 64, 3)
tensor([[0.0258, 0.0212, 0.0155, 0.0143, 0.0485, 0.0167, 0.0317, 0.0155, 0.0174,
         0.0201, 0.0188, 0.0312, 0.0331, 0.0337, 0.0339, 0.0129, 0.0213, 0.0493,
         0.0224, 0.0250, 0.0124, 0.0163, 0.0196, 0.0332, 0.0177, 0.0160, 0.0326,
         0.0255, 0.0280, 0.0264, 0.0193, 0.0244, 0.0382, 0.0278, 0.0271, 0.0225,
         0.0255, 0.0244, 0.0282, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/433
(64, 64, 3)
tensor([[0.0187, 0.0272, 0.0294, 0.0220, 0.0389, 0.0238, 0.0311, 0.0159, 0.0287,
         0.0168, 0.0148, 0.0248, 0.0356, 0.0280, 0.0196, 0.0217, 0.0180, 0.0454,
         0.0144, 0.0181, 0.0140, 0.0217, 0.0241, 0.0380, 0.0196, 0.0261, 0.0264,
         0.0177, 0.0346, 0.0424, 0.0183, 0.0276, 0.0228, 0.0198, 0.0265, 0.0248,
         0.0346, 0.0270, 0.0154, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/51
(64, 64, 3)
tensor([[0.0375, 0.0267, 0.0185, 0.0216, 0.0337, 0.0187, 0.0432, 0.0194, 0.0162,
         0.0214, 0.0202, 0.0218, 0.0391, 0.0594, 0.0208, 0.0242, 0.0103, 0.0369,
         0.0138, 0.0169, 0.0165, 0.0238, 0.0206, 0.0273, 0.0224, 0.0199, 0.0187,
         0.0414, 0.0353, 0.0163, 0.0107, 0.0290, 0.0215, 0.0157, 0.0323, 0.0186,
         0.0257, 0.0319, 0.0275, 0.0249]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 13
images/14
(64, 64, 3)
tensor([[0.0270, 0.0259, 0.0197, 0.0152, 0.0274, 0.0300, 0.0449, 0.0238, 0.0174,
         0.0228, 0.0277, 0.0405, 0.0485, 0.0323, 0.0256, 0.0204, 0.0176, 0.0196,
         0.0139, 0.0185, 0.0247, 0.0261, 0.0155, 0.0197, 0.0240, 0.0106, 0.0178,
         0.0391, 0.0229, 0.0184, 0.0166, 0.0312, 0.0396, 0.0214, 0.0291, 0.0298,
         0.0331, 0.0132, 0.0251, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 14
images/55
(64, 64, 3)
tensor([[0.0305, 0.0189, 0.0176, 0.0156, 0.0182, 0.0320, 0.0377, 0.0213, 0.0244,
         0.0178, 0.0197, 0.0233, 0.0368, 0.0289, 0.0264, 0.0137, 0.0220, 0.0442,
         0.0186, 0.0186, 0.0150, 0.0154, 0.0292, 0.0231, 0.0211, 0.0257, 0.0316,
         0.0257, 0.0268, 0.0230, 0.0210, 0.0475, 0.0320, 0.0228, 0.0143, 0.0199,
         0.0186, 0.0190, 0.0428, 0.0397]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 15
images/315
(64, 64, 3)
tensor([[0.0300, 0.0299, 0.0246, 0.0218, 0.0397, 0.0193, 0.0342, 0.0119, 0.0167,
         0.0208, 0.0151, 0.0295, 0.0281, 0.0292, 0.0344, 0.0216, 0.0142, 0.0364,
         0.0178, 0.0206, 0.0219, 0.0222, 0.0229, 0.0195, 0.0281, 0.0189, 0.0226,
         0.0335, 0.0252, 0.0325, 0.0244, 0.0385, 0.0258, 0.0140, 0.0181, 0.0319,
         0.0381, 0.0121, 0.0289, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 16
images/114
(64, 64, 3)
tensor([[0.0328, 0.0316, 0.0131, 0.0154, 0.0377, 0.0197, 0.0375, 0.0130, 0.0210,
         0.0261, 0.0160, 0.0237, 0.0467, 0.0307, 0.0318, 0.0168, 0.0203, 0.0428,
         0.0252, 0.0315, 0.0187, 0.0237, 0.0150, 0.0153, 0.0246, 0.0218, 0.0241,
         0.0317, 0.0282, 0.0249, 0.0169, 0.0402, 0.0182, 0.0174, 0.0316, 0.0335,
         0.0215, 0.0253, 0.0186, 0.0154]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 17
images/253
(64, 64, 3)
tensor([[0.0239, 0.0197, 0.0242, 0.0176, 0.0373, 0.0164, 0.0269, 0.0238, 0.0214,
         0.0229, 0.0152, 0.0258, 0.0403, 0.0536, 0.0335, 0.0134, 0.0215, 0.0435,
         0.0183, 0.0141, 0.0200, 0.0223, 0.0232, 0.0261, 0.0166, 0.0141, 0.0193,
         0.0322, 0.0321, 0.0298, 0.0119, 0.0329, 0.0288, 0.0191, 0.0289, 0.0383,
         0.0293, 0.0212, 0.0168, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 18
images/387
(64, 64, 3)
tensor([[0.0222, 0.0256, 0.0258, 0.0147, 0.0284, 0.0160, 0.0322, 0.0186, 0.0142,
         0.0157, 0.0155, 0.0301, 0.0529, 0.0283, 0.0185, 0.0192, 0.0213, 0.0405,
         0.0178, 0.0312, 0.0240, 0.0301, 0.0174, 0.0223, 0.0219, 0.0237, 0.0208,
         0.0367, 0.0260, 0.0227, 0.0200, 0.0410, 0.0255, 0.0202, 0.0213, 0.0292,
         0.0392, 0.0178, 0.0192, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 19
images/295
(64, 64, 3)
tensor([[0.0294, 0.0242, 0.0178, 0.0286, 0.0276, 0.0275, 0.0360, 0.0110, 0.0195,
         0.0239, 0.0154, 0.0305, 0.0410, 0.0429, 0.0215, 0.0175, 0.0189, 0.0491,
         0.0290, 0.0198, 0.0161, 0.0172, 0.0208, 0.0170, 0.0160, 0.0193, 0.0209,
         0.0300, 0.0369, 0.0287, 0.0142, 0.0386, 0.0215, 0.0247, 0.0291, 0.0305,
         0.0273, 0.0232, 0.0201, 0.0167]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 20
images/109
(64, 64, 3)
tensor([[0.0256, 0.0182, 0.0148, 0.0229, 0.0344, 0.0243, 0.0424, 0.0197, 0.0219,
         0.0151, 0.0186, 0.0257, 0.0410, 0.0241, 0.0364, 0.0197, 0.0183, 0.0315,
         0.0167, 0.0228, 0.0153, 0.0188, 0.0203, 0.0179, 0.0284, 0.0195, 0.0188,
         0.0284, 0.0212, 0.0229, 0.0274, 0.0328, 0.0305, 0.0220, 0.0253, 0.0525,
         0.0269, 0.0292, 0.0241, 0.0240]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 21
images/68
(64, 64, 3)
tensor([[0.0263, 0.0219, 0.0177, 0.0200, 0.0243, 0.0207, 0.0278, 0.0207, 0.0168,
         0.0196, 0.0195, 0.0295, 0.0499, 0.0416, 0.0180, 0.0161, 0.0207, 0.0295,
         0.0249, 0.0223, 0.0122, 0.0185, 0.0240, 0.0257, 0.0175, 0.0217, 0.0242,
         0.0374, 0.0337, 0.0198, 0.0215, 0.0270, 0.0281, 0.0202, 0.0350, 0.0457,
         0.0358, 0.0225, 0.0223, 0.0192]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/334
(64, 64, 3)
tensor([[0.0234, 0.0263, 0.0252, 0.0248, 0.0351, 0.0157, 0.0414, 0.0233, 0.0179,
         0.0234, 0.0129, 0.0225, 0.0316, 0.0478, 0.0247, 0.0173, 0.0241, 0.0529,
         0.0164, 0.0173, 0.0197, 0.0246, 0.0170, 0.0319, 0.0207, 0.0154, 0.0179,
         0.0204, 0.0245, 0.0237, 0.0165, 0.0228, 0.0236, 0.0434, 0.0266, 0.0453,
         0.0186, 0.0168, 0.0219, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 23
images/321
(64, 64, 3)
tensor([[0.0175, 0.0143, 0.0194, 0.0167, 0.0470, 0.0244, 0.0226, 0.0194, 0.0133,
         0.0283, 0.0187, 0.0248, 0.0437, 0.0366, 0.0305, 0.0160, 0.0308, 0.0323,
         0.0211, 0.0245, 0.0228, 0.0265, 0.0302, 0.0211, 0.0175, 0.0214, 0.0267,
         0.0248, 0.0236, 0.0201, 0.0139, 0.0261, 0.0201, 0.0242, 0.0375, 0.0302,
         0.0283, 0.0319, 0.0191, 0.0324]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 24
images/372
(64, 64, 3)
tensor([[0.0207, 0.0166, 0.0191, 0.0164, 0.0548, 0.0271, 0.0244, 0.0139, 0.0235,
         0.0209, 0.0188, 0.0393, 0.0405, 0.0285, 0.0332, 0.0200, 0.0167, 0.0214,
         0.0149, 0.0171, 0.0156, 0.0244, 0.0228, 0.0329, 0.0206, 0.0295, 0.0266,
         0.0412, 0.0205, 0.0253, 0.0288, 0.0339, 0.0276, 0.0208, 0.0306, 0.0359,
         0.0224, 0.0155, 0.0140, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 25
images/229
(64, 64, 3)
tensor([[0.0313, 0.0281, 0.0205, 0.0195, 0.0240, 0.0180, 0.0206, 0.0166, 0.0154,
         0.0219, 0.0228, 0.0263, 0.0363, 0.0295, 0.0165, 0.0211, 0.0127, 0.0391,
         0.0125, 0.0193, 0.0167, 0.0277, 0.0361, 0.0371, 0.0262, 0.0279, 0.0178,
         0.0360, 0.0259, 0.0355, 0.0241, 0.0541, 0.0259, 0.0193, 0.0170, 0.0332,
         0.0320, 0.0172, 0.0222, 0.0161]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 26
images/298
(64, 64, 3)
tensor([[0.0270, 0.0321, 0.0207, 0.0167, 0.0497, 0.0129, 0.0273, 0.0208, 0.0170,
         0.0335, 0.0148, 0.0400, 0.0219, 0.0345, 0.0248, 0.0174, 0.0162, 0.0274,
         0.0180, 0.0240, 0.0228, 0.0271, 0.0237, 0.0289, 0.0179, 0.0108, 0.0199,
         0.0391, 0.0470, 0.0304, 0.0224, 0.0182, 0.0350, 0.0212, 0.0233, 0.0226,
         0.0276, 0.0211, 0.0230, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 27
images/439
(64, 64, 3)
tensor([[0.0246, 0.0259, 0.0201, 0.0198, 0.0265, 0.0227, 0.0352, 0.0119, 0.0209,
         0.0183, 0.0221, 0.0227, 0.0481, 0.0233, 0.0237, 0.0241, 0.0292, 0.0356,
         0.0301, 0.0267, 0.0238, 0.0223, 0.0176, 0.0156, 0.0221, 0.0183, 0.0375,
         0.0210, 0.0261, 0.0226, 0.0188, 0.0324, 0.0231, 0.0244, 0.0238, 0.0427,
         0.0278, 0.0175, 0.0242, 0.0269]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 28
images/416
(64, 64, 3)
tensor([[0.0308, 0.0170, 0.0162, 0.0141, 0.0441, 0.0211, 0.0400, 0.0190, 0.0181,
         0.0167, 0.0197, 0.0238, 0.0554, 0.0280, 0.0228, 0.0105, 0.0214, 0.0316,
         0.0201, 0.0172, 0.0126, 0.0209, 0.0295, 0.0268, 0.0169, 0.0162, 0.0378,
         0.0290, 0.0289, 0.0182, 0.0272, 0.0393, 0.0254, 0.0222, 0.0360, 0.0335,
         0.0323, 0.0198, 0.0173, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 174, in <module>
    main()
  File "Torch_reinforce01.py", line 144, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: ''
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/262
(64, 64, 3)
2018-10-13 01:29:26.244 Python[9879:15730291] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0290, 0.0243, 0.0188, 0.0223, 0.0311, 0.0189, 0.0324, 0.0183, 0.0179,
         0.0201, 0.0190, 0.0222, 0.0385, 0.0230, 0.0333, 0.0256, 0.0213, 0.0280,
         0.0145, 0.0217, 0.0124, 0.0259, 0.0337, 0.0155, 0.0345, 0.0225, 0.0191,
         0.0307, 0.0308, 0.0202, 0.0179, 0.0276, 0.0177, 0.0316, 0.0233, 0.0295,
         0.0424, 0.0374, 0.0285, 0.0188]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/196
(64, 64, 3)
tensor([[0.0269, 0.0234, 0.0196, 0.0223, 0.0329, 0.0170, 0.0272, 0.0193, 0.0187,
         0.0170, 0.0169, 0.0273, 0.0243, 0.0345, 0.0266, 0.0194, 0.0271, 0.0318,
         0.0152, 0.0212, 0.0228, 0.0277, 0.0225, 0.0254, 0.0234, 0.0190, 0.0217,
         0.0400, 0.0295, 0.0195, 0.0158, 0.0432, 0.0225, 0.0340, 0.0184, 0.0375,
         0.0409, 0.0232, 0.0183, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/488
(64, 64, 3)
tensor([[0.0306, 0.0365, 0.0183, 0.0221, 0.0268, 0.0138, 0.0335, 0.0142, 0.0140,
         0.0196, 0.0196, 0.0341, 0.0289, 0.0415, 0.0218, 0.0155, 0.0325, 0.0330,
         0.0169, 0.0166, 0.0152, 0.0197, 0.0249, 0.0334, 0.0125, 0.0167, 0.0285,
         0.0266, 0.0476, 0.0190, 0.0227, 0.0269, 0.0283, 0.0263, 0.0214, 0.0314,
         0.0326, 0.0268, 0.0272, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 3
images/234
(64, 64, 3)
tensor([[0.0331, 0.0252, 0.0138, 0.0219, 0.0245, 0.0230, 0.0409, 0.0203, 0.0256,
         0.0125, 0.0351, 0.0260, 0.0384, 0.0409, 0.0255, 0.0229, 0.0143, 0.0525,
         0.0197, 0.0251, 0.0232, 0.0184, 0.0137, 0.0187, 0.0262, 0.0169, 0.0150,
         0.0314, 0.0312, 0.0165, 0.0239, 0.0178, 0.0232, 0.0242, 0.0254, 0.0303,
         0.0270, 0.0254, 0.0298, 0.0205]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 4
images/532
(64, 64, 3)
tensor([[0.0181, 0.0218, 0.0252, 0.0152, 0.0483, 0.0248, 0.0340, 0.0120, 0.0222,
         0.0255, 0.0162, 0.0392, 0.0400, 0.0457, 0.0280, 0.0172, 0.0201, 0.0427,
         0.0167, 0.0130, 0.0174, 0.0190, 0.0295, 0.0196, 0.0266, 0.0179, 0.0292,
         0.0359, 0.0355, 0.0251, 0.0117, 0.0305, 0.0208, 0.0232, 0.0306, 0.0211,
         0.0202, 0.0207, 0.0122, 0.0274]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 5
images/182
(64, 64, 3)
tensor([[0.0168, 0.0253, 0.0152, 0.0136, 0.0249, 0.0226, 0.0297, 0.0226, 0.0173,
         0.0221, 0.0247, 0.0409, 0.0321, 0.0299, 0.0278, 0.0275, 0.0206, 0.0370,
         0.0170, 0.0353, 0.0227, 0.0192, 0.0240, 0.0304, 0.0188, 0.0186, 0.0316,
         0.0279, 0.0458, 0.0263, 0.0175, 0.0332, 0.0299, 0.0240, 0.0227, 0.0354,
         0.0180, 0.0119, 0.0184, 0.0209]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 6
images/233
(64, 64, 3)
tensor([[0.0338, 0.0295, 0.0259, 0.0265, 0.0319, 0.0210, 0.0285, 0.0142, 0.0213,
         0.0220, 0.0174, 0.0238, 0.0358, 0.0250, 0.0381, 0.0163, 0.0150, 0.0333,
         0.0133, 0.0222, 0.0216, 0.0278, 0.0222, 0.0325, 0.0152, 0.0150, 0.0358,
         0.0372, 0.0318, 0.0221, 0.0241, 0.0279, 0.0234, 0.0244, 0.0203, 0.0313,
         0.0247, 0.0220, 0.0182, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 7
images/441
(64, 64, 3)
tensor([[0.0373, 0.0265, 0.0237, 0.0152, 0.0359, 0.0214, 0.0296, 0.0142, 0.0158,
         0.0204, 0.0195, 0.0416, 0.0428, 0.0257, 0.0203, 0.0265, 0.0212, 0.0246,
         0.0185, 0.0188, 0.0179, 0.0193, 0.0189, 0.0250, 0.0180, 0.0222, 0.0297,
         0.0454, 0.0390, 0.0229, 0.0201, 0.0288, 0.0217, 0.0348, 0.0243, 0.0281,
         0.0335, 0.0185, 0.0147, 0.0180]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/440
(64, 64, 3)
tensor([[0.0236, 0.0252, 0.0154, 0.0150, 0.0385, 0.0216, 0.0250, 0.0259, 0.0211,
         0.0233, 0.0160, 0.0344, 0.0469, 0.0299, 0.0262, 0.0253, 0.0382, 0.0278,
         0.0231, 0.0210, 0.0120, 0.0174, 0.0305, 0.0215, 0.0157, 0.0171, 0.0357,
         0.0231, 0.0221, 0.0223, 0.0112, 0.0323, 0.0275, 0.0234, 0.0278, 0.0363,
         0.0270, 0.0208, 0.0176, 0.0351]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 9
images/395
(64, 64, 3)
tensor([[0.0388, 0.0356, 0.0101, 0.0191, 0.0283, 0.0224, 0.0394, 0.0240, 0.0133,
         0.0192, 0.0186, 0.0310, 0.0425, 0.0322, 0.0202, 0.0141, 0.0268, 0.0426,
         0.0137, 0.0128, 0.0167, 0.0171, 0.0148, 0.0321, 0.0169, 0.0125, 0.0329,
         0.0303, 0.0671, 0.0267, 0.0256, 0.0275, 0.0222, 0.0180, 0.0187, 0.0379,
         0.0201, 0.0163, 0.0183, 0.0240]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 10
images/188
(64, 64, 3)
tensor([[0.0259, 0.0251, 0.0155, 0.0203, 0.0366, 0.0182, 0.0327, 0.0134, 0.0216,
         0.0244, 0.0180, 0.0313, 0.0408, 0.0321, 0.0319, 0.0099, 0.0193, 0.0349,
         0.0183, 0.0211, 0.0118, 0.0273, 0.0298, 0.0237, 0.0113, 0.0130, 0.0371,
         0.0235, 0.0275, 0.0254, 0.0165, 0.0279, 0.0225, 0.0257, 0.0314, 0.0332,
         0.0265, 0.0290, 0.0222, 0.0432]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/372
(64, 64, 3)
tensor([[0.0164, 0.0277, 0.0314, 0.0144, 0.0501, 0.0329, 0.0200, 0.0209, 0.0242,
         0.0273, 0.0169, 0.0244, 0.0294, 0.0242, 0.0282, 0.0176, 0.0186, 0.0314,
         0.0134, 0.0168, 0.0153, 0.0255, 0.0269, 0.0404, 0.0194, 0.0186, 0.0218,
         0.0357, 0.0303, 0.0418, 0.0193, 0.0243, 0.0348, 0.0179, 0.0244, 0.0220,
         0.0264, 0.0213, 0.0192, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/89
(64, 64, 3)
tensor([[0.0308, 0.0330, 0.0219, 0.0217, 0.0385, 0.0158, 0.0270, 0.0106, 0.0219,
         0.0183, 0.0206, 0.0246, 0.0347, 0.0353, 0.0180, 0.0217, 0.0236, 0.0260,
         0.0146, 0.0229, 0.0165, 0.0302, 0.0299, 0.0236, 0.0218, 0.0164, 0.0246,
         0.0379, 0.0486, 0.0275, 0.0137, 0.0220, 0.0219, 0.0206, 0.0199, 0.0190,
         0.0289, 0.0272, 0.0262, 0.0420]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 13
images/176
(64, 64, 3)
tensor([[0.0225, 0.0287, 0.0145, 0.0140, 0.0294, 0.0307, 0.0491, 0.0193, 0.0155,
         0.0180, 0.0268, 0.0281, 0.0549, 0.0254, 0.0173, 0.0286, 0.0174, 0.0293,
         0.0169, 0.0179, 0.0309, 0.0317, 0.0171, 0.0242, 0.0219, 0.0134, 0.0187,
         0.0455, 0.0291, 0.0121, 0.0149, 0.0289, 0.0366, 0.0123, 0.0290, 0.0319,
         0.0281, 0.0108, 0.0325, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 14
images/586
(64, 64, 3)
tensor([[0.0396, 0.0214, 0.0135, 0.0099, 0.0252, 0.0185, 0.0374, 0.0218, 0.0134,
         0.0182, 0.0179, 0.0324, 0.0332, 0.0290, 0.0457, 0.0217, 0.0221, 0.0461,
         0.0152, 0.0199, 0.0165, 0.0166, 0.0265, 0.0155, 0.0272, 0.0156, 0.0388,
         0.0236, 0.0370, 0.0345, 0.0201, 0.0419, 0.0316, 0.0193, 0.0185, 0.0149,
         0.0199, 0.0131, 0.0314, 0.0350]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 15
images/487
(64, 64, 3)
tensor([[0.0378, 0.0263, 0.0166, 0.0161, 0.0410, 0.0201, 0.0328, 0.0165, 0.0148,
         0.0259, 0.0198, 0.0286, 0.0376, 0.0346, 0.0244, 0.0167, 0.0181, 0.0304,
         0.0168, 0.0218, 0.0172, 0.0265, 0.0303, 0.0210, 0.0265, 0.0184, 0.0193,
         0.0322, 0.0250, 0.0331, 0.0232, 0.0316, 0.0222, 0.0131, 0.0160, 0.0413,
         0.0386, 0.0153, 0.0298, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 16
images/367
(64, 64, 3)
tensor([[0.0235, 0.0281, 0.0134, 0.0155, 0.0370, 0.0183, 0.0310, 0.0139, 0.0219,
         0.0224, 0.0215, 0.0200, 0.0406, 0.0295, 0.0304, 0.0198, 0.0214, 0.0573,
         0.0198, 0.0288, 0.0160, 0.0166, 0.0200, 0.0205, 0.0217, 0.0240, 0.0275,
         0.0371, 0.0277, 0.0226, 0.0187, 0.0366, 0.0242, 0.0255, 0.0293, 0.0475,
         0.0163, 0.0170, 0.0199, 0.0174]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 17
images/148
(64, 64, 3)
tensor([[0.0226, 0.0236, 0.0218, 0.0174, 0.0297, 0.0152, 0.0313, 0.0180, 0.0226,
         0.0304, 0.0175, 0.0276, 0.0512, 0.0323, 0.0253, 0.0155, 0.0229, 0.0616,
         0.0168, 0.0148, 0.0158, 0.0166, 0.0195, 0.0238, 0.0265, 0.0187, 0.0203,
         0.0376, 0.0225, 0.0283, 0.0185, 0.0341, 0.0225, 0.0224, 0.0320, 0.0357,
         0.0256, 0.0182, 0.0173, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 18
images/276
(64, 64, 3)
tensor([[0.0204, 0.0256, 0.0147, 0.0227, 0.0261, 0.0153, 0.0386, 0.0226, 0.0137,
         0.0169, 0.0196, 0.0248, 0.0623, 0.0379, 0.0147, 0.0191, 0.0174, 0.0341,
         0.0185, 0.0338, 0.0220, 0.0271, 0.0203, 0.0195, 0.0192, 0.0162, 0.0249,
         0.0380, 0.0355, 0.0212, 0.0186, 0.0304, 0.0252, 0.0209, 0.0200, 0.0317,
         0.0373, 0.0218, 0.0223, 0.0294]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 19
images/190
(64, 64, 3)
tensor([[0.0278, 0.0247, 0.0163, 0.0266, 0.0297, 0.0301, 0.0326, 0.0241, 0.0161,
         0.0172, 0.0165, 0.0232, 0.0453, 0.0307, 0.0157, 0.0184, 0.0260, 0.0560,
         0.0246, 0.0208, 0.0160, 0.0119, 0.0146, 0.0190, 0.0166, 0.0164, 0.0251,
         0.0233, 0.0350, 0.0224, 0.0214, 0.0314, 0.0332, 0.0197, 0.0344, 0.0287,
         0.0291, 0.0281, 0.0256, 0.0257]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 20
images/87
(64, 64, 3)
tensor([[0.0249, 0.0222, 0.0193, 0.0224, 0.0297, 0.0177, 0.0357, 0.0141, 0.0174,
         0.0164, 0.0234, 0.0267, 0.0334, 0.0224, 0.0320, 0.0233, 0.0176, 0.0319,
         0.0173, 0.0202, 0.0167, 0.0205, 0.0220, 0.0248, 0.0225, 0.0302, 0.0226,
         0.0442, 0.0311, 0.0261, 0.0304, 0.0261, 0.0277, 0.0320, 0.0211, 0.0336,
         0.0277, 0.0247, 0.0165, 0.0315]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 21
images/443
(64, 64, 3)
tensor([[0.0356, 0.0213, 0.0200, 0.0172, 0.0207, 0.0194, 0.0389, 0.0219, 0.0242,
         0.0170, 0.0203, 0.0336, 0.0473, 0.0331, 0.0208, 0.0151, 0.0253, 0.0234,
         0.0210, 0.0160, 0.0167, 0.0173, 0.0171, 0.0257, 0.0221, 0.0242, 0.0251,
         0.0262, 0.0350, 0.0175, 0.0250, 0.0295, 0.0206, 0.0198, 0.0257, 0.0364,
         0.0389, 0.0186, 0.0323, 0.0340]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/207
(64, 64, 3)
tensor([[0.0321, 0.0212, 0.0147, 0.0228, 0.0359, 0.0153, 0.0329, 0.0190, 0.0122,
         0.0205, 0.0122, 0.0213, 0.0445, 0.0292, 0.0151, 0.0149, 0.0336, 0.0664,
         0.0160, 0.0152, 0.0166, 0.0231, 0.0183, 0.0360, 0.0172, 0.0180, 0.0222,
         0.0262, 0.0499, 0.0204, 0.0174, 0.0230, 0.0212, 0.0248, 0.0301, 0.0439,
         0.0192, 0.0195, 0.0266, 0.0313]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 23
images/227
(64, 64, 3)
tensor([[0.0191, 0.0302, 0.0174, 0.0171, 0.0361, 0.0286, 0.0242, 0.0214, 0.0173,
         0.0316, 0.0157, 0.0372, 0.0421, 0.0319, 0.0268, 0.0165, 0.0239, 0.0252,
         0.0265, 0.0199, 0.0228, 0.0253, 0.0250, 0.0251, 0.0189, 0.0232, 0.0263,
         0.0295, 0.0313, 0.0244, 0.0226, 0.0265, 0.0178, 0.0322, 0.0235, 0.0268,
         0.0278, 0.0173, 0.0215, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 1
Session Number: 24
images/73
(64, 64, 3)
tensor([[0.0322, 0.0143, 0.0133, 0.0143, 0.0496, 0.0210, 0.0328, 0.0171, 0.0246,
         0.0177, 0.0128, 0.0404, 0.0359, 0.0301, 0.0268, 0.0202, 0.0200, 0.0347,
         0.0164, 0.0178, 0.0179, 0.0181, 0.0241, 0.0259, 0.0240, 0.0304, 0.0241,
         0.0362, 0.0345, 0.0314, 0.0291, 0.0301, 0.0211, 0.0237, 0.0318, 0.0304,
         0.0245, 0.0145, 0.0177, 0.0186]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/244
(64, 64, 3)
tensor([[0.0308, 0.0259, 0.0175, 0.0217, 0.0276, 0.0219, 0.0258, 0.0170, 0.0160,
         0.0203, 0.0207, 0.0323, 0.0693, 0.0217, 0.0198, 0.0177, 0.0231, 0.0316,
         0.0158, 0.0220, 0.0242, 0.0178, 0.0308, 0.0276, 0.0281, 0.0282, 0.0244,
         0.0432, 0.0243, 0.0353, 0.0150, 0.0270, 0.0273, 0.0190, 0.0144, 0.0232,
         0.0324, 0.0144, 0.0250, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 26
images/88
(64, 64, 3)
tensor([[0.0297, 0.0314, 0.0147, 0.0200, 0.0407, 0.0152, 0.0244, 0.0095, 0.0155,
         0.0309, 0.0153, 0.0469, 0.0325, 0.0407, 0.0319, 0.0146, 0.0169, 0.0270,
         0.0123, 0.0252, 0.0248, 0.0379, 0.0314, 0.0191, 0.0173, 0.0139, 0.0185,
         0.0502, 0.0374, 0.0277, 0.0184, 0.0190, 0.0250, 0.0223, 0.0164, 0.0372,
         0.0399, 0.0139, 0.0123, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 27
images/482
(64, 64, 3)
tensor([[0.0255, 0.0255, 0.0110, 0.0194, 0.0281, 0.0203, 0.0333, 0.0163, 0.0218,
         0.0185, 0.0247, 0.0261, 0.0457, 0.0261, 0.0301, 0.0226, 0.0340, 0.0281,
         0.0297, 0.0232, 0.0166, 0.0235, 0.0250, 0.0153, 0.0186, 0.0239, 0.0370,
         0.0342, 0.0241, 0.0187, 0.0136, 0.0254, 0.0228, 0.0219, 0.0318, 0.0331,
         0.0250, 0.0234, 0.0197, 0.0363]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 28
images/128
(64, 64, 3)
tensor([[0.0268, 0.0216, 0.0166, 0.0172, 0.0406, 0.0194, 0.0572, 0.0192, 0.0182,
         0.0197, 0.0205, 0.0365, 0.0557, 0.0379, 0.0221, 0.0102, 0.0146, 0.0287,
         0.0173, 0.0222, 0.0141, 0.0169, 0.0216, 0.0241, 0.0130, 0.0171, 0.0310,
         0.0218, 0.0161, 0.0211, 0.0190, 0.0295, 0.0280, 0.0289, 0.0426, 0.0328,
         0.0358, 0.0228, 0.0165, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 29
images/306
(64, 64, 3)
tensor([[0.0432, 0.0155, 0.0208, 0.0293, 0.0319, 0.0262, 0.0272, 0.0164, 0.0114,
         0.0216, 0.0207, 0.0243, 0.0322, 0.0231, 0.0213, 0.0232, 0.0187, 0.0324,
         0.0163, 0.0285, 0.0233, 0.0300, 0.0445, 0.0229, 0.0206, 0.0187, 0.0209,
         0.0342, 0.0224, 0.0199, 0.0228, 0.0401, 0.0298, 0.0216, 0.0212, 0.0290,
         0.0298, 0.0151, 0.0211, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 30
images/532
(64, 64, 3)
tensor([[0.0326, 0.0200, 0.0160, 0.0170, 0.0394, 0.0177, 0.0258, 0.0191, 0.0171,
         0.0198, 0.0189, 0.0282, 0.0304, 0.0421, 0.0170, 0.0184, 0.0136, 0.0449,
         0.0234, 0.0263, 0.0242, 0.0308, 0.0178, 0.0253, 0.0392, 0.0227, 0.0197,
         0.0499, 0.0387, 0.0227, 0.0214, 0.0317, 0.0197, 0.0222, 0.0190, 0.0241,
         0.0283, 0.0199, 0.0142, 0.0210]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 31
images/427
(64, 64, 3)
tensor([[0.0355, 0.0303, 0.0270, 0.0112, 0.0241, 0.0257, 0.0329, 0.0227, 0.0136,
         0.0195, 0.0243, 0.0578, 0.0225, 0.0247, 0.0169, 0.0148, 0.0164, 0.0442,
         0.0184, 0.0155, 0.0150, 0.0253, 0.0222, 0.0208, 0.0167, 0.0198, 0.0200,
         0.0299, 0.0494, 0.0323, 0.0175, 0.0352, 0.0242, 0.0184, 0.0274, 0.0229,
         0.0303, 0.0286, 0.0169, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 32
images/574
(64, 64, 3)
tensor([[0.0271, 0.0300, 0.0187, 0.0121, 0.0281, 0.0287, 0.0358, 0.0150, 0.0139,
         0.0150, 0.0240, 0.0296, 0.0338, 0.0201, 0.0396, 0.0204, 0.0238, 0.0396,
         0.0203, 0.0208, 0.0160, 0.0352, 0.0178, 0.0287, 0.0476, 0.0222, 0.0263,
         0.0206, 0.0228, 0.0357, 0.0236, 0.0232, 0.0332, 0.0229, 0.0252, 0.0201,
         0.0190, 0.0233, 0.0191, 0.0210]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 33
images/231
(64, 64, 3)
tensor([[0.0227, 0.0262, 0.0230, 0.0241, 0.0471, 0.0256, 0.0422, 0.0182, 0.0137,
         0.0183, 0.0168, 0.0297, 0.0448, 0.0212, 0.0238, 0.0110, 0.0121, 0.0348,
         0.0289, 0.0176, 0.0179, 0.0229, 0.0338, 0.0195, 0.0259, 0.0208, 0.0215,
         0.0296, 0.0448, 0.0229, 0.0188, 0.0412, 0.0329, 0.0222, 0.0185, 0.0137,
         0.0284, 0.0187, 0.0230, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 34
images/63
(64, 64, 3)
tensor([[0.0304, 0.0366, 0.0150, 0.0177, 0.0395, 0.0158, 0.0192, 0.0104, 0.0116,
         0.0189, 0.0151, 0.0308, 0.0272, 0.0235, 0.0251, 0.0201, 0.0210, 0.0456,
         0.0208, 0.0240, 0.0190, 0.0362, 0.0187, 0.0233, 0.0242, 0.0224, 0.0348,
         0.0437, 0.0295, 0.0272, 0.0134, 0.0420, 0.0235, 0.0239, 0.0208, 0.0310,
         0.0244, 0.0203, 0.0300, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 35
images/180
(64, 64, 3)
tensor([[0.0243, 0.0288, 0.0252, 0.0128, 0.0272, 0.0249, 0.0348, 0.0237, 0.0182,
         0.0194, 0.0172, 0.0275, 0.0414, 0.0466, 0.0242, 0.0162, 0.0189, 0.0360,
         0.0182, 0.0274, 0.0192, 0.0215, 0.0181, 0.0268, 0.0159, 0.0120, 0.0369,
         0.0300, 0.0583, 0.0237, 0.0232, 0.0192, 0.0242, 0.0208, 0.0193, 0.0217,
         0.0289, 0.0149, 0.0171, 0.0352]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 36
images/521
(64, 64, 3)
tensor([[0.0324, 0.0242, 0.0126, 0.0207, 0.0314, 0.0238, 0.0350, 0.0145, 0.0160,
         0.0148, 0.0183, 0.0222, 0.0258, 0.0315, 0.0261, 0.0149, 0.0166, 0.0562,
         0.0111, 0.0310, 0.0153, 0.0260, 0.0204, 0.0161, 0.0296, 0.0282, 0.0149,
         0.0286, 0.0347, 0.0304, 0.0293, 0.0357, 0.0196, 0.0230, 0.0329, 0.0398,
         0.0248, 0.0284, 0.0181, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 0
Session Number: 37
images/175
(64, 64, 3)
tensor([[0.0321, 0.0277, 0.0204, 0.0150, 0.0232, 0.0217, 0.0256, 0.0141, 0.0170,
         0.0172, 0.0261, 0.0287, 0.0514, 0.0384, 0.0204, 0.0233, 0.0197, 0.0329,
         0.0191, 0.0156, 0.0252, 0.0230, 0.0193, 0.0248, 0.0208, 0.0228, 0.0342,
         0.0425, 0.0382, 0.0357, 0.0183, 0.0208, 0.0330, 0.0155, 0.0217, 0.0266,
         0.0249, 0.0152, 0.0214, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 38
images/471
(64, 64, 3)
tensor([[0.0194, 0.0200, 0.0231, 0.0176, 0.0325, 0.0201, 0.0448, 0.0200, 0.0138,
         0.0161, 0.0161, 0.0340, 0.0358, 0.0285, 0.0275, 0.0182, 0.0153, 0.0442,
         0.0183, 0.0204, 0.0163, 0.0238, 0.0188, 0.0230, 0.0263, 0.0170, 0.0210,
         0.0347, 0.0387, 0.0228, 0.0269, 0.0336, 0.0250, 0.0179, 0.0442, 0.0277,
         0.0353, 0.0181, 0.0228, 0.0201]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 39
images/460
(64, 64, 3)
tensor([[0.0342, 0.0164, 0.0220, 0.0192, 0.0359, 0.0217, 0.0327, 0.0167, 0.0157,
         0.0289, 0.0172, 0.0275, 0.0495, 0.0451, 0.0221, 0.0167, 0.0182, 0.0467,
         0.0199, 0.0132, 0.0244, 0.0245, 0.0191, 0.0146, 0.0249, 0.0159, 0.0193,
         0.0428, 0.0405, 0.0195, 0.0174, 0.0262, 0.0314, 0.0169, 0.0216, 0.0332,
         0.0251, 0.0153, 0.0257, 0.0223]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 40
images/578
(64, 64, 3)
tensor([[0.0299, 0.0327, 0.0148, 0.0242, 0.0271, 0.0256, 0.0384, 0.0137, 0.0141,
         0.0169, 0.0235, 0.0236, 0.0313, 0.0361, 0.0286, 0.0176, 0.0197, 0.0327,
         0.0208, 0.0205, 0.0220, 0.0246, 0.0281, 0.0190, 0.0279, 0.0277, 0.0231,
         0.0301, 0.0214, 0.0267, 0.0164, 0.0385, 0.0303, 0.0243, 0.0339, 0.0269,
         0.0240, 0.0228, 0.0183, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 41
images/25
(64, 64, 3)
tensor([[0.0259, 0.0287, 0.0126, 0.0273, 0.0291, 0.0181, 0.0327, 0.0220, 0.0262,
         0.0137, 0.0236, 0.0168, 0.0375, 0.0371, 0.0258, 0.0334, 0.0318, 0.0416,
         0.0228, 0.0121, 0.0266, 0.0198, 0.0159, 0.0174, 0.0253, 0.0182, 0.0234,
         0.0219, 0.0380, 0.0300, 0.0269, 0.0237, 0.0295, 0.0259, 0.0198, 0.0236,
         0.0345, 0.0162, 0.0204, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 42
images/70
(64, 64, 3)
tensor([[0.0233, 0.0259, 0.0215, 0.0211, 0.0325, 0.0182, 0.0252, 0.0241, 0.0223,
         0.0189, 0.0201, 0.0366, 0.0350, 0.0251, 0.0224, 0.0318, 0.0192, 0.0336,
         0.0162, 0.0258, 0.0222, 0.0220, 0.0283, 0.0159, 0.0181, 0.0147, 0.0355,
         0.0458, 0.0243, 0.0237, 0.0163, 0.0330, 0.0213, 0.0231, 0.0325, 0.0322,
         0.0231, 0.0167, 0.0225, 0.0300]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 43
images/462
(64, 64, 3)
tensor([[0.0245, 0.0172, 0.0223, 0.0188, 0.0265, 0.0283, 0.0404, 0.0185, 0.0160,
         0.0332, 0.0191, 0.0282, 0.0392, 0.0315, 0.0236, 0.0214, 0.0133, 0.0606,
         0.0214, 0.0255, 0.0124, 0.0256, 0.0283, 0.0162, 0.0184, 0.0207, 0.0350,
         0.0334, 0.0307, 0.0156, 0.0254, 0.0295, 0.0189, 0.0228, 0.0151, 0.0228,
         0.0222, 0.0200, 0.0286, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/454
(64, 64, 3)
tensor([[0.0243, 0.0435, 0.0154, 0.0209, 0.0294, 0.0245, 0.0383, 0.0175, 0.0158,
         0.0151, 0.0211, 0.0230, 0.0426, 0.0339, 0.0271, 0.0168, 0.0271, 0.0353,
         0.0186, 0.0263, 0.0195, 0.0282, 0.0225, 0.0220, 0.0210, 0.0163, 0.0317,
         0.0313, 0.0296, 0.0194, 0.0194, 0.0274, 0.0303, 0.0290, 0.0175, 0.0235,
         0.0180, 0.0327, 0.0250, 0.0193]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 45
images/280
(64, 64, 3)
tensor([[0.0330, 0.0147, 0.0168, 0.0216, 0.0294, 0.0164, 0.0161, 0.0239, 0.0182,
         0.0123, 0.0197, 0.0425, 0.0600, 0.0249, 0.0279, 0.0229, 0.0151, 0.0286,
         0.0188, 0.0214, 0.0146, 0.0152, 0.0180, 0.0191, 0.0153, 0.0205, 0.0313,
         0.0401, 0.0341, 0.0287, 0.0165, 0.0427, 0.0232, 0.0436, 0.0211, 0.0408,
         0.0301, 0.0186, 0.0158, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 46
images/135
(64, 64, 3)
tensor([[0.0230, 0.0329, 0.0179, 0.0170, 0.0208, 0.0183, 0.0327, 0.0150, 0.0272,
         0.0189, 0.0239, 0.0319, 0.0513, 0.0307, 0.0349, 0.0180, 0.0249, 0.0222,
         0.0129, 0.0216, 0.0338, 0.0204, 0.0297, 0.0153, 0.0186, 0.0114, 0.0364,
         0.0311, 0.0265, 0.0245, 0.0227, 0.0323, 0.0354, 0.0296, 0.0237, 0.0176,
         0.0252, 0.0224, 0.0180, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 47
images/320
(64, 64, 3)
tensor([[0.0314, 0.0278, 0.0194, 0.0170, 0.0190, 0.0254, 0.0355, 0.0223, 0.0188,
         0.0160, 0.0249, 0.0326, 0.0395, 0.0338, 0.0259, 0.0222, 0.0215, 0.0324,
         0.0178, 0.0200, 0.0166, 0.0205, 0.0175, 0.0192, 0.0322, 0.0211, 0.0182,
         0.0270, 0.0376, 0.0224, 0.0170, 0.0253, 0.0230, 0.0279, 0.0262, 0.0361,
         0.0273, 0.0293, 0.0173, 0.0351]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 0
Session Number: 48
images/272
(64, 64, 3)
tensor([[0.0390, 0.0182, 0.0196, 0.0197, 0.0321, 0.0246, 0.0331, 0.0172, 0.0180,
         0.0186, 0.0200, 0.0471, 0.0333, 0.0330, 0.0182, 0.0227, 0.0195, 0.0405,
         0.0191, 0.0217, 0.0173, 0.0229, 0.0224, 0.0202, 0.0185, 0.0265, 0.0271,
         0.0298, 0.0328, 0.0246, 0.0175, 0.0236, 0.0172, 0.0234, 0.0211, 0.0439,
         0.0295, 0.0130, 0.0249, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 49
images/27
(64, 64, 3)
tensor([[0.0233, 0.0254, 0.0209, 0.0196, 0.0197, 0.0210, 0.0425, 0.0163, 0.0139,
         0.0237, 0.0181, 0.0348, 0.0470, 0.0269, 0.0212, 0.0220, 0.0155, 0.0241,
         0.0205, 0.0265, 0.0204, 0.0292, 0.0212, 0.0228, 0.0207, 0.0167, 0.0249,
         0.0352, 0.0322, 0.0165, 0.0265, 0.0318, 0.0405, 0.0211, 0.0246, 0.0241,
         0.0303, 0.0200, 0.0319, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 50
images/18
(64, 64, 3)
tensor([[0.0451, 0.0269, 0.0173, 0.0156, 0.0467, 0.0184, 0.0429, 0.0172, 0.0159,
         0.0180, 0.0221, 0.0288, 0.0251, 0.0349, 0.0226, 0.0183, 0.0184, 0.0296,
         0.0163, 0.0160, 0.0266, 0.0275, 0.0202, 0.0282, 0.0266, 0.0160, 0.0221,
         0.0238, 0.0291, 0.0271, 0.0129, 0.0320, 0.0339, 0.0209, 0.0199, 0.0285,
         0.0287, 0.0252, 0.0323, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 51
images/84
(64, 64, 3)
tensor([[0.0383, 0.0359, 0.0268, 0.0253, 0.0299, 0.0146, 0.0207, 0.0187, 0.0162,
         0.0187, 0.0146, 0.0337, 0.0341, 0.0271, 0.0177, 0.0193, 0.0174, 0.0256,
         0.0237, 0.0240, 0.0187, 0.0303, 0.0235, 0.0279, 0.0146, 0.0195, 0.0277,
         0.0434, 0.0322, 0.0180, 0.0174, 0.0251, 0.0319, 0.0270, 0.0232, 0.0245,
         0.0325, 0.0225, 0.0167, 0.0412]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/128
(64, 64, 3)
tensor([[0.0348, 0.0217, 0.0222, 0.0192, 0.0433, 0.0227, 0.0323, 0.0216, 0.0156,
         0.0215, 0.0185, 0.0272, 0.0372, 0.0361, 0.0281, 0.0262, 0.0153, 0.0215,
         0.0158, 0.0188, 0.0194, 0.0217, 0.0161, 0.0191, 0.0252, 0.0228, 0.0246,
         0.0269, 0.0295, 0.0289, 0.0255, 0.0226, 0.0285, 0.0215, 0.0389, 0.0222,
         0.0420, 0.0153, 0.0261, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 53
images/472
(64, 64, 3)
tensor([[0.0207, 0.0314, 0.0170, 0.0211, 0.0361, 0.0149, 0.0433, 0.0202, 0.0273,
         0.0364, 0.0171, 0.0300, 0.0371, 0.0365, 0.0276, 0.0199, 0.0169, 0.0330,
         0.0163, 0.0205, 0.0226, 0.0238, 0.0157, 0.0203, 0.0214, 0.0211, 0.0191,
         0.0344, 0.0221, 0.0168, 0.0104, 0.0208, 0.0457, 0.0276, 0.0297, 0.0160,
         0.0379, 0.0159, 0.0156, 0.0398]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 1
Session Number: 54
images/93
(64, 64, 3)
tensor([[0.0259, 0.0250, 0.0168, 0.0173, 0.0279, 0.0100, 0.0292, 0.0166, 0.0238,
         0.0141, 0.0230, 0.0233, 0.0543, 0.0407, 0.0241, 0.0169, 0.0223, 0.0418,
         0.0220, 0.0258, 0.0167, 0.0299, 0.0213, 0.0171, 0.0214, 0.0148, 0.0220,
         0.0267, 0.0347, 0.0295, 0.0311, 0.0204, 0.0348, 0.0193, 0.0269, 0.0413,
         0.0173, 0.0203, 0.0228, 0.0312]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 55
images/198
(64, 64, 3)
tensor([[0.0343, 0.0204, 0.0168, 0.0224, 0.0353, 0.0182, 0.0430, 0.0182, 0.0201,
         0.0181, 0.0168, 0.0262, 0.0404, 0.0352, 0.0273, 0.0155, 0.0199, 0.0535,
         0.0154, 0.0243, 0.0209, 0.0352, 0.0130, 0.0165, 0.0162, 0.0114, 0.0232,
         0.0373, 0.0344, 0.0298, 0.0219, 0.0214, 0.0388, 0.0235, 0.0267, 0.0217,
         0.0190, 0.0301, 0.0147, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 56
images/339
(64, 64, 3)
tensor([[0.0296, 0.0329, 0.0187, 0.0163, 0.0420, 0.0198, 0.0258, 0.0151, 0.0164,
         0.0279, 0.0216, 0.0186, 0.0459, 0.0385, 0.0260, 0.0228, 0.0227, 0.0363,
         0.0278, 0.0206, 0.0226, 0.0267, 0.0192, 0.0192, 0.0266, 0.0170, 0.0341,
         0.0210, 0.0311, 0.0280, 0.0147, 0.0275, 0.0263, 0.0227, 0.0266, 0.0215,
         0.0271, 0.0195, 0.0230, 0.0204]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 57
images/19
(64, 64, 3)
tensor([[0.0250, 0.0365, 0.0185, 0.0192, 0.0244, 0.0264, 0.0315, 0.0209, 0.0171,
         0.0158, 0.0309, 0.0235, 0.0512, 0.0228, 0.0227, 0.0195, 0.0209, 0.0383,
         0.0232, 0.0226, 0.0193, 0.0183, 0.0245, 0.0189, 0.0297, 0.0247, 0.0217,
         0.0203, 0.0326, 0.0258, 0.0186, 0.0373, 0.0282, 0.0281, 0.0216, 0.0299,
         0.0342, 0.0190, 0.0228, 0.0136]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 58
images/6
(64, 64, 3)
tensor([[0.0397, 0.0278, 0.0154, 0.0224, 0.0297, 0.0147, 0.0333, 0.0178, 0.0132,
         0.0166, 0.0167, 0.0347, 0.0527, 0.0251, 0.0262, 0.0145, 0.0179, 0.0553,
         0.0195, 0.0262, 0.0121, 0.0147, 0.0229, 0.0138, 0.0159, 0.0186, 0.0322,
         0.0354, 0.0406, 0.0303, 0.0176, 0.0117, 0.0234, 0.0214, 0.0231, 0.0287,
         0.0373, 0.0254, 0.0288, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 59
images/537
(64, 64, 3)
tensor([[0.0278, 0.0250, 0.0189, 0.0272, 0.0386, 0.0129, 0.0282, 0.0191, 0.0196,
         0.0189, 0.0318, 0.0234, 0.0404, 0.0341, 0.0191, 0.0126, 0.0195, 0.0297,
         0.0214, 0.0249, 0.0143, 0.0237, 0.0171, 0.0254, 0.0162, 0.0189, 0.0175,
         0.0357, 0.0338, 0.0234, 0.0173, 0.0276, 0.0274, 0.0301, 0.0240, 0.0389,
         0.0319, 0.0177, 0.0401, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 60
images/11
(64, 64, 3)
tensor([[0.0290, 0.0192, 0.0220, 0.0284, 0.0239, 0.0176, 0.0275, 0.0211, 0.0149,
         0.0142, 0.0244, 0.0451, 0.0323, 0.0241, 0.0206, 0.0153, 0.0156, 0.0457,
         0.0191, 0.0229, 0.0161, 0.0268, 0.0232, 0.0246, 0.0225, 0.0234, 0.0235,
         0.0374, 0.0560, 0.0166, 0.0129, 0.0343, 0.0273, 0.0260, 0.0180, 0.0218,
         0.0390, 0.0148, 0.0204, 0.0326]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 61
images/140
(64, 64, 3)
tensor([[0.0332, 0.0273, 0.0281, 0.0191, 0.0293, 0.0155, 0.0479, 0.0256, 0.0245,
         0.0253, 0.0341, 0.0343, 0.0387, 0.0295, 0.0318, 0.0122, 0.0233, 0.0283,
         0.0218, 0.0162, 0.0183, 0.0277, 0.0179, 0.0259, 0.0130, 0.0165, 0.0225,
         0.0203, 0.0234, 0.0222, 0.0151, 0.0356, 0.0288, 0.0158, 0.0176, 0.0333,
         0.0240, 0.0146, 0.0315, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 62
images/214
(64, 64, 3)
tensor([[0.0338, 0.0215, 0.0233, 0.0172, 0.0240, 0.0207, 0.0373, 0.0136, 0.0233,
         0.0136, 0.0196, 0.0359, 0.0341, 0.0216, 0.0393, 0.0204, 0.0232, 0.0267,
         0.0165, 0.0199, 0.0146, 0.0325, 0.0330, 0.0182, 0.0304, 0.0233, 0.0246,
         0.0403, 0.0320, 0.0196, 0.0178, 0.0202, 0.0330, 0.0294, 0.0210, 0.0228,
         0.0199, 0.0241, 0.0267, 0.0310]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 63
images/336
(64, 64, 3)
tensor([[0.0216, 0.0328, 0.0096, 0.0206, 0.0256, 0.0205, 0.0325, 0.0110, 0.0259,
         0.0184, 0.0169, 0.0321, 0.0447, 0.0283, 0.0236, 0.0259, 0.0179, 0.0470,
         0.0317, 0.0275, 0.0127, 0.0280, 0.0190, 0.0150, 0.0323, 0.0144, 0.0330,
         0.0369, 0.0363, 0.0217, 0.0215, 0.0196, 0.0201, 0.0201, 0.0237, 0.0314,
         0.0221, 0.0175, 0.0258, 0.0345]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 64
images/253
(64, 64, 3)
tensor([[0.0387, 0.0229, 0.0175, 0.0129, 0.0400, 0.0216, 0.0294, 0.0158, 0.0177,
         0.0198, 0.0205, 0.0358, 0.0317, 0.0339, 0.0298, 0.0150, 0.0213, 0.0279,
         0.0168, 0.0276, 0.0198, 0.0273, 0.0231, 0.0292, 0.0260, 0.0259, 0.0196,
         0.0341, 0.0408, 0.0207, 0.0168, 0.0267, 0.0252, 0.0131, 0.0198, 0.0435,
         0.0170, 0.0233, 0.0236, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 65
images/508
(64, 64, 3)
tensor([[0.0274, 0.0347, 0.0111, 0.0162, 0.0489, 0.0250, 0.0207, 0.0147, 0.0117,
         0.0201, 0.0143, 0.0440, 0.0460, 0.0319, 0.0258, 0.0204, 0.0203, 0.0227,
         0.0145, 0.0277, 0.0216, 0.0324, 0.0212, 0.0274, 0.0225, 0.0218, 0.0356,
         0.0428, 0.0257, 0.0202, 0.0141, 0.0305, 0.0318, 0.0184, 0.0128, 0.0287,
         0.0319, 0.0153, 0.0246, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 66
images/359
(64, 64, 3)
tensor([[0.0224, 0.0250, 0.0174, 0.0171, 0.0346, 0.0142, 0.0299, 0.0205, 0.0164,
         0.0151, 0.0144, 0.0325, 0.0265, 0.0420, 0.0337, 0.0160, 0.0217, 0.0665,
         0.0156, 0.0278, 0.0254, 0.0251, 0.0135, 0.0192, 0.0165, 0.0104, 0.0316,
         0.0246, 0.0310, 0.0216, 0.0198, 0.0312, 0.0309, 0.0270, 0.0207, 0.0397,
         0.0332, 0.0147, 0.0226, 0.0321]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 67
images/211
(64, 64, 3)
tensor([[0.0375, 0.0240, 0.0211, 0.0139, 0.0234, 0.0267, 0.0445, 0.0264, 0.0185,
         0.0181, 0.0214, 0.0360, 0.0308, 0.0354, 0.0239, 0.0118, 0.0155, 0.0284,
         0.0154, 0.0257, 0.0176, 0.0263, 0.0235, 0.0268, 0.0295, 0.0153, 0.0177,
         0.0247, 0.0257, 0.0256, 0.0286, 0.0469, 0.0305, 0.0176, 0.0197, 0.0327,
         0.0256, 0.0191, 0.0207, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/498
(64, 64, 3)
tensor([[0.0182, 0.0255, 0.0240, 0.0125, 0.0420, 0.0140, 0.0531, 0.0287, 0.0253,
         0.0187, 0.0200, 0.0232, 0.0374, 0.0336, 0.0177, 0.0152, 0.0236, 0.0315,
         0.0190, 0.0178, 0.0199, 0.0176, 0.0220, 0.0142, 0.0162, 0.0157, 0.0217,
         0.0287, 0.0423, 0.0242, 0.0128, 0.0240, 0.0306, 0.0233, 0.0172, 0.0295,
         0.0496, 0.0213, 0.0327, 0.0355]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 69
images/356
(64, 64, 3)
tensor([[0.0319, 0.0248, 0.0195, 0.0109, 0.0315, 0.0200, 0.0278, 0.0147, 0.0296,
         0.0234, 0.0259, 0.0362, 0.0348, 0.0465, 0.0269, 0.0195, 0.0207, 0.0417,
         0.0191, 0.0161, 0.0137, 0.0254, 0.0166, 0.0192, 0.0198, 0.0149, 0.0195,
         0.0334, 0.0431, 0.0374, 0.0179, 0.0294, 0.0318, 0.0170, 0.0320, 0.0310,
         0.0172, 0.0176, 0.0213, 0.0203]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 70
images/249
(64, 64, 3)
tensor([[0.0255, 0.0294, 0.0156, 0.0297, 0.0421, 0.0172, 0.0311, 0.0128, 0.0207,
         0.0142, 0.0181, 0.0313, 0.0457, 0.0413, 0.0293, 0.0145, 0.0195, 0.0397,
         0.0179, 0.0260, 0.0152, 0.0287, 0.0303, 0.0152, 0.0241, 0.0193, 0.0306,
         0.0231, 0.0255, 0.0327, 0.0258, 0.0207, 0.0293, 0.0171, 0.0176, 0.0381,
         0.0229, 0.0177, 0.0232, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 71
images/565
(64, 64, 3)
tensor([[0.0279, 0.0174, 0.0188, 0.0196, 0.0255, 0.0146, 0.0453, 0.0183, 0.0200,
         0.0191, 0.0171, 0.0375, 0.0415, 0.0323, 0.0182, 0.0197, 0.0280, 0.0274,
         0.0134, 0.0346, 0.0180, 0.0212, 0.0223, 0.0154, 0.0150, 0.0218, 0.0255,
         0.0351, 0.0391, 0.0205, 0.0117, 0.0273, 0.0432, 0.0198, 0.0268, 0.0370,
         0.0327, 0.0219, 0.0237, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 72
images/8
(64, 64, 3)
tensor([[0.0287, 0.0306, 0.0227, 0.0161, 0.0310, 0.0149, 0.0373, 0.0191, 0.0237,
         0.0157, 0.0146, 0.0466, 0.0379, 0.0267, 0.0214, 0.0213, 0.0178, 0.0322,
         0.0174, 0.0173, 0.0193, 0.0326, 0.0207, 0.0157, 0.0317, 0.0166, 0.0224,
         0.0344, 0.0337, 0.0332, 0.0126, 0.0297, 0.0184, 0.0310, 0.0249, 0.0305,
         0.0389, 0.0188, 0.0212, 0.0206]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 73
images/322
(64, 64, 3)
tensor([[0.0218, 0.0298, 0.0126, 0.0278, 0.0251, 0.0117, 0.0299, 0.0127, 0.0165,
         0.0202, 0.0167, 0.0260, 0.0338, 0.0197, 0.0185, 0.0261, 0.0206, 0.0528,
         0.0235, 0.0144, 0.0168, 0.0220, 0.0182, 0.0104, 0.0207, 0.0230, 0.0281,
         0.0329, 0.0369, 0.0320, 0.0158, 0.0291, 0.0339, 0.0514, 0.0267, 0.0438,
         0.0319, 0.0206, 0.0182, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 74
images/424
(64, 64, 3)
tensor([[0.0406, 0.0175, 0.0175, 0.0167, 0.0314, 0.0272, 0.0265, 0.0103, 0.0101,
         0.0156, 0.0154, 0.0309, 0.0431, 0.0338, 0.0238, 0.0222, 0.0295, 0.0398,
         0.0248, 0.0192, 0.0110, 0.0139, 0.0199, 0.0191, 0.0199, 0.0272, 0.0175,
         0.0360, 0.0469, 0.0223, 0.0182, 0.0268, 0.0207, 0.0339, 0.0272, 0.0291,
         0.0317, 0.0189, 0.0400, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 75
images/467
(64, 64, 3)
tensor([[0.0204, 0.0348, 0.0149, 0.0334, 0.0280, 0.0219, 0.0277, 0.0221, 0.0179,
         0.0269, 0.0191, 0.0157, 0.0311, 0.0380, 0.0269, 0.0273, 0.0193, 0.0303,
         0.0358, 0.0174, 0.0177, 0.0221, 0.0223, 0.0188, 0.0268, 0.0176, 0.0313,
         0.0275, 0.0460, 0.0276, 0.0153, 0.0241, 0.0304, 0.0302, 0.0199, 0.0259,
         0.0168, 0.0217, 0.0215, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 76
images/166
(64, 64, 3)
tensor([[0.0204, 0.0255, 0.0161, 0.0113, 0.0304, 0.0267, 0.0258, 0.0149, 0.0191,
         0.0175, 0.0233, 0.0277, 0.0386, 0.0290, 0.0397, 0.0179, 0.0200, 0.0264,
         0.0171, 0.0248, 0.0199, 0.0274, 0.0222, 0.0299, 0.0211, 0.0192, 0.0184,
         0.0347, 0.0233, 0.0317, 0.0139, 0.0363, 0.0234, 0.0250, 0.0238, 0.0524,
         0.0357, 0.0212, 0.0187, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 77
images/512
(64, 64, 3)
tensor([[0.0203, 0.0208, 0.0235, 0.0194, 0.0403, 0.0152, 0.0285, 0.0181, 0.0180,
         0.0116, 0.0159, 0.0303, 0.0358, 0.0287, 0.0159, 0.0222, 0.0213, 0.0657,
         0.0251, 0.0206, 0.0244, 0.0264, 0.0207, 0.0193, 0.0289, 0.0163, 0.0203,
         0.0310, 0.0373, 0.0295, 0.0185, 0.0330, 0.0322, 0.0264, 0.0122, 0.0334,
         0.0283, 0.0166, 0.0161, 0.0320]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 78
images/401
(64, 64, 3)
tensor([[0.0335, 0.0263, 0.0165, 0.0220, 0.0264, 0.0251, 0.0362, 0.0144, 0.0246,
         0.0256, 0.0173, 0.0534, 0.0310, 0.0239, 0.0243, 0.0185, 0.0212, 0.0239,
         0.0178, 0.0228, 0.0176, 0.0224, 0.0160, 0.0306, 0.0199, 0.0216, 0.0256,
         0.0209, 0.0315, 0.0156, 0.0135, 0.0180, 0.0212, 0.0209, 0.0265, 0.0444,
         0.0554, 0.0252, 0.0254, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 79
images/177
(64, 64, 3)
tensor([[0.0252, 0.0279, 0.0105, 0.0243, 0.0347, 0.0156, 0.0225, 0.0184, 0.0210,
         0.0236, 0.0253, 0.0326, 0.0483, 0.0244, 0.0239, 0.0261, 0.0187, 0.0351,
         0.0208, 0.0185, 0.0139, 0.0339, 0.0245, 0.0247, 0.0251, 0.0235, 0.0257,
         0.0459, 0.0211, 0.0270, 0.0137, 0.0198, 0.0182, 0.0247, 0.0333, 0.0366,
         0.0213, 0.0231, 0.0197, 0.0272]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 80
images/180
(64, 64, 3)
tensor([[0.0290, 0.0216, 0.0270, 0.0193, 0.0312, 0.0135, 0.0327, 0.0199, 0.0170,
         0.0178, 0.0170, 0.0243, 0.0310, 0.0284, 0.0335, 0.0215, 0.0234, 0.0357,
         0.0161, 0.0250, 0.0188, 0.0257, 0.0179, 0.0153, 0.0258, 0.0137, 0.0305,
         0.0287, 0.0416, 0.0242, 0.0274, 0.0227, 0.0218, 0.0291, 0.0251, 0.0318,
         0.0329, 0.0157, 0.0286, 0.0379]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 81
images/512
(64, 64, 3)
tensor([[0.0233, 0.0169, 0.0181, 0.0176, 0.0265, 0.0215, 0.0318, 0.0226, 0.0226,
         0.0107, 0.0140, 0.0287, 0.0304, 0.0264, 0.0202, 0.0245, 0.0160, 0.0707,
         0.0174, 0.0291, 0.0202, 0.0358, 0.0218, 0.0220, 0.0155, 0.0251, 0.0288,
         0.0309, 0.0278, 0.0258, 0.0214, 0.0492, 0.0326, 0.0199, 0.0195, 0.0296,
         0.0244, 0.0168, 0.0173, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 82
images/296
(64, 64, 3)
tensor([[0.0262, 0.0340, 0.0305, 0.0135, 0.0432, 0.0228, 0.0259, 0.0171, 0.0095,
         0.0126, 0.0161, 0.0262, 0.0378, 0.0252, 0.0248, 0.0149, 0.0288, 0.0291,
         0.0207, 0.0203, 0.0158, 0.0381, 0.0287, 0.0295, 0.0211, 0.0258, 0.0218,
         0.0199, 0.0432, 0.0271, 0.0267, 0.0207, 0.0212, 0.0229, 0.0273, 0.0274,
         0.0342, 0.0288, 0.0170, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 83
images/403
(64, 64, 3)
tensor([[0.0309, 0.0460, 0.0149, 0.0257, 0.0348, 0.0134, 0.0255, 0.0136, 0.0145,
         0.0146, 0.0221, 0.0324, 0.0487, 0.0289, 0.0239, 0.0302, 0.0278, 0.0287,
         0.0133, 0.0251, 0.0173, 0.0201, 0.0174, 0.0233, 0.0183, 0.0226, 0.0309,
         0.0276, 0.0336, 0.0259, 0.0144, 0.0260, 0.0233, 0.0272, 0.0313, 0.0318,
         0.0342, 0.0177, 0.0200, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 84
images/364
(64, 64, 3)
tensor([[0.0307, 0.0252, 0.0191, 0.0267, 0.0338, 0.0282, 0.0251, 0.0202, 0.0221,
         0.0189, 0.0189, 0.0391, 0.0265, 0.0222, 0.0152, 0.0174, 0.0375, 0.0416,
         0.0225, 0.0174, 0.0171, 0.0284, 0.0200, 0.0192, 0.0174, 0.0193, 0.0281,
         0.0466, 0.0389, 0.0180, 0.0214, 0.0319, 0.0174, 0.0268, 0.0150, 0.0278,
         0.0337, 0.0133, 0.0232, 0.0281]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 85
images/541
(64, 64, 3)
tensor([[0.0301, 0.0328, 0.0143, 0.0199, 0.0236, 0.0270, 0.0324, 0.0137, 0.0112,
         0.0195, 0.0267, 0.0393, 0.0386, 0.0342, 0.0285, 0.0237, 0.0224, 0.0332,
         0.0177, 0.0194, 0.0156, 0.0214, 0.0183, 0.0231, 0.0183, 0.0164, 0.0306,
         0.0445, 0.0314, 0.0238, 0.0134, 0.0264, 0.0306, 0.0187, 0.0314, 0.0359,
         0.0215, 0.0144, 0.0238, 0.0324]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 86
images/388
(64, 64, 3)
tensor([[0.0284, 0.0190, 0.0134, 0.0122, 0.0246, 0.0182, 0.0406, 0.0221, 0.0176,
         0.0206, 0.0238, 0.0289, 0.0468, 0.0279, 0.0284, 0.0153, 0.0296, 0.0359,
         0.0167, 0.0121, 0.0159, 0.0242, 0.0173, 0.0222, 0.0236, 0.0172, 0.0416,
         0.0358, 0.0320, 0.0225, 0.0182, 0.0296, 0.0291, 0.0250, 0.0361, 0.0258,
         0.0326, 0.0200, 0.0306, 0.0185]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 87
images/525
(64, 64, 3)
tensor([[0.0266, 0.0238, 0.0149, 0.0160, 0.0253, 0.0221, 0.0401, 0.0197, 0.0116,
         0.0221, 0.0198, 0.0328, 0.0558, 0.0250, 0.0199, 0.0239, 0.0187, 0.0248,
         0.0192, 0.0281, 0.0182, 0.0367, 0.0299, 0.0217, 0.0186, 0.0185, 0.0220,
         0.0339, 0.0309, 0.0290, 0.0146, 0.0339, 0.0240, 0.0289, 0.0197, 0.0271,
         0.0257, 0.0208, 0.0296, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 88
images/150
(64, 64, 3)
tensor([[0.0301, 0.0221, 0.0220, 0.0124, 0.0333, 0.0219, 0.0490, 0.0451, 0.0263,
         0.0151, 0.0210, 0.0476, 0.0364, 0.0342, 0.0262, 0.0162, 0.0146, 0.0304,
         0.0218, 0.0227, 0.0168, 0.0229, 0.0126, 0.0168, 0.0188, 0.0146, 0.0234,
         0.0266, 0.0307, 0.0294, 0.0194, 0.0216, 0.0247, 0.0212, 0.0185, 0.0326,
         0.0324, 0.0168, 0.0198, 0.0319]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/521
(64, 64, 3)
tensor([[0.0190, 0.0319, 0.0195, 0.0161, 0.0348, 0.0212, 0.0230, 0.0138, 0.0200,
         0.0247, 0.0138, 0.0264, 0.0443, 0.0268, 0.0301, 0.0238, 0.0162, 0.0420,
         0.0150, 0.0213, 0.0190, 0.0185, 0.0194, 0.0332, 0.0277, 0.0240, 0.0304,
         0.0442, 0.0254, 0.0305, 0.0180, 0.0326, 0.0263, 0.0295, 0.0208, 0.0238,
         0.0251, 0.0237, 0.0208, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 90
images/227
(64, 64, 3)
tensor([[0.0233, 0.0217, 0.0296, 0.0181, 0.0227, 0.0309, 0.0301, 0.0151, 0.0153,
         0.0163, 0.0178, 0.0445, 0.0302, 0.0309, 0.0259, 0.0223, 0.0219, 0.0255,
         0.0210, 0.0203, 0.0205, 0.0302, 0.0324, 0.0252, 0.0282, 0.0215, 0.0241,
         0.0353, 0.0469, 0.0290, 0.0244, 0.0149, 0.0230, 0.0216, 0.0219, 0.0250,
         0.0267, 0.0203, 0.0217, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 91
images/46
(64, 64, 3)
tensor([[0.0321, 0.0418, 0.0170, 0.0225, 0.0253, 0.0312, 0.0325, 0.0256, 0.0161,
         0.0179, 0.0206, 0.0288, 0.0579, 0.0316, 0.0151, 0.0275, 0.0163, 0.0261,
         0.0237, 0.0186, 0.0175, 0.0286, 0.0259, 0.0199, 0.0245, 0.0147, 0.0214,
         0.0237, 0.0300, 0.0350, 0.0199, 0.0434, 0.0199, 0.0218, 0.0210, 0.0265,
         0.0172, 0.0143, 0.0204, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 92
images/306
(64, 64, 3)
tensor([[0.0325, 0.0199, 0.0161, 0.0111, 0.0226, 0.0262, 0.0243, 0.0221, 0.0132,
         0.0218, 0.0147, 0.0242, 0.0489, 0.0237, 0.0218, 0.0141, 0.0303, 0.0382,
         0.0180, 0.0195, 0.0210, 0.0288, 0.0304, 0.0237, 0.0210, 0.0216, 0.0270,
         0.0374, 0.0520, 0.0178, 0.0231, 0.0340, 0.0294, 0.0266, 0.0260, 0.0352,
         0.0206, 0.0200, 0.0198, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 93
images/140
(64, 64, 3)
tensor([[0.0306, 0.0348, 0.0144, 0.0211, 0.0384, 0.0239, 0.0431, 0.0188, 0.0220,
         0.0232, 0.0248, 0.0272, 0.0339, 0.0327, 0.0264, 0.0188, 0.0178, 0.0441,
         0.0196, 0.0214, 0.0156, 0.0269, 0.0230, 0.0220, 0.0132, 0.0199, 0.0312,
         0.0159, 0.0286, 0.0272, 0.0300, 0.0226, 0.0245, 0.0259, 0.0221, 0.0266,
         0.0284, 0.0161, 0.0235, 0.0200]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 94
images/209
(64, 64, 3)
tensor([[0.0329, 0.0285, 0.0257, 0.0272, 0.0264, 0.0274, 0.0385, 0.0081, 0.0196,
         0.0193, 0.0190, 0.0244, 0.0465, 0.0358, 0.0182, 0.0119, 0.0179, 0.0260,
         0.0134, 0.0254, 0.0179, 0.0272, 0.0225, 0.0157, 0.0207, 0.0247, 0.0288,
         0.0412, 0.0321, 0.0242, 0.0153, 0.0285, 0.0302, 0.0201, 0.0178, 0.0382,
         0.0301, 0.0233, 0.0317, 0.0177]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 0
Session Number: 95
images/410
(64, 64, 3)
tensor([[0.0307, 0.0484, 0.0184, 0.0175, 0.0310, 0.0186, 0.0271, 0.0216, 0.0187,
         0.0156, 0.0236, 0.0335, 0.0564, 0.0225, 0.0367, 0.0149, 0.0206, 0.0244,
         0.0228, 0.0196, 0.0177, 0.0253, 0.0185, 0.0249, 0.0321, 0.0164, 0.0280,
         0.0254, 0.0200, 0.0233, 0.0158, 0.0288, 0.0267, 0.0209, 0.0109, 0.0302,
         0.0284, 0.0218, 0.0333, 0.0288]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 96
images/562
(64, 64, 3)
tensor([[0.0294, 0.0267, 0.0255, 0.0152, 0.0414, 0.0268, 0.0393, 0.0232, 0.0198,
         0.0222, 0.0237, 0.0415, 0.0525, 0.0292, 0.0348, 0.0171, 0.0170, 0.0417,
         0.0174, 0.0181, 0.0175, 0.0197, 0.0120, 0.0266, 0.0189, 0.0176, 0.0224,
         0.0319, 0.0310, 0.0254, 0.0192, 0.0249, 0.0149, 0.0232, 0.0321, 0.0267,
         0.0176, 0.0130, 0.0168, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 97
images/449
(64, 64, 3)
tensor([[0.0263, 0.0146, 0.0156, 0.0220, 0.0494, 0.0179, 0.0428, 0.0168, 0.0142,
         0.0159, 0.0286, 0.0267, 0.0308, 0.0410, 0.0292, 0.0104, 0.0157, 0.0257,
         0.0313, 0.0222, 0.0149, 0.0165, 0.0272, 0.0212, 0.0166, 0.0270, 0.0224,
         0.0431, 0.0407, 0.0201, 0.0124, 0.0267, 0.0303, 0.0349, 0.0265, 0.0187,
         0.0404, 0.0186, 0.0222, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 98
images/305
(64, 64, 3)
tensor([[0.0290, 0.0275, 0.0216, 0.0115, 0.0271, 0.0209, 0.0373, 0.0156, 0.0137,
         0.0200, 0.0235, 0.0244, 0.0361, 0.0294, 0.0299, 0.0173, 0.0209, 0.0312,
         0.0252, 0.0171, 0.0186, 0.0244, 0.0175, 0.0214, 0.0260, 0.0223, 0.0276,
         0.0332, 0.0296, 0.0188, 0.0216, 0.0323, 0.0264, 0.0385, 0.0291, 0.0369,
         0.0241, 0.0179, 0.0269, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 99
images/168
(64, 64, 3)
tensor([[0.0189, 0.0316, 0.0108, 0.0214, 0.0405, 0.0283, 0.0268, 0.0200, 0.0232,
         0.0139, 0.0167, 0.0181, 0.0548, 0.0288, 0.0177, 0.0158, 0.0236, 0.0531,
         0.0231, 0.0255, 0.0171, 0.0157, 0.0191, 0.0248, 0.0188, 0.0199, 0.0243,
         0.0284, 0.0287, 0.0240, 0.0178, 0.0509, 0.0256, 0.0332, 0.0197, 0.0326,
         0.0253, 0.0191, 0.0249, 0.0173]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Saving the weights
34 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/135
(64, 64, 3)
2018-10-13 01:51:59.068 Python[10390:15743325] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0330, 0.0212, 0.0232, 0.0272, 0.0280, 0.0181, 0.0376, 0.0139, 0.0240,
         0.0177, 0.0198, 0.0311, 0.0307, 0.0267, 0.0327, 0.0214, 0.0173, 0.0308,
         0.0143, 0.0216, 0.0245, 0.0257, 0.0251, 0.0159, 0.0305, 0.0222, 0.0233,
         0.0259, 0.0320, 0.0185, 0.0181, 0.0311, 0.0226, 0.0241, 0.0258, 0.0213,
         0.0468, 0.0356, 0.0230, 0.0176]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 1
images/529
(64, 64, 3)
tensor([[0.0268, 0.0293, 0.0180, 0.0214, 0.0310, 0.0115, 0.0273, 0.0225, 0.0182,
         0.0119, 0.0185, 0.0411, 0.0351, 0.0360, 0.0335, 0.0145, 0.0246, 0.0315,
         0.0176, 0.0231, 0.0163, 0.0200, 0.0243, 0.0170, 0.0201, 0.0180, 0.0212,
         0.0448, 0.0301, 0.0185, 0.0176, 0.0460, 0.0205, 0.0302, 0.0232, 0.0279,
         0.0393, 0.0227, 0.0201, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/330
(64, 64, 3)
tensor([[0.0267, 0.0298, 0.0126, 0.0217, 0.0342, 0.0207, 0.0389, 0.0149, 0.0180,
         0.0147, 0.0189, 0.0363, 0.0423, 0.0368, 0.0205, 0.0207, 0.0380, 0.0449,
         0.0135, 0.0162, 0.0211, 0.0241, 0.0270, 0.0278, 0.0149, 0.0194, 0.0346,
         0.0261, 0.0363, 0.0184, 0.0214, 0.0232, 0.0321, 0.0194, 0.0264, 0.0290,
         0.0191, 0.0216, 0.0221, 0.0155]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 1
Session Number: 3
images/14
(64, 64, 3)
tensor([[0.0321, 0.0233, 0.0155, 0.0295, 0.0285, 0.0147, 0.0431, 0.0217, 0.0264,
         0.0136, 0.0313, 0.0300, 0.0347, 0.0291, 0.0273, 0.0196, 0.0172, 0.0364,
         0.0142, 0.0277, 0.0180, 0.0203, 0.0170, 0.0179, 0.0268, 0.0149, 0.0156,
         0.0429, 0.0330, 0.0184, 0.0243, 0.0221, 0.0304, 0.0464, 0.0220, 0.0295,
         0.0248, 0.0204, 0.0204, 0.0194]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 4
images/46
(64, 64, 3)
tensor([[0.0217, 0.0355, 0.0194, 0.0165, 0.0468, 0.0280, 0.0306, 0.0233, 0.0163,
         0.0198, 0.0185, 0.0235, 0.0443, 0.0355, 0.0221, 0.0206, 0.0226, 0.0523,
         0.0232, 0.0116, 0.0140, 0.0237, 0.0254, 0.0179, 0.0152, 0.0203, 0.0369,
         0.0194, 0.0325, 0.0235, 0.0135, 0.0332, 0.0183, 0.0292, 0.0309, 0.0270,
         0.0242, 0.0196, 0.0195, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 5
images/311
(64, 64, 3)
tensor([[0.0261, 0.0305, 0.0220, 0.0160, 0.0224, 0.0193, 0.0252, 0.0247, 0.0131,
         0.0267, 0.0196, 0.0314, 0.0319, 0.0317, 0.0247, 0.0272, 0.0197, 0.0404,
         0.0203, 0.0278, 0.0184, 0.0261, 0.0237, 0.0267, 0.0123, 0.0207, 0.0296,
         0.0261, 0.0416, 0.0298, 0.0169, 0.0308, 0.0278, 0.0243, 0.0315, 0.0278,
         0.0242, 0.0202, 0.0198, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 6
images/404
(64, 64, 3)
tensor([[0.0289, 0.0334, 0.0182, 0.0137, 0.0264, 0.0265, 0.0244, 0.0214, 0.0173,
         0.0315, 0.0159, 0.0310, 0.0288, 0.0241, 0.0323, 0.0199, 0.0319, 0.0284,
         0.0178, 0.0228, 0.0127, 0.0200, 0.0239, 0.0269, 0.0205, 0.0191, 0.0199,
         0.0309, 0.0439, 0.0222, 0.0233, 0.0390, 0.0216, 0.0286, 0.0215, 0.0307,
         0.0327, 0.0170, 0.0222, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 7
images/444
(64, 64, 3)
tensor([[0.0391, 0.0251, 0.0200, 0.0170, 0.0221, 0.0165, 0.0251, 0.0144, 0.0102,
         0.0158, 0.0215, 0.0294, 0.0527, 0.0226, 0.0173, 0.0301, 0.0185, 0.0239,
         0.0180, 0.0230, 0.0137, 0.0282, 0.0215, 0.0319, 0.0247, 0.0223, 0.0411,
         0.0534, 0.0327, 0.0323, 0.0222, 0.0332, 0.0247, 0.0229, 0.0164, 0.0242,
         0.0263, 0.0199, 0.0170, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/593
(64, 64, 3)
tensor([[0.0296, 0.0213, 0.0118, 0.0116, 0.0315, 0.0220, 0.0239, 0.0238, 0.0205,
         0.0254, 0.0172, 0.0364, 0.0465, 0.0236, 0.0253, 0.0147, 0.0334, 0.0351,
         0.0222, 0.0176, 0.0100, 0.0208, 0.0268, 0.0336, 0.0208, 0.0163, 0.0317,
         0.0376, 0.0263, 0.0176, 0.0124, 0.0430, 0.0295, 0.0222, 0.0260, 0.0291,
         0.0254, 0.0229, 0.0200, 0.0344]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 9
images/73
(64, 64, 3)
tensor([[0.0335, 0.0231, 0.0095, 0.0121, 0.0405, 0.0131, 0.0385, 0.0258, 0.0129,
         0.0226, 0.0160, 0.0233, 0.0361, 0.0334, 0.0214, 0.0178, 0.0272, 0.0434,
         0.0167, 0.0156, 0.0126, 0.0204, 0.0218, 0.0231, 0.0226, 0.0200, 0.0367,
         0.0234, 0.0559, 0.0319, 0.0248, 0.0226, 0.0322, 0.0204, 0.0145, 0.0442,
         0.0178, 0.0168, 0.0296, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 10
images/400
(64, 64, 3)
tensor([[0.0217, 0.0251, 0.0179, 0.0170, 0.0386, 0.0163, 0.0251, 0.0139, 0.0193,
         0.0207, 0.0175, 0.0331, 0.0562, 0.0305, 0.0350, 0.0132, 0.0199, 0.0322,
         0.0190, 0.0230, 0.0227, 0.0234, 0.0232, 0.0231, 0.0180, 0.0166, 0.0393,
         0.0205, 0.0241, 0.0213, 0.0264, 0.0267, 0.0342, 0.0197, 0.0327, 0.0360,
         0.0241, 0.0240, 0.0167, 0.0318]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/413
(64, 64, 3)
tensor([[0.0200, 0.0294, 0.0296, 0.0137, 0.0329, 0.0267, 0.0278, 0.0241, 0.0279,
         0.0207, 0.0170, 0.0231, 0.0279, 0.0289, 0.0176, 0.0192, 0.0138, 0.0380,
         0.0149, 0.0192, 0.0129, 0.0234, 0.0198, 0.0398, 0.0223, 0.0264, 0.0266,
         0.0368, 0.0537, 0.0317, 0.0193, 0.0372, 0.0311, 0.0222, 0.0224, 0.0183,
         0.0263, 0.0191, 0.0154, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/139
(64, 64, 3)
tensor([[0.0375, 0.0205, 0.0183, 0.0277, 0.0262, 0.0202, 0.0339, 0.0154, 0.0192,
         0.0205, 0.0191, 0.0181, 0.0342, 0.0439, 0.0141, 0.0183, 0.0218, 0.0388,
         0.0157, 0.0182, 0.0251, 0.0264, 0.0252, 0.0262, 0.0228, 0.0271, 0.0205,
         0.0259, 0.0503, 0.0229, 0.0179, 0.0359, 0.0281, 0.0123, 0.0173, 0.0239,
         0.0256, 0.0240, 0.0262, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 13
images/469
(64, 64, 3)
tensor([[0.0235, 0.0234, 0.0154, 0.0149, 0.0251, 0.0315, 0.0324, 0.0170, 0.0140,
         0.0185, 0.0209, 0.0439, 0.0421, 0.0254, 0.0242, 0.0191, 0.0160, 0.0331,
         0.0226, 0.0269, 0.0183, 0.0222, 0.0188, 0.0194, 0.0202, 0.0157, 0.0249,
         0.0420, 0.0339, 0.0146, 0.0176, 0.0470, 0.0234, 0.0220, 0.0392, 0.0269,
         0.0334, 0.0173, 0.0293, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 14
images/519
(64, 64, 3)
tensor([[0.0344, 0.0209, 0.0124, 0.0110, 0.0182, 0.0172, 0.0398, 0.0220, 0.0216,
         0.0173, 0.0243, 0.0325, 0.0344, 0.0295, 0.0352, 0.0137, 0.0218, 0.0491,
         0.0209, 0.0197, 0.0140, 0.0247, 0.0301, 0.0173, 0.0196, 0.0204, 0.0250,
         0.0273, 0.0256, 0.0201, 0.0213, 0.0468, 0.0353, 0.0162, 0.0143, 0.0241,
         0.0260, 0.0166, 0.0434, 0.0358]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 15
images/524
(64, 64, 3)
tensor([[0.0326, 0.0254, 0.0190, 0.0149, 0.0392, 0.0180, 0.0274, 0.0141, 0.0152,
         0.0224, 0.0203, 0.0267, 0.0298, 0.0362, 0.0364, 0.0197, 0.0184, 0.0322,
         0.0216, 0.0250, 0.0159, 0.0208, 0.0217, 0.0201, 0.0326, 0.0149, 0.0170,
         0.0337, 0.0254, 0.0346, 0.0254, 0.0366, 0.0266, 0.0120, 0.0163, 0.0383,
         0.0410, 0.0144, 0.0319, 0.0263]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 16
images/165
(64, 64, 3)
tensor([[0.0247, 0.0379, 0.0166, 0.0169, 0.0295, 0.0184, 0.0246, 0.0158, 0.0207,
         0.0219, 0.0164, 0.0231, 0.0423, 0.0277, 0.0271, 0.0162, 0.0220, 0.0418,
         0.0204, 0.0286, 0.0150, 0.0225, 0.0163, 0.0188, 0.0229, 0.0252, 0.0303,
         0.0342, 0.0275, 0.0330, 0.0199, 0.0364, 0.0201, 0.0211, 0.0328, 0.0396,
         0.0246, 0.0238, 0.0163, 0.0274]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 17
images/132
(64, 64, 3)
tensor([[0.0208, 0.0323, 0.0202, 0.0220, 0.0310, 0.0207, 0.0250, 0.0177, 0.0191,
         0.0238, 0.0128, 0.0205, 0.0470, 0.0381, 0.0193, 0.0179, 0.0257, 0.0647,
         0.0224, 0.0152, 0.0138, 0.0234, 0.0231, 0.0220, 0.0172, 0.0208, 0.0246,
         0.0266, 0.0234, 0.0316, 0.0204, 0.0323, 0.0199, 0.0201, 0.0255, 0.0481,
         0.0292, 0.0201, 0.0194, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 18
images/397
(64, 64, 3)
tensor([[0.0298, 0.0317, 0.0193, 0.0155, 0.0418, 0.0167, 0.0398, 0.0241, 0.0142,
         0.0122, 0.0208, 0.0276, 0.0397, 0.0350, 0.0187, 0.0206, 0.0233, 0.0322,
         0.0136, 0.0200, 0.0234, 0.0223, 0.0228, 0.0251, 0.0250, 0.0206, 0.0200,
         0.0305, 0.0415, 0.0218, 0.0228, 0.0252, 0.0235, 0.0208, 0.0291, 0.0272,
         0.0443, 0.0160, 0.0230, 0.0187]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 19
images/505
(64, 64, 3)
tensor([[0.0275, 0.0256, 0.0190, 0.0170, 0.0339, 0.0284, 0.0369, 0.0166, 0.0189,
         0.0231, 0.0181, 0.0347, 0.0343, 0.0333, 0.0193, 0.0154, 0.0260, 0.0470,
         0.0348, 0.0173, 0.0224, 0.0135, 0.0165, 0.0159, 0.0135, 0.0196, 0.0210,
         0.0290, 0.0456, 0.0255, 0.0140, 0.0352, 0.0367, 0.0245, 0.0157, 0.0192,
         0.0409, 0.0165, 0.0265, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 20
images/380
(64, 64, 3)
tensor([[0.0227, 0.0231, 0.0148, 0.0230, 0.0468, 0.0244, 0.0350, 0.0167, 0.0230,
         0.0167, 0.0175, 0.0233, 0.0448, 0.0236, 0.0282, 0.0224, 0.0155, 0.0292,
         0.0128, 0.0269, 0.0142, 0.0262, 0.0172, 0.0216, 0.0255, 0.0238, 0.0176,
         0.0363, 0.0317, 0.0235, 0.0220, 0.0342, 0.0265, 0.0236, 0.0168, 0.0397,
         0.0278, 0.0304, 0.0188, 0.0319]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 21
images/251
(64, 64, 3)
tensor([[0.0291, 0.0266, 0.0181, 0.0124, 0.0142, 0.0227, 0.0380, 0.0224, 0.0193,
         0.0169, 0.0255, 0.0422, 0.0500, 0.0258, 0.0179, 0.0175, 0.0216, 0.0287,
         0.0196, 0.0140, 0.0119, 0.0211, 0.0176, 0.0224, 0.0185, 0.0270, 0.0260,
         0.0354, 0.0399, 0.0235, 0.0222, 0.0274, 0.0302, 0.0232, 0.0274, 0.0455,
         0.0338, 0.0200, 0.0245, 0.0203]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 22
images/60
(64, 64, 3)
tensor([[0.0304, 0.0197, 0.0212, 0.0264, 0.0281, 0.0169, 0.0357, 0.0191, 0.0168,
         0.0272, 0.0113, 0.0229, 0.0432, 0.0429, 0.0235, 0.0184, 0.0261, 0.0645,
         0.0186, 0.0185, 0.0198, 0.0223, 0.0244, 0.0236, 0.0181, 0.0141, 0.0274,
         0.0234, 0.0287, 0.0232, 0.0162, 0.0270, 0.0239, 0.0235, 0.0243, 0.0374,
         0.0225, 0.0181, 0.0238, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 23
images/262
(64, 64, 3)
tensor([[0.0185, 0.0231, 0.0167, 0.0152, 0.0466, 0.0237, 0.0308, 0.0254, 0.0208,
         0.0305, 0.0177, 0.0271, 0.0365, 0.0270, 0.0294, 0.0153, 0.0231, 0.0249,
         0.0226, 0.0225, 0.0176, 0.0268, 0.0200, 0.0207, 0.0178, 0.0255, 0.0322,
         0.0252, 0.0242, 0.0239, 0.0194, 0.0307, 0.0166, 0.0344, 0.0221, 0.0350,
         0.0298, 0.0196, 0.0373, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 24
images/336
(64, 64, 3)
tensor([[0.0188, 0.0218, 0.0151, 0.0166, 0.0380, 0.0293, 0.0280, 0.0118, 0.0241,
         0.0221, 0.0224, 0.0352, 0.0448, 0.0228, 0.0252, 0.0209, 0.0228, 0.0297,
         0.0207, 0.0185, 0.0225, 0.0233, 0.0193, 0.0246, 0.0195, 0.0300, 0.0373,
         0.0368, 0.0313, 0.0245, 0.0236, 0.0378, 0.0198, 0.0236, 0.0204, 0.0331,
         0.0269, 0.0134, 0.0171, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 25
images/284
(64, 64, 3)
tensor([[0.0330, 0.0248, 0.0139, 0.0207, 0.0239, 0.0223, 0.0237, 0.0134, 0.0134,
         0.0180, 0.0288, 0.0327, 0.0565, 0.0330, 0.0185, 0.0167, 0.0229, 0.0309,
         0.0164, 0.0226, 0.0211, 0.0225, 0.0303, 0.0330, 0.0221, 0.0262, 0.0242,
         0.0361, 0.0322, 0.0276, 0.0147, 0.0251, 0.0295, 0.0151, 0.0171, 0.0382,
         0.0447, 0.0228, 0.0190, 0.0123]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 26
images/338
(64, 64, 3)
tensor([[0.0290, 0.0293, 0.0188, 0.0158, 0.0369, 0.0171, 0.0317, 0.0148, 0.0145,
         0.0269, 0.0119, 0.0344, 0.0250, 0.0376, 0.0404, 0.0177, 0.0119, 0.0345,
         0.0223, 0.0235, 0.0237, 0.0386, 0.0228, 0.0259, 0.0169, 0.0142, 0.0294,
         0.0337, 0.0377, 0.0288, 0.0281, 0.0191, 0.0312, 0.0234, 0.0165, 0.0290,
         0.0310, 0.0148, 0.0189, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 27
images/81
(64, 64, 3)
tensor([[0.0277, 0.0265, 0.0154, 0.0182, 0.0280, 0.0228, 0.0302, 0.0170, 0.0199,
         0.0216, 0.0251, 0.0283, 0.0439, 0.0261, 0.0246, 0.0232, 0.0389, 0.0293,
         0.0267, 0.0262, 0.0169, 0.0237, 0.0253, 0.0166, 0.0225, 0.0179, 0.0293,
         0.0227, 0.0291, 0.0227, 0.0183, 0.0306, 0.0189, 0.0258, 0.0257, 0.0275,
         0.0258, 0.0200, 0.0265, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 28
images/436
(64, 64, 3)
tensor([[0.0304, 0.0234, 0.0165, 0.0214, 0.0289, 0.0253, 0.0396, 0.0216, 0.0147,
         0.0195, 0.0254, 0.0258, 0.0815, 0.0362, 0.0213, 0.0093, 0.0162, 0.0395,
         0.0227, 0.0199, 0.0155, 0.0125, 0.0265, 0.0227, 0.0167, 0.0156, 0.0221,
         0.0224, 0.0175, 0.0218, 0.0250, 0.0356, 0.0261, 0.0274, 0.0281, 0.0323,
         0.0281, 0.0214, 0.0266, 0.0169]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Session Number: 29
images/295
(64, 64, 3)
tensor([[0.0385, 0.0191, 0.0311, 0.0258, 0.0298, 0.0276, 0.0246, 0.0110, 0.0178,
         0.0310, 0.0207, 0.0314, 0.0413, 0.0281, 0.0230, 0.0184, 0.0159, 0.0318,
         0.0149, 0.0233, 0.0227, 0.0252, 0.0414, 0.0256, 0.0229, 0.0156, 0.0214,
         0.0200, 0.0291, 0.0197, 0.0211, 0.0376, 0.0242, 0.0245, 0.0231, 0.0304,
         0.0409, 0.0161, 0.0145, 0.0191]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 30
images/494
(64, 64, 3)
tensor([[0.0271, 0.0314, 0.0135, 0.0175, 0.0245, 0.0177, 0.0248, 0.0201, 0.0201,
         0.0193, 0.0246, 0.0232, 0.0276, 0.0456, 0.0197, 0.0186, 0.0215, 0.0516,
         0.0244, 0.0193, 0.0188, 0.0369, 0.0156, 0.0216, 0.0307, 0.0245, 0.0194,
         0.0325, 0.0283, 0.0288, 0.0202, 0.0321, 0.0273, 0.0278, 0.0190, 0.0237,
         0.0298, 0.0183, 0.0317, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 31
images/264
(64, 64, 3)
tensor([[0.0224, 0.0223, 0.0243, 0.0164, 0.0201, 0.0178, 0.0249, 0.0202, 0.0203,
         0.0243, 0.0235, 0.0680, 0.0163, 0.0289, 0.0243, 0.0154, 0.0226, 0.0521,
         0.0160, 0.0210, 0.0170, 0.0244, 0.0267, 0.0220, 0.0158, 0.0240, 0.0230,
         0.0304, 0.0363, 0.0213, 0.0168, 0.0307, 0.0322, 0.0222, 0.0238, 0.0282,
         0.0325, 0.0244, 0.0157, 0.0316]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 32
images/164
(64, 64, 3)
tensor([[0.0239, 0.0374, 0.0129, 0.0198, 0.0331, 0.0192, 0.0484, 0.0130, 0.0159,
         0.0144, 0.0160, 0.0383, 0.0425, 0.0222, 0.0403, 0.0210, 0.0436, 0.0274,
         0.0213, 0.0229, 0.0094, 0.0254, 0.0221, 0.0246, 0.0279, 0.0238, 0.0356,
         0.0216, 0.0237, 0.0350, 0.0176, 0.0203, 0.0195, 0.0271, 0.0236, 0.0189,
         0.0208, 0.0351, 0.0176, 0.0168]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 33
images/118
(64, 64, 3)
tensor([[0.0273, 0.0213, 0.0282, 0.0191, 0.0294, 0.0228, 0.0419, 0.0142, 0.0143,
         0.0214, 0.0175, 0.0393, 0.0364, 0.0274, 0.0282, 0.0103, 0.0127, 0.0354,
         0.0287, 0.0160, 0.0210, 0.0258, 0.0262, 0.0221, 0.0241, 0.0139, 0.0248,
         0.0216, 0.0282, 0.0341, 0.0302, 0.0290, 0.0297, 0.0214, 0.0150, 0.0315,
         0.0398, 0.0129, 0.0296, 0.0274]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 34
images/418
(64, 64, 3)
tensor([[0.0305, 0.0262, 0.0222, 0.0196, 0.0233, 0.0220, 0.0263, 0.0150, 0.0138,
         0.0225, 0.0145, 0.0293, 0.0360, 0.0231, 0.0197, 0.0169, 0.0204, 0.0232,
         0.0181, 0.0238, 0.0216, 0.0243, 0.0146, 0.0207, 0.0267, 0.0247, 0.0325,
         0.0638, 0.0285, 0.0325, 0.0179, 0.0393, 0.0327, 0.0216, 0.0255, 0.0279,
         0.0246, 0.0234, 0.0231, 0.0274]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 35
images/497
(64, 64, 3)
tensor([[0.0279, 0.0250, 0.0220, 0.0126, 0.0271, 0.0248, 0.0240, 0.0302, 0.0293,
         0.0218, 0.0153, 0.0259, 0.0307, 0.0480, 0.0184, 0.0161, 0.0215, 0.0338,
         0.0244, 0.0196, 0.0166, 0.0281, 0.0188, 0.0288, 0.0182, 0.0199, 0.0219,
         0.0282, 0.0508, 0.0310, 0.0217, 0.0220, 0.0278, 0.0209, 0.0232, 0.0317,
         0.0264, 0.0244, 0.0155, 0.0257]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Session Number: 36
images/167
(64, 64, 3)
tensor([[0.0221, 0.0256, 0.0149, 0.0236, 0.0369, 0.0174, 0.0452, 0.0273, 0.0182,
         0.0120, 0.0129, 0.0298, 0.0205, 0.0384, 0.0342, 0.0124, 0.0166, 0.0531,
         0.0117, 0.0257, 0.0116, 0.0234, 0.0175, 0.0154, 0.0249, 0.0210, 0.0225,
         0.0294, 0.0264, 0.0270, 0.0224, 0.0247, 0.0234, 0.0171, 0.0442, 0.0359,
         0.0375, 0.0317, 0.0205, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 37
images/302
(64, 64, 3)
tensor([[0.0218, 0.0359, 0.0174, 0.0170, 0.0297, 0.0177, 0.0487, 0.0164, 0.0184,
         0.0193, 0.0179, 0.0365, 0.0275, 0.0443, 0.0266, 0.0263, 0.0242, 0.0258,
         0.0156, 0.0216, 0.0176, 0.0299, 0.0215, 0.0198, 0.0213, 0.0193, 0.0207,
         0.0339, 0.0319, 0.0391, 0.0196, 0.0371, 0.0340, 0.0225, 0.0208, 0.0282,
         0.0215, 0.0147, 0.0150, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 38
images/224
(64, 64, 3)
tensor([[0.0233, 0.0234, 0.0264, 0.0144, 0.0355, 0.0237, 0.0295, 0.0223, 0.0194,
         0.0201, 0.0171, 0.0421, 0.0369, 0.0328, 0.0282, 0.0208, 0.0146, 0.0208,
         0.0233, 0.0232, 0.0255, 0.0282, 0.0155, 0.0195, 0.0178, 0.0185, 0.0225,
         0.0511, 0.0290, 0.0209, 0.0278, 0.0305, 0.0365, 0.0170, 0.0253, 0.0319,
         0.0202, 0.0169, 0.0231, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 39
images/274
(64, 64, 3)
tensor([[0.0336, 0.0206, 0.0201, 0.0176, 0.0416, 0.0183, 0.0224, 0.0170, 0.0157,
         0.0383, 0.0183, 0.0223, 0.0247, 0.0345, 0.0249, 0.0241, 0.0146, 0.0337,
         0.0161, 0.0233, 0.0288, 0.0258, 0.0246, 0.0204, 0.0298, 0.0200, 0.0252,
         0.0372, 0.0322, 0.0235, 0.0168, 0.0409, 0.0269, 0.0171, 0.0197, 0.0308,
         0.0309, 0.0139, 0.0250, 0.0286]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 1
Session Number: 40
images/61
(64, 64, 3)
tensor([[0.0416, 0.0322, 0.0145, 0.0262, 0.0318, 0.0280, 0.0310, 0.0139, 0.0159,
         0.0279, 0.0128, 0.0198, 0.0302, 0.0383, 0.0227, 0.0205, 0.0232, 0.0253,
         0.0157, 0.0250, 0.0221, 0.0301, 0.0258, 0.0230, 0.0265, 0.0216, 0.0173,
         0.0289, 0.0397, 0.0283, 0.0186, 0.0244, 0.0270, 0.0208, 0.0253, 0.0259,
         0.0322, 0.0221, 0.0160, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 41
images/448
(64, 64, 3)
tensor([[0.0243, 0.0274, 0.0157, 0.0322, 0.0247, 0.0181, 0.0356, 0.0135, 0.0280,
         0.0152, 0.0167, 0.0249, 0.0660, 0.0322, 0.0263, 0.0189, 0.0246, 0.0420,
         0.0299, 0.0147, 0.0211, 0.0208, 0.0185, 0.0172, 0.0175, 0.0203, 0.0265,
         0.0284, 0.0370, 0.0253, 0.0255, 0.0248, 0.0255, 0.0221, 0.0194, 0.0263,
         0.0243, 0.0158, 0.0224, 0.0304]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 42
images/200
(64, 64, 3)
tensor([[0.0202, 0.0305, 0.0184, 0.0179, 0.0338, 0.0241, 0.0230, 0.0244, 0.0299,
         0.0185, 0.0148, 0.0305, 0.0487, 0.0375, 0.0289, 0.0335, 0.0183, 0.0425,
         0.0144, 0.0244, 0.0163, 0.0241, 0.0221, 0.0236, 0.0185, 0.0195, 0.0268,
         0.0329, 0.0242, 0.0204, 0.0167, 0.0287, 0.0227, 0.0294, 0.0298, 0.0262,
         0.0238, 0.0241, 0.0158, 0.0201]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/275
(64, 64, 3)
tensor([[0.0303, 0.0230, 0.0215, 0.0160, 0.0328, 0.0282, 0.0323, 0.0188, 0.0119,
         0.0243, 0.0223, 0.0325, 0.0355, 0.0457, 0.0219, 0.0178, 0.0172, 0.0555,
         0.0295, 0.0265, 0.0146, 0.0225, 0.0236, 0.0129, 0.0168, 0.0195, 0.0303,
         0.0345, 0.0220, 0.0167, 0.0198, 0.0286, 0.0216, 0.0247, 0.0171, 0.0282,
         0.0328, 0.0132, 0.0328, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/597
(64, 64, 3)
tensor([[0.0172, 0.0415, 0.0175, 0.0197, 0.0319, 0.0240, 0.0444, 0.0211, 0.0167,
         0.0118, 0.0172, 0.0308, 0.0416, 0.0328, 0.0230, 0.0200, 0.0238, 0.0558,
         0.0185, 0.0264, 0.0232, 0.0230, 0.0169, 0.0237, 0.0198, 0.0170, 0.0267,
         0.0247, 0.0286, 0.0208, 0.0215, 0.0386, 0.0221, 0.0278, 0.0160, 0.0255,
         0.0193, 0.0194, 0.0284, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 45
images/372
(64, 64, 3)
tensor([[0.0366, 0.0232, 0.0186, 0.0150, 0.0258, 0.0196, 0.0176, 0.0264, 0.0182,
         0.0143, 0.0213, 0.0479, 0.0590, 0.0277, 0.0367, 0.0217, 0.0177, 0.0276,
         0.0183, 0.0280, 0.0135, 0.0214, 0.0222, 0.0254, 0.0174, 0.0134, 0.0307,
         0.0410, 0.0215, 0.0268, 0.0154, 0.0256, 0.0305, 0.0299, 0.0209, 0.0356,
         0.0208, 0.0200, 0.0218, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 46
images/595
(64, 64, 3)
tensor([[0.0236, 0.0260, 0.0283, 0.0175, 0.0247, 0.0216, 0.0411, 0.0154, 0.0163,
         0.0244, 0.0221, 0.0221, 0.0448, 0.0279, 0.0231, 0.0149, 0.0180, 0.0147,
         0.0317, 0.0301, 0.0173, 0.0217, 0.0318, 0.0184, 0.0169, 0.0187, 0.0216,
         0.0320, 0.0350, 0.0228, 0.0174, 0.0208, 0.0481, 0.0349, 0.0172, 0.0336,
         0.0288, 0.0212, 0.0262, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 47
images/479
(64, 64, 3)
tensor([[0.0288, 0.0190, 0.0222, 0.0123, 0.0350, 0.0260, 0.0260, 0.0168, 0.0137,
         0.0174, 0.0215, 0.0381, 0.0332, 0.0272, 0.0277, 0.0197, 0.0238, 0.0281,
         0.0181, 0.0216, 0.0139, 0.0290, 0.0209, 0.0241, 0.0246, 0.0216, 0.0282,
         0.0282, 0.0325, 0.0257, 0.0175, 0.0209, 0.0248, 0.0318, 0.0275, 0.0256,
         0.0399, 0.0229, 0.0176, 0.0464]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 48
images/329
(64, 64, 3)
tensor([[0.0283, 0.0281, 0.0163, 0.0193, 0.0441, 0.0223, 0.0323, 0.0149, 0.0235,
         0.0151, 0.0155, 0.0418, 0.0292, 0.0333, 0.0196, 0.0219, 0.0280, 0.0445,
         0.0218, 0.0209, 0.0192, 0.0308, 0.0138, 0.0200, 0.0228, 0.0202, 0.0309,
         0.0295, 0.0361, 0.0199, 0.0228, 0.0338, 0.0153, 0.0208, 0.0282, 0.0237,
         0.0265, 0.0130, 0.0175, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 49
images/465
(64, 64, 3)
tensor([[0.0195, 0.0223, 0.0158, 0.0336, 0.0299, 0.0162, 0.0428, 0.0142, 0.0186,
         0.0283, 0.0147, 0.0306, 0.0520, 0.0418, 0.0299, 0.0172, 0.0142, 0.0416,
         0.0253, 0.0181, 0.0301, 0.0212, 0.0125, 0.0168, 0.0205, 0.0131, 0.0217,
         0.0405, 0.0345, 0.0115, 0.0147, 0.0199, 0.0320, 0.0300, 0.0283, 0.0255,
         0.0318, 0.0254, 0.0189, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 50
images/245
(64, 64, 3)
tensor([[0.0342, 0.0318, 0.0153, 0.0114, 0.0453, 0.0161, 0.0270, 0.0167, 0.0192,
         0.0165, 0.0143, 0.0242, 0.0351, 0.0245, 0.0329, 0.0186, 0.0202, 0.0401,
         0.0166, 0.0146, 0.0161, 0.0377, 0.0201, 0.0160, 0.0254, 0.0206, 0.0277,
         0.0239, 0.0355, 0.0310, 0.0150, 0.0415, 0.0333, 0.0243, 0.0130, 0.0237,
         0.0244, 0.0394, 0.0301, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 51
images/82
(64, 64, 3)
tensor([[0.0328, 0.0452, 0.0207, 0.0228, 0.0260, 0.0150, 0.0266, 0.0160, 0.0167,
         0.0238, 0.0215, 0.0378, 0.0467, 0.0312, 0.0213, 0.0125, 0.0149, 0.0374,
         0.0204, 0.0188, 0.0203, 0.0423, 0.0195, 0.0252, 0.0123, 0.0193, 0.0210,
         0.0396, 0.0303, 0.0170, 0.0192, 0.0365, 0.0270, 0.0229, 0.0212, 0.0190,
         0.0372, 0.0182, 0.0162, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/232
(64, 64, 3)
tensor([[0.0297, 0.0222, 0.0211, 0.0202, 0.0238, 0.0236, 0.0242, 0.0327, 0.0155,
         0.0149, 0.0281, 0.0200, 0.0342, 0.0339, 0.0240, 0.0300, 0.0157, 0.0286,
         0.0210, 0.0173, 0.0197, 0.0340, 0.0199, 0.0200, 0.0250, 0.0226, 0.0204,
         0.0262, 0.0379, 0.0303, 0.0262, 0.0235, 0.0261, 0.0220, 0.0334, 0.0232,
         0.0416, 0.0217, 0.0188, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 53
images/344
(64, 64, 3)
tensor([[0.0298, 0.0383, 0.0136, 0.0263, 0.0273, 0.0180, 0.0330, 0.0203, 0.0197,
         0.0310, 0.0149, 0.0295, 0.0331, 0.0243, 0.0264, 0.0189, 0.0198, 0.0472,
         0.0137, 0.0177, 0.0163, 0.0313, 0.0193, 0.0198, 0.0305, 0.0170, 0.0260,
         0.0285, 0.0261, 0.0278, 0.0125, 0.0220, 0.0524, 0.0223, 0.0200, 0.0165,
         0.0295, 0.0183, 0.0193, 0.0417]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 54
images/251
(64, 64, 3)
tensor([[0.0256, 0.0244, 0.0240, 0.0173, 0.0231, 0.0167, 0.0478, 0.0200, 0.0278,
         0.0120, 0.0261, 0.0287, 0.0463, 0.0295, 0.0245, 0.0217, 0.0159, 0.0389,
         0.0225, 0.0133, 0.0128, 0.0251, 0.0191, 0.0206, 0.0149, 0.0196, 0.0224,
         0.0344, 0.0298, 0.0275, 0.0242, 0.0236, 0.0364, 0.0213, 0.0301, 0.0316,
         0.0266, 0.0190, 0.0256, 0.0292]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 55
images/319
(64, 64, 3)
tensor([[0.0264, 0.0194, 0.0178, 0.0202, 0.0391, 0.0228, 0.0321, 0.0176, 0.0290,
         0.0203, 0.0213, 0.0305, 0.0495, 0.0342, 0.0235, 0.0138, 0.0156, 0.0402,
         0.0213, 0.0197, 0.0182, 0.0293, 0.0174, 0.0168, 0.0164, 0.0177, 0.0323,
         0.0314, 0.0258, 0.0279, 0.0193, 0.0281, 0.0427, 0.0191, 0.0289, 0.0278,
         0.0247, 0.0265, 0.0137, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 56
images/519
(64, 64, 3)
tensor([[0.0230, 0.0276, 0.0146, 0.0168, 0.0247, 0.0208, 0.0334, 0.0194, 0.0185,
         0.0155, 0.0212, 0.0292, 0.0388, 0.0370, 0.0261, 0.0156, 0.0216, 0.0360,
         0.0214, 0.0174, 0.0166, 0.0404, 0.0255, 0.0205, 0.0235, 0.0182, 0.0253,
         0.0322, 0.0327, 0.0229, 0.0139, 0.0389, 0.0354, 0.0155, 0.0200, 0.0357,
         0.0303, 0.0191, 0.0280, 0.0268]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 57
images/475
(64, 64, 3)
tensor([[0.0253, 0.0212, 0.0263, 0.0279, 0.0273, 0.0184, 0.0306, 0.0220, 0.0176,
         0.0188, 0.0307, 0.0254, 0.0456, 0.0235, 0.0231, 0.0175, 0.0198, 0.0383,
         0.0293, 0.0201, 0.0183, 0.0158, 0.0153, 0.0206, 0.0282, 0.0208, 0.0239,
         0.0308, 0.0312, 0.0255, 0.0202, 0.0457, 0.0243, 0.0262, 0.0190, 0.0295,
         0.0236, 0.0263, 0.0277, 0.0186]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 58
images/4
(64, 64, 3)
tensor([[0.0388, 0.0255, 0.0179, 0.0173, 0.0661, 0.0152, 0.0382, 0.0129, 0.0218,
         0.0157, 0.0165, 0.0337, 0.0475, 0.0253, 0.0277, 0.0135, 0.0140, 0.0606,
         0.0161, 0.0239, 0.0181, 0.0195, 0.0224, 0.0229, 0.0185, 0.0239, 0.0231,
         0.0344, 0.0269, 0.0250, 0.0254, 0.0240, 0.0167, 0.0186, 0.0234, 0.0212,
         0.0315, 0.0150, 0.0218, 0.0195]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 59
images/456
(64, 64, 3)
tensor([[0.0268, 0.0265, 0.0192, 0.0291, 0.0347, 0.0184, 0.0263, 0.0221, 0.0214,
         0.0151, 0.0222, 0.0287, 0.0526, 0.0349, 0.0326, 0.0173, 0.0185, 0.0299,
         0.0189, 0.0183, 0.0148, 0.0212, 0.0156, 0.0252, 0.0214, 0.0217, 0.0183,
         0.0305, 0.0325, 0.0324, 0.0233, 0.0266, 0.0269, 0.0301, 0.0239, 0.0277,
         0.0263, 0.0147, 0.0280, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 60
images/181
(64, 64, 3)
tensor([[0.0312, 0.0228, 0.0185, 0.0350, 0.0269, 0.0230, 0.0268, 0.0146, 0.0188,
         0.0136, 0.0155, 0.0524, 0.0361, 0.0295, 0.0202, 0.0123, 0.0123, 0.0375,
         0.0185, 0.0183, 0.0130, 0.0217, 0.0339, 0.0290, 0.0226, 0.0204, 0.0313,
         0.0522, 0.0323, 0.0231, 0.0128, 0.0237, 0.0305, 0.0177, 0.0203, 0.0275,
         0.0397, 0.0146, 0.0216, 0.0284]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 61
images/480
(64, 64, 3)
tensor([[0.0209, 0.0334, 0.0252, 0.0153, 0.0445, 0.0131, 0.0455, 0.0261, 0.0275,
         0.0179, 0.0256, 0.0336, 0.0353, 0.0262, 0.0346, 0.0129, 0.0287, 0.0353,
         0.0263, 0.0172, 0.0225, 0.0247, 0.0111, 0.0137, 0.0151, 0.0124, 0.0177,
         0.0209, 0.0231, 0.0191, 0.0177, 0.0546, 0.0277, 0.0197, 0.0198, 0.0261,
         0.0256, 0.0146, 0.0291, 0.0395]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 62
images/209
(64, 64, 3)
tensor([[0.0299, 0.0309, 0.0194, 0.0152, 0.0226, 0.0190, 0.0344, 0.0077, 0.0172,
         0.0160, 0.0162, 0.0418, 0.0383, 0.0215, 0.0188, 0.0110, 0.0304, 0.0267,
         0.0182, 0.0321, 0.0144, 0.0271, 0.0329, 0.0187, 0.0298, 0.0287, 0.0260,
         0.0355, 0.0304, 0.0200, 0.0144, 0.0221, 0.0314, 0.0271, 0.0209, 0.0560,
         0.0269, 0.0213, 0.0231, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 63
images/195
(64, 64, 3)
tensor([[0.0221, 0.0343, 0.0153, 0.0237, 0.0272, 0.0226, 0.0261, 0.0117, 0.0250,
         0.0211, 0.0188, 0.0337, 0.0427, 0.0285, 0.0227, 0.0221, 0.0139, 0.0443,
         0.0258, 0.0233, 0.0121, 0.0303, 0.0231, 0.0188, 0.0375, 0.0117, 0.0190,
         0.0399, 0.0316, 0.0165, 0.0203, 0.0247, 0.0231, 0.0190, 0.0283, 0.0210,
         0.0285, 0.0286, 0.0248, 0.0365]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 1
Session Number: 64
images/144
(64, 64, 3)
tensor([[0.0347, 0.0346, 0.0226, 0.0152, 0.0319, 0.0235, 0.0253, 0.0125, 0.0109,
         0.0275, 0.0154, 0.0349, 0.0379, 0.0342, 0.0213, 0.0219, 0.0186, 0.0255,
         0.0240, 0.0189, 0.0246, 0.0241, 0.0293, 0.0241, 0.0322, 0.0150, 0.0165,
         0.0353, 0.0480, 0.0389, 0.0160, 0.0260, 0.0233, 0.0154, 0.0173, 0.0352,
         0.0250, 0.0172, 0.0171, 0.0283]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 65
images/442
(64, 64, 3)
tensor([[0.0298, 0.0226, 0.0194, 0.0185, 0.0534, 0.0370, 0.0240, 0.0144, 0.0152,
         0.0201, 0.0161, 0.0274, 0.0534, 0.0234, 0.0249, 0.0188, 0.0175, 0.0197,
         0.0299, 0.0248, 0.0282, 0.0330, 0.0152, 0.0253, 0.0198, 0.0173, 0.0310,
         0.0345, 0.0282, 0.0208, 0.0153, 0.0272, 0.0282, 0.0209, 0.0265, 0.0267,
         0.0314, 0.0236, 0.0223, 0.0144]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 66
images/134
(64, 64, 3)
tensor([[0.0291, 0.0314, 0.0213, 0.0203, 0.0226, 0.0161, 0.0293, 0.0152, 0.0167,
         0.0183, 0.0284, 0.0293, 0.0303, 0.0306, 0.0448, 0.0147, 0.0178, 0.0509,
         0.0146, 0.0249, 0.0183, 0.0252, 0.0282, 0.0143, 0.0210, 0.0136, 0.0203,
         0.0275, 0.0375, 0.0223, 0.0186, 0.0211, 0.0209, 0.0313, 0.0193, 0.0426,
         0.0311, 0.0254, 0.0319, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 67
images/196
(64, 64, 3)
tensor([[0.0327, 0.0289, 0.0205, 0.0171, 0.0224, 0.0196, 0.0485, 0.0280, 0.0115,
         0.0194, 0.0204, 0.0293, 0.0356, 0.0449, 0.0226, 0.0141, 0.0233, 0.0260,
         0.0153, 0.0198, 0.0253, 0.0192, 0.0220, 0.0196, 0.0302, 0.0222, 0.0318,
         0.0228, 0.0319, 0.0225, 0.0166, 0.0333, 0.0232, 0.0213, 0.0192, 0.0357,
         0.0323, 0.0184, 0.0211, 0.0315]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/261
(64, 64, 3)
tensor([[0.0184, 0.0320, 0.0235, 0.0193, 0.0357, 0.0140, 0.0463, 0.0287, 0.0216,
         0.0183, 0.0168, 0.0287, 0.0446, 0.0272, 0.0181, 0.0130, 0.0327, 0.0428,
         0.0227, 0.0160, 0.0228, 0.0222, 0.0175, 0.0156, 0.0205, 0.0214, 0.0258,
         0.0277, 0.0462, 0.0292, 0.0142, 0.0196, 0.0346, 0.0136, 0.0182, 0.0260,
         0.0387, 0.0150, 0.0263, 0.0246]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 69
images/54
(64, 64, 3)
tensor([[0.0229, 0.0275, 0.0165, 0.0172, 0.0232, 0.0192, 0.0342, 0.0153, 0.0208,
         0.0217, 0.0263, 0.0285, 0.0405, 0.0484, 0.0249, 0.0215, 0.0149, 0.0317,
         0.0176, 0.0210, 0.0136, 0.0216, 0.0176, 0.0231, 0.0270, 0.0161, 0.0245,
         0.0249, 0.0518, 0.0332, 0.0181, 0.0438, 0.0291, 0.0180, 0.0230, 0.0389,
         0.0183, 0.0188, 0.0236, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 70
images/88
(64, 64, 3)
tensor([[0.0328, 0.0333, 0.0169, 0.0375, 0.0306, 0.0205, 0.0365, 0.0092, 0.0211,
         0.0241, 0.0259, 0.0315, 0.0499, 0.0383, 0.0291, 0.0178, 0.0166, 0.0191,
         0.0130, 0.0287, 0.0202, 0.0225, 0.0265, 0.0236, 0.0122, 0.0196, 0.0299,
         0.0286, 0.0338, 0.0235, 0.0200, 0.0168, 0.0209, 0.0185, 0.0192, 0.0408,
         0.0253, 0.0227, 0.0208, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 71
images/476
(64, 64, 3)
tensor([[0.0274, 0.0171, 0.0178, 0.0142, 0.0220, 0.0171, 0.0434, 0.0210, 0.0166,
         0.0206, 0.0198, 0.0368, 0.0442, 0.0357, 0.0225, 0.0183, 0.0218, 0.0280,
         0.0134, 0.0263, 0.0162, 0.0263, 0.0197, 0.0180, 0.0194, 0.0224, 0.0269,
         0.0500, 0.0422, 0.0206, 0.0159, 0.0261, 0.0401, 0.0173, 0.0244, 0.0203,
         0.0214, 0.0237, 0.0404, 0.0248]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 72
images/526
(64, 64, 3)
tensor([[0.0357, 0.0302, 0.0190, 0.0159, 0.0324, 0.0166, 0.0233, 0.0182, 0.0274,
         0.0195, 0.0140, 0.0369, 0.0387, 0.0334, 0.0154, 0.0183, 0.0267, 0.0312,
         0.0133, 0.0165, 0.0171, 0.0343, 0.0196, 0.0234, 0.0236, 0.0174, 0.0242,
         0.0348, 0.0437, 0.0207, 0.0176, 0.0264, 0.0213, 0.0338, 0.0268, 0.0310,
         0.0404, 0.0135, 0.0242, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 1
Session Number: 73
images/13
(64, 64, 3)
tensor([[0.0189, 0.0299, 0.0242, 0.0181, 0.0293, 0.0212, 0.0476, 0.0196, 0.0187,
         0.0192, 0.0310, 0.0257, 0.0300, 0.0236, 0.0275, 0.0155, 0.0150, 0.0484,
         0.0293, 0.0204, 0.0123, 0.0166, 0.0204, 0.0159, 0.0242, 0.0148, 0.0148,
         0.0213, 0.0306, 0.0289, 0.0197, 0.0313, 0.0369, 0.0346, 0.0244, 0.0428,
         0.0318, 0.0200, 0.0229, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 74
images/238
(64, 64, 3)
tensor([[0.0342, 0.0221, 0.0187, 0.0119, 0.0374, 0.0221, 0.0199, 0.0121, 0.0124,
         0.0158, 0.0189, 0.0297, 0.0531, 0.0292, 0.0274, 0.0210, 0.0262, 0.0449,
         0.0208, 0.0178, 0.0116, 0.0152, 0.0191, 0.0274, 0.0282, 0.0166, 0.0216,
         0.0326, 0.0423, 0.0156, 0.0227, 0.0170, 0.0297, 0.0339, 0.0407, 0.0226,
         0.0260, 0.0166, 0.0317, 0.0333]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 75
images/12
(64, 64, 3)
tensor([[0.0131, 0.0273, 0.0108, 0.0317, 0.0299, 0.0230, 0.0196, 0.0196, 0.0272,
         0.0275, 0.0164, 0.0184, 0.0403, 0.0339, 0.0270, 0.0300, 0.0167, 0.0216,
         0.0478, 0.0245, 0.0163, 0.0276, 0.0163, 0.0215, 0.0294, 0.0181, 0.0285,
         0.0301, 0.0384, 0.0217, 0.0169, 0.0242, 0.0325, 0.0229, 0.0163, 0.0257,
         0.0248, 0.0273, 0.0264, 0.0290]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 76
images/68
(64, 64, 3)
tensor([[0.0199, 0.0232, 0.0180, 0.0231, 0.0464, 0.0164, 0.0366, 0.0164, 0.0161,
         0.0206, 0.0192, 0.0388, 0.0398, 0.0390, 0.0357, 0.0229, 0.0157, 0.0287,
         0.0228, 0.0210, 0.0162, 0.0158, 0.0271, 0.0230, 0.0221, 0.0162, 0.0173,
         0.0316, 0.0281, 0.0253, 0.0175, 0.0310, 0.0238, 0.0183, 0.0326, 0.0421,
         0.0238, 0.0235, 0.0190, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 77
images/240
(64, 64, 3)
tensor([[0.0223, 0.0253, 0.0269, 0.0184, 0.0524, 0.0181, 0.0253, 0.0125, 0.0182,
         0.0169, 0.0134, 0.0234, 0.0411, 0.0410, 0.0236, 0.0259, 0.0254, 0.0353,
         0.0187, 0.0227, 0.0156, 0.0218, 0.0204, 0.0222, 0.0163, 0.0134, 0.0245,
         0.0402, 0.0324, 0.0309, 0.0170, 0.0277, 0.0336, 0.0311, 0.0197, 0.0244,
         0.0260, 0.0178, 0.0168, 0.0414]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 78
images/64
(64, 64, 3)
tensor([[0.0226, 0.0404, 0.0194, 0.0370, 0.0250, 0.0199, 0.0242, 0.0163, 0.0212,
         0.0248, 0.0200, 0.0360, 0.0598, 0.0271, 0.0250, 0.0232, 0.0192, 0.0366,
         0.0202, 0.0210, 0.0219, 0.0187, 0.0131, 0.0185, 0.0161, 0.0185, 0.0316,
         0.0206, 0.0311, 0.0233, 0.0131, 0.0170, 0.0171, 0.0200, 0.0252, 0.0339,
         0.0275, 0.0362, 0.0256, 0.0321]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/498
(64, 64, 3)
tensor([[0.0260, 0.0205, 0.0148, 0.0134, 0.0421, 0.0146, 0.0291, 0.0255, 0.0182,
         0.0243, 0.0156, 0.0334, 0.0481, 0.0361, 0.0206, 0.0179, 0.0229, 0.0268,
         0.0196, 0.0190, 0.0147, 0.0379, 0.0197, 0.0280, 0.0241, 0.0184, 0.0218,
         0.0416, 0.0221, 0.0306, 0.0158, 0.0268, 0.0231, 0.0260, 0.0248, 0.0359,
         0.0175, 0.0235, 0.0263, 0.0324]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 80
images/270
(64, 64, 3)
tensor([[0.0285, 0.0342, 0.0211, 0.0218, 0.0270, 0.0168, 0.0335, 0.0166, 0.0192,
         0.0241, 0.0155, 0.0223, 0.0216, 0.0234, 0.0375, 0.0270, 0.0256, 0.0385,
         0.0213, 0.0190, 0.0216, 0.0269, 0.0197, 0.0168, 0.0307, 0.0171, 0.0202,
         0.0257, 0.0269, 0.0219, 0.0286, 0.0354, 0.0240, 0.0269, 0.0165, 0.0232,
         0.0225, 0.0244, 0.0375, 0.0392]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 81
images/66
(64, 64, 3)
tensor([[0.0226, 0.0176, 0.0260, 0.0233, 0.0294, 0.0162, 0.0258, 0.0205, 0.0251,
         0.0175, 0.0136, 0.0360, 0.0315, 0.0240, 0.0210, 0.0230, 0.0136, 0.0432,
         0.0167, 0.0276, 0.0186, 0.0263, 0.0261, 0.0247, 0.0147, 0.0283, 0.0276,
         0.0216, 0.0340, 0.0271, 0.0174, 0.0726, 0.0292, 0.0156, 0.0297, 0.0255,
         0.0269, 0.0195, 0.0169, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 82
images/376
(64, 64, 3)
tensor([[0.0336, 0.0277, 0.0339, 0.0177, 0.0423, 0.0241, 0.0236, 0.0131, 0.0144,
         0.0119, 0.0169, 0.0254, 0.0526, 0.0244, 0.0173, 0.0210, 0.0293, 0.0293,
         0.0229, 0.0177, 0.0176, 0.0377, 0.0314, 0.0273, 0.0197, 0.0305, 0.0219,
         0.0272, 0.0319, 0.0240, 0.0213, 0.0253, 0.0264, 0.0216, 0.0186, 0.0338,
         0.0317, 0.0188, 0.0131, 0.0208]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 83
images/192
(64, 64, 3)
tensor([[0.0280, 0.0381, 0.0174, 0.0259, 0.0303, 0.0137, 0.0334, 0.0127, 0.0116,
         0.0225, 0.0182, 0.0319, 0.0423, 0.0286, 0.0261, 0.0208, 0.0234, 0.0417,
         0.0134, 0.0243, 0.0221, 0.0241, 0.0165, 0.0269, 0.0146, 0.0273, 0.0243,
         0.0318, 0.0353, 0.0328, 0.0145, 0.0306, 0.0258, 0.0196, 0.0259, 0.0245,
         0.0397, 0.0210, 0.0219, 0.0169]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 84
images/77
(64, 64, 3)
tensor([[0.0343, 0.0234, 0.0211, 0.0184, 0.0316, 0.0237, 0.0237, 0.0243, 0.0199,
         0.0184, 0.0208, 0.0448, 0.0288, 0.0208, 0.0214, 0.0200, 0.0351, 0.0255,
         0.0209, 0.0170, 0.0210, 0.0287, 0.0185, 0.0246, 0.0247, 0.0212, 0.0206,
         0.0461, 0.0417, 0.0234, 0.0205, 0.0207, 0.0199, 0.0349, 0.0190, 0.0273,
         0.0280, 0.0181, 0.0254, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 85
images/536
(64, 64, 3)
tensor([[0.0216, 0.0213, 0.0158, 0.0273, 0.0238, 0.0218, 0.0463, 0.0137, 0.0128,
         0.0203, 0.0166, 0.0314, 0.0327, 0.0343, 0.0214, 0.0273, 0.0174, 0.0480,
         0.0184, 0.0222, 0.0217, 0.0207, 0.0193, 0.0193, 0.0164, 0.0200, 0.0246,
         0.0410, 0.0321, 0.0209, 0.0130, 0.0482, 0.0259, 0.0210, 0.0349, 0.0257,
         0.0280, 0.0148, 0.0225, 0.0355]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 86
images/166
(64, 64, 3)
tensor([[0.0274, 0.0219, 0.0100, 0.0107, 0.0198, 0.0234, 0.0346, 0.0240, 0.0181,
         0.0192, 0.0220, 0.0250, 0.0412, 0.0309, 0.0279, 0.0144, 0.0335, 0.0324,
         0.0183, 0.0116, 0.0163, 0.0245, 0.0219, 0.0281, 0.0189, 0.0194, 0.0408,
         0.0334, 0.0203, 0.0270, 0.0117, 0.0378, 0.0305, 0.0326, 0.0409, 0.0268,
         0.0346, 0.0172, 0.0297, 0.0212]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 87
images/475
(64, 64, 3)
tensor([[0.0282, 0.0184, 0.0142, 0.0237, 0.0305, 0.0292, 0.0432, 0.0237, 0.0132,
         0.0171, 0.0250, 0.0416, 0.0550, 0.0270, 0.0159, 0.0233, 0.0157, 0.0308,
         0.0165, 0.0216, 0.0176, 0.0275, 0.0336, 0.0220, 0.0243, 0.0162, 0.0195,
         0.0283, 0.0280, 0.0265, 0.0181, 0.0371, 0.0239, 0.0223, 0.0194, 0.0296,
         0.0208, 0.0267, 0.0250, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 88
images/425
(64, 64, 3)
tensor([[0.0360, 0.0162, 0.0260, 0.0175, 0.0309, 0.0152, 0.0401, 0.0318, 0.0249,
         0.0119, 0.0301, 0.0476, 0.0404, 0.0315, 0.0164, 0.0168, 0.0118, 0.0255,
         0.0226, 0.0185, 0.0171, 0.0133, 0.0270, 0.0216, 0.0159, 0.0212, 0.0225,
         0.0421, 0.0339, 0.0226, 0.0228, 0.0290, 0.0208, 0.0275, 0.0258, 0.0273,
         0.0319, 0.0149, 0.0246, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/509
(64, 64, 3)
tensor([[0.0188, 0.0256, 0.0203, 0.0207, 0.0376, 0.0206, 0.0251, 0.0166, 0.0237,
         0.0249, 0.0130, 0.0227, 0.0637, 0.0352, 0.0328, 0.0297, 0.0143, 0.0312,
         0.0231, 0.0227, 0.0170, 0.0198, 0.0195, 0.0171, 0.0173, 0.0251, 0.0249,
         0.0308, 0.0190, 0.0250, 0.0127, 0.0279, 0.0228, 0.0371, 0.0193, 0.0314,
         0.0341, 0.0209, 0.0255, 0.0308]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 90
images/309
(64, 64, 3)
tensor([[0.0236, 0.0283, 0.0219, 0.0250, 0.0246, 0.0293, 0.0265, 0.0160, 0.0134,
         0.0167, 0.0190, 0.0391, 0.0359, 0.0255, 0.0203, 0.0294, 0.0198, 0.0289,
         0.0181, 0.0307, 0.0221, 0.0286, 0.0317, 0.0260, 0.0232, 0.0199, 0.0273,
         0.0277, 0.0367, 0.0224, 0.0158, 0.0241, 0.0220, 0.0232, 0.0210, 0.0288,
         0.0425, 0.0178, 0.0247, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 91
images/42
(64, 64, 3)
tensor([[0.0273, 0.0385, 0.0172, 0.0157, 0.0174, 0.0274, 0.0348, 0.0250, 0.0200,
         0.0231, 0.0185, 0.0521, 0.0443, 0.0162, 0.0229, 0.0248, 0.0154, 0.0244,
         0.0212, 0.0167, 0.0180, 0.0162, 0.0207, 0.0299, 0.0203, 0.0188, 0.0307,
         0.0499, 0.0232, 0.0327, 0.0242, 0.0364, 0.0278, 0.0191, 0.0234, 0.0228,
         0.0159, 0.0149, 0.0226, 0.0293]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 92
images/54
(64, 64, 3)
tensor([[0.0227, 0.0324, 0.0235, 0.0195, 0.0197, 0.0203, 0.0303, 0.0176, 0.0226,
         0.0221, 0.0199, 0.0238, 0.0576, 0.0241, 0.0189, 0.0173, 0.0184, 0.0304,
         0.0133, 0.0251, 0.0147, 0.0216, 0.0199, 0.0226, 0.0277, 0.0160, 0.0285,
         0.0318, 0.0559, 0.0203, 0.0228, 0.0399, 0.0237, 0.0278, 0.0234, 0.0333,
         0.0183, 0.0214, 0.0255, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 93
images/283
(64, 64, 3)
tensor([[0.0286, 0.0408, 0.0146, 0.0228, 0.0300, 0.0255, 0.0449, 0.0134, 0.0174,
         0.0229, 0.0171, 0.0250, 0.0296, 0.0304, 0.0285, 0.0231, 0.0222, 0.0338,
         0.0177, 0.0171, 0.0241, 0.0324, 0.0228, 0.0154, 0.0198, 0.0188, 0.0303,
         0.0186, 0.0352, 0.0265, 0.0257, 0.0256, 0.0373, 0.0321, 0.0187, 0.0260,
         0.0421, 0.0129, 0.0126, 0.0177]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 94
images/421
(64, 64, 3)
tensor([[0.0338, 0.0318, 0.0204, 0.0218, 0.0278, 0.0206, 0.0402, 0.0147, 0.0234,
         0.0263, 0.0176, 0.0247, 0.0453, 0.0299, 0.0253, 0.0124, 0.0191, 0.0304,
         0.0130, 0.0271, 0.0164, 0.0213, 0.0214, 0.0247, 0.0197, 0.0237, 0.0233,
         0.0323, 0.0329, 0.0198, 0.0179, 0.0263, 0.0332, 0.0164, 0.0156, 0.0338,
         0.0262, 0.0404, 0.0252, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 1
Session Number: 95
images/405
(64, 64, 3)
tensor([[0.0230, 0.0313, 0.0184, 0.0220, 0.0349, 0.0233, 0.0408, 0.0171, 0.0151,
         0.0146, 0.0140, 0.0359, 0.0587, 0.0322, 0.0322, 0.0144, 0.0223, 0.0283,
         0.0252, 0.0208, 0.0177, 0.0232, 0.0156, 0.0215, 0.0332, 0.0168, 0.0270,
         0.0256, 0.0265, 0.0264, 0.0149, 0.0447, 0.0222, 0.0168, 0.0119, 0.0447,
         0.0206, 0.0225, 0.0248, 0.0189]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 96
images/355
(64, 64, 3)
tensor([[0.0194, 0.0302, 0.0169, 0.0200, 0.0480, 0.0224, 0.0320, 0.0260, 0.0174,
         0.0212, 0.0177, 0.0338, 0.0395, 0.0259, 0.0318, 0.0190, 0.0116, 0.0425,
         0.0240, 0.0249, 0.0184, 0.0202, 0.0162, 0.0188, 0.0186, 0.0200, 0.0349,
         0.0455, 0.0294, 0.0195, 0.0150, 0.0358, 0.0219, 0.0277, 0.0311, 0.0190,
         0.0228, 0.0150, 0.0200, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 97
images/181
(64, 64, 3)
tensor([[0.0253, 0.0198, 0.0180, 0.0378, 0.0334, 0.0192, 0.0496, 0.0149, 0.0184,
         0.0135, 0.0171, 0.0417, 0.0334, 0.0466, 0.0309, 0.0132, 0.0124, 0.0390,
         0.0243, 0.0252, 0.0175, 0.0141, 0.0316, 0.0190, 0.0184, 0.0186, 0.0239,
         0.0271, 0.0249, 0.0173, 0.0169, 0.0190, 0.0350, 0.0262, 0.0184, 0.0286,
         0.0376, 0.0202, 0.0222, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 98
images/592
(64, 64, 3)
tensor([[0.0301, 0.0233, 0.0165, 0.0114, 0.0291, 0.0169, 0.0341, 0.0186, 0.0179,
         0.0198, 0.0159, 0.0415, 0.0321, 0.0375, 0.0286, 0.0188, 0.0195, 0.0336,
         0.0240, 0.0256, 0.0159, 0.0284, 0.0183, 0.0198, 0.0186, 0.0271, 0.0368,
         0.0300, 0.0276, 0.0211, 0.0132, 0.0366, 0.0319, 0.0255, 0.0369, 0.0306,
         0.0247, 0.0193, 0.0187, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 99
images/541
(64, 64, 3)
tensor([[0.0258, 0.0290, 0.0152, 0.0138, 0.0416, 0.0255, 0.0342, 0.0171, 0.0170,
         0.0123, 0.0180, 0.0342, 0.0473, 0.0353, 0.0199, 0.0136, 0.0249, 0.0407,
         0.0274, 0.0200, 0.0161, 0.0168, 0.0217, 0.0214, 0.0223, 0.0181, 0.0394,
         0.0269, 0.0285, 0.0206, 0.0169, 0.0347, 0.0403, 0.0262, 0.0207, 0.0358,
         0.0187, 0.0157, 0.0244, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Saving the weights
36 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/392
(64, 64, 3)
2018-10-13 02:20:05.636 Python[10969:15755970] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0398, 0.0221, 0.0162, 0.0253, 0.0364, 0.0211, 0.0288, 0.0129, 0.0193,
         0.0169, 0.0157, 0.0226, 0.0350, 0.0251, 0.0294, 0.0192, 0.0182, 0.0330,
         0.0176, 0.0175, 0.0112, 0.0272, 0.0301, 0.0200, 0.0284, 0.0269, 0.0201,
         0.0267, 0.0251, 0.0203, 0.0142, 0.0375, 0.0307, 0.0214, 0.0288, 0.0457,
         0.0314, 0.0346, 0.0249, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/75
(64, 64, 3)
tensor([[0.0366, 0.0280, 0.0298, 0.0164, 0.0349, 0.0182, 0.0351, 0.0193, 0.0179,
         0.0170, 0.0155, 0.0324, 0.0354, 0.0265, 0.0365, 0.0145, 0.0209, 0.0347,
         0.0166, 0.0223, 0.0161, 0.0228, 0.0175, 0.0302, 0.0254, 0.0204, 0.0189,
         0.0425, 0.0342, 0.0148, 0.0220, 0.0348, 0.0207, 0.0226, 0.0296, 0.0209,
         0.0390, 0.0242, 0.0147, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/357
(64, 64, 3)
tensor([[0.0396, 0.0321, 0.0101, 0.0176, 0.0294, 0.0237, 0.0350, 0.0137, 0.0134,
         0.0237, 0.0235, 0.0348, 0.0351, 0.0436, 0.0244, 0.0160, 0.0247, 0.0429,
         0.0187, 0.0151, 0.0203, 0.0276, 0.0160, 0.0226, 0.0165, 0.0164, 0.0250,
         0.0232, 0.0357, 0.0215, 0.0244, 0.0288, 0.0475, 0.0231, 0.0275, 0.0275,
         0.0182, 0.0219, 0.0211, 0.0181]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 3
images/326
(64, 64, 3)
tensor([[0.0304, 0.0225, 0.0197, 0.0212, 0.0365, 0.0155, 0.0294, 0.0154, 0.0233,
         0.0158, 0.0286, 0.0448, 0.0340, 0.0337, 0.0294, 0.0195, 0.0132, 0.0309,
         0.0104, 0.0325, 0.0238, 0.0289, 0.0139, 0.0128, 0.0300, 0.0148, 0.0190,
         0.0656, 0.0364, 0.0169, 0.0197, 0.0222, 0.0205, 0.0400, 0.0296, 0.0183,
         0.0268, 0.0226, 0.0182, 0.0132]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 4
images/56
(64, 64, 3)
tensor([[0.0234, 0.0246, 0.0225, 0.0162, 0.0547, 0.0225, 0.0292, 0.0208, 0.0196,
         0.0231, 0.0139, 0.0310, 0.0255, 0.0267, 0.0287, 0.0163, 0.0246, 0.0496,
         0.0158, 0.0119, 0.0114, 0.0277, 0.0252, 0.0250, 0.0230, 0.0246, 0.0316,
         0.0230, 0.0322, 0.0243, 0.0131, 0.0484, 0.0222, 0.0247, 0.0281, 0.0199,
         0.0236, 0.0224, 0.0264, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 5
images/557
(64, 64, 3)
tensor([[0.0173, 0.0427, 0.0175, 0.0214, 0.0280, 0.0161, 0.0264, 0.0171, 0.0152,
         0.0226, 0.0212, 0.0323, 0.0393, 0.0338, 0.0237, 0.0271, 0.0262, 0.0347,
         0.0129, 0.0206, 0.0140, 0.0195, 0.0236, 0.0276, 0.0133, 0.0221, 0.0385,
         0.0317, 0.0274, 0.0336, 0.0193, 0.0248, 0.0293, 0.0239, 0.0297, 0.0311,
         0.0268, 0.0164, 0.0187, 0.0326]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 6
images/146
(64, 64, 3)
tensor([[0.0290, 0.0343, 0.0276, 0.0175, 0.0302, 0.0239, 0.0262, 0.0157, 0.0203,
         0.0348, 0.0162, 0.0275, 0.0359, 0.0199, 0.0214, 0.0164, 0.0198, 0.0410,
         0.0193, 0.0249, 0.0169, 0.0239, 0.0256, 0.0244, 0.0133, 0.0222, 0.0283,
         0.0281, 0.0396, 0.0224, 0.0215, 0.0305, 0.0214, 0.0209, 0.0182, 0.0360,
         0.0278, 0.0225, 0.0247, 0.0301]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 7
images/257
(64, 64, 3)
tensor([[0.0322, 0.0263, 0.0263, 0.0172, 0.0250, 0.0149, 0.0262, 0.0204, 0.0181,
         0.0157, 0.0220, 0.0361, 0.0467, 0.0263, 0.0232, 0.0249, 0.0207, 0.0188,
         0.0167, 0.0242, 0.0147, 0.0220, 0.0198, 0.0240, 0.0219, 0.0213, 0.0372,
         0.0455, 0.0333, 0.0234, 0.0261, 0.0328, 0.0215, 0.0415, 0.0209, 0.0287,
         0.0237, 0.0207, 0.0159, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/408
(64, 64, 3)
tensor([[0.0262, 0.0218, 0.0090, 0.0154, 0.0239, 0.0231, 0.0282, 0.0194, 0.0166,
         0.0242, 0.0138, 0.0342, 0.0634, 0.0292, 0.0264, 0.0210, 0.0313, 0.0461,
         0.0217, 0.0181, 0.0102, 0.0230, 0.0319, 0.0197, 0.0166, 0.0242, 0.0264,
         0.0241, 0.0284, 0.0186, 0.0113, 0.0434, 0.0271, 0.0212, 0.0162, 0.0403,
         0.0255, 0.0193, 0.0244, 0.0355]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 9
images/151
(64, 64, 3)
tensor([[0.0333, 0.0389, 0.0081, 0.0138, 0.0230, 0.0160, 0.0294, 0.0201, 0.0101,
         0.0346, 0.0214, 0.0386, 0.0217, 0.0341, 0.0331, 0.0149, 0.0248, 0.0369,
         0.0185, 0.0155, 0.0130, 0.0208, 0.0191, 0.0223, 0.0207, 0.0192, 0.0280,
         0.0342, 0.0530, 0.0234, 0.0207, 0.0308, 0.0325, 0.0307, 0.0189, 0.0420,
         0.0204, 0.0171, 0.0182, 0.0281]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 10
images/278
(64, 64, 3)
tensor([[0.0354, 0.0231, 0.0199, 0.0175, 0.0380, 0.0191, 0.0258, 0.0113, 0.0171,
         0.0194, 0.0233, 0.0349, 0.0421, 0.0306, 0.0387, 0.0122, 0.0184, 0.0278,
         0.0167, 0.0241, 0.0150, 0.0253, 0.0321, 0.0322, 0.0195, 0.0152, 0.0372,
         0.0262, 0.0252, 0.0210, 0.0253, 0.0317, 0.0256, 0.0211, 0.0374, 0.0283,
         0.0226, 0.0222, 0.0215, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/326
(64, 64, 3)
tensor([[0.0213, 0.0219, 0.0436, 0.0139, 0.0478, 0.0259, 0.0257, 0.0149, 0.0258,
         0.0210, 0.0103, 0.0391, 0.0277, 0.0286, 0.0219, 0.0195, 0.0129, 0.0334,
         0.0156, 0.0202, 0.0194, 0.0290, 0.0192, 0.0225, 0.0238, 0.0201, 0.0270,
         0.0347, 0.0562, 0.0260, 0.0174, 0.0261, 0.0237, 0.0246, 0.0323, 0.0154,
         0.0333, 0.0193, 0.0161, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 12
images/221
(64, 64, 3)
tensor([[0.0356, 0.0298, 0.0175, 0.0161, 0.0294, 0.0188, 0.0400, 0.0234, 0.0158,
         0.0224, 0.0184, 0.0204, 0.0366, 0.0439, 0.0183, 0.0185, 0.0207, 0.0388,
         0.0138, 0.0147, 0.0192, 0.0295, 0.0243, 0.0336, 0.0301, 0.0115, 0.0224,
         0.0388, 0.0428, 0.0157, 0.0115, 0.0278, 0.0314, 0.0190, 0.0231, 0.0249,
         0.0239, 0.0260, 0.0215, 0.0300]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 13
images/85
(64, 64, 3)
tensor([[0.0216, 0.0237, 0.0186, 0.0198, 0.0315, 0.0326, 0.0365, 0.0201, 0.0175,
         0.0189, 0.0256, 0.0251, 0.0378, 0.0288, 0.0179, 0.0217, 0.0146, 0.0149,
         0.0125, 0.0219, 0.0263, 0.0205, 0.0166, 0.0210, 0.0305, 0.0162, 0.0318,
         0.0394, 0.0332, 0.0160, 0.0210, 0.0295, 0.0541, 0.0126, 0.0292, 0.0297,
         0.0415, 0.0121, 0.0273, 0.0300]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 14
images/536
(64, 64, 3)
tensor([[0.0372, 0.0204, 0.0133, 0.0131, 0.0245, 0.0214, 0.0353, 0.0188, 0.0167,
         0.0176, 0.0165, 0.0310, 0.0313, 0.0295, 0.0237, 0.0137, 0.0203, 0.0523,
         0.0142, 0.0264, 0.0148, 0.0161, 0.0322, 0.0155, 0.0221, 0.0230, 0.0287,
         0.0335, 0.0331, 0.0217, 0.0205, 0.0770, 0.0310, 0.0161, 0.0184, 0.0189,
         0.0250, 0.0166, 0.0268, 0.0319]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 15
images/57
(64, 64, 3)
tensor([[0.0331, 0.0224, 0.0229, 0.0194, 0.0305, 0.0243, 0.0369, 0.0166, 0.0156,
         0.0223, 0.0224, 0.0270, 0.0285, 0.0325, 0.0269, 0.0167, 0.0180, 0.0317,
         0.0176, 0.0208, 0.0208, 0.0191, 0.0293, 0.0200, 0.0250, 0.0153, 0.0158,
         0.0264, 0.0258, 0.0319, 0.0378, 0.0360, 0.0287, 0.0138, 0.0176, 0.0373,
         0.0406, 0.0102, 0.0389, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 16
images/272
(64, 64, 3)
tensor([[0.0330, 0.0265, 0.0102, 0.0136, 0.0318, 0.0188, 0.0416, 0.0170, 0.0214,
         0.0268, 0.0193, 0.0243, 0.0552, 0.0278, 0.0273, 0.0154, 0.0183, 0.0511,
         0.0229, 0.0223, 0.0205, 0.0245, 0.0170, 0.0196, 0.0163, 0.0275, 0.0206,
         0.0337, 0.0294, 0.0261, 0.0159, 0.0405, 0.0192, 0.0261, 0.0246, 0.0341,
         0.0158, 0.0167, 0.0223, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 17
images/584
(64, 64, 3)
tensor([[0.0220, 0.0215, 0.0204, 0.0154, 0.0328, 0.0208, 0.0280, 0.0185, 0.0190,
         0.0278, 0.0208, 0.0150, 0.0569, 0.0370, 0.0261, 0.0142, 0.0211, 0.0730,
         0.0221, 0.0128, 0.0127, 0.0231, 0.0262, 0.0217, 0.0131, 0.0213, 0.0194,
         0.0371, 0.0264, 0.0345, 0.0178, 0.0376, 0.0194, 0.0197, 0.0242, 0.0335,
         0.0211, 0.0161, 0.0265, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 18
images/314
(64, 64, 3)
tensor([[0.0182, 0.0240, 0.0186, 0.0162, 0.0287, 0.0199, 0.0355, 0.0205, 0.0159,
         0.0151, 0.0118, 0.0260, 0.0528, 0.0349, 0.0214, 0.0223, 0.0155, 0.0291,
         0.0204, 0.0314, 0.0304, 0.0283, 0.0234, 0.0186, 0.0222, 0.0191, 0.0258,
         0.0286, 0.0400, 0.0254, 0.0202, 0.0388, 0.0271, 0.0205, 0.0229, 0.0277,
         0.0395, 0.0158, 0.0171, 0.0305]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 19
images/251
(64, 64, 3)
tensor([[0.0295, 0.0189, 0.0248, 0.0176, 0.0293, 0.0267, 0.0474, 0.0164, 0.0155,
         0.0153, 0.0154, 0.0364, 0.0273, 0.0350, 0.0238, 0.0193, 0.0209, 0.0439,
         0.0213, 0.0139, 0.0182, 0.0173, 0.0190, 0.0158, 0.0136, 0.0169, 0.0182,
         0.0335, 0.0320, 0.0312, 0.0227, 0.0394, 0.0304, 0.0297, 0.0338, 0.0319,
         0.0251, 0.0225, 0.0297, 0.0204]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 20
images/123
(64, 64, 3)
tensor([[0.0249, 0.0286, 0.0175, 0.0222, 0.0280, 0.0202, 0.0398, 0.0167, 0.0141,
         0.0177, 0.0158, 0.0228, 0.0341, 0.0235, 0.0295, 0.0231, 0.0164, 0.0398,
         0.0133, 0.0202, 0.0166, 0.0312, 0.0185, 0.0265, 0.0206, 0.0269, 0.0208,
         0.0322, 0.0267, 0.0312, 0.0253, 0.0312, 0.0323, 0.0234, 0.0256, 0.0387,
         0.0268, 0.0264, 0.0206, 0.0302]], grad_fn=<SoftmaxBackward>)


Action: 0.2
0
Enter Reward: Saving the weights
**************************************************
Session Number: 21
images/359
(64, 64, 3)
tensor([[0.0241, 0.0318, 0.0172, 0.0150, 0.0271, 0.0203, 0.0341, 0.0158, 0.0180,
         0.0222, 0.0167, 0.0313, 0.0421, 0.0317, 0.0166, 0.0135, 0.0237, 0.0243,
         0.0217, 0.0213, 0.0167, 0.0206, 0.0200, 0.0297, 0.0176, 0.0242, 0.0320,
         0.0379, 0.0449, 0.0203, 0.0181, 0.0286, 0.0298, 0.0206, 0.0202, 0.0414,
         0.0444, 0.0159, 0.0215, 0.0273]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 22
images/293
(64, 64, 3)
tensor([[0.0285, 0.0283, 0.0213, 0.0166, 0.0270, 0.0120, 0.0391, 0.0255, 0.0134,
         0.0219, 0.0136, 0.0309, 0.0334, 0.0272, 0.0208, 0.0113, 0.0253, 0.0554,
         0.0127, 0.0211, 0.0190, 0.0248, 0.0252, 0.0299, 0.0229, 0.0157, 0.0201,
         0.0301, 0.0391, 0.0212, 0.0172, 0.0309, 0.0275, 0.0354, 0.0220, 0.0391,
         0.0236, 0.0208, 0.0258, 0.0243]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 23
images/399
(64, 64, 3)
tensor([[0.0175, 0.0190, 0.0255, 0.0150, 0.0357, 0.0273, 0.0291, 0.0194, 0.0181,
         0.0287, 0.0165, 0.0310, 0.0360, 0.0440, 0.0309, 0.0162, 0.0177, 0.0271,
         0.0188, 0.0244, 0.0160, 0.0293, 0.0251, 0.0247, 0.0209, 0.0275, 0.0289,
         0.0254, 0.0220, 0.0271, 0.0175, 0.0253, 0.0211, 0.0262, 0.0376, 0.0295,
         0.0262, 0.0271, 0.0217, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 24
images/313
(64, 64, 3)
tensor([[0.0192, 0.0183, 0.0167, 0.0206, 0.0365, 0.0189, 0.0315, 0.0186, 0.0211,
         0.0231, 0.0149, 0.0249, 0.0267, 0.0249, 0.0310, 0.0208, 0.0275, 0.0341,
         0.0214, 0.0143, 0.0200, 0.0168, 0.0190, 0.0381, 0.0190, 0.0242, 0.0277,
         0.0352, 0.0368, 0.0185, 0.0284, 0.0362, 0.0251, 0.0257, 0.0242, 0.0329,
         0.0294, 0.0150, 0.0200, 0.0426]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 25
images/339
(64, 64, 3)
tensor([[0.0226, 0.0276, 0.0220, 0.0150, 0.0304, 0.0205, 0.0228, 0.0267, 0.0123,
         0.0193, 0.0248, 0.0307, 0.0361, 0.0324, 0.0202, 0.0255, 0.0180, 0.0430,
         0.0177, 0.0237, 0.0211, 0.0224, 0.0312, 0.0336, 0.0243, 0.0220, 0.0173,
         0.0302, 0.0278, 0.0347, 0.0221, 0.0392, 0.0245, 0.0177, 0.0176, 0.0337,
         0.0237, 0.0209, 0.0206, 0.0240]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 26
images/289
(64, 64, 3)
tensor([[0.0227, 0.0211, 0.0172, 0.0182, 0.0399, 0.0157, 0.0319, 0.0218, 0.0134,
         0.0281, 0.0091, 0.0344, 0.0201, 0.0355, 0.0330, 0.0145, 0.0149, 0.0511,
         0.0118, 0.0292, 0.0305, 0.0450, 0.0245, 0.0227, 0.0286, 0.0131, 0.0169,
         0.0433, 0.0461, 0.0237, 0.0211, 0.0223, 0.0197, 0.0227, 0.0151, 0.0290,
         0.0216, 0.0171, 0.0199, 0.0333]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 27
images/290
(64, 64, 3)
tensor([[0.0293, 0.0358, 0.0132, 0.0195, 0.0188, 0.0196, 0.0281, 0.0182, 0.0193,
         0.0173, 0.0205, 0.0150, 0.0542, 0.0276, 0.0338, 0.0288, 0.0247, 0.0385,
         0.0189, 0.0194, 0.0148, 0.0270, 0.0194, 0.0189, 0.0177, 0.0241, 0.0332,
         0.0287, 0.0203, 0.0270, 0.0213, 0.0301, 0.0290, 0.0160, 0.0305, 0.0263,
         0.0305, 0.0222, 0.0313, 0.0311]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 28
images/520
(64, 64, 3)
tensor([[0.0366, 0.0226, 0.0129, 0.0163, 0.0247, 0.0210, 0.0436, 0.0124, 0.0158,
         0.0176, 0.0249, 0.0293, 0.0600, 0.0347, 0.0223, 0.0109, 0.0153, 0.0360,
         0.0216, 0.0188, 0.0154, 0.0218, 0.0285, 0.0216, 0.0140, 0.0166, 0.0318,
         0.0275, 0.0232, 0.0170, 0.0210, 0.0262, 0.0230, 0.0262, 0.0385, 0.0401,
         0.0409, 0.0202, 0.0264, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Session Number: 29
images/576
(64, 64, 3)
tensor([[0.0368, 0.0257, 0.0191, 0.0249, 0.0279, 0.0228, 0.0239, 0.0124, 0.0215,
         0.0211, 0.0242, 0.0294, 0.0422, 0.0229, 0.0180, 0.0230, 0.0135, 0.0193,
         0.0167, 0.0272, 0.0226, 0.0353, 0.0315, 0.0288, 0.0235, 0.0175, 0.0263,
         0.0334, 0.0238, 0.0162, 0.0181, 0.0405, 0.0285, 0.0272, 0.0297, 0.0205,
         0.0325, 0.0163, 0.0216, 0.0336]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 30
images/417
(64, 64, 3)
tensor([[0.0356, 0.0190, 0.0200, 0.0198, 0.0319, 0.0164, 0.0226, 0.0144, 0.0139,
         0.0142, 0.0180, 0.0280, 0.0278, 0.0361, 0.0166, 0.0178, 0.0171, 0.0522,
         0.0205, 0.0351, 0.0289, 0.0236, 0.0240, 0.0147, 0.0296, 0.0361, 0.0245,
         0.0354, 0.0368, 0.0272, 0.0260, 0.0338, 0.0252, 0.0271, 0.0160, 0.0277,
         0.0290, 0.0181, 0.0177, 0.0216]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 31
images/519
(64, 64, 3)
tensor([[0.0220, 0.0206, 0.0188, 0.0150, 0.0200, 0.0131, 0.0352, 0.0240, 0.0165,
         0.0209, 0.0233, 0.0698, 0.0210, 0.0297, 0.0166, 0.0123, 0.0281, 0.0406,
         0.0116, 0.0276, 0.0141, 0.0243, 0.0241, 0.0233, 0.0196, 0.0197, 0.0177,
         0.0396, 0.0403, 0.0227, 0.0184, 0.0365, 0.0388, 0.0202, 0.0132, 0.0281,
         0.0281, 0.0218, 0.0266, 0.0363]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 32
images/538
(64, 64, 3)
tensor([[0.0254, 0.0361, 0.0191, 0.0146, 0.0293, 0.0233, 0.0333, 0.0206, 0.0173,
         0.0191, 0.0260, 0.0266, 0.0319, 0.0271, 0.0336, 0.0208, 0.0295, 0.0239,
         0.0246, 0.0252, 0.0150, 0.0324, 0.0200, 0.0305, 0.0184, 0.0212, 0.0287,
         0.0206, 0.0258, 0.0203, 0.0224, 0.0194, 0.0370, 0.0291, 0.0198, 0.0199,
         0.0258, 0.0344, 0.0269, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 33
images/598
(64, 64, 3)
tensor([[0.0268, 0.0209, 0.0200, 0.0197, 0.0416, 0.0188, 0.0441, 0.0168, 0.0168,
         0.0282, 0.0144, 0.0434, 0.0366, 0.0372, 0.0238, 0.0117, 0.0213, 0.0372,
         0.0354, 0.0160, 0.0192, 0.0224, 0.0196, 0.0195, 0.0229, 0.0159, 0.0206,
         0.0327, 0.0283, 0.0266, 0.0177, 0.0342, 0.0393, 0.0191, 0.0194, 0.0191,
         0.0260, 0.0175, 0.0212, 0.0283]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 34
images/359
(64, 64, 3)
tensor([[0.0376, 0.0278, 0.0105, 0.0142, 0.0342, 0.0199, 0.0298, 0.0203, 0.0124,
         0.0203, 0.0157, 0.0270, 0.0252, 0.0251, 0.0193, 0.0149, 0.0209, 0.0378,
         0.0167, 0.0212, 0.0208, 0.0332, 0.0135, 0.0265, 0.0237, 0.0217, 0.0336,
         0.0422, 0.0327, 0.0347, 0.0169, 0.0404, 0.0311, 0.0253, 0.0309, 0.0296,
         0.0300, 0.0203, 0.0164, 0.0258]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 35
images/298
(64, 64, 3)
tensor([[0.0344, 0.0196, 0.0216, 0.0135, 0.0319, 0.0259, 0.0326, 0.0284, 0.0205,
         0.0168, 0.0204, 0.0326, 0.0375, 0.0449, 0.0152, 0.0194, 0.0194, 0.0284,
         0.0212, 0.0174, 0.0212, 0.0195, 0.0202, 0.0232, 0.0209, 0.0152, 0.0207,
         0.0360, 0.0600, 0.0325, 0.0190, 0.0304, 0.0309, 0.0240, 0.0199, 0.0213,
         0.0215, 0.0196, 0.0203, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 36
images/207
(64, 64, 3)
tensor([[0.0202, 0.0199, 0.0116, 0.0273, 0.0371, 0.0193, 0.0416, 0.0234, 0.0133,
         0.0150, 0.0157, 0.0211, 0.0302, 0.0300, 0.0201, 0.0162, 0.0241, 0.0604,
         0.0158, 0.0198, 0.0133, 0.0277, 0.0147, 0.0151, 0.0236, 0.0332, 0.0209,
         0.0342, 0.0408, 0.0255, 0.0249, 0.0286, 0.0185, 0.0135, 0.0393, 0.0463,
         0.0289, 0.0228, 0.0234, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 37
images/338
(64, 64, 3)
tensor([[0.0211, 0.0238, 0.0161, 0.0236, 0.0268, 0.0228, 0.0356, 0.0118, 0.0168,
         0.0203, 0.0228, 0.0376, 0.0370, 0.0410, 0.0298, 0.0219, 0.0174, 0.0412,
         0.0218, 0.0232, 0.0221, 0.0204, 0.0196, 0.0211, 0.0205, 0.0215, 0.0253,
         0.0332, 0.0298, 0.0300, 0.0273, 0.0278, 0.0265, 0.0191, 0.0174, 0.0268,
         0.0332, 0.0188, 0.0243, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 38
images/112
(64, 64, 3)
tensor([[0.0204, 0.0223, 0.0259, 0.0108, 0.0348, 0.0168, 0.0317, 0.0198, 0.0133,
         0.0141, 0.0200, 0.0592, 0.0358, 0.0247, 0.0283, 0.0155, 0.0202, 0.0348,
         0.0223, 0.0223, 0.0240, 0.0211, 0.0212, 0.0188, 0.0245, 0.0198, 0.0198,
         0.0340, 0.0429, 0.0213, 0.0209, 0.0312, 0.0318, 0.0173, 0.0268, 0.0404,
         0.0359, 0.0136, 0.0192, 0.0223]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 39
images/33
(64, 64, 3)
tensor([[0.0298, 0.0186, 0.0328, 0.0190, 0.0407, 0.0231, 0.0303, 0.0163, 0.0219,
         0.0334, 0.0140, 0.0252, 0.0475, 0.0346, 0.0180, 0.0204, 0.0133, 0.0345,
         0.0185, 0.0192, 0.0283, 0.0265, 0.0214, 0.0178, 0.0196, 0.0175, 0.0190,
         0.0455, 0.0247, 0.0297, 0.0214, 0.0324, 0.0249, 0.0161, 0.0261, 0.0354,
         0.0226, 0.0164, 0.0231, 0.0205]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 40
images/427
(64, 64, 3)
tensor([[0.0390, 0.0371, 0.0175, 0.0228, 0.0248, 0.0327, 0.0320, 0.0197, 0.0095,
         0.0178, 0.0198, 0.0275, 0.0251, 0.0302, 0.0305, 0.0200, 0.0220, 0.0316,
         0.0171, 0.0219, 0.0200, 0.0354, 0.0285, 0.0273, 0.0230, 0.0244, 0.0217,
         0.0311, 0.0385, 0.0315, 0.0192, 0.0310, 0.0308, 0.0213, 0.0224, 0.0195,
         0.0202, 0.0204, 0.0162, 0.0192]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 41
images/318
(64, 64, 3)
tensor([[0.0216, 0.0223, 0.0141, 0.0249, 0.0274, 0.0182, 0.0306, 0.0189, 0.0263,
         0.0116, 0.0222, 0.0338, 0.0336, 0.0423, 0.0264, 0.0216, 0.0264, 0.0477,
         0.0181, 0.0125, 0.0234, 0.0242, 0.0197, 0.0209, 0.0210, 0.0210, 0.0228,
         0.0243, 0.0333, 0.0267, 0.0317, 0.0260, 0.0320, 0.0250, 0.0248, 0.0280,
         0.0275, 0.0183, 0.0226, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 1
Session Number: 42
images/268
(64, 64, 3)
tensor([[0.0243, 0.0284, 0.0222, 0.0219, 0.0296, 0.0187, 0.0218, 0.0201, 0.0288,
         0.0251, 0.0163, 0.0317, 0.0362, 0.0305, 0.0329, 0.0333, 0.0195, 0.0446,
         0.0148, 0.0225, 0.0185, 0.0203, 0.0243, 0.0162, 0.0193, 0.0143, 0.0323,
         0.0322, 0.0173, 0.0221, 0.0222, 0.0310, 0.0354, 0.0252, 0.0206, 0.0322,
         0.0181, 0.0205, 0.0203, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 43
images/312
(64, 64, 3)
tensor([[0.0390, 0.0269, 0.0162, 0.0179, 0.0270, 0.0240, 0.0226, 0.0127, 0.0142,
         0.0270, 0.0231, 0.0255, 0.0468, 0.0374, 0.0235, 0.0177, 0.0162, 0.0483,
         0.0291, 0.0320, 0.0123, 0.0332, 0.0213, 0.0172, 0.0182, 0.0212, 0.0263,
         0.0281, 0.0341, 0.0193, 0.0208, 0.0246, 0.0169, 0.0220, 0.0189, 0.0355,
         0.0241, 0.0271, 0.0271, 0.0247]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 44
images/126
(64, 64, 3)
tensor([[0.0225, 0.0277, 0.0158, 0.0171, 0.0340, 0.0157, 0.0383, 0.0225, 0.0174,
         0.0166, 0.0152, 0.0164, 0.0493, 0.0312, 0.0219, 0.0272, 0.0224, 0.0552,
         0.0190, 0.0278, 0.0115, 0.0222, 0.0203, 0.0176, 0.0247, 0.0289, 0.0309,
         0.0399, 0.0269, 0.0203, 0.0160, 0.0324, 0.0222, 0.0245, 0.0276, 0.0225,
         0.0180, 0.0288, 0.0322, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 45
images/68
(64, 64, 3)
tensor([[0.0366, 0.0201, 0.0154, 0.0188, 0.0277, 0.0182, 0.0238, 0.0280, 0.0178,
         0.0158, 0.0214, 0.0412, 0.0546, 0.0311, 0.0267, 0.0251, 0.0178, 0.0367,
         0.0209, 0.0249, 0.0147, 0.0174, 0.0233, 0.0255, 0.0216, 0.0138, 0.0310,
         0.0275, 0.0252, 0.0178, 0.0155, 0.0503, 0.0256, 0.0284, 0.0324, 0.0312,
         0.0151, 0.0221, 0.0176, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 46
images/249
(64, 64, 3)
tensor([[0.0239, 0.0244, 0.0137, 0.0159, 0.0200, 0.0170, 0.0354, 0.0161, 0.0137,
         0.0181, 0.0197, 0.0229, 0.0567, 0.0309, 0.0269, 0.0187, 0.0245, 0.0298,
         0.0198, 0.0294, 0.0141, 0.0217, 0.0307, 0.0170, 0.0169, 0.0165, 0.0428,
         0.0383, 0.0324, 0.0247, 0.0233, 0.0230, 0.0404, 0.0306, 0.0219, 0.0312,
         0.0285, 0.0229, 0.0216, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Session Number: 47
images/483
(64, 64, 3)
tensor([[0.0328, 0.0248, 0.0238, 0.0166, 0.0262, 0.0201, 0.0266, 0.0207, 0.0181,
         0.0176, 0.0196, 0.0357, 0.0284, 0.0293, 0.0244, 0.0241, 0.0171, 0.0486,
         0.0135, 0.0211, 0.0166, 0.0287, 0.0172, 0.0224, 0.0207, 0.0241, 0.0244,
         0.0316, 0.0298, 0.0253, 0.0163, 0.0264, 0.0275, 0.0247, 0.0290, 0.0333,
         0.0366, 0.0206, 0.0155, 0.0402]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 0
Session Number: 48
images/264
(64, 64, 3)
tensor([[0.0328, 0.0169, 0.0187, 0.0149, 0.0329, 0.0183, 0.0227, 0.0172, 0.0207,
         0.0146, 0.0227, 0.0350, 0.0218, 0.0233, 0.0278, 0.0292, 0.0229, 0.0535,
         0.0248, 0.0223, 0.0145, 0.0289, 0.0231, 0.0211, 0.0233, 0.0240, 0.0269,
         0.0237, 0.0341, 0.0229, 0.0330, 0.0229, 0.0189, 0.0327, 0.0224, 0.0447,
         0.0295, 0.0172, 0.0199, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 49
images/316
(64, 64, 3)
tensor([[0.0361, 0.0289, 0.0184, 0.0160, 0.0252, 0.0246, 0.0548, 0.0237, 0.0179,
         0.0270, 0.0166, 0.0377, 0.0415, 0.0397, 0.0210, 0.0180, 0.0137, 0.0289,
         0.0221, 0.0237, 0.0183, 0.0235, 0.0161, 0.0161, 0.0183, 0.0123, 0.0281,
         0.0356, 0.0306, 0.0175, 0.0182, 0.0192, 0.0376, 0.0236, 0.0333, 0.0264,
         0.0239, 0.0172, 0.0237, 0.0247]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 50
images/354
(64, 64, 3)
tensor([[0.0368, 0.0318, 0.0145, 0.0102, 0.0337, 0.0134, 0.0328, 0.0180, 0.0154,
         0.0182, 0.0194, 0.0203, 0.0448, 0.0478, 0.0266, 0.0162, 0.0192, 0.0475,
         0.0159, 0.0153, 0.0143, 0.0401, 0.0233, 0.0189, 0.0209, 0.0137, 0.0203,
         0.0273, 0.0359, 0.0312, 0.0136, 0.0368, 0.0334, 0.0214, 0.0123, 0.0324,
         0.0155, 0.0242, 0.0391, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 51
images/372
(64, 64, 3)
tensor([[0.0302, 0.0280, 0.0239, 0.0214, 0.0340, 0.0218, 0.0252, 0.0172, 0.0232,
         0.0188, 0.0282, 0.0314, 0.0377, 0.0303, 0.0237, 0.0175, 0.0199, 0.0278,
         0.0264, 0.0196, 0.0146, 0.0285, 0.0202, 0.0327, 0.0129, 0.0230, 0.0282,
         0.0374, 0.0216, 0.0219, 0.0200, 0.0244, 0.0358, 0.0271, 0.0203, 0.0182,
         0.0301, 0.0185, 0.0252, 0.0331]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 1
Session Number: 52
images/593
(64, 64, 3)
tensor([[0.0431, 0.0207, 0.0287, 0.0149, 0.0263, 0.0212, 0.0259, 0.0223, 0.0201,
         0.0193, 0.0212, 0.0227, 0.0383, 0.0305, 0.0268, 0.0192, 0.0181, 0.0223,
         0.0197, 0.0188, 0.0191, 0.0284, 0.0180, 0.0208, 0.0224, 0.0195, 0.0211,
         0.0308, 0.0344, 0.0264, 0.0302, 0.0268, 0.0271, 0.0326, 0.0343, 0.0256,
         0.0351, 0.0186, 0.0272, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 53
images/434
(64, 64, 3)
tensor([[0.0277, 0.0433, 0.0146, 0.0158, 0.0291, 0.0233, 0.0341, 0.0181, 0.0177,
         0.0370, 0.0172, 0.0318, 0.0223, 0.0333, 0.0295, 0.0254, 0.0172, 0.0347,
         0.0133, 0.0165, 0.0150, 0.0268, 0.0273, 0.0209, 0.0301, 0.0157, 0.0246,
         0.0190, 0.0285, 0.0197, 0.0076, 0.0268, 0.0360, 0.0369, 0.0283, 0.0241,
         0.0357, 0.0179, 0.0209, 0.0363]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 54
images/422
(64, 64, 3)
tensor([[0.0218, 0.0164, 0.0328, 0.0208, 0.0295, 0.0117, 0.0371, 0.0195, 0.0274,
         0.0119, 0.0251, 0.0185, 0.0490, 0.0400, 0.0220, 0.0177, 0.0152, 0.0374,
         0.0186, 0.0211, 0.0191, 0.0230, 0.0192, 0.0171, 0.0219, 0.0147, 0.0219,
         0.0324, 0.0359, 0.0186, 0.0333, 0.0223, 0.0367, 0.0165, 0.0191, 0.0279,
         0.0226, 0.0208, 0.0487, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 1
Session Number: 55
images/341
(64, 64, 3)
tensor([[0.0210, 0.0231, 0.0203, 0.0200, 0.0410, 0.0234, 0.0426, 0.0189, 0.0221,
         0.0176, 0.0148, 0.0224, 0.0557, 0.0330, 0.0246, 0.0126, 0.0238, 0.0564,
         0.0190, 0.0226, 0.0146, 0.0218, 0.0165, 0.0133, 0.0225, 0.0181, 0.0230,
         0.0232, 0.0286, 0.0260, 0.0254, 0.0406, 0.0326, 0.0181, 0.0276, 0.0252,
         0.0204, 0.0308, 0.0138, 0.0229]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 56
images/254
(64, 64, 3)
tensor([[0.0227, 0.0273, 0.0143, 0.0199, 0.0445, 0.0137, 0.0245, 0.0160, 0.0173,
         0.0170, 0.0228, 0.0214, 0.0431, 0.0510, 0.0237, 0.0208, 0.0193, 0.0422,
         0.0307, 0.0231, 0.0105, 0.0205, 0.0236, 0.0149, 0.0184, 0.0172, 0.0386,
         0.0334, 0.0262, 0.0295, 0.0135, 0.0342, 0.0327, 0.0177, 0.0313, 0.0277,
         0.0304, 0.0182, 0.0170, 0.0291]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 57
images/443
(64, 64, 3)
tensor([[0.0277, 0.0301, 0.0203, 0.0180, 0.0244, 0.0191, 0.0348, 0.0206, 0.0187,
         0.0268, 0.0265, 0.0285, 0.0419, 0.0226, 0.0213, 0.0199, 0.0232, 0.0295,
         0.0344, 0.0236, 0.0235, 0.0164, 0.0154, 0.0170, 0.0272, 0.0263, 0.0281,
         0.0258, 0.0235, 0.0290, 0.0154, 0.0485, 0.0274, 0.0315, 0.0218, 0.0278,
         0.0290, 0.0161, 0.0188, 0.0194]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 58
images/535
(64, 64, 3)
tensor([[0.0317, 0.0233, 0.0154, 0.0245, 0.0400, 0.0146, 0.0342, 0.0149, 0.0153,
         0.0223, 0.0182, 0.0349, 0.0376, 0.0299, 0.0228, 0.0207, 0.0155, 0.0579,
         0.0166, 0.0311, 0.0188, 0.0185, 0.0221, 0.0211, 0.0139, 0.0248, 0.0277,
         0.0323, 0.0326, 0.0272, 0.0211, 0.0168, 0.0212, 0.0203, 0.0257, 0.0279,
         0.0399, 0.0218, 0.0223, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 59
images/200
(64, 64, 3)
tensor([[0.0222, 0.0203, 0.0178, 0.0178, 0.0419, 0.0212, 0.0256, 0.0203, 0.0306,
         0.0168, 0.0223, 0.0248, 0.0379, 0.0628, 0.0263, 0.0125, 0.0168, 0.0280,
         0.0201, 0.0235, 0.0172, 0.0240, 0.0149, 0.0308, 0.0242, 0.0225, 0.0183,
         0.0366, 0.0360, 0.0176, 0.0177, 0.0204, 0.0276, 0.0304, 0.0326, 0.0302,
         0.0253, 0.0210, 0.0231, 0.0203]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 60
images/439
(64, 64, 3)
tensor([[0.0340, 0.0295, 0.0151, 0.0336, 0.0292, 0.0232, 0.0282, 0.0197, 0.0136,
         0.0139, 0.0228, 0.0303, 0.0367, 0.0262, 0.0192, 0.0158, 0.0143, 0.0397,
         0.0191, 0.0199, 0.0135, 0.0267, 0.0248, 0.0312, 0.0317, 0.0180, 0.0266,
         0.0224, 0.0427, 0.0262, 0.0163, 0.0388, 0.0252, 0.0284, 0.0194, 0.0258,
         0.0373, 0.0171, 0.0201, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 61
images/534
(64, 64, 3)
tensor([[0.0272, 0.0310, 0.0287, 0.0181, 0.0328, 0.0168, 0.0550, 0.0214, 0.0328,
         0.0292, 0.0225, 0.0274, 0.0368, 0.0206, 0.0367, 0.0153, 0.0171, 0.0336,
         0.0201, 0.0171, 0.0262, 0.0250, 0.0125, 0.0178, 0.0160, 0.0132, 0.0227,
         0.0219, 0.0246, 0.0261, 0.0160, 0.0408, 0.0282, 0.0238, 0.0150, 0.0346,
         0.0214, 0.0193, 0.0256, 0.0291]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 62
images/263
(64, 64, 3)
tensor([[0.0322, 0.0330, 0.0171, 0.0139, 0.0390, 0.0196, 0.0353, 0.0116, 0.0132,
         0.0229, 0.0209, 0.0351, 0.0373, 0.0256, 0.0346, 0.0129, 0.0308, 0.0339,
         0.0196, 0.0320, 0.0180, 0.0366, 0.0223, 0.0251, 0.0284, 0.0271, 0.0216,
         0.0350, 0.0327, 0.0166, 0.0119, 0.0250, 0.0216, 0.0202, 0.0180, 0.0221,
         0.0210, 0.0232, 0.0252, 0.0281]], grad_fn=<SoftmaxBackward>)


Action: 0.45
Enter Reward: 0
Session Number: 63
images/327
(64, 64, 3)
tensor([[0.0215, 0.0296, 0.0118, 0.0217, 0.0266, 0.0188, 0.0370, 0.0150, 0.0259,
         0.0163, 0.0146, 0.0292, 0.0475, 0.0305, 0.0239, 0.0183, 0.0178, 0.0473,
         0.0183, 0.0247, 0.0197, 0.0320, 0.0150, 0.0179, 0.0357, 0.0170, 0.0349,
         0.0500, 0.0349, 0.0248, 0.0271, 0.0209, 0.0234, 0.0132, 0.0280, 0.0181,
         0.0206, 0.0215, 0.0177, 0.0315]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 64
images/230
(64, 64, 3)
tensor([[0.0348, 0.0286, 0.0221, 0.0197, 0.0279, 0.0276, 0.0216, 0.0160, 0.0173,
         0.0280, 0.0293, 0.0300, 0.0382, 0.0351, 0.0231, 0.0137, 0.0232, 0.0250,
         0.0172, 0.0179, 0.0175, 0.0244, 0.0245, 0.0192, 0.0352, 0.0170, 0.0231,
         0.0420, 0.0428, 0.0216, 0.0210, 0.0264, 0.0191, 0.0184, 0.0202, 0.0382,
         0.0197, 0.0205, 0.0230, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 65
images/160
(64, 64, 3)
tensor([[0.0254, 0.0226, 0.0200, 0.0157, 0.0399, 0.0317, 0.0194, 0.0173, 0.0130,
         0.0250, 0.0148, 0.0291, 0.0439, 0.0365, 0.0229, 0.0160, 0.0277, 0.0231,
         0.0314, 0.0223, 0.0229, 0.0275, 0.0134, 0.0216, 0.0172, 0.0238, 0.0298,
         0.0318, 0.0240, 0.0241, 0.0144, 0.0394, 0.0231, 0.0252, 0.0226, 0.0325,
         0.0312, 0.0285, 0.0211, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 66
images/552
(64, 64, 3)
tensor([[0.0220, 0.0315, 0.0193, 0.0204, 0.0295, 0.0162, 0.0267, 0.0193, 0.0172,
         0.0155, 0.0220, 0.0331, 0.0266, 0.0285, 0.0367, 0.0185, 0.0163, 0.0634,
         0.0199, 0.0224, 0.0187, 0.0268, 0.0209, 0.0144, 0.0246, 0.0201, 0.0243,
         0.0226, 0.0270, 0.0244, 0.0235, 0.0329, 0.0262, 0.0168, 0.0216, 0.0307,
         0.0406, 0.0284, 0.0271, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 67
images/336
(64, 64, 3)
tensor([[0.0301, 0.0290, 0.0123, 0.0158, 0.0156, 0.0326, 0.0387, 0.0227, 0.0145,
         0.0275, 0.0214, 0.0259, 0.0562, 0.0365, 0.0231, 0.0177, 0.0203, 0.0271,
         0.0224, 0.0271, 0.0155, 0.0302, 0.0161, 0.0171, 0.0212, 0.0201, 0.0342,
         0.0186, 0.0390, 0.0272, 0.0187, 0.0262, 0.0210, 0.0243, 0.0193, 0.0373,
         0.0410, 0.0179, 0.0145, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 68
images/54
(64, 64, 3)
tensor([[0.0165, 0.0413, 0.0275, 0.0220, 0.0278, 0.0139, 0.0405, 0.0239, 0.0205,
         0.0231, 0.0252, 0.0301, 0.0462, 0.0345, 0.0238, 0.0164, 0.0221, 0.0243,
         0.0221, 0.0208, 0.0146, 0.0214, 0.0197, 0.0151, 0.0258, 0.0165, 0.0245,
         0.0256, 0.0496, 0.0303, 0.0131, 0.0273, 0.0241, 0.0184, 0.0171, 0.0258,
         0.0367, 0.0181, 0.0230, 0.0310]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 69
images/471
(64, 64, 3)
tensor([[0.0268, 0.0297, 0.0136, 0.0158, 0.0306, 0.0169, 0.0326, 0.0144, 0.0206,
         0.0166, 0.0284, 0.0209, 0.0482, 0.0473, 0.0238, 0.0218, 0.0174, 0.0344,
         0.0169, 0.0172, 0.0135, 0.0221, 0.0187, 0.0185, 0.0212, 0.0126, 0.0219,
         0.0324, 0.0393, 0.0290, 0.0190, 0.0366, 0.0440, 0.0174, 0.0346, 0.0317,
         0.0256, 0.0167, 0.0269, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 70
images/349
(64, 64, 3)
tensor([[0.0283, 0.0436, 0.0154, 0.0397, 0.0364, 0.0238, 0.0341, 0.0127, 0.0204,
         0.0191, 0.0175, 0.0294, 0.0478, 0.0312, 0.0302, 0.0154, 0.0179, 0.0265,
         0.0203, 0.0360, 0.0226, 0.0289, 0.0160, 0.0213, 0.0177, 0.0173, 0.0250,
         0.0265, 0.0220, 0.0256, 0.0205, 0.0196, 0.0248, 0.0193, 0.0203, 0.0331,
         0.0192, 0.0285, 0.0248, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 71
images/588
(64, 64, 3)
tensor([[0.0362, 0.0214, 0.0206, 0.0222, 0.0335, 0.0166, 0.0328, 0.0165, 0.0152,
         0.0177, 0.0198, 0.0434, 0.0419, 0.0151, 0.0192, 0.0205, 0.0191, 0.0241,
         0.0129, 0.0172, 0.0203, 0.0200, 0.0264, 0.0207, 0.0247, 0.0244, 0.0227,
         0.0498, 0.0339, 0.0186, 0.0162, 0.0341, 0.0341, 0.0267, 0.0188, 0.0291,
         0.0373, 0.0231, 0.0253, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 72
images/372
(64, 64, 3)
tensor([[0.0213, 0.0323, 0.0249, 0.0117, 0.0574, 0.0207, 0.0304, 0.0233, 0.0177,
         0.0144, 0.0265, 0.0381, 0.0416, 0.0378, 0.0270, 0.0182, 0.0172, 0.0245,
         0.0218, 0.0185, 0.0174, 0.0212, 0.0269, 0.0219, 0.0203, 0.0142, 0.0253,
         0.0315, 0.0248, 0.0294, 0.0144, 0.0215, 0.0261, 0.0315, 0.0327, 0.0286,
         0.0265, 0.0160, 0.0174, 0.0271]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 73
images/514
(64, 64, 3)
tensor([[0.0204, 0.0333, 0.0160, 0.0183, 0.0376, 0.0209, 0.0309, 0.0160, 0.0168,
         0.0168, 0.0175, 0.0305, 0.0343, 0.0213, 0.0256, 0.0276, 0.0229, 0.0640,
         0.0150, 0.0176, 0.0215, 0.0173, 0.0253, 0.0132, 0.0276, 0.0217, 0.0155,
         0.0266, 0.0362, 0.0324, 0.0191, 0.0276, 0.0409, 0.0246, 0.0215, 0.0344,
         0.0295, 0.0192, 0.0139, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 74
images/424
(64, 64, 3)
tensor([[0.0406, 0.0175, 0.0175, 0.0167, 0.0314, 0.0272, 0.0265, 0.0103, 0.0101,
         0.0156, 0.0154, 0.0309, 0.0431, 0.0338, 0.0238, 0.0222, 0.0295, 0.0398,
         0.0248, 0.0192, 0.0110, 0.0139, 0.0199, 0.0191, 0.0199, 0.0272, 0.0175,
         0.0360, 0.0469, 0.0223, 0.0182, 0.0268, 0.0207, 0.0339, 0.0272, 0.0291,
         0.0317, 0.0189, 0.0400, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 75
images/569
(64, 64, 3)
tensor([[0.0135, 0.0418, 0.0156, 0.0183, 0.0287, 0.0198, 0.0296, 0.0176, 0.0143,
         0.0252, 0.0170, 0.0201, 0.0288, 0.0318, 0.0307, 0.0227, 0.0163, 0.0261,
         0.0469, 0.0211, 0.0182, 0.0284, 0.0199, 0.0171, 0.0255, 0.0141, 0.0333,
         0.0272, 0.0528, 0.0381, 0.0187, 0.0309, 0.0210, 0.0349, 0.0189, 0.0307,
         0.0203, 0.0239, 0.0186, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Session Number: 76
images/228
(64, 64, 3)
tensor([[0.0273, 0.0220, 0.0226, 0.0133, 0.0325, 0.0253, 0.0495, 0.0133, 0.0168,
         0.0171, 0.0251, 0.0380, 0.0552, 0.0381, 0.0279, 0.0183, 0.0228, 0.0255,
         0.0209, 0.0156, 0.0185, 0.0176, 0.0192, 0.0171, 0.0166, 0.0190, 0.0136,
         0.0279, 0.0333, 0.0244, 0.0149, 0.0267, 0.0226, 0.0221, 0.0236, 0.0475,
         0.0256, 0.0235, 0.0270, 0.0322]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 1
Session Number: 77
images/455
(64, 64, 3)
tensor([[0.0183, 0.0292, 0.0208, 0.0165, 0.0375, 0.0244, 0.0241, 0.0202, 0.0259,
         0.0147, 0.0226, 0.0302, 0.0358, 0.0317, 0.0215, 0.0251, 0.0181, 0.0288,
         0.0326, 0.0213, 0.0196, 0.0209, 0.0176, 0.0256, 0.0253, 0.0116, 0.0161,
         0.0472, 0.0411, 0.0267, 0.0200, 0.0345, 0.0255, 0.0300, 0.0123, 0.0221,
         0.0283, 0.0193, 0.0154, 0.0415]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 78
images/75
(64, 64, 3)
tensor([[0.0321, 0.0348, 0.0231, 0.0215, 0.0309, 0.0156, 0.0439, 0.0191, 0.0274,
         0.0247, 0.0147, 0.0418, 0.0449, 0.0218, 0.0233, 0.0158, 0.0265, 0.0241,
         0.0179, 0.0152, 0.0171, 0.0242, 0.0137, 0.0221, 0.0146, 0.0293, 0.0357,
         0.0300, 0.0408, 0.0227, 0.0133, 0.0178, 0.0251, 0.0185, 0.0295, 0.0224,
         0.0395, 0.0215, 0.0209, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 79
images/18
(64, 64, 3)
tensor([[0.0358, 0.0227, 0.0183, 0.0232, 0.0404, 0.0193, 0.0399, 0.0257, 0.0166,
         0.0238, 0.0209, 0.0391, 0.0358, 0.0323, 0.0204, 0.0222, 0.0169, 0.0277,
         0.0219, 0.0203, 0.0149, 0.0267, 0.0197, 0.0252, 0.0272, 0.0159, 0.0254,
         0.0443, 0.0218, 0.0186, 0.0166, 0.0192, 0.0229, 0.0219, 0.0290, 0.0298,
         0.0185, 0.0290, 0.0238, 0.0266]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 80
images/226
(64, 64, 3)
tensor([[0.0273, 0.0215, 0.0221, 0.0262, 0.0281, 0.0165, 0.0365, 0.0156, 0.0261,
         0.0233, 0.0186, 0.0183, 0.0342, 0.0304, 0.0321, 0.0202, 0.0251, 0.0453,
         0.0168, 0.0173, 0.0223, 0.0319, 0.0165, 0.0159, 0.0279, 0.0201, 0.0242,
         0.0242, 0.0271, 0.0279, 0.0191, 0.0275, 0.0310, 0.0261, 0.0195, 0.0245,
         0.0242, 0.0227, 0.0363, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 81
images/38
(64, 64, 3)
tensor([[0.0271, 0.0223, 0.0267, 0.0213, 0.0252, 0.0205, 0.0291, 0.0148, 0.0233,
         0.0228, 0.0151, 0.0230, 0.0405, 0.0256, 0.0197, 0.0190, 0.0139, 0.0337,
         0.0208, 0.0267, 0.0267, 0.0285, 0.0265, 0.0254, 0.0183, 0.0283, 0.0339,
         0.0272, 0.0271, 0.0243, 0.0203, 0.0433, 0.0275, 0.0161, 0.0233, 0.0390,
         0.0299, 0.0207, 0.0183, 0.0242]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 82
images/552
(64, 64, 3)
tensor([[0.0229, 0.0336, 0.0197, 0.0189, 0.0305, 0.0171, 0.0240, 0.0222, 0.0184,
         0.0199, 0.0220, 0.0277, 0.0376, 0.0241, 0.0217, 0.0265, 0.0231, 0.0314,
         0.0217, 0.0207, 0.0161, 0.0327, 0.0241, 0.0211, 0.0258, 0.0276, 0.0222,
         0.0296, 0.0308, 0.0272, 0.0220, 0.0224, 0.0295, 0.0294, 0.0299, 0.0250,
         0.0421, 0.0243, 0.0111, 0.0234]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 83
images/361
(64, 64, 3)
tensor([[0.0359, 0.0409, 0.0166, 0.0188, 0.0313, 0.0138, 0.0244, 0.0127, 0.0181,
         0.0172, 0.0289, 0.0263, 0.0446, 0.0286, 0.0323, 0.0295, 0.0159, 0.0443,
         0.0147, 0.0153, 0.0165, 0.0216, 0.0147, 0.0159, 0.0243, 0.0172, 0.0234,
         0.0323, 0.0315, 0.0280, 0.0138, 0.0345, 0.0294, 0.0282, 0.0235, 0.0362,
         0.0301, 0.0217, 0.0147, 0.0323]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 84
images/533
(64, 64, 3)
tensor([[0.0292, 0.0249, 0.0170, 0.0140, 0.0383, 0.0234, 0.0309, 0.0197, 0.0191,
         0.0213, 0.0169, 0.0480, 0.0456, 0.0194, 0.0162, 0.0186, 0.0325, 0.0298,
         0.0250, 0.0171, 0.0219, 0.0354, 0.0173, 0.0163, 0.0253, 0.0152, 0.0228,
         0.0416, 0.0477, 0.0182, 0.0159, 0.0230, 0.0231, 0.0338, 0.0209, 0.0270,
         0.0320, 0.0162, 0.0197, 0.0195]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 85
images/301
(64, 64, 3)
tensor([[0.0246, 0.0310, 0.0166, 0.0250, 0.0330, 0.0248, 0.0349, 0.0140, 0.0112,
         0.0286, 0.0204, 0.0358, 0.0341, 0.0322, 0.0249, 0.0195, 0.0173, 0.0313,
         0.0163, 0.0225, 0.0208, 0.0181, 0.0167, 0.0183, 0.0164, 0.0225, 0.0231,
         0.0463, 0.0301, 0.0206, 0.0117, 0.0377, 0.0270, 0.0250, 0.0239, 0.0354,
         0.0253, 0.0205, 0.0239, 0.0387]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 1
Session Number: 86
images/171
(64, 64, 3)
tensor([[0.0284, 0.0246, 0.0091, 0.0109, 0.0228, 0.0196, 0.0343, 0.0161, 0.0129,
         0.0217, 0.0238, 0.0436, 0.0338, 0.0253, 0.0204, 0.0170, 0.0275, 0.0304,
         0.0200, 0.0126, 0.0177, 0.0294, 0.0189, 0.0320, 0.0240, 0.0218, 0.0349,
         0.0327, 0.0370, 0.0216, 0.0159, 0.0368, 0.0335, 0.0256, 0.0261, 0.0257,
         0.0306, 0.0227, 0.0329, 0.0253]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 87
images/378
(64, 64, 3)
tensor([[0.0265, 0.0309, 0.0175, 0.0184, 0.0295, 0.0313, 0.0374, 0.0194, 0.0160,
         0.0214, 0.0246, 0.0390, 0.0452, 0.0216, 0.0222, 0.0207, 0.0192, 0.0219,
         0.0132, 0.0194, 0.0213, 0.0272, 0.0225, 0.0186, 0.0265, 0.0200, 0.0203,
         0.0340, 0.0357, 0.0278, 0.0207, 0.0322, 0.0195, 0.0230, 0.0225, 0.0268,
         0.0297, 0.0223, 0.0304, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Session Number: 88
images/235
(64, 64, 3)
tensor([[0.0300, 0.0166, 0.0188, 0.0164, 0.0485, 0.0160, 0.0421, 0.0251, 0.0257,
         0.0180, 0.0218, 0.0251, 0.0403, 0.0403, 0.0222, 0.0141, 0.0145, 0.0291,
         0.0219, 0.0210, 0.0229, 0.0165, 0.0212, 0.0162, 0.0196, 0.0187, 0.0280,
         0.0274, 0.0464, 0.0277, 0.0247, 0.0364, 0.0260, 0.0294, 0.0258, 0.0211,
         0.0287, 0.0150, 0.0184, 0.0223]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 89
images/188
(64, 64, 3)
tensor([[0.0215, 0.0382, 0.0184, 0.0178, 0.0310, 0.0181, 0.0327, 0.0156, 0.0200,
         0.0234, 0.0136, 0.0253, 0.0516, 0.0363, 0.0227, 0.0198, 0.0198, 0.0537,
         0.0211, 0.0210, 0.0154, 0.0202, 0.0211, 0.0249, 0.0160, 0.0180, 0.0260,
         0.0327, 0.0284, 0.0207, 0.0138, 0.0283, 0.0188, 0.0346, 0.0261, 0.0355,
         0.0233, 0.0282, 0.0151, 0.0311]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 90
images/430
(64, 64, 3)
tensor([[0.0233, 0.0190, 0.0176, 0.0255, 0.0389, 0.0287, 0.0309, 0.0141, 0.0196,
         0.0132, 0.0189, 0.0420, 0.0298, 0.0305, 0.0326, 0.0292, 0.0164, 0.0235,
         0.0231, 0.0183, 0.0216, 0.0217, 0.0289, 0.0248, 0.0241, 0.0175, 0.0290,
         0.0316, 0.0379, 0.0234, 0.0156, 0.0223, 0.0194, 0.0186, 0.0279, 0.0249,
         0.0430, 0.0228, 0.0266, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 91
images/574
(64, 64, 3)
tensor([[0.0303, 0.0319, 0.0279, 0.0138, 0.0216, 0.0363, 0.0293, 0.0270, 0.0174,
         0.0258, 0.0218, 0.0339, 0.0394, 0.0276, 0.0247, 0.0196, 0.0124, 0.0271,
         0.0154, 0.0160, 0.0271, 0.0214, 0.0199, 0.0265, 0.0305, 0.0184, 0.0199,
         0.0400, 0.0230, 0.0275, 0.0274, 0.0497, 0.0303, 0.0213, 0.0212, 0.0189,
         0.0144, 0.0151, 0.0177, 0.0308]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 0
Session Number: 92
images/493
(64, 64, 3)
tensor([[0.0375, 0.0223, 0.0200, 0.0124, 0.0274, 0.0250, 0.0155, 0.0254, 0.0307,
         0.0226, 0.0169, 0.0360, 0.0513, 0.0243, 0.0230, 0.0195, 0.0240, 0.0315,
         0.0206, 0.0178, 0.0147, 0.0288, 0.0244, 0.0229, 0.0217, 0.0145, 0.0335,
         0.0361, 0.0441, 0.0232, 0.0221, 0.0228, 0.0284, 0.0287, 0.0308, 0.0247,
         0.0143, 0.0206, 0.0217, 0.0184]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 93
images/136
(64, 64, 3)
tensor([[0.0283, 0.0347, 0.0142, 0.0240, 0.0347, 0.0287, 0.0321, 0.0125, 0.0221,
         0.0214, 0.0199, 0.0222, 0.0399, 0.0378, 0.0295, 0.0286, 0.0201, 0.0339,
         0.0207, 0.0251, 0.0163, 0.0278, 0.0214, 0.0200, 0.0180, 0.0167, 0.0250,
         0.0256, 0.0268, 0.0268, 0.0242, 0.0203, 0.0233, 0.0312, 0.0213, 0.0296,
         0.0345, 0.0212, 0.0204, 0.0191]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 94
images/160
(64, 64, 3)
tensor([[0.0334, 0.0302, 0.0243, 0.0201, 0.0281, 0.0250, 0.0371, 0.0153, 0.0181,
         0.0233, 0.0181, 0.0221, 0.0516, 0.0356, 0.0159, 0.0122, 0.0158, 0.0249,
         0.0207, 0.0245, 0.0175, 0.0216, 0.0158, 0.0169, 0.0170, 0.0233, 0.0231,
         0.0311, 0.0279, 0.0209, 0.0165, 0.0346, 0.0307, 0.0174, 0.0198, 0.0498,
         0.0269, 0.0327, 0.0305, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 0.95
Enter Reward: 1
Session Number: 95
images/288
(64, 64, 3)
tensor([[0.0390, 0.0365, 0.0235, 0.0146, 0.0232, 0.0177, 0.0364, 0.0191, 0.0198,
         0.0194, 0.0200, 0.0376, 0.0376, 0.0359, 0.0250, 0.0131, 0.0244, 0.0201,
         0.0155, 0.0210, 0.0222, 0.0315, 0.0188, 0.0227, 0.0391, 0.0146, 0.0237,
         0.0227, 0.0296, 0.0243, 0.0180, 0.0299, 0.0343, 0.0185, 0.0142, 0.0339,
         0.0241, 0.0237, 0.0314, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 96
images/260
(64, 64, 3)
tensor([[0.0311, 0.0336, 0.0170, 0.0162, 0.0278, 0.0155, 0.0412, 0.0255, 0.0214,
         0.0184, 0.0244, 0.0372, 0.0390, 0.0323, 0.0306, 0.0245, 0.0200, 0.0532,
         0.0189, 0.0236, 0.0160, 0.0204, 0.0171, 0.0270, 0.0151, 0.0173, 0.0221,
         0.0282, 0.0266, 0.0195, 0.0254, 0.0228, 0.0214, 0.0254, 0.0248, 0.0360,
         0.0199, 0.0169, 0.0211, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 97
images/2
(64, 64, 3)
tensor([[0.0263, 0.0239, 0.0173, 0.0292, 0.0364, 0.0168, 0.0390, 0.0165, 0.0166,
         0.0213, 0.0258, 0.0377, 0.0184, 0.0291, 0.0349, 0.0155, 0.0179, 0.0393,
         0.0324, 0.0211, 0.0146, 0.0171, 0.0187, 0.0166, 0.0223, 0.0214, 0.0193,
         0.0368, 0.0362, 0.0290, 0.0169, 0.0259, 0.0311, 0.0346, 0.0220, 0.0225,
         0.0366, 0.0209, 0.0206, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 98
images/349
(64, 64, 3)
tensor([[0.0386, 0.0324, 0.0195, 0.0188, 0.0285, 0.0255, 0.0271, 0.0211, 0.0133,
         0.0179, 0.0179, 0.0289, 0.0339, 0.0314, 0.0215, 0.0179, 0.0165, 0.0345,
         0.0300, 0.0265, 0.0168, 0.0220, 0.0211, 0.0242, 0.0231, 0.0240, 0.0236,
         0.0394, 0.0215, 0.0186, 0.0126, 0.0389, 0.0232, 0.0278, 0.0270, 0.0405,
         0.0250, 0.0181, 0.0207, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 99
images/287
(64, 64, 3)
tensor([[0.0241, 0.0301, 0.0149, 0.0191, 0.0260, 0.0385, 0.0308, 0.0216, 0.0207,
         0.0195, 0.0210, 0.0248, 0.0613, 0.0239, 0.0252, 0.0163, 0.0208, 0.0278,
         0.0290, 0.0220, 0.0270, 0.0215, 0.0188, 0.0266, 0.0207, 0.0140, 0.0279,
         0.0364, 0.0282, 0.0193, 0.0209, 0.0374, 0.0274, 0.0294, 0.0182, 0.0304,
         0.0185, 0.0211, 0.0220, 0.0170]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Saving the weights
37 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/476
(64, 64, 3)
2018-10-13 02:46:52.436 Python[11524:15768762] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0290, 0.0236, 0.0197, 0.0187, 0.0240, 0.0207, 0.0349, 0.0200, 0.0134,
         0.0149, 0.0206, 0.0257, 0.0290, 0.0306, 0.0349, 0.0258, 0.0227, 0.0226,
         0.0176, 0.0162, 0.0127, 0.0255, 0.0364, 0.0256, 0.0274, 0.0237, 0.0242,
         0.0349, 0.0262, 0.0192, 0.0271, 0.0329, 0.0206, 0.0225, 0.0265, 0.0332,
         0.0332, 0.0315, 0.0258, 0.0264]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 1
images/255
(64, 64, 3)
tensor([[0.0315, 0.0245, 0.0126, 0.0179, 0.0343, 0.0195, 0.0301, 0.0167, 0.0152,
         0.0174, 0.0174, 0.0414, 0.0200, 0.0384, 0.0301, 0.0194, 0.0261, 0.0451,
         0.0178, 0.0251, 0.0140, 0.0261, 0.0248, 0.0260, 0.0269, 0.0196, 0.0212,
         0.0449, 0.0327, 0.0242, 0.0121, 0.0395, 0.0293, 0.0272, 0.0182, 0.0248,
         0.0312, 0.0181, 0.0144, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 2
images/427
(64, 64, 3)
tensor([[0.0339, 0.0399, 0.0139, 0.0201, 0.0324, 0.0207, 0.0389, 0.0172, 0.0123,
         0.0194, 0.0332, 0.0348, 0.0406, 0.0317, 0.0230, 0.0205, 0.0338, 0.0387,
         0.0208, 0.0111, 0.0185, 0.0231, 0.0183, 0.0322, 0.0187, 0.0196, 0.0240,
         0.0192, 0.0277, 0.0241, 0.0204, 0.0343, 0.0210, 0.0251, 0.0339, 0.0285,
         0.0241, 0.0232, 0.0159, 0.0111]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 3
images/474
(64, 64, 3)
tensor([[0.0261, 0.0300, 0.0148, 0.0208, 0.0310, 0.0164, 0.0366, 0.0180, 0.0303,
         0.0124, 0.0282, 0.0291, 0.0362, 0.0369, 0.0214, 0.0168, 0.0199, 0.0452,
         0.0091, 0.0386, 0.0206, 0.0255, 0.0171, 0.0235, 0.0221, 0.0190, 0.0246,
         0.0488, 0.0336, 0.0194, 0.0187, 0.0259, 0.0257, 0.0267, 0.0268, 0.0275,
         0.0163, 0.0245, 0.0205, 0.0150]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 4
images/73
(64, 64, 3)
tensor([[0.0242, 0.0221, 0.0179, 0.0161, 0.0607, 0.0174, 0.0262, 0.0172, 0.0205,
         0.0180, 0.0173, 0.0410, 0.0290, 0.0342, 0.0327, 0.0184, 0.0181, 0.0441,
         0.0188, 0.0170, 0.0127, 0.0225, 0.0240, 0.0206, 0.0177, 0.0234, 0.0265,
         0.0261, 0.0319, 0.0305, 0.0168, 0.0332, 0.0262, 0.0274, 0.0377, 0.0241,
         0.0180, 0.0175, 0.0246, 0.0276]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 5
images/386
(64, 64, 3)
tensor([[0.0161, 0.0385, 0.0244, 0.0237, 0.0259, 0.0217, 0.0212, 0.0220, 0.0137,
         0.0241, 0.0219, 0.0317, 0.0331, 0.0389, 0.0199, 0.0241, 0.0252, 0.0395,
         0.0156, 0.0221, 0.0160, 0.0235, 0.0222, 0.0312, 0.0139, 0.0174, 0.0267,
         0.0301, 0.0310, 0.0276, 0.0221, 0.0331, 0.0302, 0.0275, 0.0197, 0.0260,
         0.0287, 0.0172, 0.0190, 0.0336]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 0
Session Number: 6
images/300
(64, 64, 3)
tensor([[0.0355, 0.0316, 0.0243, 0.0192, 0.0189, 0.0203, 0.0225, 0.0235, 0.0208,
         0.0262, 0.0223, 0.0290, 0.0341, 0.0239, 0.0356, 0.0265, 0.0201, 0.0350,
         0.0205, 0.0250, 0.0131, 0.0301, 0.0251, 0.0263, 0.0177, 0.0154, 0.0266,
         0.0324, 0.0288, 0.0228, 0.0196, 0.0224, 0.0237, 0.0281, 0.0204, 0.0355,
         0.0268, 0.0203, 0.0250, 0.0252]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 7
images/330
(64, 64, 3)
tensor([[0.0369, 0.0288, 0.0184, 0.0157, 0.0245, 0.0187, 0.0209, 0.0098, 0.0142,
         0.0146, 0.0190, 0.0360, 0.0402, 0.0339, 0.0225, 0.0306, 0.0212, 0.0306,
         0.0159, 0.0250, 0.0190, 0.0237, 0.0261, 0.0277, 0.0158, 0.0263, 0.0386,
         0.0440, 0.0367, 0.0267, 0.0231, 0.0298, 0.0244, 0.0306, 0.0162, 0.0228,
         0.0340, 0.0202, 0.0142, 0.0224]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 8
images/508
(64, 64, 3)
tensor([[0.0254, 0.0288, 0.0093, 0.0210, 0.0227, 0.0209, 0.0197, 0.0225, 0.0190,
         0.0177, 0.0115, 0.0439, 0.0394, 0.0263, 0.0344, 0.0192, 0.0201, 0.0402,
         0.0151, 0.0227, 0.0108, 0.0238, 0.0427, 0.0235, 0.0170, 0.0197, 0.0288,
         0.0276, 0.0287, 0.0211, 0.0103, 0.0322, 0.0273, 0.0273, 0.0197, 0.0341,
         0.0290, 0.0260, 0.0268, 0.0438]], grad_fn=<SoftmaxBackward>)


Action: 0.9
Enter Reward: 0
Session Number: 9
images/68
(64, 64, 3)
tensor([[0.0245, 0.0301, 0.0108, 0.0165, 0.0314, 0.0164, 0.0450, 0.0246, 0.0152,
         0.0222, 0.0214, 0.0237, 0.0349, 0.0423, 0.0222, 0.0159, 0.0212, 0.0491,
         0.0197, 0.0200, 0.0127, 0.0203, 0.0180, 0.0233, 0.0195, 0.0193, 0.0316,
         0.0269, 0.0441, 0.0229, 0.0217, 0.0312, 0.0329, 0.0194, 0.0226, 0.0493,
         0.0164, 0.0168, 0.0229, 0.0208]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 10
images/366
(64, 64, 3)
tensor([[0.0232, 0.0232, 0.0191, 0.0117, 0.0457, 0.0235, 0.0301, 0.0113, 0.0165,
         0.0235, 0.0186, 0.0312, 0.0553, 0.0286, 0.0314, 0.0119, 0.0229, 0.0333,
         0.0230, 0.0188, 0.0158, 0.0247, 0.0224, 0.0231, 0.0169, 0.0197, 0.0287,
         0.0250, 0.0279, 0.0195, 0.0226, 0.0281, 0.0299, 0.0233, 0.0215, 0.0279,
         0.0325, 0.0308, 0.0200, 0.0368]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/36
(64, 64, 3)
tensor([[0.0202, 0.0239, 0.0254, 0.0160, 0.0639, 0.0285, 0.0281, 0.0196, 0.0298,
         0.0217, 0.0105, 0.0231, 0.0412, 0.0307, 0.0177, 0.0184, 0.0152, 0.0383,
         0.0246, 0.0201, 0.0126, 0.0209, 0.0181, 0.0320, 0.0236, 0.0187, 0.0273,
         0.0274, 0.0286, 0.0279, 0.0169, 0.0266, 0.0344, 0.0206, 0.0312, 0.0211,
         0.0292, 0.0243, 0.0157, 0.0259]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 12
images/295
(64, 64, 3)
tensor([[0.0399, 0.0347, 0.0161, 0.0256, 0.0311, 0.0217, 0.0322, 0.0145, 0.0201,
         0.0275, 0.0206, 0.0271, 0.0375, 0.0413, 0.0207, 0.0224, 0.0137, 0.0353,
         0.0178, 0.0173, 0.0176, 0.0271, 0.0225, 0.0284, 0.0176, 0.0215, 0.0162,
         0.0308, 0.0363, 0.0238, 0.0090, 0.0308, 0.0278, 0.0181, 0.0219, 0.0251,
         0.0351, 0.0273, 0.0231, 0.0226]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 13
images/295
(64, 64, 3)
tensor([[0.0260, 0.0235, 0.0154, 0.0151, 0.0232, 0.0438, 0.0362, 0.0144, 0.0172,
         0.0296, 0.0227, 0.0295, 0.0528, 0.0333, 0.0184, 0.0235, 0.0113, 0.0292,
         0.0209, 0.0224, 0.0138, 0.0255, 0.0242, 0.0205, 0.0188, 0.0159, 0.0202,
         0.0323, 0.0403, 0.0198, 0.0130, 0.0421, 0.0281, 0.0142, 0.0418, 0.0217,
         0.0378, 0.0184, 0.0251, 0.0183]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: -1
Breaking
Saving the weights
4 number of +1 rewards in 13 images
Saving the weights
4 number of +1 rewards in 13 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/374
(64, 64, 3)
2018-10-13 02:50:37.466 Python[11646:15771635] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0295, 0.0345, 0.0120, 0.0192, 0.0262, 0.0125, 0.0346, 0.0198, 0.0276,
         0.0122, 0.0158, 0.0413, 0.0350, 0.0286, 0.0327, 0.0203, 0.0192, 0.0520,
         0.0154, 0.0146, 0.0220, 0.0140, 0.0191, 0.0174, 0.0209, 0.0171, 0.0315,
         0.0293, 0.0492, 0.0203, 0.0217, 0.0286, 0.0293, 0.0167, 0.0296, 0.0193,
         0.0297, 0.0169, 0.0312, 0.0332]], grad_fn=<SoftmaxBackward>)


Action: 0.65
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/232
(64, 64, 3)
tensor([[0.0281, 0.0355, 0.0183, 0.0332, 0.0252, 0.0231, 0.0232, 0.0192, 0.0262,
         0.0254, 0.0176, 0.0251, 0.0425, 0.0279, 0.0326, 0.0242, 0.0190, 0.0488,
         0.0214, 0.0159, 0.0191, 0.0256, 0.0104, 0.0326, 0.0200, 0.0193, 0.0217,
         0.0331, 0.0207, 0.0358, 0.0240, 0.0270, 0.0214, 0.0164, 0.0178, 0.0237,
         0.0215, 0.0298, 0.0218, 0.0262]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/398
(64, 64, 3)
tensor([[0.0429, 0.0259, 0.0176, 0.0134, 0.0529, 0.0192, 0.0248, 0.0270, 0.0126,
         0.0157, 0.0198, 0.0304, 0.0334, 0.0326, 0.0232, 0.0171, 0.0186, 0.0459,
         0.0252, 0.0151, 0.0122, 0.0254, 0.0232, 0.0248, 0.0226, 0.0180, 0.0299,
         0.0360, 0.0306, 0.0170, 0.0198, 0.0266, 0.0215, 0.0151, 0.0239, 0.0325,
         0.0255, 0.0167, 0.0371, 0.0282]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 3
images/41
(64, 64, 3)
tensor([[0.0251, 0.0291, 0.0196, 0.0200, 0.0278, 0.0209, 0.0237, 0.0134, 0.0170,
         0.0159, 0.0200, 0.0291, 0.0333, 0.0307, 0.0236, 0.0224, 0.0164, 0.0510,
         0.0221, 0.0146, 0.0253, 0.0267, 0.0212, 0.0208, 0.0211, 0.0160, 0.0206,
         0.0336, 0.0513, 0.0208, 0.0253, 0.0255, 0.0271, 0.0169, 0.0279, 0.0276,
         0.0407, 0.0183, 0.0279, 0.0294]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 4
images/242
(64, 64, 3)
tensor([[0.0187, 0.0335, 0.0169, 0.0174, 0.0271, 0.0191, 0.0315, 0.0221, 0.0236,
         0.0217, 0.0180, 0.0314, 0.0356, 0.0382, 0.0281, 0.0223, 0.0199, 0.0507,
         0.0131, 0.0210, 0.0171, 0.0267, 0.0189, 0.0205, 0.0309, 0.0228, 0.0257,
         0.0220, 0.0287, 0.0329, 0.0160, 0.0370, 0.0310, 0.0206, 0.0250, 0.0263,
         0.0257, 0.0159, 0.0238, 0.0225]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 5
images/164
(64, 64, 3)
tensor([[0.0218, 0.0196, 0.0191, 0.0228, 0.0385, 0.0189, 0.0387, 0.0185, 0.0218,
         0.0096, 0.0236, 0.0392, 0.0427, 0.0320, 0.0301, 0.0238, 0.0137, 0.0341,
         0.0214, 0.0181, 0.0159, 0.0220, 0.0272, 0.0177, 0.0198, 0.0259, 0.0419,
         0.0212, 0.0328, 0.0238, 0.0288, 0.0292, 0.0193, 0.0245, 0.0283, 0.0300,
         0.0191, 0.0176, 0.0205, 0.0265]], grad_fn=<SoftmaxBackward>)


Action: 1.45
Enter Reward: 1
Session Number: 6
images/238
(64, 64, 3)
tensor([[0.0205, 0.0197, 0.0202, 0.0172, 0.0201, 0.0117, 0.0263, 0.0244, 0.0119,
         0.0154, 0.0212, 0.0292, 0.0434, 0.0229, 0.0206, 0.0192, 0.0179, 0.0413,
         0.0234, 0.0251, 0.0159, 0.0167, 0.0189, 0.0306, 0.0193, 0.0208, 0.0277,
         0.0328, 0.0361, 0.0232, 0.0284, 0.0247, 0.0411, 0.0125, 0.0320, 0.0236,
         0.0519, 0.0296, 0.0343, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 7
images/378
(64, 64, 3)
tensor([[0.0196, 0.0299, 0.0215, 0.0162, 0.0412, 0.0235, 0.0404, 0.0175, 0.0168,
         0.0195, 0.0172, 0.0356, 0.0400, 0.0224, 0.0218, 0.0240, 0.0151, 0.0402,
         0.0131, 0.0175, 0.0271, 0.0169, 0.0226, 0.0218, 0.0304, 0.0208, 0.0212,
         0.0307, 0.0489, 0.0219, 0.0128, 0.0299, 0.0241, 0.0232, 0.0161, 0.0236,
         0.0392, 0.0180, 0.0279, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 8
images/258
(64, 64, 3)
tensor([[0.0259, 0.0273, 0.0196, 0.0231, 0.0327, 0.0180, 0.0295, 0.0202, 0.0209,
         0.0188, 0.0187, 0.0267, 0.0700, 0.0293, 0.0236, 0.0209, 0.0202, 0.0344,
         0.0259, 0.0188, 0.0237, 0.0145, 0.0240, 0.0176, 0.0188, 0.0186, 0.0305,
         0.0313, 0.0290, 0.0218, 0.0300, 0.0268, 0.0247, 0.0183, 0.0335, 0.0272,
         0.0257, 0.0260, 0.0152, 0.0185]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Session Number: 9
images/557
(64, 64, 3)
tensor([[0.0190, 0.0370, 0.0164, 0.0284, 0.0401, 0.0193, 0.0321, 0.0123, 0.0123,
         0.0237, 0.0125, 0.0285, 0.0423, 0.0342, 0.0245, 0.0263, 0.0360, 0.0262,
         0.0145, 0.0182, 0.0175, 0.0152, 0.0169, 0.0253, 0.0227, 0.0243, 0.0269,
         0.0221, 0.0370, 0.0242, 0.0122, 0.0301, 0.0332, 0.0266, 0.0250, 0.0357,
         0.0214, 0.0289, 0.0131, 0.0380]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 10
images/172
(64, 64, 3)
tensor([[0.0293, 0.0281, 0.0186, 0.0281, 0.0308, 0.0193, 0.0436, 0.0121, 0.0223,
         0.0306, 0.0190, 0.0280, 0.0501, 0.0443, 0.0168, 0.0144, 0.0222, 0.0489,
         0.0177, 0.0169, 0.0134, 0.0245, 0.0342, 0.0235, 0.0139, 0.0148, 0.0318,
         0.0191, 0.0317, 0.0326, 0.0126, 0.0153, 0.0390, 0.0242, 0.0167, 0.0353,
         0.0205, 0.0182, 0.0199, 0.0176]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 11
images/428
(64, 64, 3)
tensor([[0.0166, 0.0226, 0.0172, 0.0231, 0.0365, 0.0145, 0.0285, 0.0242, 0.0158,
         0.0230, 0.0202, 0.0268, 0.0283, 0.0250, 0.0364, 0.0193, 0.0187, 0.0339,
         0.0159, 0.0178, 0.0162, 0.0209, 0.0285, 0.0254, 0.0271, 0.0217, 0.0248,
         0.0541, 0.0183, 0.0307, 0.0201, 0.0324, 0.0303, 0.0199, 0.0288, 0.0275,
         0.0291, 0.0161, 0.0223, 0.0416]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 12
images/145
(64, 64, 3)
tensor([[0.0329, 0.0242, 0.0133, 0.0232, 0.0405, 0.0112, 0.0378, 0.0146, 0.0158,
         0.0200, 0.0254, 0.0212, 0.0247, 0.0409, 0.0400, 0.0190, 0.0248, 0.0381,
         0.0133, 0.0153, 0.0175, 0.0203, 0.0205, 0.0306, 0.0161, 0.0248, 0.0297,
         0.0253, 0.0284, 0.0269, 0.0199, 0.0318, 0.0306, 0.0260, 0.0227, 0.0415,
         0.0235, 0.0214, 0.0255, 0.0208]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 13
images/173
(64, 64, 3)
tensor([[0.0237, 0.0250, 0.0113, 0.0184, 0.0259, 0.0233, 0.0321, 0.0229, 0.0147,
         0.0179, 0.0264, 0.0316, 0.0388, 0.0372, 0.0246, 0.0233, 0.0200, 0.0309,
         0.0153, 0.0258, 0.0176, 0.0209, 0.0225, 0.0246, 0.0262, 0.0163, 0.0395,
         0.0399, 0.0434, 0.0169, 0.0176, 0.0320, 0.0213, 0.0189, 0.0287, 0.0273,
         0.0210, 0.0235, 0.0227, 0.0301]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 14
images/89
(64, 64, 3)
tensor([[0.0224, 0.0342, 0.0167, 0.0195, 0.0247, 0.0157, 0.0438, 0.0168, 0.0143,
         0.0196, 0.0189, 0.0279, 0.0498, 0.0329, 0.0216, 0.0170, 0.0239, 0.0196,
         0.0179, 0.0185, 0.0158, 0.0266, 0.0247, 0.0160, 0.0215, 0.0168, 0.0292,
         0.0341, 0.0476, 0.0243, 0.0188, 0.0224, 0.0357, 0.0296, 0.0244, 0.0249,
         0.0301, 0.0219, 0.0273, 0.0327]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 15
images/196
(64, 64, 3)
tensor([[0.0331, 0.0316, 0.0192, 0.0201, 0.0268, 0.0267, 0.0343, 0.0204, 0.0243,
         0.0171, 0.0283, 0.0201, 0.0527, 0.0377, 0.0251, 0.0272, 0.0150, 0.0406,
         0.0191, 0.0193, 0.0232, 0.0233, 0.0229, 0.0133, 0.0202, 0.0167, 0.0250,
         0.0240, 0.0224, 0.0186, 0.0230, 0.0269, 0.0189, 0.0277, 0.0222, 0.0362,
         0.0207, 0.0177, 0.0264, 0.0321]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 16
images/171
(64, 64, 3)
tensor([[0.0245, 0.0273, 0.0217, 0.0141, 0.0258, 0.0120, 0.0237, 0.0138, 0.0173,
         0.0158, 0.0216, 0.0299, 0.0393, 0.0457, 0.0214, 0.0201, 0.0293, 0.0452,
         0.0403, 0.0250, 0.0215, 0.0266, 0.0151, 0.0180, 0.0324, 0.0230, 0.0222,
         0.0323, 0.0274, 0.0223, 0.0134, 0.0325, 0.0356, 0.0222, 0.0176, 0.0300,
         0.0232, 0.0287, 0.0153, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 1
Session Number: 17
images/223
(64, 64, 3)
tensor([[0.0379, 0.0289, 0.0332, 0.0174, 0.0335, 0.0176, 0.0206, 0.0201, 0.0260,
         0.0168, 0.0130, 0.0360, 0.0307, 0.0278, 0.0204, 0.0173, 0.0155, 0.0354,
         0.0133, 0.0181, 0.0169, 0.0233, 0.0201, 0.0249, 0.0217, 0.0219, 0.0330,
         0.0324, 0.0422, 0.0290, 0.0183, 0.0275, 0.0309, 0.0338, 0.0233, 0.0246,
         0.0293, 0.0187, 0.0190, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 0
Session Number: 18
images/120
(64, 64, 3)
tensor([[0.0193, 0.0270, 0.0175, 0.0168, 0.0353, 0.0142, 0.0339, 0.0209, 0.0172,
         0.0136, 0.0189, 0.0311, 0.0266, 0.0287, 0.0231, 0.0208, 0.0197, 0.0268,
         0.0153, 0.0266, 0.0145, 0.0258, 0.0288, 0.0371, 0.0266, 0.0261, 0.0224,
         0.0251, 0.0356, 0.0268, 0.0206, 0.0470, 0.0273, 0.0223, 0.0219, 0.0375,
         0.0336, 0.0180, 0.0256, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Session Number: 19
images/201
(64, 64, 3)
tensor([[0.0283, 0.0665, 0.0162, 0.0171, 0.0183, 0.0173, 0.0250, 0.0182, 0.0213,
         0.0119, 0.0194, 0.0279, 0.0309, 0.0346, 0.0187, 0.0212, 0.0210, 0.0291,
         0.0134, 0.0272, 0.0132, 0.0340, 0.0235, 0.0383, 0.0142, 0.0158, 0.0230,
         0.0388, 0.0304, 0.0169, 0.0177, 0.0358, 0.0192, 0.0178, 0.0192, 0.0317,
         0.0339, 0.0274, 0.0179, 0.0475]], grad_fn=<SoftmaxBackward>)


Action: 0.75
Enter Reward: 1
Session Number: 20
images/405
(64, 64, 3)
tensor([[0.0251, 0.0327, 0.0207, 0.0215, 0.0285, 0.0212, 0.0426, 0.0230, 0.0151,
         0.0224, 0.0105, 0.0246, 0.0397, 0.0274, 0.0261, 0.0207, 0.0216, 0.0475,
         0.0179, 0.0215, 0.0140, 0.0168, 0.0187, 0.0204, 0.0182, 0.0244, 0.0183,
         0.0209, 0.0404, 0.0298, 0.0222, 0.0363, 0.0188, 0.0142, 0.0123, 0.0443,
         0.0426, 0.0203, 0.0324, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 0.2
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 21
images/134
(64, 64, 3)
tensor([[0.0311, 0.0283, 0.0346, 0.0175, 0.0384, 0.0178, 0.0260, 0.0131, 0.0205,
         0.0258, 0.0194, 0.0387, 0.0403, 0.0239, 0.0299, 0.0190, 0.0189, 0.0355,
         0.0209, 0.0188, 0.0192, 0.0251, 0.0214, 0.0197, 0.0192, 0.0196, 0.0251,
         0.0394, 0.0368, 0.0326, 0.0151, 0.0219, 0.0163, 0.0364, 0.0146, 0.0281,
         0.0322, 0.0219, 0.0200, 0.0166]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 22
images/439
(64, 64, 3)
tensor([[0.0226, 0.0232, 0.0143, 0.0268, 0.0218, 0.0223, 0.0557, 0.0174, 0.0230,
         0.0150, 0.0168, 0.0324, 0.0434, 0.0258, 0.0199, 0.0207, 0.0160, 0.0351,
         0.0204, 0.0253, 0.0216, 0.0178, 0.0151, 0.0176, 0.0168, 0.0106, 0.0227,
         0.0149, 0.0276, 0.0282, 0.0300, 0.0536, 0.0271, 0.0265, 0.0381, 0.0420,
         0.0220, 0.0175, 0.0219, 0.0307]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 23
images/546
(64, 64, 3)
tensor([[0.0272, 0.0308, 0.0141, 0.0167, 0.0203, 0.0204, 0.0444, 0.0166, 0.0247,
         0.0236, 0.0250, 0.0289, 0.0478, 0.0344, 0.0334, 0.0192, 0.0214, 0.0463,
         0.0152, 0.0123, 0.0166, 0.0182, 0.0157, 0.0327, 0.0239, 0.0263, 0.0210,
         0.0261, 0.0177, 0.0288, 0.0194, 0.0371, 0.0253, 0.0167, 0.0231, 0.0278,
         0.0233, 0.0219, 0.0268, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 24
images/108
(64, 64, 3)
tensor([[0.0193, 0.0337, 0.0195, 0.0172, 0.0231, 0.0209, 0.0395, 0.0174, 0.0145,
         0.0365, 0.0244, 0.0341, 0.0395, 0.0354, 0.0358, 0.0161, 0.0217, 0.0483,
         0.0150, 0.0250, 0.0191, 0.0217, 0.0185, 0.0276, 0.0214, 0.0172, 0.0172,
         0.0272, 0.0270, 0.0249, 0.0161, 0.0353, 0.0229, 0.0236, 0.0311, 0.0222,
         0.0228, 0.0196, 0.0233, 0.0244]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 1
Session Number: 25
images/341
(64, 64, 3)
tensor([[0.0211, 0.0343, 0.0179, 0.0214, 0.0285, 0.0205, 0.0354, 0.0228, 0.0187,
         0.0206, 0.0339, 0.0257, 0.0338, 0.0378, 0.0265, 0.0135, 0.0287, 0.0317,
         0.0175, 0.0220, 0.0123, 0.0176, 0.0166, 0.0184, 0.0253, 0.0294, 0.0141,
         0.0298, 0.0320, 0.0208, 0.0240, 0.0349, 0.0263, 0.0224, 0.0256, 0.0453,
         0.0261, 0.0226, 0.0258, 0.0186]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 1
Session Number: 26
images/321
(64, 64, 3)
tensor([[0.0214, 0.0263, 0.0259, 0.0225, 0.0501, 0.0136, 0.0334, 0.0142, 0.0170,
         0.0178, 0.0209, 0.0221, 0.0433, 0.0326, 0.0220, 0.0168, 0.0207, 0.0327,
         0.0147, 0.0343, 0.0196, 0.0195, 0.0216, 0.0195, 0.0245, 0.0308, 0.0205,
         0.0320, 0.0348, 0.0195, 0.0162, 0.0272, 0.0197, 0.0265, 0.0189, 0.0336,
         0.0448, 0.0246, 0.0142, 0.0296]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 27
images/519
(64, 64, 3)
tensor([[0.0265, 0.0215, 0.0154, 0.0190, 0.0244, 0.0212, 0.0364, 0.0250, 0.0199,
         0.0139, 0.0271, 0.0379, 0.0296, 0.0403, 0.0258, 0.0115, 0.0267, 0.0322,
         0.0225, 0.0206, 0.0174, 0.0283, 0.0323, 0.0214, 0.0216, 0.0104, 0.0230,
         0.0282, 0.0410, 0.0273, 0.0138, 0.0270, 0.0348, 0.0228, 0.0228, 0.0284,
         0.0225, 0.0307, 0.0261, 0.0228]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 0
Session Number: 28
images/200
(64, 64, 3)
tensor([[0.0149, 0.0261, 0.0157, 0.0239, 0.0230, 0.0264, 0.0594, 0.0158, 0.0218,
         0.0182, 0.0192, 0.0174, 0.0390, 0.0413, 0.0214, 0.0154, 0.0211, 0.0288,
         0.0160, 0.0252, 0.0211, 0.0193, 0.0170, 0.0354, 0.0234, 0.0368, 0.0274,
         0.0316, 0.0401, 0.0217, 0.0168, 0.0294, 0.0300, 0.0237, 0.0260, 0.0278,
         0.0209, 0.0232, 0.0172, 0.0211]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 0
Session Number: 29
images/305
(64, 64, 3)
tensor([[0.0177, 0.0278, 0.0194, 0.0346, 0.0349, 0.0257, 0.0258, 0.0167, 0.0185,
         0.0249, 0.0173, 0.0191, 0.0561, 0.0215, 0.0166, 0.0152, 0.0273, 0.0252,
         0.0215, 0.0291, 0.0169, 0.0242, 0.0163, 0.0218, 0.0271, 0.0250, 0.0221,
         0.0274, 0.0322, 0.0273, 0.0253, 0.0357, 0.0275, 0.0210, 0.0197, 0.0237,
         0.0221, 0.0210, 0.0401, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 0
Session Number: 30
images/449
(64, 64, 3)
tensor([[0.0271, 0.0188, 0.0105, 0.0165, 0.0337, 0.0198, 0.0441, 0.0218, 0.0221,
         0.0167, 0.0246, 0.0375, 0.0445, 0.0450, 0.0238, 0.0165, 0.0171, 0.0338,
         0.0202, 0.0277, 0.0185, 0.0214, 0.0210, 0.0227, 0.0201, 0.0176, 0.0207,
         0.0266, 0.0323, 0.0214, 0.0136, 0.0348, 0.0367, 0.0220, 0.0262, 0.0327,
         0.0305, 0.0227, 0.0191, 0.0176]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 31
images/170
(64, 64, 3)
tensor([[0.0151, 0.0305, 0.0209, 0.0207, 0.0272, 0.0225, 0.0481, 0.0152, 0.0173,
         0.0211, 0.0176, 0.0285, 0.0508, 0.0224, 0.0323, 0.0188, 0.0186, 0.0298,
         0.0218, 0.0176, 0.0252, 0.0264, 0.0156, 0.0187, 0.0221, 0.0157, 0.0343,
         0.0393, 0.0253, 0.0238, 0.0271, 0.0313, 0.0208, 0.0218, 0.0232, 0.0284,
         0.0328, 0.0212, 0.0224, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 1.4
Enter Reward: 0
Session Number: 32
images/319
(64, 64, 3)
tensor([[0.0284, 0.0279, 0.0124, 0.0117, 0.0294, 0.0233, 0.0312, 0.0203, 0.0166,
         0.0200, 0.0194, 0.0415, 0.0477, 0.0416, 0.0230, 0.0133, 0.0210, 0.0262,
         0.0212, 0.0184, 0.0188, 0.0285, 0.0237, 0.0224, 0.0271, 0.0192, 0.0211,
         0.0288, 0.0447, 0.0196, 0.0158, 0.0341, 0.0326, 0.0216, 0.0240, 0.0395,
         0.0314, 0.0129, 0.0197, 0.0202]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 33
images/113
(64, 64, 3)
tensor([[0.0282, 0.0194, 0.0198, 0.0242, 0.0323, 0.0154, 0.0269, 0.0284, 0.0201,
         0.0163, 0.0193, 0.0291, 0.0387, 0.0299, 0.0290, 0.0136, 0.0125, 0.0387,
         0.0127, 0.0149, 0.0328, 0.0186, 0.0214, 0.0268, 0.0373, 0.0218, 0.0193,
         0.0288, 0.0399, 0.0222, 0.0190, 0.0448, 0.0346, 0.0269, 0.0215, 0.0271,
         0.0283, 0.0250, 0.0203, 0.0142]], grad_fn=<SoftmaxBackward>)


Action: 0.8
Enter Reward: 1
Session Number: 34
images/298
(64, 64, 3)
tensor([[0.0213, 0.0239, 0.0229, 0.0190, 0.0287, 0.0202, 0.0255, 0.0242, 0.0223,
         0.0127, 0.0183, 0.0360, 0.0329, 0.0290, 0.0181, 0.0168, 0.0194, 0.0340,
         0.0284, 0.0254, 0.0198, 0.0272, 0.0177, 0.0239, 0.0240, 0.0182, 0.0227,
         0.0336, 0.0373, 0.0197, 0.0265, 0.0224, 0.0280, 0.0201, 0.0352, 0.0203,
         0.0252, 0.0371, 0.0404, 0.0220]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 35
images/232
(64, 64, 3)
tensor([[0.0209, 0.0256, 0.0179, 0.0202, 0.0380, 0.0197, 0.0447, 0.0181, 0.0263,
         0.0171, 0.0265, 0.0274, 0.0216, 0.0397, 0.0217, 0.0218, 0.0204, 0.0415,
         0.0272, 0.0200, 0.0197, 0.0203, 0.0173, 0.0197, 0.0229, 0.0187, 0.0345,
         0.0243, 0.0362, 0.0321, 0.0217, 0.0229, 0.0263, 0.0172, 0.0201, 0.0219,
         0.0259, 0.0178, 0.0346, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 1
Session Number: 36
images/408
(64, 64, 3)
tensor([[0.0293, 0.0208, 0.0152, 0.0252, 0.0303, 0.0219, 0.0376, 0.0202, 0.0125,
         0.0179, 0.0114, 0.0292, 0.0502, 0.0357, 0.0176, 0.0221, 0.0333, 0.0422,
         0.0196, 0.0155, 0.0109, 0.0252, 0.0258, 0.0199, 0.0211, 0.0197, 0.0281,
         0.0219, 0.0401, 0.0202, 0.0130, 0.0424, 0.0222, 0.0151, 0.0322, 0.0365,
         0.0245, 0.0253, 0.0199, 0.0282]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 37
images/476
(64, 64, 3)
tensor([[0.0253, 0.0300, 0.0183, 0.0108, 0.0237, 0.0205, 0.0664, 0.0267, 0.0177,
         0.0199, 0.0314, 0.0229, 0.0469, 0.0425, 0.0192, 0.0157, 0.0200, 0.0352,
         0.0331, 0.0185, 0.0182, 0.0223, 0.0190, 0.0124, 0.0194, 0.0168, 0.0225,
         0.0295, 0.0379, 0.0215, 0.0201, 0.0206, 0.0234, 0.0185, 0.0267, 0.0259,
         0.0289, 0.0195, 0.0206, 0.0318]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 38
images/148
(64, 64, 3)
tensor([[0.0189, 0.0403, 0.0184, 0.0250, 0.0517, 0.0173, 0.0338, 0.0179, 0.0226,
         0.0194, 0.0151, 0.0367, 0.0483, 0.0190, 0.0156, 0.0166, 0.0191, 0.0241,
         0.0231, 0.0201, 0.0249, 0.0188, 0.0166, 0.0162, 0.0273, 0.0221, 0.0322,
         0.0389, 0.0276, 0.0263, 0.0140, 0.0330, 0.0432, 0.0297, 0.0211, 0.0166,
         0.0307, 0.0186, 0.0134, 0.0260]], grad_fn=<SoftmaxBackward>)


Action: 1.5
Enter Reward: 0
Session Number: 39
images/385
(64, 64, 3)
tensor([[0.0282, 0.0300, 0.0313, 0.0144, 0.0409, 0.0196, 0.0272, 0.0166, 0.0304,
         0.0289, 0.0200, 0.0210, 0.0428, 0.0318, 0.0251, 0.0196, 0.0347, 0.0227,
         0.0182, 0.0200, 0.0169, 0.0265, 0.0168, 0.0200, 0.0152, 0.0209, 0.0275,
         0.0288, 0.0366, 0.0262, 0.0246, 0.0175, 0.0262, 0.0231, 0.0212, 0.0223,
         0.0318, 0.0172, 0.0308, 0.0267]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 40
images/366
(64, 64, 3)
tensor([[0.0248, 0.0236, 0.0202, 0.0223, 0.0202, 0.0264, 0.0291, 0.0147, 0.0188,
         0.0193, 0.0263, 0.0301, 0.0451, 0.0229, 0.0230, 0.0171, 0.0252, 0.0243,
         0.0203, 0.0248, 0.0292, 0.0231, 0.0192, 0.0263, 0.0173, 0.0222, 0.0254,
         0.0430, 0.0408, 0.0214, 0.0121, 0.0450, 0.0290, 0.0243, 0.0120, 0.0314,
         0.0316, 0.0190, 0.0237, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 41
images/362
(64, 64, 3)
tensor([[0.0344, 0.0378, 0.0155, 0.0144, 0.0361, 0.0111, 0.0368, 0.0156, 0.0227,
         0.0164, 0.0179, 0.0312, 0.0326, 0.0376, 0.0256, 0.0183, 0.0198, 0.0377,
         0.0179, 0.0212, 0.0122, 0.0228, 0.0192, 0.0192, 0.0187, 0.0263, 0.0275,
         0.0213, 0.0518, 0.0232, 0.0206, 0.0556, 0.0217, 0.0262, 0.0171, 0.0171,
         0.0352, 0.0222, 0.0218, 0.0198]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Session Number: 42
images/484
(64, 64, 3)
tensor([[0.0175, 0.0370, 0.0118, 0.0197, 0.0197, 0.0292, 0.0237, 0.0178, 0.0132,
         0.0146, 0.0255, 0.0232, 0.0461, 0.0394, 0.0198, 0.0178, 0.0255, 0.0251,
         0.0143, 0.0269, 0.0157, 0.0368, 0.0193, 0.0203, 0.0179, 0.0226, 0.0397,
         0.0263, 0.0306, 0.0277, 0.0192, 0.0272, 0.0325, 0.0260, 0.0302, 0.0255,
         0.0243, 0.0274, 0.0311, 0.0317]], grad_fn=<SoftmaxBackward>)


Action: 1.05
Enter Reward: 0
Session Number: 43
images/230
(64, 64, 3)
tensor([[0.0312, 0.0339, 0.0159, 0.0230, 0.0317, 0.0242, 0.0313, 0.0219, 0.0147,
         0.0194, 0.0203, 0.0373, 0.0484, 0.0304, 0.0266, 0.0166, 0.0165, 0.0387,
         0.0165, 0.0146, 0.0166, 0.0212, 0.0186, 0.0187, 0.0255, 0.0184, 0.0178,
         0.0231, 0.0469, 0.0166, 0.0238, 0.0268, 0.0216, 0.0246, 0.0247, 0.0189,
         0.0337, 0.0339, 0.0254, 0.0299]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 44
images/589
(64, 64, 3)
tensor([[0.0199, 0.0257, 0.0179, 0.0226, 0.0273, 0.0231, 0.0325, 0.0179, 0.0261,
         0.0137, 0.0211, 0.0378, 0.0289, 0.0256, 0.0311, 0.0216, 0.0164, 0.0209,
         0.0208, 0.0182, 0.0135, 0.0290, 0.0266, 0.0158, 0.0206, 0.0200, 0.0182,
         0.0519, 0.0472, 0.0238, 0.0212, 0.0333, 0.0260, 0.0272, 0.0287, 0.0182,
         0.0351, 0.0234, 0.0276, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 0.4
Enter Reward: 1
Session Number: 45
images/544
(64, 64, 3)
tensor([[0.0392, 0.0322, 0.0224, 0.0185, 0.0358, 0.0181, 0.0263, 0.0101, 0.0166,
         0.0172, 0.0220, 0.0274, 0.0224, 0.0536, 0.0316, 0.0195, 0.0133, 0.0261,
         0.0227, 0.0368, 0.0193, 0.0272, 0.0162, 0.0199, 0.0210, 0.0210, 0.0275,
         0.0262, 0.0463, 0.0181, 0.0119, 0.0316, 0.0425, 0.0227, 0.0172, 0.0222,
         0.0256, 0.0202, 0.0213, 0.0304]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 1
Session Number: 46
images/119
(64, 64, 3)
tensor([[0.0239, 0.0226, 0.0143, 0.0224, 0.0297, 0.0190, 0.0317, 0.0200, 0.0233,
         0.0175, 0.0200, 0.0256, 0.0345, 0.0582, 0.0327, 0.0148, 0.0205, 0.0362,
         0.0173, 0.0230, 0.0202, 0.0271, 0.0240, 0.0199, 0.0163, 0.0152, 0.0248,
         0.0238, 0.0446, 0.0241, 0.0244, 0.0293, 0.0208, 0.0211, 0.0210, 0.0371,
         0.0311, 0.0180, 0.0212, 0.0289]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 47
images/63
(64, 64, 3)
tensor([[0.0304, 0.0242, 0.0155, 0.0165, 0.0310, 0.0175, 0.0310, 0.0193, 0.0154,
         0.0242, 0.0183, 0.0285, 0.0350, 0.0365, 0.0250, 0.0144, 0.0193, 0.0535,
         0.0166, 0.0231, 0.0187, 0.0258, 0.0218, 0.0245, 0.0173, 0.0148, 0.0274,
         0.0287, 0.0331, 0.0193, 0.0155, 0.0405, 0.0299, 0.0372, 0.0223, 0.0336,
         0.0226, 0.0221, 0.0253, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 1
Session Number: 48
images/334
(64, 64, 3)
tensor([[0.0282, 0.0238, 0.0177, 0.0139, 0.0289, 0.0170, 0.0370, 0.0259, 0.0176,
         0.0192, 0.0233, 0.0377, 0.0310, 0.0372, 0.0398, 0.0190, 0.0275, 0.0373,
         0.0193, 0.0195, 0.0353, 0.0142, 0.0165, 0.0228, 0.0216, 0.0170, 0.0265,
         0.0292, 0.0278, 0.0287, 0.0154, 0.0267, 0.0291, 0.0328, 0.0232, 0.0265,
         0.0215, 0.0139, 0.0276, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 49
images/582
(64, 64, 3)
tensor([[0.0214, 0.0209, 0.0198, 0.0223, 0.0326, 0.0212, 0.0356, 0.0124, 0.0233,
         0.0323, 0.0167, 0.0294, 0.0605, 0.0277, 0.0236, 0.0116, 0.0193, 0.0412,
         0.0163, 0.0272, 0.0183, 0.0183, 0.0167, 0.0186, 0.0291, 0.0230, 0.0313,
         0.0273, 0.0218, 0.0241, 0.0259, 0.0234, 0.0232, 0.0281, 0.0300, 0.0359,
         0.0283, 0.0223, 0.0153, 0.0241]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 50
images/501
(64, 64, 3)
tensor([[0.0425, 0.0325, 0.0190, 0.0226, 0.0288, 0.0149, 0.0306, 0.0212, 0.0120,
         0.0231, 0.0176, 0.0193, 0.0291, 0.0421, 0.0320, 0.0161, 0.0157, 0.0275,
         0.0181, 0.0162, 0.0193, 0.0229, 0.0202, 0.0316, 0.0273, 0.0181, 0.0270,
         0.0355, 0.0259, 0.0251, 0.0146, 0.0380, 0.0199, 0.0282, 0.0223, 0.0390,
         0.0289, 0.0192, 0.0302, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 51
images/567
(64, 64, 3)
tensor([[0.0289, 0.0235, 0.0196, 0.0208, 0.0361, 0.0309, 0.0356, 0.0168, 0.0160,
         0.0120, 0.0169, 0.0329, 0.0349, 0.0402, 0.0304, 0.0227, 0.0154, 0.0333,
         0.0142, 0.0231, 0.0147, 0.0232, 0.0209, 0.0263, 0.0261, 0.0260, 0.0357,
         0.0309, 0.0301, 0.0159, 0.0173, 0.0222, 0.0228, 0.0189, 0.0302, 0.0350,
         0.0242, 0.0234, 0.0262, 0.0258]], grad_fn=<SoftmaxBackward>)


Action: 1.8
Enter Reward: 0
Session Number: 52
images/350
(64, 64, 3)
tensor([[0.0154, 0.0154, 0.0251, 0.0130, 0.0337, 0.0188, 0.0258, 0.0218, 0.0214,
         0.0185, 0.0190, 0.0515, 0.0341, 0.0340, 0.0281, 0.0175, 0.0206, 0.0283,
         0.0242, 0.0153, 0.0193, 0.0231, 0.0277, 0.0245, 0.0197, 0.0267, 0.0242,
         0.0452, 0.0372, 0.0208, 0.0151, 0.0295, 0.0233, 0.0249, 0.0226, 0.0288,
         0.0348, 0.0312, 0.0171, 0.0230]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 53
images/447
(64, 64, 3)
tensor([[0.0214, 0.0266, 0.0321, 0.0114, 0.0384, 0.0181, 0.0459, 0.0239, 0.0279,
         0.0248, 0.0184, 0.0277, 0.0397, 0.0237, 0.0184, 0.0222, 0.0172, 0.0305,
         0.0200, 0.0226, 0.0218, 0.0199, 0.0104, 0.0175, 0.0245, 0.0249, 0.0256,
         0.0274, 0.0499, 0.0291, 0.0202, 0.0194, 0.0239, 0.0168, 0.0319, 0.0206,
         0.0247, 0.0241, 0.0200, 0.0365]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Session Number: 54
images/200
(64, 64, 3)
tensor([[0.0269, 0.0352, 0.0181, 0.0206, 0.0367, 0.0305, 0.0537, 0.0142, 0.0202,
         0.0148, 0.0215, 0.0194, 0.0423, 0.0462, 0.0215, 0.0184, 0.0202, 0.0335,
         0.0188, 0.0251, 0.0201, 0.0172, 0.0161, 0.0234, 0.0196, 0.0210, 0.0217,
         0.0178, 0.0375, 0.0149, 0.0197, 0.0187, 0.0221, 0.0279, 0.0361, 0.0333,
         0.0183, 0.0324, 0.0162, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 1.75
Enter Reward: 0
Session Number: 55
images/424
(64, 64, 3)
tensor([[0.0275, 0.0226, 0.0237, 0.0186, 0.0276, 0.0246, 0.0370, 0.0206, 0.0178,
         0.0210, 0.0142, 0.0225, 0.0480, 0.0382, 0.0179, 0.0205, 0.0220, 0.0488,
         0.0281, 0.0203, 0.0148, 0.0145, 0.0178, 0.0175, 0.0276, 0.0178, 0.0204,
         0.0258, 0.0345, 0.0273, 0.0168, 0.0366, 0.0331, 0.0251, 0.0285, 0.0232,
         0.0309, 0.0126, 0.0205, 0.0333]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 56
images/406
(64, 64, 3)
tensor([[0.0181, 0.0203, 0.0111, 0.0266, 0.0232, 0.0213, 0.0205, 0.0155, 0.0139,
         0.0174, 0.0399, 0.0315, 0.0407, 0.0361, 0.0229, 0.0136, 0.0251, 0.0387,
         0.0216, 0.0229, 0.0223, 0.0236, 0.0257, 0.0195, 0.0226, 0.0218, 0.0234,
         0.0451, 0.0263, 0.0178, 0.0252, 0.0377, 0.0273, 0.0167, 0.0159, 0.0294,
         0.0430, 0.0248, 0.0294, 0.0217]], grad_fn=<SoftmaxBackward>)


Action: 1.15
Enter Reward: 1
Session Number: 57
images/84
(64, 64, 3)
tensor([[0.0182, 0.0376, 0.0175, 0.0174, 0.0165, 0.0208, 0.0378, 0.0260, 0.0106,
         0.0243, 0.0256, 0.0214, 0.0568, 0.0243, 0.0261, 0.0221, 0.0174, 0.0273,
         0.0161, 0.0262, 0.0172, 0.0318, 0.0246, 0.0255, 0.0228, 0.0209, 0.0220,
         0.0364, 0.0322, 0.0216, 0.0268, 0.0190, 0.0378, 0.0160, 0.0382, 0.0192,
         0.0177, 0.0289, 0.0175, 0.0340]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 58
images/286
(64, 64, 3)
tensor([[0.0208, 0.0244, 0.0119, 0.0150, 0.0347, 0.0123, 0.0208, 0.0213, 0.0141,
         0.0193, 0.0190, 0.0270, 0.0374, 0.0254, 0.0209, 0.0246, 0.0286, 0.0511,
         0.0229, 0.0208, 0.0194, 0.0295, 0.0175, 0.0143, 0.0286, 0.0220, 0.0246,
         0.0605, 0.0434, 0.0250, 0.0151, 0.0260, 0.0401, 0.0235, 0.0194, 0.0226,
         0.0298, 0.0261, 0.0216, 0.0188]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 59
images/52
(64, 64, 3)
tensor([[0.0294, 0.0376, 0.0135, 0.0192, 0.0259, 0.0225, 0.0309, 0.0155, 0.0166,
         0.0216, 0.0237, 0.0214, 0.0292, 0.0302, 0.0314, 0.0209, 0.0203, 0.0465,
         0.0159, 0.0185, 0.0192, 0.0249, 0.0216, 0.0196, 0.0247, 0.0166, 0.0273,
         0.0331, 0.0348, 0.0303, 0.0240, 0.0293, 0.0233, 0.0227, 0.0278, 0.0218,
         0.0228, 0.0217, 0.0243, 0.0395]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 60
images/102
(64, 64, 3)
tensor([[0.0299, 0.0239, 0.0280, 0.0209, 0.0278, 0.0261, 0.0284, 0.0190, 0.0164,
         0.0208, 0.0165, 0.0242, 0.0393, 0.0295, 0.0370, 0.0173, 0.0198, 0.0349,
         0.0154, 0.0135, 0.0226, 0.0204, 0.0235, 0.0222, 0.0294, 0.0261, 0.0114,
         0.0373, 0.0347, 0.0255, 0.0184, 0.0369, 0.0376, 0.0238, 0.0236, 0.0233,
         0.0285, 0.0171, 0.0263, 0.0227]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 61
images/269
(64, 64, 3)
tensor([[0.0279, 0.0260, 0.0209, 0.0178, 0.0206, 0.0141, 0.0208, 0.0106, 0.0249,
         0.0337, 0.0179, 0.0352, 0.0371, 0.0315, 0.0443, 0.0315, 0.0157, 0.0336,
         0.0203, 0.0224, 0.0219, 0.0290, 0.0170, 0.0187, 0.0248, 0.0246, 0.0231,
         0.0409, 0.0302, 0.0286, 0.0262, 0.0179, 0.0191, 0.0259, 0.0210, 0.0295,
         0.0372, 0.0138, 0.0223, 0.0214]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 62
images/402
(64, 64, 3)
tensor([[0.0250, 0.0340, 0.0200, 0.0172, 0.0296, 0.0259, 0.0369, 0.0223, 0.0138,
         0.0214, 0.0340, 0.0253, 0.0224, 0.0343, 0.0351, 0.0180, 0.0209, 0.0311,
         0.0250, 0.0203, 0.0218, 0.0197, 0.0200, 0.0228, 0.0265, 0.0210, 0.0178,
         0.0317, 0.0264, 0.0276, 0.0201, 0.0351, 0.0279, 0.0323, 0.0183, 0.0232,
         0.0282, 0.0258, 0.0169, 0.0245]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 63
images/129
(64, 64, 3)
tensor([[0.0192, 0.0279, 0.0137, 0.0150, 0.0425, 0.0174, 0.0382, 0.0209, 0.0245,
         0.0176, 0.0276, 0.0304, 0.0458, 0.0257, 0.0209, 0.0243, 0.0215, 0.0274,
         0.0179, 0.0188, 0.0210, 0.0190, 0.0230, 0.0190, 0.0272, 0.0131, 0.0300,
         0.0393, 0.0191, 0.0275, 0.0146, 0.0448, 0.0255, 0.0275, 0.0174, 0.0427,
         0.0279, 0.0146, 0.0247, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 64
images/338
(64, 64, 3)
tensor([[0.0241, 0.0180, 0.0299, 0.0212, 0.0331, 0.0218, 0.0217, 0.0190, 0.0207,
         0.0176, 0.0148, 0.0332, 0.0402, 0.0288, 0.0348, 0.0158, 0.0228, 0.0301,
         0.0349, 0.0172, 0.0216, 0.0191, 0.0147, 0.0251, 0.0142, 0.0265, 0.0446,
         0.0249, 0.0255, 0.0256, 0.0239, 0.0250, 0.0289, 0.0289, 0.0284, 0.0195,
         0.0275, 0.0281, 0.0201, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 65
images/245
(64, 64, 3)
tensor([[0.0204, 0.0303, 0.0146, 0.0142, 0.0358, 0.0241, 0.0258, 0.0197, 0.0165,
         0.0161, 0.0204, 0.0252, 0.0267, 0.0238, 0.0283, 0.0241, 0.0248, 0.0319,
         0.0202, 0.0333, 0.0144, 0.0241, 0.0180, 0.0179, 0.0297, 0.0359, 0.0357,
         0.0264, 0.0263, 0.0213, 0.0182, 0.0304, 0.0250, 0.0194, 0.0252, 0.0386,
         0.0421, 0.0225, 0.0196, 0.0329]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 1
Session Number: 66
images/105
(64, 64, 3)
tensor([[0.0295, 0.0250, 0.0164, 0.0159, 0.0285, 0.0144, 0.0528, 0.0217, 0.0123,
         0.0188, 0.0271, 0.0350, 0.0281, 0.0315, 0.0286, 0.0188, 0.0231, 0.0387,
         0.0227, 0.0233, 0.0131, 0.0193, 0.0233, 0.0243, 0.0307, 0.0172, 0.0280,
         0.0382, 0.0299, 0.0271, 0.0180, 0.0298, 0.0228, 0.0397, 0.0252, 0.0189,
         0.0227, 0.0220, 0.0223, 0.0151]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 67
images/243
(64, 64, 3)
tensor([[0.0307, 0.0261, 0.0115, 0.0167, 0.0206, 0.0220, 0.0244, 0.0190, 0.0161,
         0.0249, 0.0328, 0.0312, 0.0393, 0.0411, 0.0278, 0.0146, 0.0158, 0.0353,
         0.0289, 0.0237, 0.0167, 0.0179, 0.0140, 0.0159, 0.0250, 0.0226, 0.0195,
         0.0327, 0.0281, 0.0281, 0.0139, 0.0227, 0.0280, 0.0314, 0.0207, 0.0478,
         0.0362, 0.0255, 0.0284, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 1
Session Number: 68
images/141
(64, 64, 3)
tensor([[0.0303, 0.0252, 0.0174, 0.0168, 0.0378, 0.0212, 0.0266, 0.0260, 0.0169,
         0.0243, 0.0187, 0.0320, 0.0399, 0.0370, 0.0337, 0.0185, 0.0160, 0.0387,
         0.0196, 0.0194, 0.0216, 0.0307, 0.0211, 0.0278, 0.0268, 0.0225, 0.0281,
         0.0270, 0.0287, 0.0273, 0.0150, 0.0249, 0.0247, 0.0244, 0.0207, 0.0303,
         0.0243, 0.0178, 0.0260, 0.0145]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 69
images/171
(64, 64, 3)
tensor([[0.0244, 0.0321, 0.0186, 0.0133, 0.0329, 0.0251, 0.0246, 0.0143, 0.0236,
         0.0205, 0.0303, 0.0275, 0.0364, 0.0262, 0.0176, 0.0141, 0.0182, 0.0203,
         0.0250, 0.0275, 0.0165, 0.0207, 0.0176, 0.0271, 0.0182, 0.0257, 0.0310,
         0.0338, 0.0470, 0.0178, 0.0175, 0.0331, 0.0273, 0.0213, 0.0158, 0.0297,
         0.0397, 0.0227, 0.0236, 0.0414]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 70
images/53
(64, 64, 3)
tensor([[0.0271, 0.0247, 0.0149, 0.0189, 0.0282, 0.0190, 0.0363, 0.0171, 0.0245,
         0.0165, 0.0186, 0.0259, 0.0634, 0.0377, 0.0174, 0.0149, 0.0234, 0.0287,
         0.0195, 0.0235, 0.0176, 0.0181, 0.0138, 0.0252, 0.0170, 0.0213, 0.0426,
         0.0400, 0.0355, 0.0225, 0.0159, 0.0208, 0.0263, 0.0277, 0.0363, 0.0274,
         0.0300, 0.0193, 0.0258, 0.0165]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Saving the weights
**************************************************
Session Number: 71
images/459
(64, 64, 3)
tensor([[0.0247, 0.0259, 0.0156, 0.0181, 0.0254, 0.0163, 0.0310, 0.0173, 0.0232,
         0.0154, 0.0220, 0.0162, 0.0368, 0.0590, 0.0272, 0.0227, 0.0254, 0.0273,
         0.0196, 0.0135, 0.0198, 0.0279, 0.0132, 0.0227, 0.0249, 0.0170, 0.0290,
         0.0357, 0.0421, 0.0261, 0.0169, 0.0241, 0.0337, 0.0337, 0.0282, 0.0184,
         0.0282, 0.0244, 0.0232, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 72
images/128
(64, 64, 3)
tensor([[0.0201, 0.0224, 0.0134, 0.0203, 0.0447, 0.0174, 0.0386, 0.0162, 0.0263,
         0.0228, 0.0151, 0.0387, 0.0323, 0.0342, 0.0406, 0.0154, 0.0211, 0.0190,
         0.0159, 0.0269, 0.0187, 0.0293, 0.0174, 0.0178, 0.0150, 0.0225, 0.0387,
         0.0272, 0.0223, 0.0285, 0.0159, 0.0244, 0.0192, 0.0262, 0.0322, 0.0346,
         0.0395, 0.0226, 0.0268, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Session Number: 73
images/405
(64, 64, 3)
tensor([[0.0277, 0.0275, 0.0141, 0.0161, 0.0309, 0.0220, 0.0371, 0.0197, 0.0129,
         0.0198, 0.0169, 0.0250, 0.0370, 0.0361, 0.0292, 0.0231, 0.0197, 0.0343,
         0.0237, 0.0201, 0.0249, 0.0199, 0.0219, 0.0215, 0.0262, 0.0200, 0.0196,
         0.0416, 0.0264, 0.0218, 0.0241, 0.0424, 0.0234, 0.0252, 0.0212, 0.0299,
         0.0407, 0.0159, 0.0172, 0.0231]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 74
images/110
(64, 64, 3)
tensor([[0.0234, 0.0162, 0.0325, 0.0100, 0.0261, 0.0110, 0.0422, 0.0249, 0.0219,
         0.0146, 0.0208, 0.0353, 0.0332, 0.0328, 0.0249, 0.0173, 0.0188, 0.0322,
         0.0128, 0.0322, 0.0124, 0.0308, 0.0211, 0.0170, 0.0229, 0.0238, 0.0221,
         0.0351, 0.0338, 0.0240, 0.0135, 0.0404, 0.0320, 0.0219, 0.0290, 0.0353,
         0.0257, 0.0234, 0.0228, 0.0301]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 75
images/246
(64, 64, 3)
tensor([[0.0372, 0.0331, 0.0169, 0.0224, 0.0417, 0.0208, 0.0453, 0.0153, 0.0203,
         0.0240, 0.0188, 0.0216, 0.0373, 0.0375, 0.0244, 0.0197, 0.0196, 0.0452,
         0.0156, 0.0177, 0.0272, 0.0180, 0.0179, 0.0219, 0.0183, 0.0142, 0.0213,
         0.0311, 0.0387, 0.0262, 0.0126, 0.0282, 0.0227, 0.0182, 0.0224, 0.0274,
         0.0329, 0.0205, 0.0176, 0.0279]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 0
Session Number: 76
images/297
(64, 64, 3)
tensor([[0.0331, 0.0236, 0.0148, 0.0263, 0.0312, 0.0210, 0.0306, 0.0267, 0.0162,
         0.0187, 0.0200, 0.0234, 0.0297, 0.0241, 0.0168, 0.0234, 0.0223, 0.0406,
         0.0173, 0.0216, 0.0191, 0.0136, 0.0370, 0.0257, 0.0248, 0.0235, 0.0246,
         0.0436, 0.0350, 0.0277, 0.0331, 0.0368, 0.0299, 0.0188, 0.0163, 0.0210,
         0.0303, 0.0163, 0.0197, 0.0221]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 77
images/105
(64, 64, 3)
tensor([[0.0233, 0.0216, 0.0241, 0.0154, 0.0249, 0.0209, 0.0393, 0.0184, 0.0127,
         0.0192, 0.0256, 0.0298, 0.0476, 0.0268, 0.0343, 0.0201, 0.0131, 0.0389,
         0.0157, 0.0232, 0.0141, 0.0204, 0.0190, 0.0224, 0.0164, 0.0204, 0.0364,
         0.0512, 0.0287, 0.0202, 0.0249, 0.0304, 0.0269, 0.0212, 0.0321, 0.0297,
         0.0219, 0.0276, 0.0178, 0.0235]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 1
Session Number: 78
images/445
(64, 64, 3)
tensor([[0.0223, 0.0220, 0.0180, 0.0186, 0.0395, 0.0167, 0.0257, 0.0244, 0.0201,
         0.0132, 0.0201, 0.0377, 0.0376, 0.0365, 0.0298, 0.0133, 0.0307, 0.0345,
         0.0172, 0.0183, 0.0178, 0.0232, 0.0240, 0.0211, 0.0243, 0.0288, 0.0398,
         0.0162, 0.0464, 0.0188, 0.0164, 0.0280, 0.0241, 0.0284, 0.0359, 0.0278,
         0.0188, 0.0244, 0.0159, 0.0238]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 79
images/435
(64, 64, 3)
tensor([[0.0304, 0.0276, 0.0139, 0.0185, 0.0180, 0.0247, 0.0288, 0.0168, 0.0220,
         0.0156, 0.0249, 0.0243, 0.0579, 0.0350, 0.0164, 0.0218, 0.0229, 0.0281,
         0.0176, 0.0276, 0.0229, 0.0327, 0.0245, 0.0210, 0.0203, 0.0143, 0.0239,
         0.0331, 0.0393, 0.0183, 0.0179, 0.0438, 0.0326, 0.0240, 0.0186, 0.0269,
         0.0295, 0.0178, 0.0205, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 80
images/560
(64, 64, 3)
tensor([[0.0200, 0.0382, 0.0114, 0.0266, 0.0543, 0.0187, 0.0165, 0.0135, 0.0180,
         0.0155, 0.0109, 0.0289, 0.0276, 0.0428, 0.0277, 0.0162, 0.0261, 0.0332,
         0.0276, 0.0229, 0.0233, 0.0237, 0.0144, 0.0284, 0.0361, 0.0350, 0.0220,
         0.0261, 0.0276, 0.0206, 0.0103, 0.0323, 0.0270, 0.0212, 0.0215, 0.0263,
         0.0353, 0.0306, 0.0154, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 1.85
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 81
images/537
(64, 64, 3)
tensor([[0.0294, 0.0281, 0.0255, 0.0241, 0.0279, 0.0172, 0.0390, 0.0166, 0.0106,
         0.0323, 0.0268, 0.0210, 0.0309, 0.0191, 0.0230, 0.0120, 0.0308, 0.0294,
         0.0134, 0.0190, 0.0153, 0.0230, 0.0181, 0.0273, 0.0231, 0.0127, 0.0149,
         0.0284, 0.0495, 0.0258, 0.0174, 0.0345, 0.0340, 0.0261, 0.0216, 0.0297,
         0.0209, 0.0390, 0.0344, 0.0280]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 82
images/360
(64, 64, 3)
tensor([[0.0385, 0.0143, 0.0181, 0.0348, 0.0269, 0.0147, 0.0359, 0.0205, 0.0208,
         0.0193, 0.0168, 0.0243, 0.0307, 0.0311, 0.0243, 0.0172, 0.0188, 0.0271,
         0.0277, 0.0140, 0.0184, 0.0265, 0.0233, 0.0205, 0.0236, 0.0164, 0.0211,
         0.0377, 0.0395, 0.0166, 0.0260, 0.0200, 0.0293, 0.0243, 0.0240, 0.0386,
         0.0439, 0.0220, 0.0269, 0.0256]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 83
images/295
(64, 64, 3)
tensor([[0.0271, 0.0291, 0.0276, 0.0174, 0.0272, 0.0222, 0.0349, 0.0120, 0.0331,
         0.0231, 0.0188, 0.0499, 0.0408, 0.0310, 0.0188, 0.0229, 0.0158, 0.0466,
         0.0245, 0.0212, 0.0186, 0.0165, 0.0127, 0.0256, 0.0219, 0.0217, 0.0272,
         0.0330, 0.0205, 0.0173, 0.0199, 0.0482, 0.0258, 0.0153, 0.0247, 0.0247,
         0.0218, 0.0170, 0.0218, 0.0219]], grad_fn=<SoftmaxBackward>)


Action: 1.6
Enter Reward: 0
Session Number: 84
images/139
(64, 64, 3)
tensor([[0.0377, 0.0219, 0.0205, 0.0177, 0.0276, 0.0213, 0.0233, 0.0163, 0.0228,
         0.0182, 0.0195, 0.0401, 0.0635, 0.0377, 0.0301, 0.0165, 0.0212, 0.0306,
         0.0124, 0.0172, 0.0175, 0.0344, 0.0231, 0.0179, 0.0180, 0.0240, 0.0318,
         0.0341, 0.0281, 0.0264, 0.0153, 0.0143, 0.0320, 0.0144, 0.0265, 0.0313,
         0.0283, 0.0151, 0.0234, 0.0278]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 1
Session Number: 85
images/432
(64, 64, 3)
tensor([[0.0297, 0.0302, 0.0186, 0.0204, 0.0438, 0.0315, 0.0334, 0.0094, 0.0152,
         0.0235, 0.0226, 0.0217, 0.0503, 0.0289, 0.0188, 0.0154, 0.0137, 0.0429,
         0.0225, 0.0249, 0.0198, 0.0150, 0.0197, 0.0179, 0.0248, 0.0201, 0.0221,
         0.0319, 0.0378, 0.0223, 0.0349, 0.0246, 0.0315, 0.0216, 0.0236, 0.0240,
         0.0237, 0.0179, 0.0209, 0.0285]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 86
images/488
(64, 64, 3)
tensor([[0.0215, 0.0331, 0.0127, 0.0197, 0.0230, 0.0134, 0.0483, 0.0150, 0.0186,
         0.0232, 0.0231, 0.0379, 0.0516, 0.0322, 0.0274, 0.0122, 0.0163, 0.0311,
         0.0151, 0.0273, 0.0161, 0.0225, 0.0181, 0.0273, 0.0156, 0.0100, 0.0251,
         0.0348, 0.0328, 0.0216, 0.0179, 0.0358, 0.0244, 0.0305, 0.0263, 0.0405,
         0.0293, 0.0195, 0.0195, 0.0294]], grad_fn=<SoftmaxBackward>)


Action: 1.95
Enter Reward: 0
Session Number: 87
images/42
(64, 64, 3)
tensor([[0.0270, 0.0319, 0.0176, 0.0159, 0.0286, 0.0203, 0.0278, 0.0248, 0.0241,
         0.0198, 0.0247, 0.0251, 0.0361, 0.0227, 0.0287, 0.0192, 0.0157, 0.0410,
         0.0168, 0.0184, 0.0156, 0.0174, 0.0268, 0.0237, 0.0186, 0.0187, 0.0317,
         0.0383, 0.0329, 0.0251, 0.0180, 0.0223, 0.0287, 0.0264, 0.0357, 0.0296,
         0.0394, 0.0197, 0.0198, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 1
Session Number: 88
images/584
(64, 64, 3)
tensor([[0.0249, 0.0265, 0.0227, 0.0168, 0.0554, 0.0193, 0.0449, 0.0169, 0.0220,
         0.0163, 0.0206, 0.0196, 0.0370, 0.0326, 0.0259, 0.0152, 0.0162, 0.0438,
         0.0297, 0.0177, 0.0130, 0.0242, 0.0210, 0.0211, 0.0168, 0.0266, 0.0208,
         0.0290, 0.0241, 0.0219, 0.0227, 0.0339, 0.0238, 0.0272, 0.0257, 0.0320,
         0.0233, 0.0214, 0.0277, 0.0199]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Session Number: 89
images/105
(64, 64, 3)
tensor([[0.0223, 0.0209, 0.0153, 0.0143, 0.0234, 0.0180, 0.0299, 0.0170, 0.0211,
         0.0128, 0.0264, 0.0311, 0.0631, 0.0275, 0.0335, 0.0251, 0.0153, 0.0416,
         0.0245, 0.0271, 0.0187, 0.0304, 0.0209, 0.0157, 0.0253, 0.0225, 0.0281,
         0.0317, 0.0269, 0.0218, 0.0230, 0.0223, 0.0266, 0.0176, 0.0264, 0.0307,
         0.0306, 0.0178, 0.0313, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 1
Session Number: 90
images/436
(64, 64, 3)
tensor([[0.0346, 0.0212, 0.0125, 0.0231, 0.0290, 0.0254, 0.0342, 0.0163, 0.0233,
         0.0176, 0.0246, 0.0271, 0.0393, 0.0437, 0.0203, 0.0171, 0.0165, 0.0354,
         0.0218, 0.0247, 0.0137, 0.0190, 0.0271, 0.0212, 0.0166, 0.0186, 0.0335,
         0.0251, 0.0442, 0.0321, 0.0102, 0.0343, 0.0281, 0.0287, 0.0265, 0.0195,
         0.0271, 0.0285, 0.0185, 0.0197]], grad_fn=<SoftmaxBackward>)


Action: 1.9
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 91
images/139
(64, 64, 3)
tensor([[0.0350, 0.0235, 0.0266, 0.0319, 0.0223, 0.0168, 0.0196, 0.0218, 0.0240,
         0.0213, 0.0153, 0.0263, 0.0552, 0.0275, 0.0176, 0.0139, 0.0216, 0.0331,
         0.0142, 0.0180, 0.0222, 0.0264, 0.0160, 0.0210, 0.0213, 0.0288, 0.0411,
         0.0283, 0.0369, 0.0356, 0.0165, 0.0172, 0.0287, 0.0235, 0.0199, 0.0274,
         0.0231, 0.0197, 0.0310, 0.0295]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: 0
Session Number: 92
images/248
(64, 64, 3)
tensor([[0.0334, 0.0255, 0.0155, 0.0151, 0.0313, 0.0179, 0.0318, 0.0153, 0.0203,
         0.0168, 0.0237, 0.0482, 0.0356, 0.0323, 0.0218, 0.0147, 0.0234, 0.0313,
         0.0154, 0.0184, 0.0132, 0.0155, 0.0237, 0.0253, 0.0231, 0.0236, 0.0236,
         0.0299, 0.0608, 0.0182, 0.0126, 0.0270, 0.0325, 0.0270, 0.0202, 0.0389,
         0.0158, 0.0270, 0.0282, 0.0261]], grad_fn=<SoftmaxBackward>)


Action: 0.5
Enter Reward: 0
Session Number: 93
images/4
(64, 64, 3)
tensor([[0.0269, 0.0357, 0.0141, 0.0176, 0.0496, 0.0196, 0.0220, 0.0163, 0.0234,
         0.0113, 0.0203, 0.0377, 0.0392, 0.0247, 0.0279, 0.0121, 0.0208, 0.0270,
         0.0194, 0.0271, 0.0153, 0.0323, 0.0235, 0.0172, 0.0249, 0.0157, 0.0191,
         0.0448, 0.0302, 0.0253, 0.0297, 0.0275, 0.0399, 0.0241, 0.0255, 0.0205,
         0.0293, 0.0275, 0.0168, 0.0182]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 94
images/170
(64, 64, 3)
tensor([[0.0194, 0.0225, 0.0282, 0.0109, 0.0514, 0.0207, 0.0446, 0.0160, 0.0179,
         0.0206, 0.0166, 0.0237, 0.0329, 0.0327, 0.0342, 0.0109, 0.0203, 0.0444,
         0.0158, 0.0171, 0.0243, 0.0327, 0.0221, 0.0183, 0.0213, 0.0127, 0.0227,
         0.0337, 0.0273, 0.0269, 0.0247, 0.0297, 0.0187, 0.0278, 0.0250, 0.0293,
         0.0313, 0.0246, 0.0207, 0.0255]], grad_fn=<SoftmaxBackward>)


Action: 1.1
Enter Reward: 1
Session Number: 95
images/589
(64, 64, 3)
tensor([[0.0489, 0.0305, 0.0141, 0.0233, 0.0303, 0.0162, 0.0254, 0.0118, 0.0184,
         0.0137, 0.0129, 0.0409, 0.0265, 0.0327, 0.0524, 0.0208, 0.0150, 0.0264,
         0.0154, 0.0230, 0.0274, 0.0413, 0.0211, 0.0202, 0.0265, 0.0123, 0.0152,
         0.0362, 0.0387, 0.0251, 0.0130, 0.0200, 0.0236, 0.0193, 0.0298, 0.0296,
         0.0206, 0.0272, 0.0226, 0.0313]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 0
Session Number: 96
images/373
(64, 64, 3)
tensor([[0.0215, 0.0316, 0.0213, 0.0250, 0.0283, 0.0195, 0.0254, 0.0141, 0.0213,
         0.0256, 0.0193, 0.0278, 0.0299, 0.0556, 0.0246, 0.0166, 0.0242, 0.0393,
         0.0151, 0.0236, 0.0186, 0.0260, 0.0219, 0.0386, 0.0224, 0.0233, 0.0264,
         0.0323, 0.0338, 0.0190, 0.0171, 0.0207, 0.0245, 0.0279, 0.0181, 0.0253,
         0.0229, 0.0275, 0.0153, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 97
images/248
(64, 64, 3)
tensor([[0.0293, 0.0323, 0.0136, 0.0260, 0.0253, 0.0166, 0.0210, 0.0150, 0.0129,
         0.0167, 0.0259, 0.0369, 0.0554, 0.0236, 0.0231, 0.0191, 0.0285, 0.0221,
         0.0300, 0.0269, 0.0135, 0.0282, 0.0206, 0.0196, 0.0193, 0.0190, 0.0266,
         0.0319, 0.0398, 0.0285, 0.0133, 0.0195, 0.0444, 0.0263, 0.0174, 0.0268,
         0.0297, 0.0286, 0.0260, 0.0208]], grad_fn=<SoftmaxBackward>)


Action: 1.0
Enter Reward: 0
Session Number: 98
images/449
(64, 64, 3)
tensor([[0.0295, 0.0233, 0.0217, 0.0152, 0.0322, 0.0181, 0.0349, 0.0150, 0.0147,
         0.0268, 0.0279, 0.0309, 0.0257, 0.0274, 0.0267, 0.0128, 0.0267, 0.0292,
         0.0173, 0.0163, 0.0168, 0.0249, 0.0235, 0.0194, 0.0158, 0.0222, 0.0245,
         0.0526, 0.0375, 0.0334, 0.0163, 0.0230, 0.0284, 0.0280, 0.0173, 0.0244,
         0.0333, 0.0297, 0.0230, 0.0337]], grad_fn=<SoftmaxBackward>)


Action: 1.35
Enter Reward: 0
Session Number: 99
images/337
(64, 64, 3)
tensor([[0.0281, 0.0220, 0.0205, 0.0203, 0.0305, 0.0165, 0.0372, 0.0197, 0.0130,
         0.0200, 0.0177, 0.0365, 0.0304, 0.0341, 0.0219, 0.0138, 0.0251, 0.0284,
         0.0212, 0.0289, 0.0164, 0.0198, 0.0389, 0.0199, 0.0214, 0.0160, 0.0221,
         0.0355, 0.0312, 0.0209, 0.0123, 0.0322, 0.0263, 0.0218, 0.0287, 0.0409,
         0.0273, 0.0273, 0.0265, 0.0287]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Saving the weights
34 number of +1 rewards in 99 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/339
(64, 64, 3)
2018-10-13 02:58:26.178 Python[11844:15775878] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0189, 0.0256, 0.0214, 0.0183, 0.0264, 0.0159, 0.0370, 0.0286, 0.0195,
         0.0159, 0.0260, 0.0339, 0.0231, 0.0308, 0.0327, 0.0241, 0.0148, 0.0511,
         0.0228, 0.0222, 0.0312, 0.0164, 0.0192, 0.0244, 0.0252, 0.0164, 0.0270,
         0.0388, 0.0366, 0.0166, 0.0142, 0.0291, 0.0292, 0.0233, 0.0244, 0.0153,
         0.0212, 0.0190, 0.0286, 0.0347]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/239
(64, 64, 3)
tensor([[0.0309, 0.0337, 0.0212, 0.0182, 0.0271, 0.0264, 0.0181, 0.0138, 0.0187,
         0.0297, 0.0138, 0.0345, 0.0367, 0.0212, 0.0360, 0.0322, 0.0180, 0.0491,
         0.0260, 0.0160, 0.0175, 0.0228, 0.0186, 0.0246, 0.0177, 0.0178, 0.0213,
         0.0341, 0.0195, 0.0294, 0.0201, 0.0234, 0.0255, 0.0258, 0.0349, 0.0333,
         0.0253, 0.0314, 0.0176, 0.0180]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0 
Session Number: 2
images/103
(64, 64, 3)
tensor([[0.0295, 0.0199, 0.0157, 0.0169, 0.0502, 0.0148, 0.0398, 0.0472, 0.0132,
         0.0179, 0.0225, 0.0349, 0.0295, 0.0295, 0.0210, 0.0173, 0.0171, 0.0544,
         0.0223, 0.0162, 0.0135, 0.0218, 0.0181, 0.0211, 0.0188, 0.0213, 0.0348,
         0.0234, 0.0257, 0.0218, 0.0225, 0.0416, 0.0222, 0.0156, 0.0257, 0.0241,
         0.0274, 0.0218, 0.0253, 0.0237]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 3
images/367
(64, 64, 3)
tensor([[0.0138, 0.0267, 0.0194, 0.0274, 0.0351, 0.0154, 0.0187, 0.0163, 0.0172,
         0.0194, 0.0141, 0.0240, 0.0331, 0.0356, 0.0266, 0.0231, 0.0190, 0.0620,
         0.0150, 0.0265, 0.0269, 0.0227, 0.0199, 0.0253, 0.0202, 0.0164, 0.0249,
         0.0250, 0.0455, 0.0179, 0.0221, 0.0458, 0.0351, 0.0178, 0.0280, 0.0263,
         0.0279, 0.0165, 0.0176, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: 0
Session Number: 4
images/490
(64, 64, 3)
tensor([[0.0187, 0.0301, 0.0247, 0.0218, 0.0267, 0.0172, 0.0316, 0.0179, 0.0203,
         0.0233, 0.0178, 0.0236, 0.0381, 0.0379, 0.0304, 0.0194, 0.0224, 0.0331,
         0.0153, 0.0201, 0.0229, 0.0273, 0.0195, 0.0228, 0.0168, 0.0147, 0.0380,
         0.0245, 0.0334, 0.0462, 0.0233, 0.0255, 0.0248, 0.0275, 0.0200, 0.0232,
         0.0213, 0.0209, 0.0205, 0.0366]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 0
Session Number: 5
images/267
(64, 64, 3)
tensor([[0.0213, 0.0206, 0.0247, 0.0238, 0.0307, 0.0179, 0.0282, 0.0161, 0.0210,
         0.0131, 0.0229, 0.0203, 0.0469, 0.0283, 0.0210, 0.0182, 0.0175, 0.0405,
         0.0215, 0.0226, 0.0109, 0.0213, 0.0184, 0.0186, 0.0207, 0.0274, 0.0337,
         0.0186, 0.0225, 0.0276, 0.0265, 0.0351, 0.0320, 0.0319, 0.0296, 0.0499,
         0.0254, 0.0232, 0.0205, 0.0291]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 1
Session Number: 6
images/346
(64, 64, 3)
tensor([[0.0188, 0.0256, 0.0205, 0.0172, 0.0299, 0.0182, 0.0308, 0.0203, 0.0179,
         0.0128, 0.0167, 0.0469, 0.0455, 0.0198, 0.0186, 0.0155, 0.0143, 0.0399,
         0.0195, 0.0312, 0.0226, 0.0219, 0.0159, 0.0260, 0.0126, 0.0153, 0.0283,
         0.0313, 0.0313, 0.0244, 0.0195, 0.0310, 0.0349, 0.0145, 0.0317, 0.0395,
         0.0502, 0.0254, 0.0251, 0.0191]], grad_fn=<SoftmaxBackward>)


Action: 0.0
Enter Reward: 0
Session Number: 7
images/368
(64, 64, 3)
tensor([[0.0175, 0.0221, 0.0160, 0.0139, 0.0490, 0.0215, 0.0441, 0.0137, 0.0203,
         0.0153, 0.0169, 0.0381, 0.0517, 0.0215, 0.0203, 0.0223, 0.0141, 0.0448,
         0.0120, 0.0164, 0.0223, 0.0212, 0.0141, 0.0227, 0.0280, 0.0238, 0.0264,
         0.0328, 0.0312, 0.0237, 0.0111, 0.0412, 0.0258, 0.0205, 0.0182, 0.0405,
         0.0298, 0.0193, 0.0222, 0.0336]], grad_fn=<SoftmaxBackward>)


Action: 0.35
Enter Reward: -1
Breaking
Saving the weights
1 number of +1 rewards in 7 images
Saving the weights
1 number of +1 rewards in 7 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/322
(64, 64, 3)
2018-10-13 02:59:45.855 Python[11908:15776851] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0243, 0.0261, 0.0136, 0.0231, 0.0201, 0.0166, 0.0443, 0.0182, 0.0201,
         0.0160, 0.0152, 0.0292, 0.0418, 0.0248, 0.0266, 0.0306, 0.0157, 0.0393,
         0.0175, 0.0272, 0.0433, 0.0218, 0.0162, 0.0187, 0.0220, 0.0157, 0.0394,
         0.0336, 0.0412, 0.0197, 0.0192, 0.0324, 0.0344, 0.0242, 0.0266, 0.0179,
         0.0199, 0.0140, 0.0199, 0.0298]], grad_fn=<SoftmaxBackward>)


Action: 0.7
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/472
(64, 64, 3)
tensor([[0.0290, 0.0384, 0.0165, 0.0243, 0.0233, 0.0234, 0.0227, 0.0249, 0.0213,
         0.0317, 0.0159, 0.0366, 0.0467, 0.0331, 0.0269, 0.0267, 0.0184, 0.0413,
         0.0217, 0.0178, 0.0218, 0.0179, 0.0130, 0.0224, 0.0162, 0.0162, 0.0202,
         0.0325, 0.0217, 0.0185, 0.0231, 0.0191, 0.0364, 0.0190, 0.0255, 0.0249,
         0.0330, 0.0307, 0.0221, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 0.05
Enter Reward: 0
Session Number: 2
images/582
(64, 64, 3)
tensor([[0.0241, 0.0247, 0.0171, 0.0177, 0.0299, 0.0166, 0.0416, 0.0224, 0.0231,
         0.0169, 0.0156, 0.0307, 0.0461, 0.0280, 0.0194, 0.0145, 0.0207, 0.0549,
         0.0153, 0.0189, 0.0122, 0.0227, 0.0185, 0.0152, 0.0210, 0.0151, 0.0389,
         0.0422, 0.0279, 0.0282, 0.0226, 0.0477, 0.0231, 0.0212, 0.0332, 0.0239,
         0.0251, 0.0183, 0.0168, 0.0277]], grad_fn=<SoftmaxBackward>)


Action: 1.55
Enter Reward: 0
Session Number: 3
images/391
(64, 64, 3)
tensor([[0.0179, 0.0336, 0.0225, 0.0170, 0.0216, 0.0260, 0.0351, 0.0187, 0.0189,
         0.0183, 0.0209, 0.0326, 0.0252, 0.0294, 0.0270, 0.0191, 0.0125, 0.0542,
         0.0196, 0.0283, 0.0187, 0.0271, 0.0206, 0.0236, 0.0217, 0.0117, 0.0186,
         0.0243, 0.0532, 0.0146, 0.0294, 0.0316, 0.0236, 0.0238, 0.0267, 0.0291,
         0.0314, 0.0208, 0.0226, 0.0285]], grad_fn=<SoftmaxBackward>)


Action: 0.85
Enter Reward: -1
Breaking
Saving the weights
0 number of +1 rewards in 3 images
Saving the weights
0 number of +1 rewards in 3 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/114
(64, 64, 3)
2018-10-13 03:00:25.278 Python[11959:15777305] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0302, 0.0264, 0.0299, 0.0147, 0.0256, 0.0286, 0.0292, 0.0146, 0.0127,
         0.0332, 0.0181, 0.0447, 0.0468, 0.0273, 0.0213, 0.0182, 0.0241, 0.0197,
         0.0214, 0.0189, 0.0224, 0.0273, 0.0214, 0.0221, 0.0208, 0.0127, 0.0268,
         0.0313, 0.0339, 0.0256, 0.0194, 0.0486, 0.0249, 0.0212, 0.0317, 0.0250,
         0.0182, 0.0213, 0.0206, 0.0195]], grad_fn=<SoftmaxBackward>)


Action: 0.25
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/3
(64, 64, 3)
tensor([[0.0190, 0.0278, 0.0191, 0.0305, 0.0385, 0.0176, 0.0533, 0.0248, 0.0260,
         0.0175, 0.0213, 0.0281, 0.0459, 0.0296, 0.0254, 0.0150, 0.0170, 0.0256,
         0.0205, 0.0205, 0.0220, 0.0217, 0.0198, 0.0211, 0.0192, 0.0155, 0.0253,
         0.0249, 0.0289, 0.0318, 0.0236, 0.0303, 0.0255, 0.0228, 0.0304, 0.0226,
         0.0244, 0.0217, 0.0244, 0.0215]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 0
Session Number: 2
images/296
(64, 64, 3)
tensor([[0.0461, 0.0405, 0.0193, 0.0168, 0.0344, 0.0348, 0.0363, 0.0158, 0.0083,
         0.0096, 0.0182, 0.0355, 0.0261, 0.0402, 0.0240, 0.0262, 0.0178, 0.0323,
         0.0185, 0.0193, 0.0190, 0.0292, 0.0257, 0.0189, 0.0187, 0.0168, 0.0217,
         0.0251, 0.0370, 0.0224, 0.0181, 0.0220, 0.0319, 0.0165, 0.0254, 0.0274,
         0.0210, 0.0237, 0.0240, 0.0358]], grad_fn=<SoftmaxBackward>)


Action: 1.25
Enter Reward: 0
Session Number: 3
images/10
(64, 64, 3)
tensor([[0.0207, 0.0294, 0.0231, 0.0132, 0.0334, 0.0242, 0.0520, 0.0140, 0.0218,
         0.0237, 0.0197, 0.0388, 0.0451, 0.0318, 0.0363, 0.0163, 0.0203, 0.0448,
         0.0169, 0.0216, 0.0173, 0.0164, 0.0195, 0.0137, 0.0235, 0.0179, 0.0203,
         0.0288, 0.0272, 0.0202, 0.0240, 0.0223, 0.0285, 0.0256, 0.0230, 0.0269,
         0.0280, 0.0176, 0.0267, 0.0254]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 4
images/326
(64, 64, 3)
tensor([[0.0229, 0.0243, 0.0205, 0.0156, 0.0655, 0.0225, 0.0283, 0.0175, 0.0211,
         0.0167, 0.0117, 0.0323, 0.0445, 0.0256, 0.0246, 0.0298, 0.0184, 0.0274,
         0.0157, 0.0145, 0.0245, 0.0245, 0.0153, 0.0215, 0.0180, 0.0201, 0.0419,
         0.0334, 0.0417, 0.0278, 0.0197, 0.0210, 0.0262, 0.0342, 0.0264, 0.0226,
         0.0298, 0.0165, 0.0164, 0.0193]], grad_fn=<SoftmaxBackward>)


Action: 0.55
Enter Reward: 0
Session Number: 5
images/148
(64, 64, 3)
tensor([[0.0276, 0.0337, 0.0167, 0.0183, 0.0370, 0.0166, 0.0315, 0.0208, 0.0202,
         0.0120, 0.0148, 0.0270, 0.0638, 0.0328, 0.0213, 0.0179, 0.0160, 0.0419,
         0.0188, 0.0239, 0.0181, 0.0148, 0.0153, 0.0186, 0.0200, 0.0188, 0.0272,
         0.0281, 0.0286, 0.0325, 0.0178, 0.0362, 0.0268, 0.0252, 0.0258, 0.0330,
         0.0368, 0.0188, 0.0265, 0.0185]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 6
images/126
(64, 64, 3)
tensor([[0.0305, 0.0195, 0.0200, 0.0263, 0.0273, 0.0105, 0.0317, 0.0253, 0.0165,
         0.0173, 0.0196, 0.0327, 0.0376, 0.0458, 0.0271, 0.0200, 0.0157, 0.0352,
         0.0233, 0.0198, 0.0138, 0.0282, 0.0193, 0.0146, 0.0241, 0.0306, 0.0183,
         0.0460, 0.0317, 0.0268, 0.0118, 0.0319, 0.0263, 0.0238, 0.0256, 0.0206,
         0.0347, 0.0209, 0.0313, 0.0180]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: -1
Breaking
Saving the weights
0 number of +1 rewards in 6 images
Saving the weights
0 number of +1 rewards in 6 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/334
(64, 64, 3)
2018-10-13 03:01:41.222 Python[12021:15778234] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0342, 0.0266, 0.0236, 0.0141, 0.0317, 0.0205, 0.0220, 0.0159, 0.0170,
         0.0275, 0.0218, 0.0300, 0.0411, 0.0366, 0.0330, 0.0182, 0.0266, 0.0251,
         0.0209, 0.0190, 0.0262, 0.0334, 0.0145, 0.0355, 0.0186, 0.0130, 0.0360,
         0.0326, 0.0267, 0.0228, 0.0201, 0.0311, 0.0191, 0.0304, 0.0217, 0.0309,
         0.0170, 0.0183, 0.0254, 0.0213]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/245
(64, 64, 3)
tensor([[0.0250, 0.0208, 0.0174, 0.0145, 0.0397, 0.0232, 0.0223, 0.0162, 0.0322,
         0.0232, 0.0240, 0.0277, 0.0372, 0.0203, 0.0278, 0.0285, 0.0177, 0.0369,
         0.0215, 0.0210, 0.0132, 0.0318, 0.0200, 0.0212, 0.0181, 0.0243, 0.0235,
         0.0355, 0.0243, 0.0389, 0.0225, 0.0273, 0.0214, 0.0237, 0.0273, 0.0241,
         0.0315, 0.0348, 0.0205, 0.0192]], grad_fn=<SoftmaxBackward>)


Action: 1.7
Enter Reward: 1
Session Number: 2
images/67
(64, 64, 3)
tensor([[0.0477, 0.0258, 0.0186, 0.0193, 0.0432, 0.0292, 0.0276, 0.0179, 0.0132,
         0.0167, 0.0187, 0.0504, 0.0189, 0.0337, 0.0291, 0.0249, 0.0157, 0.0296,
         0.0208, 0.0198, 0.0280, 0.0220, 0.0256, 0.0207, 0.0200, 0.0160, 0.0247,
         0.0323, 0.0394, 0.0257, 0.0162, 0.0257, 0.0295, 0.0174, 0.0153, 0.0232,
         0.0273, 0.0139, 0.0237, 0.0327]], grad_fn=<SoftmaxBackward>)


Action: 1.2
Enter Reward: 1
Session Number: 3
images/263
(64, 64, 3)
tensor([[0.0186, 0.0371, 0.0183, 0.0165, 0.0458, 0.0270, 0.0362, 0.0139, 0.0191,
         0.0280, 0.0219, 0.0279, 0.0333, 0.0216, 0.0294, 0.0131, 0.0220, 0.0326,
         0.0261, 0.0212, 0.0140, 0.0219, 0.0154, 0.0210, 0.0259, 0.0205, 0.0242,
         0.0335, 0.0373, 0.0231, 0.0189, 0.0415, 0.0234, 0.0298, 0.0179, 0.0163,
         0.0238, 0.0330, 0.0215, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 0
Session Number: 4
images/550
(64, 64, 3)
tensor([[0.0232, 0.0422, 0.0119, 0.0148, 0.0392, 0.0267, 0.0242, 0.0191, 0.0221,
         0.0181, 0.0218, 0.0213, 0.0272, 0.0199, 0.0241, 0.0263, 0.0269, 0.0308,
         0.0194, 0.0162, 0.0136, 0.0261, 0.0281, 0.0275, 0.0267, 0.0188, 0.0299,
         0.0328, 0.0304, 0.0211, 0.0214, 0.0349, 0.0348, 0.0265, 0.0257, 0.0215,
         0.0295, 0.0238, 0.0242, 0.0275]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 1
Session Number: 5
images/485
(64, 64, 3)
tensor([[0.0180, 0.0369, 0.0141, 0.0181, 0.0297, 0.0171, 0.0251, 0.0177, 0.0245,
         0.0152, 0.0246, 0.0279, 0.0494, 0.0382, 0.0354, 0.0139, 0.0214, 0.0390,
         0.0323, 0.0222, 0.0159, 0.0241, 0.0180, 0.0264, 0.0142, 0.0177, 0.0331,
         0.0264, 0.0338, 0.0372, 0.0203, 0.0341, 0.0323, 0.0205, 0.0171, 0.0250,
         0.0234, 0.0150, 0.0251, 0.0198]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 6
images/310
(64, 64, 3)
tensor([[0.0355, 0.0248, 0.0281, 0.0207, 0.0328, 0.0110, 0.0291, 0.0163, 0.0132,
         0.0228, 0.0147, 0.0385, 0.0311, 0.0346, 0.0478, 0.0188, 0.0176, 0.0299,
         0.0165, 0.0171, 0.0188, 0.0294, 0.0247, 0.0190, 0.0151, 0.0220, 0.0220,
         0.0391, 0.0309, 0.0233, 0.0137, 0.0290, 0.0347, 0.0333, 0.0281, 0.0290,
         0.0256, 0.0202, 0.0161, 0.0250]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 7
images/244
(64, 64, 3)
tensor([[0.0301, 0.0244, 0.0255, 0.0223, 0.0290, 0.0189, 0.0305, 0.0301, 0.0189,
         0.0200, 0.0181, 0.0440, 0.0293, 0.0240, 0.0261, 0.0162, 0.0187, 0.0265,
         0.0154, 0.0160, 0.0229, 0.0175, 0.0165, 0.0169, 0.0194, 0.0276, 0.0175,
         0.0445, 0.0422, 0.0338, 0.0193, 0.0367, 0.0287, 0.0308, 0.0231, 0.0157,
         0.0385, 0.0182, 0.0223, 0.0239]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: -1
Breaking
Saving the weights
4 number of +1 rewards in 7 images
Saving the weights
4 number of +1 rewards in 7 images
**************************************************
 siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/150
(64, 64, 3)
2018-10-13 03:18:55.217 Python[12455:15789822] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0290, 0.0222, 0.0257, 0.0130, 0.0289, 0.0244, 0.0319, 0.0226, 0.0195,
         0.0388, 0.0233, 0.0445, 0.0364, 0.0354, 0.0251, 0.0202, 0.0188, 0.0212,
         0.0176, 0.0221, 0.0248, 0.0293, 0.0113, 0.0329, 0.0201, 0.0136, 0.0317,
         0.0246, 0.0268, 0.0235, 0.0162, 0.0365, 0.0285, 0.0168, 0.0237, 0.0209,
         0.0192, 0.0188, 0.0324, 0.0278]], grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 170, in <module>
    main()
  File "Torch_reinforce01.py", line 130, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 91, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[action]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/481
(64, 64, 3)
2018-10-13 03:21:24.243 Python[12542:15791383] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0306, 0.0234, 0.0282, 0.0131, 0.0230, 0.0199, 0.0296, 0.0176, 0.0162,
         0.0307, 0.0292, 0.0229, 0.0415, 0.0421, 0.0264, 0.0155, 0.0235, 0.0233,
         0.0187, 0.0191, 0.0209, 0.0316, 0.0184, 0.0311, 0.0189, 0.0149, 0.0282,
         0.0320, 0.0250, 0.0259, 0.0140, 0.0351, 0.0286, 0.0227, 0.0279, 0.0298,
         0.0275, 0.0170, 0.0319, 0.0240]], grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 170, in <module>
    main()
  File "Torch_reinforce01.py", line 130, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 91, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[action]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/82
(64, 64, 3)
2018-10-13 03:21:55.775 Python[12586:15791789] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0249, 0.0281, 0.0273, 0.0164, 0.0277, 0.0200, 0.0238, 0.0152, 0.0157,
         0.0310, 0.0277, 0.0380, 0.0487, 0.0366, 0.0259, 0.0143, 0.0159, 0.0198,
         0.0208, 0.0212, 0.0239, 0.0269, 0.0189, 0.0248, 0.0216, 0.0135, 0.0340,
         0.0410, 0.0334, 0.0280, 0.0176, 0.0364, 0.0239, 0.0224, 0.0300, 0.0271,
         0.0190, 0.0178, 0.0176, 0.0228]], grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 170, in <module>
    main()
  File "Torch_reinforce01.py", line 130, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 91, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[action]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/363
(64, 64, 3)
2018-10-13 03:22:43.464 Python[12637:15792294] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0284, 0.0256, 0.0262, 0.0174, 0.0231, 0.0194, 0.0202, 0.0136, 0.0201,
         0.0315, 0.0214, 0.0333, 0.0427, 0.0356, 0.0271, 0.0206, 0.0197, 0.0249,
         0.0169, 0.0281, 0.0234, 0.0292, 0.0204, 0.0219, 0.0178, 0.0168, 0.0369,
         0.0397, 0.0295, 0.0261, 0.0211, 0.0378, 0.0307, 0.0194, 0.0220, 0.0274,
         0.0224, 0.0175, 0.0186, 0.0257]], grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 170, in <module>
    main()
  File "Torch_reinforce01.py", line 130, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 91, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[action]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/113
(64, 64, 3)
2018-10-13 03:23:01.998 Python[12678:15792598] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0291, 0.0216, 0.0213, 0.0150, 0.0214, 0.0251, 0.0273, 0.0187, 0.0218,
         0.0343, 0.0230, 0.0320, 0.0392, 0.0306, 0.0336, 0.0166, 0.0182, 0.0284,
         0.0157, 0.0163, 0.0303, 0.0253, 0.0257, 0.0249, 0.0234, 0.0134, 0.0281,
         0.0272, 0.0328, 0.0287, 0.0218, 0.0391, 0.0263, 0.0228, 0.0245, 0.0344,
         0.0155, 0.0188, 0.0261, 0.0219]], grad_fn=<SoftmaxBackward>)
tensor([6])
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 171, in <module>
    main()
  File "Torch_reinforce01.py", line 131, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 92, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[action]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/146
(64, 64, 3)
2018-10-13 03:23:25.190 Python[12719:15792872] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0277, 0.0285, 0.0237, 0.0125, 0.0259, 0.0264, 0.0214, 0.0165, 0.0154,
         0.0342, 0.0205, 0.0251, 0.0612, 0.0288, 0.0168, 0.0188, 0.0188, 0.0307,
         0.0224, 0.0173, 0.0157, 0.0320, 0.0212, 0.0257, 0.0150, 0.0131, 0.0334,
         0.0314, 0.0305, 0.0230, 0.0220, 0.0352, 0.0275, 0.0183, 0.0237, 0.0341,
         0.0162, 0.0208, 0.0367, 0.0321]], grad_fn=<SoftmaxBackward>)
6
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 171, in <module>
    main()
  File "Torch_reinforce01.py", line 131, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 92, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[action]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/171
(64, 64, 3)
2018-10-13 03:24:08.457 Python[12767:15793288] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0323, 0.0282, 0.0189, 0.0119, 0.0265, 0.0266, 0.0242, 0.0156, 0.0143,
         0.0305, 0.0300, 0.0277, 0.0463, 0.0294, 0.0167, 0.0137, 0.0249, 0.0248,
         0.0211, 0.0212, 0.0267, 0.0340, 0.0162, 0.0325, 0.0203, 0.0123, 0.0300,
         0.0359, 0.0428, 0.0231, 0.0191, 0.0415, 0.0317, 0.0197, 0.0152, 0.0249,
         0.0143, 0.0224, 0.0258, 0.0267]], grad_fn=<SoftmaxBackward>)
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 171, in <module>
    main()
  File "Torch_reinforce01.py", line 131, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 92, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[int(np.array(action))]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/58
(64, 64, 3)
2018-10-13 03:24:31.963 Python[12809:15793665] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0334, 0.0240, 0.0241, 0.0173, 0.0301, 0.0223, 0.0343, 0.0157, 0.0149,
         0.0271, 0.0209, 0.0242, 0.0488, 0.0271, 0.0241, 0.0216, 0.0205, 0.0304,
         0.0191, 0.0224, 0.0226, 0.0409, 0.0208, 0.0239, 0.0212, 0.0139, 0.0295,
         0.0346, 0.0314, 0.0200, 0.0216, 0.0271, 0.0240, 0.0210, 0.0191, 0.0343,
         0.0217, 0.0211, 0.0265, 0.0227]], grad_fn=<SoftmaxBackward>)
5
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 171, in <module>
    main()
  File "Torch_reinforce01.py", line 131, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 92, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[int(np.array(action))]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/283
(64, 64, 3)
2018-10-13 03:25:28.848 Python[12862:15794185] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0281, 0.0311, 0.0202, 0.0189, 0.0231, 0.0243, 0.0286, 0.0150, 0.0147,
         0.0224, 0.0234, 0.0256, 0.0341, 0.0302, 0.0174, 0.0160, 0.0326, 0.0253,
         0.0196, 0.0192, 0.0326, 0.0355, 0.0229, 0.0228, 0.0177, 0.0173, 0.0326,
         0.0259, 0.0477, 0.0240, 0.0169, 0.0462, 0.0363, 0.0230, 0.0208, 0.0295,
         0.0179, 0.0152, 0.0186, 0.0268]], grad_fn=<SoftmaxBackward>)
0.3
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 171, in <module>
    main()
  File "Torch_reinforce01.py", line 131, in main
    action = select_action(np.reshape(state,(3,64,64)))
  File "Torch_reinforce01.py", line 92, in select_action
    policy.saved_log_probs.append(m.log_prob(action_table[int(np.array(action))]))
  File "/usr/local/lib/python3.6/site-packages/torch/distributions/categorical.py", line 96, in log_prob
    value_shape = torch._C._infer_size(value.size(), self.batch_shape) if self.batch_shape else value.size()
TypeError: 'int' object is not callable
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  python3 Torch_reinforce01.py --load_model 1   
Loading the model if any
1
Weights.pt
Optimizer.pt
Session Number: 0
images/136
(64, 64, 3)
2018-10-13 03:28:50.889 Python[12976:15795774] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)
tensor([[0.0235, 0.0341, 0.0206, 0.0129, 0.0238, 0.0237, 0.0286, 0.0161, 0.0215,
         0.0210, 0.0257, 0.0294, 0.0601, 0.0343, 0.0211, 0.0170, 0.0301, 0.0242,
         0.0186, 0.0245, 0.0189, 0.0301, 0.0190, 0.0263, 0.0160, 0.0145, 0.0235,
         0.0311, 0.0357, 0.0277, 0.0144, 0.0249, 0.0292, 0.0277, 0.0231, 0.0401,
         0.0218, 0.0204, 0.0225, 0.0222]], grad_fn=<SoftmaxBackward>)


Action: 0.3
Enter Reward: 0
Saving the weights
**************************************************
Session Number: 1
images/414
(64, 64, 3)
tensor([[0.0237, 0.0220, 0.0125, 0.0179, 0.0288, 0.0216, 0.0371, 0.0162, 0.0236,
         0.0164, 0.0302, 0.0283, 0.0409, 0.0245, 0.0252, 0.0262, 0.0169, 0.0482,
         0.0253, 0.0188, 0.0152, 0.0285, 0.0183, 0.0176, 0.0286, 0.0178, 0.0250,
         0.0276, 0.0344, 0.0354, 0.0254, 0.0306, 0.0237, 0.0327, 0.0277, 0.0192,
         0.0262, 0.0262, 0.0201, 0.0154]], grad_fn=<SoftmaxBackward>)


Action: 1.65
Enter Reward: 1
Session Number: 2
images/327
(64, 64, 3)
tensor([[0.0444, 0.0264, 0.0193, 0.0219, 0.0252, 0.0164, 0.0307, 0.0177, 0.0129,
         0.0100, 0.0206, 0.0447, 0.0205, 0.0308, 0.0269, 0.0225, 0.0163, 0.0328,
         0.0126, 0.0228, 0.0292, 0.0212, 0.0274, 0.0174, 0.0247, 0.0171, 0.0287,
         0.0342, 0.0400, 0.0305, 0.0147, 0.0284, 0.0523, 0.0164, 0.0242, 0.0262,
         0.0233, 0.0207, 0.0177, 0.0304]], grad_fn=<SoftmaxBackward>)


Action: 1.3
Enter Reward: 1
Session Number: 3
images/473
(64, 64, 3)
tensor([[0.0154, 0.0293, 0.0179, 0.0186, 0.0468, 0.0187, 0.0519, 0.0143, 0.0208,
         0.0252, 0.0143, 0.0346, 0.0446, 0.0203, 0.0244, 0.0111, 0.0217, 0.0358,
         0.0215, 0.0237, 0.0125, 0.0174, 0.0202, 0.0210, 0.0260, 0.0221, 0.0191,
         0.0247, 0.0361, 0.0183, 0.0167, 0.0387, 0.0292, 0.0250, 0.0225, 0.0215,
         0.0498, 0.0285, 0.0166, 0.0233]], grad_fn=<SoftmaxBackward>)


Action: 0.15
Enter Reward: 0
Session Number: 4
images/268
(64, 64, 3)
tensor([[0.0206, 0.0277, 0.0161, 0.0146, 0.0452, 0.0197, 0.0310, 0.0163, 0.0298,
         0.0230, 0.0154, 0.0270, 0.0381, 0.0242, 0.0277, 0.0190, 0.0221, 0.0374,
         0.0172, 0.0178, 0.0166, 0.0186, 0.0190, 0.0250, 0.0222, 0.0231, 0.0382,
         0.0327, 0.0351, 0.0272, 0.0225, 0.0267, 0.0373, 0.0230, 0.0233, 0.0206,
         0.0246, 0.0184, 0.0189, 0.0370]], grad_fn=<SoftmaxBackward>)


Action: 0.6
Enter Reward: 0
Session Number: 5
images/453
(64, 64, 3)
tensor([[0.0257, 0.0324, 0.0166, 0.0169, 0.0386, 0.0150, 0.0276, 0.0158, 0.0269,
         0.0139, 0.0238, 0.0495, 0.0405, 0.0259, 0.0249, 0.0163, 0.0198, 0.0289,
         0.0248, 0.0269, 0.0181, 0.0205, 0.0218, 0.0176, 0.0185, 0.0166, 0.0372,
         0.0339, 0.0279, 0.0385, 0.0145, 0.0357, 0.0297, 0.0243, 0.0207, 0.0355,
         0.0277, 0.0128, 0.0216, 0.0161]], grad_fn=<SoftmaxBackward>)


Action: 0.1
Enter Reward: 
Traceback (most recent call last):
  File "Torch_reinforce01.py", line 170, in <module>
    main()
  File "Torch_reinforce01.py", line 140, in main
    reward = int(input("Enter Reward: "))
ValueError: invalid literal for int() with base 10: ''
 ✘ siddharthnayak@Siddharths-MacBook-Air  ~/Downloads/RL Project/Code   master ●  
