apiVersion: v1
kind: Pod
metadata:
  # Name of the pod. This is the name to use in any interaction with kubectl
  name: RL_Project
spec:
  securityContext:
    # You need to specify your user ID here. You can get this by running "id -u"
    runAsUser: 1096
  volumes:
  # The following 3 entries are the NFS mounts available to you. You do not need to
  # modify them. They are for your home folder, and the shared tools and datasets
  # folders.
  - name: home
    persistentVolumeClaim:
      claimName: home
  - name: tools
    persistentVolumeClaim:
      claimName: tools
#  - name: data1
#    persistentVolumeClaim:
#      claimName: data1
#  - name: data2
#    persistentVolumeClaim:
#      claimName: data2
#  - name: data3
#    persistentVolumeClaim:
#      claimName: data3
  - name: scratch1
    persistentVolumeClaim:
      claimName: scratch1
#  - name: scratch2
#    persistentVolumeClaim:
#      claimName: scratch2
  # The following 3 entries make the Nvidia drivers available. You do not need to
  # modify them.
  - hostPath:
      path: /usr/lib/nvidia-driver/bin
    name: nvbin
  - hostPath:
      path: /usr/lib/nvidia-driver
    name: nvlib
  - hostPath:
      path: /usr/lib/
    name: usrlib
  - hostPath:
      path: /usr/bin
    name: bin
  - hostPath:
      path: /lib
    name: lib
  # You can specify a label indicating a specific model of GPU here when you need it.
  # Leave it commented when learning how to use the cluster.
#  nodeSelector:
#    gputype: k40
  # This part specifies the Docker container in which your code will run.
  containers:
  - name: py # The container also has a name but it ususally doesn't matter
    # This is the Docker image on which your container is based. Leave it unchanged.
    image: ubuntu:16.04
    # This is the command which is run once the container is created. Point it to
    # your code. It is best to encapsulate your commands in a shell script and
    # call that script like below.
    #
    # Note that all paths have to be according to the filesystem inside the container.
    command: ["/bin/bash", "/storage/home/sidnayak/Reinforcement-Learning-for-Object-Detection/src_phase2/run.sh"]
    # This section specifies the resources you ask for.
    resources:
      # For the purposes of using the cluster, the "requests" section should be the
      # same as the "limits" section except for the line for GPU
      limits:
        alpha.kubernetes.io/nvidia-gpu: 1 # Number of GPUs
        # RAM can be specified in either MiB (1024x1024 bytes) (ex. "500Mi")
        # or GiB (ex. "4Gi")
        memory: "25Gi" #max 50
        cpu: "7" # Number of CPU cores #max is 8
      requests:
        memory: "25Gi"
        cpu: "7"
    # Here, you can specify where you want the above directories to be mounted
    # within the container. It is recommended to use this configuration as
    # it mirrors what is present on the master machine.
    volumeMounts:
    # Entry for your home folder. Make sure to replace <username> with your
    # username.
    - mountPath: /storage/home/sidnayak
      name: home
    # Entry for the other folders mentioned above.
    - mountPath: /tools
      name: tools
#    - mountPath: /datasets/data1
#      name: data1
#    - mountPath: /datasets/data2
#      name: data2
#    - mountPath: /datasets/data3
#      name: data3
    - mountPath: /scratch/scratch1
      name: scratch1
#    - mountPath: /scratch/scratch2
#      name: scratch2
    - mountPath: /usr/local/nvidia/bin
      name: nvbin
    - mountPath: /usr/local/nvidia/lib
      name: nvlib
    - mountPath: /usr/lib/
      name: usrlib
    - mountPath: /usr/bin/
      name: bin
    - mountPath: /lib
      name: lib
  restartPolicy: Never